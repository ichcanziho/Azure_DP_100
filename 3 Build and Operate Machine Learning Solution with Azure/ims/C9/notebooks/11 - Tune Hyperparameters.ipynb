{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Tune Hyperparameters\n",
        "\n",
        "There are many machine learning algorithms that require *hyperparameters* (parameter values that influence training, but can't be determined from the training data itself). For example, when training a logistic regression model, you can use a *regularization rate* hyperparameter to counteract bias in the model; or when training a convolutional neural network, you can use hyperparameters like *learning rate* and *batch size* to control how weights are adjusted and how many data items are processed in a mini-batch respectively. The choice of hyperparameter values can significantly affect the performance of a trained model, or the time taken to train it; and often you need to try multiple combinations to find the optimal solution.\n",
        "\n",
        "In this case, you'll train a classification model with two hyperparameters, but the principles apply to any kind of model you can train with Azure Machine Learning."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Connect to your workspace\n",
        "\n",
        "To get started, connect to your workspace.\n",
        "\n",
        "> **Note**: If you haven't already established an authenticated session with your Azure subscription, you'll be prompted to authenticate by clicking a link, entering an authentication code, and signing into Azure."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import azureml.core\n",
        "from azureml.core import Workspace\n",
        "\n",
        "# Load the workspace from the saved config file\n",
        "ws = Workspace.from_config()\n",
        "print('Ready to use Azure ML {} to work with {}'.format(azureml.core.VERSION, ws.name))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Ready to use Azure ML 1.51.0 to work with mlw-dp100-labs\n"
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1699044238239
        },
        "vscode": {
          "languageId": "python"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare data\n",
        "\n",
        "In this lab, you'll use a dataset containing details of diabetes patients. Run the cell below to create this dataset (if it already exists, the existing version will be used)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Dataset\n",
        "\n",
        "default_ds = ws.get_default_datastore()\n",
        "\n",
        "if 'diabetes dataset' not in ws.datasets:\n",
        "    default_ds.upload_files(files=['./data/diabetes.csv', './data/diabetes2.csv'], # Upload the diabetes csv files in /data\n",
        "                        target_path='diabetes-data/', # Put it in a folder path in the datastore\n",
        "                        overwrite=True, # Replace existing files of the same name\n",
        "                        show_progress=True)\n",
        "\n",
        "    #Create a tabular dataset from the path on the datastore (this may take a short while)\n",
        "    tab_data_set = Dataset.Tabular.from_delimited_files(path=(default_ds, 'diabetes-data/*.csv'))\n",
        "\n",
        "    # Register the tabular dataset\n",
        "    try:\n",
        "        tab_data_set = tab_data_set.register(workspace=ws, \n",
        "                                name='diabetes dataset',\n",
        "                                description='diabetes data',\n",
        "                                tags = {'format':'CSV'},\n",
        "                                create_new_version=True)\n",
        "        print('Dataset registered.')\n",
        "    except Exception as ex:\n",
        "        print(ex)\n",
        "else:\n",
        "    print('Dataset already registered.')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Dataset already registered.\n"
        }
      ],
      "execution_count": 2,
      "metadata": {
        "vscode": {
          "languageId": "python"
        },
        "gather": {
          "logged": 1699044270897
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare a training script\n",
        "\n",
        "Now let's create a folder for the training script you'll use to train the model."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "experiment_folder = 'diabetes_training-hyperdrive'\n",
        "os.makedirs(experiment_folder, exist_ok=True)\n",
        "\n",
        "print('Folder ready.')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Folder ready.\n"
        }
      ],
      "execution_count": 3,
      "metadata": {
        "vscode": {
          "languageId": "python"
        },
        "gather": {
          "logged": 1699044327951
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now create the Python script to train the model. In this example, you'll use a *Gradient Boosting* algorithm to train a classification model. The script must include:\n",
        "\n",
        "- An argument for each hyperparameter you want to optimize (in this case, the learning rate and number of estimators for the Gradient Boosting algorithm)\n",
        "- Code to log the performance metric you want to optimize for (in this case, you'll log both AUC and accuracy, so you can choose to optimize the model for either of these)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile $experiment_folder/diabetes_training.py\n",
        "# Import libraries\n",
        "import argparse, joblib, os\n",
        "from azureml.core import Run\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.metrics import roc_auc_score, roc_curve\n",
        "\n",
        "# Get the experiment run context\n",
        "run = Run.get_context()\n",
        "\n",
        "# Get script arguments\n",
        "parser = argparse.ArgumentParser()\n",
        "\n",
        "# Input dataset\n",
        "parser.add_argument(\"--input-data\", type=str, dest='input_data', help='training dataset')\n",
        "\n",
        "# Hyperparameters\n",
        "parser.add_argument('--learning_rate', type=float, dest='learning_rate', default=0.1, help='learning rate')\n",
        "parser.add_argument('--n_estimators', type=int, dest='n_estimators', default=100, help='number of estimators')\n",
        "\n",
        "# Add arguments to args collection\n",
        "args = parser.parse_args()\n",
        "\n",
        "# Log Hyperparameter values\n",
        "run.log('learning_rate',  np.float(args.learning_rate))\n",
        "run.log('n_estimators',  np.int(args.n_estimators))\n",
        "\n",
        "# load the diabetes dataset\n",
        "print(\"Loading Data...\")\n",
        "diabetes = run.input_datasets['training_data'].to_pandas_dataframe() # Get the training data from the estimator input\n",
        "\n",
        "# Separate features and labels\n",
        "X, y = diabetes[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']].values, diabetes['Diabetic'].values\n",
        "\n",
        "# Split data into training set and test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
        "\n",
        "# Train a Gradient Boosting classification model with the specified hyperparameters\n",
        "print('Training a classification model')\n",
        "model = GradientBoostingClassifier(learning_rate=args.learning_rate,\n",
        "                                   n_estimators=args.n_estimators).fit(X_train, y_train)\n",
        "\n",
        "# calculate accuracy\n",
        "y_hat = model.predict(X_test)\n",
        "acc = np.average(y_hat == y_test)\n",
        "print('Accuracy:', acc)\n",
        "run.log('Accuracy', np.float(acc))\n",
        "\n",
        "# calculate AUC\n",
        "y_scores = model.predict_proba(X_test)\n",
        "auc = roc_auc_score(y_test,y_scores[:,1])\n",
        "print('AUC: ' + str(auc))\n",
        "run.log('AUC', np.float(auc))\n",
        "\n",
        "# Save the model in the run outputs\n",
        "os.makedirs('outputs', exist_ok=True)\n",
        "joblib.dump(value=model, filename='outputs/diabetes_model.pkl')\n",
        "\n",
        "run.complete()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Writing diabetes_training-hyperdrive/diabetes_training.py\n"
        }
      ],
      "execution_count": 4,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create compute\n",
        "\n",
        "Hyperparameter tuning involves running multiple training iterations with different hyperparameter values and comparing the performance metrics of the resulting models. To do this efficiently, we'll take advantage of on-demand cloud compute and create a cluster - this will allow multiple training iterations to be run concurrently.\n",
        "\n",
        "Use the following code to specify an Azure Machine Learning compute cluster (it will be created if it doesn't already exist).\n",
        "\n",
        "> **Important**: Change *your-compute-cluster* to the name of your compute cluster in the code below before running it! Cluster names must be globally unique names between 2 to 16 characters in length. Valid characters are letters, digits, and the - character."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.compute import ComputeTarget, AmlCompute\n",
        "from azureml.core.compute_target import ComputeTargetException\n",
        "\n",
        "cluster_name = \"coursera-cluster\"\n",
        "\n",
        "try:\n",
        "    # Check for existing compute target\n",
        "    training_cluster = ComputeTarget(workspace=ws, name=cluster_name)\n",
        "    print('Found existing cluster, use it.')\n",
        "except ComputeTargetException:\n",
        "    # If it doesn't already exist, create it\n",
        "    try:\n",
        "        compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_DS11_V2', max_nodes=2)\n",
        "        training_cluster = ComputeTarget.create(ws, cluster_name, compute_config)\n",
        "        training_cluster.wait_for_completion(show_output=True)\n",
        "    except Exception as ex:\n",
        "        print(ex)\n",
        "    "
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Found existing cluster, use it.\n"
        }
      ],
      "execution_count": 5,
      "metadata": {
        "vscode": {
          "languageId": "python"
        },
        "gather": {
          "logged": 1699044386301
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Note**: Compute instances and clusters are based on standard Azure virtual machine images. For this exercise, the *Standard_DS11_v2* image is recommended to achieve the optimal balance of cost and performance. If your subscription has a quota that does not include this image, choose an alternative image; but bear in mind that a larger image may incur higher cost and a smaller image may not be sufficient to complete the tasks. Alternatively, ask your Azure administrator to extend your quota.\n",
        "\n",
        "You'll need a Python environment to be hosted on the compute, so let's define that as Conda configuration file."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile $experiment_folder/hyperdrive_env.yml\n",
        "name: batch_environment\n",
        "dependencies:\n",
        "- python=3.6.2\n",
        "- scikit-learn\n",
        "- pandas\n",
        "- numpy\n",
        "- pip\n",
        "- pip:\n",
        "  - azureml-defaults\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Writing diabetes_training-hyperdrive/hyperdrive_env.yml\n"
        }
      ],
      "execution_count": 6,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run a hyperparameter tuning experiment\n",
        "\n",
        "Azure Machine Learning includes a hyperparameter tuning capability through *hyperdrive* experiments. These experiments launch multiple child runs, each with a different hyperparameter combination. The run producing the best model (as determined by the logged target performance metric for which you want to optimize) can be identified, and its trained model selected for registration and deployment.\n",
        "\n",
        "> **Note**: In this example, we aren't specifying an early stopping policy. Such a policy is only relevant if the training script performs multiple training iterations, logging the primary metric for each iteration. This approach is typically employed when training deep neural network models over multiple *epochs*."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Experiment, ScriptRunConfig, Environment\n",
        "from azureml.train.hyperdrive import GridParameterSampling, HyperDriveConfig, PrimaryMetricGoal, choice\n",
        "from azureml.widgets import RunDetails\n",
        "\n",
        "# Create a Python environment for the experiment\n",
        "hyper_env = Environment.from_conda_specification(\"experiment_env\", experiment_folder + \"/hyperdrive_env.yml\")\n",
        "\n",
        "# Get the training dataset\n",
        "diabetes_ds = ws.datasets.get(\"diabetes dataset\")\n",
        "\n",
        "# Create a script config\n",
        "script_config = ScriptRunConfig(source_directory=experiment_folder,\n",
        "                                script='diabetes_training.py',\n",
        "                                # Add non-hyperparameter arguments -in this case, the training dataset\n",
        "                                arguments = ['--input-data', diabetes_ds.as_named_input('training_data')],\n",
        "                                environment=hyper_env,\n",
        "                                compute_target = training_cluster)\n",
        "\n",
        "# Sample a range of parameter values\n",
        "params = GridParameterSampling(\n",
        "    {\n",
        "        # Hyperdrive will try 6 combinations, adding these as script arguments\n",
        "        '--learning_rate': choice(0.01, 0.1, 1.0),\n",
        "        '--n_estimators' : choice(10, 100)\n",
        "    }\n",
        ")\n",
        "\n",
        "# Configure hyperdrive settings\n",
        "hyperdrive = HyperDriveConfig(run_config=script_config, \n",
        "                          hyperparameter_sampling=params, \n",
        "                          policy=None, # No early stopping policy\n",
        "                          primary_metric_name='AUC', # Find the highest AUC metric\n",
        "                          primary_metric_goal=PrimaryMetricGoal.MAXIMIZE, \n",
        "                          max_total_runs=6, # Restict the experiment to 6 iterations\n",
        "                          max_concurrent_runs=2) # Run up to 2 iterations in parallel\n",
        "\n",
        "# Run the experiment\n",
        "experiment = Experiment(workspace=ws, name='mslearn-diabetes-hyperdrive')\n",
        "run = experiment.submit(config=hyperdrive)\n",
        "\n",
        "# Show the status in the notebook as the experiment runs\n",
        "RunDetails(run).show()\n",
        "run.wait_for_completion()"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "_HyperDriveWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO'…",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5f79e660eb9c49839efd9edd5877bcf0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/aml.mini.widget.v1": "{\"status\": \"Completed\", \"workbench_run_details_uri\": \"https://ml.azure.com/runs/HD_d76ac347-e8af-4632-8395-3f4e47f677e5?wsid=/subscriptions/42233ac3-1d6b-40e9-920d-ae1ce13376ed/resourcegroups/rg-dp100-labs/workspaces/mlw-dp100-labs&tid=54f76ea3-fed9-41fc-a628-e91383900a39\", \"run_id\": \"HD_d76ac347-e8af-4632-8395-3f4e47f677e5\", \"run_properties\": {\"run_id\": \"HD_d76ac347-e8af-4632-8395-3f4e47f677e5\", \"created_utc\": \"2023-11-03T20:48:28.225045Z\", \"properties\": {\"primary_metric_config\": \"{\\\"name\\\":\\\"AUC\\\",\\\"goal\\\":\\\"maximize\\\"}\", \"resume_from\": \"null\", \"runTemplate\": \"HyperDrive\", \"azureml.runsource\": \"hyperdrive\", \"platform\": \"AML\", \"ContentSnapshotId\": \"1382b228-9762-4d45-90bb-538627d0fe5e\", \"user_agent\": \"python/3.8.5 (Linux-5.15.0-1040-azure-x86_64-with-glibc2.10) msrest/0.7.1 Hyperdrive.Service/1.0.0 Hyperdrive.SDK/core.1.51.0\", \"space_size\": \"6\", \"best_child_run_id\": \"HD_d76ac347-e8af-4632-8395-3f4e47f677e5_3\", \"score\": \"0.9885804604667666\", \"best_metric_status\": \"Succeeded\", \"best_data_container_id\": \"dcid.HD_d76ac347-e8af-4632-8395-3f4e47f677e5_3\"}, \"tags\": {\"_aml_system_max_concurrent_jobs\": \"2\", \"_aml_system_max_total_jobs\": \"6\", \"_aml_system_max_duration_minutes\": \"10080\", \"_aml_system_policy_config\": \"{\\\"name\\\":\\\"Default\\\",\\\"properties\\\":null}\", \"_aml_system_generator_config\": \"{\\\"name\\\":\\\"GRID\\\",\\\"parameter_space\\\":{\\\"--learning_rate\\\":[\\\"choice\\\",[[0.01,0.1,1.0]]],\\\"--n_estimators\\\":[\\\"choice\\\",[[10,100]]]},\\\"properties\\\":null}\", \"_aml_system_primary_metric_config\": \"{\\\"name\\\":\\\"AUC\\\",\\\"goal\\\":\\\"maximize\\\"}\", \"_aml_system_platform_config\": \"{\\\"ServiceAddress\\\":\\\"https://eastus2.experiments.azureml.net\\\",\\\"SubscriptionId\\\":\\\"42233ac3-1d6b-40e9-920d-ae1ce13376ed\\\",\\\"ResourceGroupName\\\":\\\"rg-dp100-labs\\\",\\\"WorkspaceName\\\":\\\"mlw-dp100-labs\\\",\\\"ExperimentName\\\":\\\"mslearn-diabetes-hyperdrive\\\",\\\"Definition\\\":{\\\"Configuration\\\":null,\\\"Attribution\\\":null,\\\"TelemetryValues\\\":{\\\"amlClientType\\\":\\\"azureml-sdk-train\\\",\\\"amlClientModule\\\":\\\"[Scrubbed]\\\",\\\"amlClientFunction\\\":\\\"[Scrubbed]\\\",\\\"tenantId\\\":\\\"54f76ea3-fed9-41fc-a628-e91383900a39\\\",\\\"amlClientRequestId\\\":\\\"a768b1ad-9db9-44c9-a7a8-9f5c474a7f35\\\",\\\"amlClientSessionId\\\":\\\"e2c82060-5993-4c5a-b725-ca7fe232224a\\\",\\\"subscriptionId\\\":\\\"42233ac3-1d6b-40e9-920d-ae1ce13376ed\\\",\\\"estimator\\\":\\\"NoneType\\\",\\\"samplingMethod\\\":\\\"GRID\\\",\\\"terminationPolicy\\\":\\\"Default\\\",\\\"primaryMetricGoal\\\":\\\"maximize\\\",\\\"maxTotalRuns\\\":6,\\\"maxConcurrentRuns\\\":2,\\\"maxDurationMinutes\\\":10080,\\\"vmSize\\\":null},\\\"Overrides\\\":{\\\"Script\\\":\\\"diabetes_training.py\\\",\\\"Command\\\":\\\"\\\",\\\"UseAbsolutePath\\\":false,\\\"Arguments\\\":[\\\"--input-data\\\",\\\"DatasetConsumptionConfig:training_data\\\"],\\\"SourceDirectoryDataStore\\\":null,\\\"Framework\\\":0,\\\"Communicator\\\":0,\\\"Target\\\":\\\"coursera-cluster\\\",\\\"DataReferences\\\":{},\\\"Data\\\":{\\\"training_data\\\":{\\\"DataLocation\\\":{\\\"Dataset\\\":{\\\"Id\\\":\\\"007692f3-f89e-452c-9865-05a49e7a4c50\\\",\\\"Name\\\":\\\"diabetes dataset\\\",\\\"Version\\\":\\\"1\\\"},\\\"DataPath\\\":null,\\\"Uri\\\":null,\\\"Type\\\":null},\\\"Mechanism\\\":\\\"Direct\\\",\\\"EnvironmentVariableName\\\":\\\"training_data\\\",\\\"PathOnCompute\\\":null,\\\"Overwrite\\\":false,\\\"Options\\\":null}},\\\"OutputData\\\":{},\\\"Datacaches\\\":[],\\\"JobName\\\":null,\\\"MaxRunDurationSeconds\\\":2592000,\\\"NodeCount\\\":1,\\\"InstanceTypes\\\":[],\\\"Priority\\\":null,\\\"CredentialPassthrough\\\":false,\\\"Identity\\\":null,\\\"Environment\\\":{\\\"Name\\\":\\\"experiment_env\\\",\\\"AutoRebuild\\\":true,\\\"Python\\\":{\\\"InterpreterPath\\\":\\\"python\\\",\\\"UserManagedDependencies\\\":false,\\\"CondaDependencies\\\":{\\\"name\\\":\\\"batch_environment\\\",\\\"dependencies\\\":[\\\"python=3.6.2\\\",\\\"scikit-learn\\\",\\\"pandas\\\",\\\"numpy\\\",\\\"pip\\\",{\\\"pip\\\":[\\\"azureml-defaults\\\"]}]},\\\"BaseCondaEnvironment\\\":null},\\\"EnvironmentVariables\\\":{\\\"EXAMPLE_ENV_VAR\\\":\\\"EXAMPLE_VALUE\\\"},\\\"Docker\\\":{\\\"BaseImage\\\":\\\"mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:20230509.v1\\\",\\\"Platform\\\":{\\\"Os\\\":\\\"Linux\\\",\\\"Architecture\\\":\\\"amd64\\\"},\\\"BaseDockerfile\\\":null,\\\"BaseImageRegistry\\\":{\\\"Address\\\":null,\\\"Username\\\":null,\\\"Password\\\":null},\\\"Enabled\\\":false,\\\"Arguments\\\":[]},\\\"Spark\\\":{\\\"Repositories\\\":[],\\\"Packages\\\":[],\\\"PrecachePackages\\\":true},\\\"InferencingStackVersion\\\":null},\\\"History\\\":{\\\"OutputCollection\\\":true,\\\"DirectoriesToWatch\\\":[\\\"logs\\\"],\\\"EnableMLflowTracking\\\":true,\\\"snapshotProject\\\":true},\\\"Spark\\\":{\\\"Configuration\\\":{\\\"spark.app.name\\\":\\\"Azure ML Experiment\\\",\\\"spark.yarn.maxAppAttempts\\\":\\\"1\\\"}},\\\"ParallelTask\\\":{\\\"MaxRetriesPerWorker\\\":0,\\\"WorkerCountPerNode\\\":1,\\\"TerminalExitCodes\\\":null,\\\"Configuration\\\":{}},\\\"BatchAi\\\":{\\\"NodeCount\\\":0},\\\"AmlCompute\\\":{\\\"Name\\\":null,\\\"VmSize\\\":null,\\\"RetainCluster\\\":false,\\\"ClusterMaxNodeCount\\\":null},\\\"AISuperComputer\\\":{\\\"InstanceType\\\":\\\"D2\\\",\\\"FrameworkImage\\\":null,\\\"ImageVersion\\\":null,\\\"Location\\\":null,\\\"AISuperComputerStorageData\\\":null,\\\"Interactive\\\":false,\\\"ScalePolicy\\\":null,\\\"VirtualClusterArmId\\\":null,\\\"TensorboardLogDirectory\\\":null,\\\"SSHPublicKey\\\":null,\\\"SSHPublicKeys\\\":null,\\\"EnableAzmlInt\\\":true,\\\"Priority\\\":\\\"Medium\\\",\\\"SLATier\\\":\\\"Standard\\\",\\\"UserAlias\\\":null},\\\"KubernetesCompute\\\":{\\\"InstanceType\\\":null},\\\"Tensorflow\\\":{\\\"WorkerCount\\\":1,\\\"ParameterServerCount\\\":1},\\\"Mpi\\\":{\\\"ProcessCountPerNode\\\":1},\\\"PyTorch\\\":{\\\"CommunicationBackend\\\":\\\"nccl\\\",\\\"ProcessCount\\\":null},\\\"Hdi\\\":{\\\"YarnDeployMode\\\":2},\\\"ContainerInstance\\\":{\\\"Region\\\":null,\\\"CpuCores\\\":2.0,\\\"MemoryGb\\\":3.5},\\\"ExposedPorts\\\":null,\\\"Docker\\\":{\\\"UseDocker\\\":false,\\\"SharedVolumes\\\":true,\\\"ShmSize\\\":\\\"2g\\\",\\\"Arguments\\\":[]},\\\"Cmk8sCompute\\\":{\\\"Configuration\\\":{}},\\\"CommandReturnCodeConfig\\\":{\\\"ReturnCode\\\":0,\\\"SuccessfulReturnCodes\\\":[]},\\\"EnvironmentVariables\\\":{},\\\"ApplicationEndpoints\\\":{},\\\"Parameters\\\":[]},\\\"SnapshotId\\\":\\\"1382b228-9762-4d45-90bb-538627d0fe5e\\\",\\\"Snapshots\\\":[],\\\"SourceCodeDataReference\\\":null,\\\"ParentRunId\\\":null,\\\"DataContainerId\\\":null,\\\"RunType\\\":null,\\\"DisplayName\\\":null,\\\"EnvironmentAssetId\\\":null,\\\"Properties\\\":{},\\\"Tags\\\":{},\\\"AggregatedArtifactPath\\\":null},\\\"ParentRunId\\\":\\\"HD_d76ac347-e8af-4632-8395-3f4e47f677e5\\\"}\", \"_aml_system_resume_child_runs\": \"null\", \"_aml_system_all_jobs_generated\": \"true\", \"_aml_system_cancellation_requested\": \"false\", \"_aml_system_samples_generated_count\": \"6\", \"_aml_system_progress_metadata_evaluation_timestamp\": \"\\\"2023-11-03T20:48:58.142928\\\"\", \"_aml_system_progress_metadata_digest\": \"\\\"2cf923bcac058c2fe0c4943f8a3584bf21c814b95e6e87ccb51471cf0bedd492\\\"\", \"_aml_system_progress_metadata_active_timestamp\": \"\\\"2023-11-03T20:48:58.142928\\\"\", \"_aml_system_optimizer_state_artifact\": \"null\", \"_aml_system_outdated_optimizer_state_artifacts\": \"\\\"[]\\\"\", \"_aml_system_HD_d76ac347-e8af-4632-8395-3f4e47f677e5_0\": \"{\\\"--learning_rate\\\": 0.01, \\\"--n_estimators\\\": 10}\", \"_aml_system_HD_d76ac347-e8af-4632-8395-3f4e47f677e5_1\": \"{\\\"--learning_rate\\\": 0.01, \\\"--n_estimators\\\": 100}\", \"_aml_system_HD_d76ac347-e8af-4632-8395-3f4e47f677e5_2\": \"{\\\"--learning_rate\\\": 0.1, \\\"--n_estimators\\\": 10}\", \"_aml_system_HD_d76ac347-e8af-4632-8395-3f4e47f677e5_3\": \"{\\\"--learning_rate\\\": 0.1, \\\"--n_estimators\\\": 100}\", \"_aml_system_HD_d76ac347-e8af-4632-8395-3f4e47f677e5_4\": \"{\\\"--learning_rate\\\": 1.0, \\\"--n_estimators\\\": 10}\", \"_aml_system_HD_d76ac347-e8af-4632-8395-3f4e47f677e5_5\": \"{\\\"--learning_rate\\\": 1.0, \\\"--n_estimators\\\": 100}\"}, \"script_name\": null, \"arguments\": null, \"end_time_utc\": \"2023-11-03T21:08:04.6329Z\", \"status\": \"Completed\", \"log_files\": {\"azureml-logs/hyperdrive.txt\": \"https://mlwdp100labs0576378376.blob.core.windows.net/azureml/ExperimentRun/dcid.HD_d76ac347-e8af-4632-8395-3f4e47f677e5/azureml-logs/hyperdrive.txt?sv=2019-07-07&sr=b&sig=nNHZeCfpzug%2FE8vwyvomDwO9BHUJqmObozvkTW7V%2B3E%3D&skoid=b22ab211-1a77-4e41-b54e-76819173f4ea&sktid=54f76ea3-fed9-41fc-a628-e91383900a39&skt=2023-11-03T20%3A38%3A33Z&ske=2023-11-05T04%3A48%3A33Z&sks=b&skv=2019-07-07&st=2023-11-03T20%3A58%3A27Z&se=2023-11-04T05%3A08%3A27Z&sp=r\"}, \"log_groups\": [[\"azureml-logs/hyperdrive.txt\"]], \"run_duration\": \"0:19:36\", \"run_number\": \"1699044508\", \"run_queued_details\": {\"status\": \"Completed\", \"details\": null}, \"hyper_parameters\": {\"--learning_rate\": [\"choice\", [[0.01, 0.1, 1.0]]], \"--n_estimators\": [\"choice\", [[10, 100]]]}}, \"child_runs\": [{\"run_id\": \"HD_d76ac347-e8af-4632-8395-3f4e47f677e5_0\", \"run_number\": 1699044510, \"metric\": 0.93548338, \"status\": \"Completed\", \"run_type\": \"azureml.scriptrun\", \"training_percent\": null, \"start_time\": \"2023-11-03T21:02:42.472158Z\", \"end_time\": \"2023-11-03T21:04:17.562098Z\", \"created_time\": \"2023-11-03T20:48:30.199779Z\", \"created_time_dt\": \"2023-11-03T20:48:30.199779Z\", \"duration\": \"0:15:47\", \"hyperdrive_id\": \"d76ac347-e8af-4632-8395-3f4e47f677e5\", \"arguments\": null, \"param_--learning_rate\": 0.01, \"param_--n_estimators\": 10, \"best_metric\": 0.93548338}, {\"run_id\": \"HD_d76ac347-e8af-4632-8395-3f4e47f677e5_2\", \"run_number\": 1699045499, \"metric\": 0.95163239, \"status\": \"Completed\", \"run_type\": \"azureml.scriptrun\", \"training_percent\": null, \"start_time\": \"2023-11-03T21:05:27.646806Z\", \"end_time\": \"2023-11-03T21:05:51.083466Z\", \"created_time\": \"2023-11-03T21:04:59.843702Z\", \"created_time_dt\": \"2023-11-03T21:04:59.843702Z\", \"duration\": \"0:00:51\", \"hyperdrive_id\": \"d76ac347-e8af-4632-8395-3f4e47f677e5\", \"arguments\": null, \"param_--learning_rate\": 0.1, \"param_--n_estimators\": 10, \"best_metric\": 0.95163239}, {\"run_id\": \"HD_d76ac347-e8af-4632-8395-3f4e47f677e5_4\", \"run_number\": 1699045589, \"metric\": 0.98290813, \"status\": \"Completed\", \"run_type\": \"azureml.scriptrun\", \"training_percent\": null, \"start_time\": \"2023-11-03T21:06:52.40152Z\", \"end_time\": \"2023-11-03T21:07:09.794408Z\", \"created_time\": \"2023-11-03T21:06:29.650618Z\", \"created_time_dt\": \"2023-11-03T21:06:29.650618Z\", \"duration\": \"0:00:40\", \"hyperdrive_id\": \"d76ac347-e8af-4632-8395-3f4e47f677e5\", \"arguments\": null, \"param_--learning_rate\": 1.0, \"param_--n_estimators\": 10, \"best_metric\": 0.98290813}], \"children_metrics\": {\"categories\": [0], \"series\": {\"learning_rate\": [{\"categories\": [1699044510, 1699045499, 1699045589], \"mode\": \"markers\", \"name\": \"learning_rate\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.01, 0.1, 1.0]}, {\"categories\": [1699044510, 1699045499, 1699045589], \"mode\": \"lines\", \"name\": \"learning_rate_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.01, 0.1, 1.0]}], \"n_estimators\": [{\"categories\": [1699044510, 1699045499, 1699045589], \"mode\": \"markers\", \"name\": \"n_estimators\", \"stepped\": false, \"type\": \"scatter\", \"data\": [10, 10, 10]}, {\"categories\": [1699044510, 1699045499, 1699045589], \"mode\": \"lines\", \"name\": \"n_estimators_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [10, 10, 10]}], \"AUC\": [{\"categories\": [1699044510, 1699045499, 1699045589], \"mode\": \"markers\", \"name\": \"AUC\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.9354833786202631, 0.9516323866285732, 0.982908128731084]}, {\"categories\": [1699044510, 1699045499, 1699045589], \"mode\": \"lines\", \"name\": \"AUC_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.9354833786202631, 0.9516323866285732, 0.982908128731084]}], \"Accuracy\": [{\"categories\": [1699044510, 1699045499, 1699045589], \"mode\": \"markers\", \"name\": \"Accuracy\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.6635555555555556, 0.8944444444444445, 0.9368888888888889]}, {\"categories\": [1699044510, 1699045499, 1699045589], \"mode\": \"lines\", \"name\": \"Accuracy_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.6635555555555556, 0.8944444444444445, 0.9368888888888889]}]}, \"metricName\": null, \"primaryMetricName\": \"AUC\", \"showLegend\": false}, \"run_metrics\": [{\"name\": \"best_child_by_primary_metric\", \"run_id\": \"HD_d76ac347-e8af-4632-8395-3f4e47f677e5\", \"categories\": [0], \"series\": [{\"data\": [{\"time_elapse\": [990, 1081, 139], \"metric_value\": [0.9559393638830617, 0.9885804604667666, 0.9885804604667666], \"metric_name\": [\"AUC\", \"AUC\", \"AUC\"], \"run_id\": [\"HD_d76ac347-e8af-4632-8395-3f4e47f677e5_1\", \"HD_d76ac347-e8af-4632-8395-3f4e47f677e5_3\", \"HD_d76ac347-e8af-4632-8395-3f4e47f677e5_3\"], \"final\": [false, false, true]}]}]}], \"run_logs\": \"[2023-11-03T20:48:29.041919][GENERATOR][INFO]Trying to sample '2' jobs from the hyperparameter space\\n[2023-11-03T20:48:29.5255588Z][SCHEDULER][INFO]Scheduling job, id='HD_d76ac347-e8af-4632-8395-3f4e47f677e5_0' \\n[2023-11-03T20:48:29.7538144Z][SCHEDULER][INFO]Scheduling job, id='HD_d76ac347-e8af-4632-8395-3f4e47f677e5_1' \\n[2023-11-03T20:48:29.583204][GENERATOR][INFO]Successfully sampled '2' jobs, they will soon be submitted to the execution target.\\n[2023-11-03T20:48:30.2242612Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_d76ac347-e8af-4632-8395-3f4e47f677e5_1' \\n[2023-11-03T20:48:30.2891607Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_d76ac347-e8af-4632-8395-3f4e47f677e5_0' \\n[2023-11-03T21:04:59.147284][GENERATOR][INFO]Trying to sample '2' jobs from the hyperparameter space\\n[2023-11-03T21:04:59.4858048Z][SCHEDULER][INFO]Scheduling job, id='HD_d76ac347-e8af-4632-8395-3f4e47f677e5_2' \\n[2023-11-03T21:04:59.6131240Z][SCHEDULER][INFO]Scheduling job, id='HD_d76ac347-e8af-4632-8395-3f4e47f677e5_3' \\n[2023-11-03T21:04:59.562257][GENERATOR][INFO]Successfully sampled '2' jobs, they will soon be submitted to the execution target.\\n[2023-11-03T21:04:59.8820734Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_d76ac347-e8af-4632-8395-3f4e47f677e5_3' \\n[2023-11-03T21:04:59.9474741Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_d76ac347-e8af-4632-8395-3f4e47f677e5_2' \\n[2023-11-03T21:06:29.169883][GENERATOR][INFO]Trying to sample '2' jobs from the hyperparameter space\\n[2023-11-03T21:06:29.4579501Z][SCHEDULER][INFO]Scheduling job, id='HD_d76ac347-e8af-4632-8395-3f4e47f677e5_4' \\n[2023-11-03T21:06:29.5978352Z][SCHEDULER][INFO]Scheduling job, id='HD_d76ac347-e8af-4632-8395-3f4e47f677e5_5' \\n[2023-11-03T21:06:29.558524][GENERATOR][INFO]Successfully sampled '2' jobs, they will soon be submitted to the execution target.\\n[2023-11-03T21:06:29.7624408Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_d76ac347-e8af-4632-8395-3f4e47f677e5_4' \\n[2023-11-03T21:06:29.8328789Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_d76ac347-e8af-4632-8395-3f4e47f677e5_5' \\n[2023-11-03T21:06:59.138945][GENERATOR][INFO]Max number of jobs '6' reached for experiment.\\n[2023-11-03T21:06:59.289270][GENERATOR][INFO]All jobs generated.\\n[2023-11-03T21:08:04.5074851Z][CONTROLLER][INFO]Changing Run Status from Running to Completed \\n\\nRun is completed.\", \"graph\": {}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.51.0\"}, \"loading\": false}"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "execution_count": 7,
          "data": {
            "text/plain": "{'runId': 'HD_d76ac347-e8af-4632-8395-3f4e47f677e5',\n 'target': 'coursera-cluster',\n 'status': 'Completed',\n 'startTimeUtc': '2023-11-03T20:48:28.339629Z',\n 'endTimeUtc': '2023-11-03T21:08:04.6329Z',\n 'services': {},\n 'properties': {'primary_metric_config': '{\"name\":\"AUC\",\"goal\":\"maximize\"}',\n  'resume_from': 'null',\n  'runTemplate': 'HyperDrive',\n  'azureml.runsource': 'hyperdrive',\n  'platform': 'AML',\n  'ContentSnapshotId': '1382b228-9762-4d45-90bb-538627d0fe5e',\n  'user_agent': 'python/3.8.5 (Linux-5.15.0-1040-azure-x86_64-with-glibc2.10) msrest/0.7.1 Hyperdrive.Service/1.0.0 Hyperdrive.SDK/core.1.51.0',\n  'space_size': '6',\n  'best_child_run_id': 'HD_d76ac347-e8af-4632-8395-3f4e47f677e5_3',\n  'score': '0.9885804604667666',\n  'best_metric_status': 'Succeeded',\n  'best_data_container_id': 'dcid.HD_d76ac347-e8af-4632-8395-3f4e47f677e5_3'},\n 'inputDatasets': [],\n 'outputDatasets': [],\n 'runDefinition': {'configuration': None,\n  'attribution': None,\n  'telemetryValues': {'amlClientType': 'azureml-sdk-train',\n   'amlClientModule': '[Scrubbed]',\n   'amlClientFunction': '[Scrubbed]',\n   'tenantId': '54f76ea3-fed9-41fc-a628-e91383900a39',\n   'amlClientRequestId': 'a768b1ad-9db9-44c9-a7a8-9f5c474a7f35',\n   'amlClientSessionId': 'e2c82060-5993-4c5a-b725-ca7fe232224a',\n   'subscriptionId': '42233ac3-1d6b-40e9-920d-ae1ce13376ed',\n   'estimator': 'NoneType',\n   'samplingMethod': 'GRID',\n   'terminationPolicy': 'Default',\n   'primaryMetricGoal': 'maximize',\n   'maxTotalRuns': 6,\n   'maxConcurrentRuns': 2,\n   'maxDurationMinutes': 10080,\n   'vmSize': None},\n  'snapshotId': '1382b228-9762-4d45-90bb-538627d0fe5e',\n  'snapshots': [],\n  'sourceCodeDataReference': None,\n  'parentRunId': None,\n  'dataContainerId': None,\n  'runType': None,\n  'displayName': None,\n  'environmentAssetId': None,\n  'properties': {},\n  'tags': {},\n  'aggregatedArtifactPath': None},\n 'logFiles': {'azureml-logs/hyperdrive.txt': 'https://mlwdp100labs0576378376.blob.core.windows.net/azureml/ExperimentRun/dcid.HD_d76ac347-e8af-4632-8395-3f4e47f677e5/azureml-logs/hyperdrive.txt?sv=2019-07-07&sr=b&sig=nNHZeCfpzug%2FE8vwyvomDwO9BHUJqmObozvkTW7V%2B3E%3D&skoid=b22ab211-1a77-4e41-b54e-76819173f4ea&sktid=54f76ea3-fed9-41fc-a628-e91383900a39&skt=2023-11-03T20%3A38%3A33Z&ske=2023-11-05T04%3A48%3A33Z&sks=b&skv=2019-07-07&st=2023-11-03T20%3A58%3A27Z&se=2023-11-04T05%3A08%3A27Z&sp=r'},\n 'submittedBy': 'Gabriel Ichcanziho Pérez Landa'}"
          },
          "metadata": {}
        }
      ],
      "execution_count": 7,
      "metadata": {
        "vscode": {
          "languageId": "python"
        },
        "gather": {
          "logged": 1699045711596
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can view the experiment run status in the widget above. You can also view the main Hyperdrive experiment run and its child runs in [Azure Machine Learning studio](https://ml.azure.com).\n",
        "\n",
        "> **Note**: If a message indicating that a non-numeric can't be visualized is displayed, you can ignore it.\n",
        "\n",
        "## Determine the best performing run\n",
        "\n",
        "When all of the runs have finished, you can find the best one based on the performance metric you specified (in this case, the one with the best AUC)."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Print all child runs, sorted by the primary metric\n",
        "for child_run in run.get_children_sorted_by_primary_metric():\n",
        "    print(child_run)\n",
        "\n",
        "# Get the best run, and its metrics and arguments\n",
        "best_run = run.get_best_run_by_primary_metric()\n",
        "best_run_metrics = best_run.get_metrics()\n",
        "script_arguments = best_run.get_details() ['runDefinition']['arguments']\n",
        "print('Best Run Id: ', best_run.id)\n",
        "print(' -AUC:', best_run_metrics['AUC'])\n",
        "print(' -Accuracy:', best_run_metrics['Accuracy'])\n",
        "print(' -Arguments:',script_arguments)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "{'run_id': 'HD_d76ac347-e8af-4632-8395-3f4e47f677e5_3', 'hyperparameters': '{\"--learning_rate\": 0.1, \"--n_estimators\": 100}', 'best_primary_metric': 0.9885804604667666, 'status': 'Completed'}\n{'run_id': 'HD_d76ac347-e8af-4632-8395-3f4e47f677e5_5', 'hyperparameters': '{\"--learning_rate\": 1.0, \"--n_estimators\": 100}', 'best_primary_metric': 0.9854149837064381, 'status': 'Completed'}\n{'run_id': 'HD_d76ac347-e8af-4632-8395-3f4e47f677e5_4', 'hyperparameters': '{\"--learning_rate\": 1.0, \"--n_estimators\": 10}', 'best_primary_metric': 0.982908128731084, 'status': 'Completed'}\n{'run_id': 'HD_d76ac347-e8af-4632-8395-3f4e47f677e5_1', 'hyperparameters': '{\"--learning_rate\": 0.01, \"--n_estimators\": 100}', 'best_primary_metric': 0.9559393638830617, 'status': 'Completed'}\n{'run_id': 'HD_d76ac347-e8af-4632-8395-3f4e47f677e5_2', 'hyperparameters': '{\"--learning_rate\": 0.1, \"--n_estimators\": 10}', 'best_primary_metric': 0.9516323866285732, 'status': 'Completed'}\n{'run_id': 'HD_d76ac347-e8af-4632-8395-3f4e47f677e5_0', 'hyperparameters': '{\"--learning_rate\": 0.01, \"--n_estimators\": 10}', 'best_primary_metric': 0.9354833786202631, 'status': 'Completed'}\nBest Run Id:  HD_d76ac347-e8af-4632-8395-3f4e47f677e5_3\n -AUC: 0.9885804604667666\n -Accuracy: 0.9457777777777778\n -Arguments: ['--input-data', 'DatasetConsumptionConfig:training_data', '--learning_rate', '0.1', '--n_estimators', '100']\n"
        }
      ],
      "execution_count": 8,
      "metadata": {
        "vscode": {
          "languageId": "python"
        },
        "gather": {
          "logged": 1699045747827
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that you've found the best run, you can register the model it trained."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Model\n",
        "\n",
        "# Register model\n",
        "best_run.register_model(model_path='outputs/diabetes_model.pkl', model_name='diabetes_model',\n",
        "                        tags={'Training context':'Hyperdrive'},\n",
        "                        properties={'AUC': best_run_metrics['AUC'], 'Accuracy': best_run_metrics['Accuracy']})\n",
        "\n",
        "# List registered models\n",
        "for model in Model.list(ws):\n",
        "    print(model.name, 'version:', model.version)\n",
        "    for tag_name in model.tags:\n",
        "        tag = model.tags[tag_name]\n",
        "        print ('\\t',tag_name, ':', tag)\n",
        "    for prop_name in model.properties:\n",
        "        prop = model.properties[prop_name]\n",
        "        print ('\\t',prop_name, ':', prop)\n",
        "    print('\\n')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "diabetes_model version: 11\n\t Training context : Hyperdrive\n\t AUC : 0.9885804604667666\n\t Accuracy : 0.9457777777777778\n\n\ndiabetes_model version: 10\n\t Training context : Inline Training\n\t AUC : 0.8803323548435243\n\t Accuracy : 0.8926666666666667\n\n\ndiabetes_model version: 9\n\t Training context : Pipeline\n\t AUC : 0.8837616052365906\n\t Accuracy : 0.8988888888888888\n\n\ndiabetes_model version: 8\n\t Training context : Pipeline\n\t AUC : 0.8870734055269813\n\t Accuracy : 0.9015555555555556\n\n\ndiabetes_model version: 7\n\t Training context : Pipeline\n\t AUC : 0.8847337774431273\n\t Accuracy : 0.8986666666666666\n\n\ndiabetes_model version: 6\n\t Training context : Pipeline\n\t AUC : 0.8863989679711839\n\t Accuracy : 0.9004444444444445\n\n\ndiabetes_model version: 5\n\t Training context : Compute cluster\n\t AUC : 0.8850918995824636\n\t Accuracy : 0.9002222222222223\n\n\ndiabetes_model version: 4\n\t Training context : File dataset\n\t AUC : 0.8468514889078735\n\t Accuracy : 0.7788888888888889\n\n\ndiabetes_model version: 3\n\t Training context : Tabular dataset\n\t AUC : 0.8568650620553335\n\t Accuracy : 0.7893333333333333\n\n\ndiabetes_model version: 2\n\t Training context : Parameterized script\n\t AUC : 0.8484377332205582\n\t Accuracy : 0.774\n\t Regularization Rate : 0.1\n\n\ndiabetes_model version: 1\n\t Training context : Script\n\t AUC : 0.8483441962286681\n\t Accuracy : 0.774\n\n\n"
        }
      ],
      "execution_count": 9,
      "metadata": {
        "vscode": {
          "languageId": "python"
        },
        "gather": {
          "logged": 1699045791650
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **More Information**: For more information about Hyperdrive, see the [Azure ML documentation](https://docs.microsoft.com/azure/machine-learning/how-to-tune-hyperparameters)."
      ],
      "metadata": {}
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}