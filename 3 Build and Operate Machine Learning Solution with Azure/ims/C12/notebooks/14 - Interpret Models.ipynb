{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Interpret Models\n",
        "\n",
        "You can use Azure Machine Learning to interpret a model by using an *explainer* that quantifies the amount of influence each feature contribues to the predicted label. There are many common explainers, each suitable for different kinds of modeling algorithm; but the basic approach to using them is the same.\n",
        "\n",
        "## Install SDK packages\n",
        "\n",
        "In addition to the latest version of the **azureml-sdk** and **azureml-widgets** packages, you'll need the **azureml-explain-model** package to run the code in this notebook. You'll also use the Azure ML Interpretability library (**azureml-interpret**). You can use this to interpret many typical kinds of model, even if they haven't been trained in an Azure ML experiment or registered in an Azure ML workspace.\n",
        "\n",
        "Run the cell below to verify that these packages are installed. "
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "pip show azureml-explain-model azureml-interpret"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Name: azureml-explain-model\r\nVersion: 1.51.0\r\nSummary: The package has been deprecated and might not receive future updates.\r\nHome-page: https://docs.microsoft.com/python/api/overview/azure/ml/?view=azure-ml-py\r\nAuthor: Microsoft Corp\r\nAuthor-email: None\r\nLicense: https://aka.ms/azureml-sdk-license\r\nLocation: /anaconda/envs/azureml_py38/lib/python3.8/site-packages\r\nRequires: azureml-interpret\r\nRequired-by: \r\n---\r\nName: azureml-interpret\r\nVersion: 1.51.0\r\nSummary: Machine Learning interpret package is used to interpret ML models\r\nHome-page: https://docs.microsoft.com/python/api/overview/azure/ml/?view=azure-ml-py\r\nAuthor: Microsoft Corp\r\nAuthor-email: None\r\nLicense: https://aka.ms/azureml-sdk-license\r\nLocation: /anaconda/envs/azureml_py38/lib/python3.8/site-packages\r\nRequires: numba, numpy, shap, azureml-core, interpret-community\r\nRequired-by: azureml-train-automl-runtime, azureml-responsibleai, azureml-explain-model\r\nNote: you may need to restart the kernel to use updated packages.\n"
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1699814069982
        },
        "vscode": {
          "languageId": "python"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Explain a model\n",
        "\n",
        "Let's start with a model that is trained outside of Azure Machine Learning - Run the cell below to train a decision tree classification model."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import roc_curve\n",
        "\n",
        "# load the diabetes dataset\n",
        "print(\"Loading Data...\")\n",
        "data = pd.read_csv('data/diabetes.csv')\n",
        "\n",
        "# Separate features and labels\n",
        "features = ['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']\n",
        "labels = ['not-diabetic', 'diabetic']\n",
        "X, y = data[features].values, data['Diabetic'].values\n",
        "\n",
        "# Split data into training set and test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
        "\n",
        "# Train a decision tree model\n",
        "print('Training a decision tree model')\n",
        "model = DecisionTreeClassifier().fit(X_train, y_train)\n",
        "\n",
        "# calculate accuracy\n",
        "y_hat = model.predict(X_test)\n",
        "acc = np.average(y_hat == y_test)\n",
        "print('Accuracy:', acc)\n",
        "\n",
        "# calculate AUC\n",
        "y_scores = model.predict_proba(X_test)\n",
        "auc = roc_auc_score(y_test,y_scores[:,1])\n",
        "print('AUC: ' + str(auc))\n",
        "\n",
        "print('Model trained.')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Loading Data...\nTraining a decision tree model\nAccuracy: 0.8896666666666667\nAUC: 0.8761207025225135\nModel trained.\n"
        }
      ],
      "execution_count": 2,
      "metadata": {
        "vscode": {
          "languageId": "python"
        },
        "gather": {
          "logged": 1699814127285
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The training process generated some model evaluation metrics based on a hold-back validation dataset, so you have an idea of how accurately it predicts; but how do the features in the data influence the prediction?"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get an explainer for the model\n",
        "\n",
        "Let's get a suitable explainer for the model from the Azure ML interpretability library you installed earlier. There are many kinds of explainer. In this example you'll use a *Tabular Explainer*, which is a \"black box\" explainer that can be used to explain many kinds of model by invoking an appropriate [SHAP](https://github.com/slundberg/shap) model explainer."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from interpret.ext.blackbox import TabularExplainer\n",
        "\n",
        "# \"features\" and \"classes\" fields are optional\n",
        "tab_explainer = TabularExplainer(model,\n",
        "                             X_train, \n",
        "                             features=features, \n",
        "                             classes=labels)\n",
        "print(tab_explainer, \"ready!\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "TabularExplainer ready!\n"
        }
      ],
      "execution_count": 3,
      "metadata": {
        "vscode": {
          "languageId": "python"
        },
        "gather": {
          "logged": 1699814189913
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get *global* feature importance\n",
        "\n",
        "The first thing to do is try to explain the model by evaluating the overall *feature importance* - in other words, quantifying the extent to which each feature influences the prediction based on the whole training dataset."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# you can use the training data or the test data here\n",
        "global_tab_explanation = tab_explainer.explain_global(X_train)\n",
        "\n",
        "# Get the top features by importance\n",
        "global_tab_feature_importance = global_tab_explanation.get_feature_importance_dict()\n",
        "for feature, importance in global_tab_feature_importance.items():\n",
        "    print(feature,\":\", importance)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Pregnancies : 0.2176583694669954\nAge : 0.10674270987813131\nBMI : 0.09415787508610748\nSerumInsulin : 0.06714047551680649\nPlasmaGlucose : 0.049601586759051186\nTricepsThickness : 0.022457797001820254\nDiastolicBloodPressure : 0.016143539058397195\nDiabetesPedigree : 0.013417351563530713\n"
        }
      ],
      "execution_count": 4,
      "metadata": {
        "vscode": {
          "languageId": "python"
        },
        "gather": {
          "logged": 1699814215949
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The feature importance is ranked, with the most important feature listed first.\n",
        "\n",
        "### Get *local* feature importance\n",
        "\n",
        "So you have an overall view, but what about explaining individual observations? Let's generate *local* explanations for individual predictions, quantifying the extent to which each feature influenced the decision to predict each of the possible label values. In this case, it's a binary model, so there are two possible labels (non-diabetic and diabetic); and you can quantify the influence of each feature for each of these label values for individual observations in a dataset. You'll just evaluate the first two cases in the test dataset."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the observations we want to explain (the first two)\n",
        "X_explain = X_test[0:2]\n",
        "print(\"X_test:\", X_explain)\n",
        "# Get predictions\n",
        "predictions = model.predict(X_explain)\n",
        "\n",
        "# Get local explanations\n",
        "local_tab_explanation = tab_explainer.explain_local(X_explain)\n",
        "\n",
        "# Get feature names and importance for each possible label\n",
        "local_tab_features = local_tab_explanation.get_ranked_local_names()\n",
        "local_tab_importance = local_tab_explanation.get_ranked_local_values()\n",
        "\n",
        "for l in range(len(local_tab_features)):\n",
        "    print('Support for', labels[l])\n",
        "    label = local_tab_features[l]\n",
        "    for o in range(len(label)):\n",
        "        print(\"\\tObservation\", o + 1)\n",
        "        feature_list = label[o]\n",
        "        total_support = 0\n",
        "        for f in range(len(feature_list)):\n",
        "            print(\"\\t\\t\", feature_list[f], ':', local_tab_importance[l][o][f])\n",
        "            total_support += local_tab_importance[l][o][f]\n",
        "        print(\"\\t\\t ----------\\n\\t\\t Total:\", total_support, \"Prediction:\", labels[predictions[o]])"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "X_test: [[3.00000000e+00 1.22000000e+02 6.30000000e+01 1.10000000e+01\n  2.30000000e+01 4.02146352e+01 2.66846118e-01 3.10000000e+01]\n [7.00000000e+00 1.28000000e+02 4.20000000e+01 4.40000000e+01\n  1.71000000e+02 2.01910198e+01 1.37972838e-01 2.20000000e+01]]\nSupport for not-diabetic\n\tObservation 1\n\t\t SerumInsulin : 0.3523590850467859\n\t\t Age : 0.2475938305442843\n\t\t TricepsThickness : 0.025197405120594686\n\t\t BMI : 0.018537595862091\n\t\t DiabetesPedigree : 0.0017817340184702636\n\t\t DiastolicBloodPressure : -0.017993310575992957\n\t\t PlasmaGlucose : -0.0335209469752423\n\t\t Pregnancies : -0.26052682161241997\n\t\t ----------\n\t\t Total: 0.3334285714285709 Prediction: not-diabetic\n\tObservation 2\n\t\t BMI : 0.3616310088610713\n\t\t Age : 0.05160676172407855\n\t\t DiabetesPedigree : 0.012333136327517496\n\t\t PlasmaGlucose : 0.0042715993014197625\n\t\t DiastolicBloodPressure : -0.005280571310443728\n\t\t Pregnancies : -0.014648224111857167\n\t\t TricepsThickness : -0.025595712705695953\n\t\t SerumInsulin : -0.050889426657519846\n\t\t ----------\n\t\t Total: 0.3334285714285704 Prediction: not-diabetic\nSupport for diabetic\n\tObservation 1\n\t\t Pregnancies : 0.26052682161241986\n\t\t PlasmaGlucose : 0.03352094697524231\n\t\t DiastolicBloodPressure : 0.017993310575992977\n\t\t DiabetesPedigree : -0.001781734018470261\n\t\t BMI : -0.01853759586209102\n\t\t TricepsThickness : -0.025197405120594665\n\t\t Age : -0.24759383054428463\n\t\t SerumInsulin : -0.35235908504678615\n\t\t ----------\n\t\t Total: -0.3334285714285716 Prediction: not-diabetic\n\tObservation 2\n\t\t SerumInsulin : 0.05088942665751994\n\t\t TricepsThickness : 0.025595712705695974\n\t\t Pregnancies : 0.014648224111856305\n\t\t DiastolicBloodPressure : 0.005280571310443795\n\t\t PlasmaGlucose : -0.004271599301419764\n\t\t DiabetesPedigree : -0.01233313632751745\n\t\t Age : -0.051606761724078416\n\t\t BMI : -0.3616310088610711\n\t\t ----------\n\t\t Total: -0.3334285714285707 Prediction: not-diabetic\n"
        }
      ],
      "execution_count": 5,
      "metadata": {
        "scrolled": false,
        "vscode": {
          "languageId": "python"
        },
        "gather": {
          "logged": 1699814278582
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Adding explainability to a model training experiment\n",
        "\n",
        "As you've seen, you can generate explanations for models trained outside of Azure Machine Learning; but when you use experiments to train and register models in your Azure Machine Learning workspace, you can generate model explanations and log them.\n",
        "\n",
        "Run the code in the following cell to connect to your workspace.\n",
        "\n",
        "> **Note**: If you haven't already established an authenticated session with your Azure subscription, you'll be prompted to authenticate by clicking a link, entering an authentication code, and signing into Azure."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import azureml.core\n",
        "from azureml.core import Workspace\n",
        "\n",
        "# Load the workspace from the saved config file\n",
        "ws = Workspace.from_config()\n",
        "print('Ready to use Azure ML {} to work with {}'.format(azureml.core.VERSION, ws.name))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Ready to use Azure ML 1.51.0 to work with mlw-dp100-labs\n"
        }
      ],
      "execution_count": 6,
      "metadata": {
        "vscode": {
          "languageId": "python"
        },
        "gather": {
          "logged": 1699814366070
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train and explain a model using an experiment\n",
        "\n",
        "OK, let's create an experiment and put the files it needs in a local folder - in this case we'll just use the same CSV file of diabetes data to train the model."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import os, shutil\n",
        "from azureml.core import Experiment\n",
        "\n",
        "# Create a folder for the experiment files\n",
        "experiment_folder = 'diabetes_train_and_explain'\n",
        "os.makedirs(experiment_folder, exist_ok=True)\n",
        "\n",
        "# Copy the data file into the experiment folder\n",
        "shutil.copy('data/diabetes.csv', os.path.join(experiment_folder, \"diabetes.csv\"))"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 7,
          "data": {
            "text/plain": "'diabetes_train_and_explain/diabetes.csv'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 7,
      "metadata": {
        "vscode": {
          "languageId": "python"
        },
        "gather": {
          "logged": 1699814374923
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we'll create a training script that looks similar to any other Azure ML training script except that is includes the following features:\n",
        "\n",
        "- The same libraries to generate model explanations we used before are imported and used to generate a global explanation\n",
        "- The **ExplanationClient** library is used to upload the explanation to the experiment output"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile $experiment_folder/diabetes_training.py\n",
        "# Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import roc_curve\n",
        "\n",
        "# Import Azure ML run library\n",
        "from azureml.core.run import Run\n",
        "\n",
        "# Import libraries for model explanation\n",
        "from azureml.interpret import ExplanationClient\n",
        "from interpret.ext.blackbox import TabularExplainer\n",
        "\n",
        "# Get the experiment run context\n",
        "run = Run.get_context()\n",
        "\n",
        "# load the diabetes dataset\n",
        "print(\"Loading Data...\")\n",
        "data = pd.read_csv('diabetes.csv')\n",
        "\n",
        "features = ['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']\n",
        "labels = ['not-diabetic', 'diabetic']\n",
        "\n",
        "# Separate features and labels\n",
        "X, y = data[features].values, data['Diabetic'].values\n",
        "\n",
        "# Split data into training set and test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
        "\n",
        "# Train a decision tree model\n",
        "print('Training a decision tree model')\n",
        "model = DecisionTreeClassifier().fit(X_train, y_train)\n",
        "\n",
        "# calculate accuracy\n",
        "y_hat = model.predict(X_test)\n",
        "acc = np.average(y_hat == y_test)\n",
        "run.log('Accuracy', np.float(acc))\n",
        "\n",
        "# calculate AUC\n",
        "y_scores = model.predict_proba(X_test)\n",
        "auc = roc_auc_score(y_test,y_scores[:,1])\n",
        "run.log('AUC', np.float(auc))\n",
        "\n",
        "os.makedirs('outputs', exist_ok=True)\n",
        "# note file saved in the outputs folder is automatically uploaded into experiment record\n",
        "joblib.dump(value=model, filename='outputs/diabetes.pkl')\n",
        "\n",
        "# Get explanation\n",
        "explainer = TabularExplainer(model, X_train, features=features, classes=labels)\n",
        "explanation = explainer.explain_global(X_test)\n",
        "\n",
        "# Get an Explanation Client and upload the explanation\n",
        "explain_client = ExplanationClient.from_run(run)\n",
        "explain_client.upload_model_explanation(explanation, comment='Tabular Explanation')\n",
        "\n",
        "# Complete the run\n",
        "run.complete()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Writing diabetes_train_and_explain/diabetes_training.py\n"
        }
      ],
      "execution_count": 8,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The experiment needs a Python environment in which to run the script, so we'll define a Conda specification for it. Note that the **azureml-interpret** library is included in the training environment so the script can create a **TabularExplainer** and use the **ExplainerClient** class."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile $experiment_folder/interpret_env.yml\n",
        "name: batch_environment\n",
        "dependencies:\n",
        "- python=3.6.2\n",
        "- scikit-learn\n",
        "- pandas\n",
        "- pip\n",
        "- pip:\n",
        "  - azureml-defaults\n",
        "  - azureml-interpret"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Writing diabetes_train_and_explain/interpret_env.yml\n"
        }
      ],
      "execution_count": 9,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now you can run the experiment."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Experiment, ScriptRunConfig, Environment\n",
        "from azureml.core.runconfig import DockerConfiguration\n",
        "from azureml.widgets import RunDetails\n",
        "\n",
        "\n",
        "# Create a Python environment for the experiment\n",
        "explain_env = Environment.from_conda_specification(\"explain_env\", experiment_folder + \"/interpret_env.yml\")\n",
        "\n",
        "# Create a script config\n",
        "script_config = ScriptRunConfig(source_directory=experiment_folder,\n",
        "                      script='diabetes_training.py',\n",
        "                      environment=explain_env,\n",
        "                      docker_runtime_config=DockerConfiguration(use_docker=True)) \n",
        "\n",
        "# submit the experiment\n",
        "experiment_name = 'mslearn-diabetes-explain'\n",
        "experiment = Experiment(workspace=ws, name=experiment_name)\n",
        "run = experiment.submit(config=script_config)\n",
        "RunDetails(run).show()\n",
        "run.wait_for_completion()"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "_UserRunWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', '…",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ed05e740b07a49ebbad60dde3f1c02d7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/aml.mini.widget.v1": "{\"status\": \"Completed\", \"workbench_run_details_uri\": \"https://ml.azure.com/runs/mslearn-diabetes-explain_1699814505_ab7c4ab0?wsid=/subscriptions/42233ac3-1d6b-40e9-920d-ae1ce13376ed/resourcegroups/rg-dp100-labs/workspaces/mlw-dp100-labs&tid=54f76ea3-fed9-41fc-a628-e91383900a39\", \"run_id\": \"mslearn-diabetes-explain_1699814505_ab7c4ab0\", \"run_properties\": {\"run_id\": \"mslearn-diabetes-explain_1699814505_ab7c4ab0\", \"created_utc\": \"2023-11-12T18:41:46.514077Z\", \"properties\": {\"_azureml.ComputeTargetType\": \"local\", \"ContentSnapshotId\": \"29724a88-5472-4d1d-ab04-193946d24841\"}, \"tags\": {\"model_explanation\": \"True\"}, \"script_name\": null, \"arguments\": null, \"end_time_utc\": \"2023-11-12T18:45:37.556775Z\", \"status\": \"Completed\", \"log_files\": {\"azureml-logs/60_control_log.txt\": \"https://mlwdp100labs0576378376.blob.core.windows.net/azureml/ExperimentRun/dcid.mslearn-diabetes-explain_1699814505_ab7c4ab0/azureml-logs/60_control_log.txt?sv=2019-07-07&sr=b&sig=qU4qNP9X9mpMejrj3%2FfcVjr3mlbEryZEXjrECW%2FFdp8%3D&skoid=b22ab211-1a77-4e41-b54e-76819173f4ea&sktid=54f76ea3-fed9-41fc-a628-e91383900a39&skt=2023-11-12T18%3A12%3A30Z&ske=2023-11-14T02%3A22%3A30Z&sks=b&skv=2019-07-07&st=2023-11-12T18%3A35%3A46Z&se=2023-11-13T02%3A45%3A46Z&sp=r\", \"azureml-logs/70_driver_log.txt\": \"https://mlwdp100labs0576378376.blob.core.windows.net/azureml/ExperimentRun/dcid.mslearn-diabetes-explain_1699814505_ab7c4ab0/azureml-logs/70_driver_log.txt?sv=2019-07-07&sr=b&sig=5kZeO68kafl2g8uBfJtAs%2F3O1nRZICbYEw%2BVioawzMY%3D&skoid=b22ab211-1a77-4e41-b54e-76819173f4ea&sktid=54f76ea3-fed9-41fc-a628-e91383900a39&skt=2023-11-12T18%3A12%3A30Z&ske=2023-11-14T02%3A22%3A30Z&sks=b&skv=2019-07-07&st=2023-11-12T18%3A35%3A46Z&se=2023-11-13T02%3A45%3A46Z&sp=r\", \"logs/azureml/7_azureml.log\": \"https://mlwdp100labs0576378376.blob.core.windows.net/azureml/ExperimentRun/dcid.mslearn-diabetes-explain_1699814505_ab7c4ab0/logs/azureml/7_azureml.log?sv=2019-07-07&sr=b&sig=ZaJwYZOPwubZf5kO4sZ6s%2BWQAu4k%2B5effVoxZ%2BVqEcA%3D&skoid=b22ab211-1a77-4e41-b54e-76819173f4ea&sktid=54f76ea3-fed9-41fc-a628-e91383900a39&skt=2023-11-12T18%3A12%3A30Z&ske=2023-11-14T02%3A22%3A30Z&sks=b&skv=2019-07-07&st=2023-11-12T18%3A35%3A37Z&se=2023-11-13T02%3A45%3A37Z&sp=r\"}, \"log_groups\": [[\"logs/azureml/7_azureml.log\"], [\"azureml-logs/60_control_log.txt\"], [\"azureml-logs/70_driver_log.txt\"]], \"run_duration\": \"0:03:51\", \"run_number\": \"1699814506\", \"run_queued_details\": {\"status\": \"Completed\", \"details\": null}}, \"child_runs\": [], \"children_metrics\": {}, \"run_metrics\": [{\"name\": \"AUC\", \"run_id\": \"mslearn-diabetes-explain_1699814505_ab7c4ab0\", \"categories\": [0], \"series\": [{\"data\": [0.8813224538534254]}]}, {\"name\": \"Accuracy\", \"run_id\": \"mslearn-diabetes-explain_1699814505_ab7c4ab0\", \"categories\": [0], \"series\": [{\"data\": [0.8933333333333333]}]}, {\"name\": \"model_explanation\", \"run_id\": \"mslearn-diabetes-explain_1699814505_ab7c4ab0\", \"categories\": [0], \"series\": [{\"data\": [{\"class_labels\": [\"not-diabetic\", \"diabetic\"], \"overall_summary\": [0.22145431379902925, 0.10503201579003854, 0.09729114383018309, 0.06939104728513473, 0.04888407982432888, 0.021689149038496346, 0.016444560503340113, 0.015371370064175818], \"overall_imp\": [\"Pregnancies\", \"Age\", \"BMI\", \"SerumInsulin\", \"PlasmaGlucose\", \"TricepsThickness\", \"DiastolicBloodPressure\", \"DiabetesPedigree\"], \"per_class_summary\": [[0.22145431379902925, 0.10503201579003847, 0.09729114383018309, 0.0693910472851347, 0.04888407982432887, 0.021689149038496343, 0.01644456050334011, 0.015371370064175821], [0.22145431379902925, 0.1050320157900386, 0.09729114383018307, 0.06939104728513476, 0.04888407982432889, 0.02168914903849635, 0.016444560503340117, 0.015371370064175814]], \"per_class_imp\": [[\"Pregnancies\", \"Age\", \"BMI\", \"SerumInsulin\", \"PlasmaGlucose\", \"TricepsThickness\", \"DiastolicBloodPressure\", \"DiabetesPedigree\"], [\"Pregnancies\", \"Age\", \"BMI\", \"SerumInsulin\", \"PlasmaGlucose\", \"TricepsThickness\", \"DiastolicBloodPressure\", \"DiabetesPedigree\"]]}]}]}], \"run_logs\": \"[2023-11-12T18:45:29.373823] Entering context manager injector.\\nCannot provide tracer without any exporter configured.\\n/azureml-envs/azureml_4612c5564caffc186e5bd2016e43147c/lib/python3.6/site-packages/paramiko/transport.py:33: CryptographyDeprecationWarning: Python 3.6 is no longer supported by the Python core team. Therefore, support for it is deprecated in cryptography and will be removed in a future release.\\n  from cryptography.hazmat.backends import default_backend\\n[2023-11-12T18:45:30.279469] context_manager_injector.py Command line Options: Namespace(inject=['ProjectPythonPath:context_managers.ProjectPythonPath', 'RunHistory:context_managers.RunHistory', 'TrackUserError:context_managers.TrackUserError'], invocation=['diabetes_training.py'])\\nScript type = None\\n[2023-11-12T18:45:30.283003] Entering Run History Context Manager.\\n/azureml-envs/azureml_4612c5564caffc186e5bd2016e43147c/lib/python3.6/site-packages/azureml/history/_tracking.py:367: FutureWarning: azureml.core: AzureML support for Python 3.6 is deprecated and will be dropped in an upcoming release. At that point, existing Python 3.6 workflows that use AzureML will continue to work without modification, but Python 3.6 users will no longer get access to the latest AzureML features and bugfixes. We recommend that you upgrade to Python 3.7 or newer. To disable SDK V1 deprecation warning set the environment variable AZUREML_DEPRECATE_WARNING to 'False'\\n  from azureml.core.run import Run\\n[2023-11-12T18:45:31.299972] Current directory: /azureml-run\\n[2023-11-12T18:45:31.300008] Preparing to call script [diabetes_training.py] with arguments:[]\\n[2023-11-12T18:45:31.300023] After variable expansion, calling script [diabetes_training.py] with arguments:[]\\n\\nCould not import lightgbm, required if using LGBMExplainableModel\\nLoading Data...\\nTraining a decision tree model\\n\\n\\n[2023-11-12T18:45:35.249052] The experiment completed successfully. Finalizing run...\\n[2023-11-12T18:45:35.249075] Start FinalizingInRunHistory\\n[2023-11-12T18:45:35.252238] Logging experiment finalizing status in history service.\\nStarting the daemon thread to refresh tokens in background for process with pid = 7\\nCleaning up all outstanding Run operations, waiting 300.0 seconds\\n2 items cleaning up...\\nCleanup took 0.09121131896972656 seconds\\n[2023-11-12T18:45:36.180171] Finished context manager injector.\\n\\nRun is completed.\", \"graph\": {}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.51.0\"}, \"loading\": false}"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "execution_count": 10,
          "data": {
            "text/plain": "{'runId': 'mslearn-diabetes-explain_1699814505_ab7c4ab0',\n 'target': 'local',\n 'status': 'Completed',\n 'startTimeUtc': '2023-11-12T18:45:28.569286Z',\n 'endTimeUtc': '2023-11-12T18:45:37.556775Z',\n 'services': {},\n 'properties': {'_azureml.ComputeTargetType': 'local',\n  'ContentSnapshotId': '29724a88-5472-4d1d-ab04-193946d24841'},\n 'inputDatasets': [],\n 'outputDatasets': [],\n 'runDefinition': {'script': 'diabetes_training.py',\n  'command': '',\n  'useAbsolutePath': False,\n  'arguments': [],\n  'sourceDirectoryDataStore': None,\n  'framework': 'Python',\n  'communicator': 'None',\n  'target': 'local',\n  'dataReferences': {},\n  'data': {},\n  'outputData': {},\n  'datacaches': [],\n  'jobName': None,\n  'maxRunDurationSeconds': 2592000,\n  'nodeCount': 1,\n  'instanceTypes': [],\n  'priority': None,\n  'credentialPassthrough': False,\n  'identity': None,\n  'environment': {'name': 'explain_env',\n   'version': 'Autosave_2023-11-12T18:41:46Z_69fedab8',\n   'assetId': 'azureml://locations/eastus2/workspaces/699734a3-1bff-45ae-b4a4-07c66269f461/environments/explain_env/versions/Autosave_2023-11-12T18:41:46Z_69fedab8',\n   'autoRebuild': True,\n   'python': {'interpreterPath': 'python',\n    'userManagedDependencies': False,\n    'condaDependencies': {'dependencies': ['python=3.6.2',\n      'scikit-learn',\n      'pandas',\n      'pip',\n      {'pip': ['azureml-defaults', 'azureml-interpret']}],\n     'name': 'batch_environment'},\n    'baseCondaEnvironment': None},\n   'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'},\n   'docker': {'baseImage': 'mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:20230509.v1',\n    'platform': {'os': 'Linux', 'architecture': 'amd64'},\n    'baseDockerfile': None,\n    'baseImageRegistry': {'address': None, 'username': None, 'password': None},\n    'enabled': False,\n    'arguments': []},\n   'spark': {'repositories': [], 'packages': [], 'precachePackages': True},\n   'inferencingStackVersion': None},\n  'history': {'outputCollection': True,\n   'directoriesToWatch': ['logs'],\n   'enableMLflowTracking': True,\n   'snapshotProject': True},\n  'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment',\n    'spark.yarn.maxAppAttempts': '1'}},\n  'parallelTask': {'maxRetriesPerWorker': 0,\n   'workerCountPerNode': 1,\n   'terminalExitCodes': None,\n   'configuration': {}},\n  'amlCompute': {'name': None,\n   'vmSize': None,\n   'retainCluster': False,\n   'clusterMaxNodeCount': None},\n  'aiSuperComputer': {'instanceType': 'D2',\n   'imageVersion': None,\n   'location': None,\n   'aiSuperComputerStorageData': None,\n   'interactive': False,\n   'scalePolicy': None,\n   'virtualClusterArmId': None,\n   'tensorboardLogDirectory': None,\n   'sshPublicKey': None,\n   'sshPublicKeys': None,\n   'enableAzmlInt': True,\n   'priority': 'Medium',\n   'slaTier': 'Standard',\n   'userAlias': None},\n  'kubernetesCompute': {'instanceType': None},\n  'tensorflow': {'workerCount': 1, 'parameterServerCount': 1},\n  'mpi': {'processCountPerNode': 1},\n  'pyTorch': {'communicationBackend': 'nccl', 'processCount': None},\n  'hdi': {'yarnDeployMode': 'Cluster'},\n  'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5},\n  'exposedPorts': None,\n  'docker': {'useDocker': True,\n   'sharedVolumes': True,\n   'shmSize': '2g',\n   'arguments': []},\n  'cmk8sCompute': {'configuration': {}},\n  'commandReturnCodeConfig': {'returnCode': 'Zero',\n   'successfulReturnCodes': []},\n  'environmentVariables': {},\n  'applicationEndpoints': {},\n  'parameters': []},\n 'logFiles': {'azureml-logs/60_control_log.txt': 'https://mlwdp100labs0576378376.blob.core.windows.net/azureml/ExperimentRun/dcid.mslearn-diabetes-explain_1699814505_ab7c4ab0/azureml-logs/60_control_log.txt?sv=2019-07-07&sr=b&sig=qU4qNP9X9mpMejrj3%2FfcVjr3mlbEryZEXjrECW%2FFdp8%3D&skoid=b22ab211-1a77-4e41-b54e-76819173f4ea&sktid=54f76ea3-fed9-41fc-a628-e91383900a39&skt=2023-11-12T18%3A12%3A30Z&ske=2023-11-14T02%3A22%3A30Z&sks=b&skv=2019-07-07&st=2023-11-12T18%3A35%3A46Z&se=2023-11-13T02%3A45%3A46Z&sp=r',\n  'azureml-logs/70_driver_log.txt': 'https://mlwdp100labs0576378376.blob.core.windows.net/azureml/ExperimentRun/dcid.mslearn-diabetes-explain_1699814505_ab7c4ab0/azureml-logs/70_driver_log.txt?sv=2019-07-07&sr=b&sig=5kZeO68kafl2g8uBfJtAs%2F3O1nRZICbYEw%2BVioawzMY%3D&skoid=b22ab211-1a77-4e41-b54e-76819173f4ea&sktid=54f76ea3-fed9-41fc-a628-e91383900a39&skt=2023-11-12T18%3A12%3A30Z&ske=2023-11-14T02%3A22%3A30Z&sks=b&skv=2019-07-07&st=2023-11-12T18%3A35%3A46Z&se=2023-11-13T02%3A45%3A46Z&sp=r',\n  'logs/azureml/7_azureml.log': 'https://mlwdp100labs0576378376.blob.core.windows.net/azureml/ExperimentRun/dcid.mslearn-diabetes-explain_1699814505_ab7c4ab0/logs/azureml/7_azureml.log?sv=2019-07-07&sr=b&sig=ZaJwYZOPwubZf5kO4sZ6s%2BWQAu4k%2B5effVoxZ%2BVqEcA%3D&skoid=b22ab211-1a77-4e41-b54e-76819173f4ea&sktid=54f76ea3-fed9-41fc-a628-e91383900a39&skt=2023-11-12T18%3A12%3A30Z&ske=2023-11-14T02%3A22%3A30Z&sks=b&skv=2019-07-07&st=2023-11-12T18%3A35%3A37Z&se=2023-11-13T02%3A45%3A37Z&sp=r'},\n 'submittedBy': 'Gabriel Ichcanziho Pérez Landa'}"
          },
          "metadata": {}
        }
      ],
      "execution_count": 10,
      "metadata": {
        "vscode": {
          "languageId": "python"
        },
        "gather": {
          "logged": 1699814770565
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Retrieve the feature importance values\n",
        "\n",
        "With the experiment run completed, you can use the **ExplanationClient** class to retrieve the feature importance from the explanation registered for the run."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.interpret import ExplanationClient\n",
        "\n",
        "# Get the feature explanations\n",
        "client = ExplanationClient.from_run(run)\n",
        "engineered_explanations = client.download_model_explanation()\n",
        "feature_importances = engineered_explanations.get_feature_importance_dict()\n",
        "\n",
        "# Overall feature importance\n",
        "print('Feature\\tImportance')\n",
        "for key, value in feature_importances.items():\n",
        "    print(key, '\\t', value)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Feature\tImportance\nPregnancies \t 0.22145431379902925\nAge \t 0.10503201579003854\nBMI \t 0.09729114383018309\nSerumInsulin \t 0.06939104728513473\nPlasmaGlucose \t 0.04888407982432888\nTricepsThickness \t 0.021689149038496346\nDiastolicBloodPressure \t 0.016444560503340113\nDiabetesPedigree \t 0.015371370064175818\n"
        }
      ],
      "execution_count": 11,
      "metadata": {
        "vscode": {
          "languageId": "python"
        },
        "gather": {
          "logged": 1699814831371
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## View the model explanation in Azure Machine Learning studio\n",
        "\n",
        "You can also click the **View run details** link in the Run Details widget to see the run in Azure Machine Learning studio, and view the **Explanations** tab. Then:\n",
        "\n",
        "1. Select the explanation ID for your tabular explainer.\n",
        "2. View the **Aggregate feature importance** chart, which shows the overall global feature importance.\n",
        "3. View the **Individual feature importance** chart, which shows each data point from the test data.\n",
        "4. Select an individual point to see the local feature importance for the individual prediction for the selected data point.\n",
        "5. Use the **New Cohort** button to define a subset of the data with the following settings:\n",
        "    - **Dataset cohort name**: Under 25s\n",
        "    - **Select filter**: Dataset\n",
        "        - Age less than 25 (Make sure you add this filter before saving the new cohort).\n",
        "6. Create a second new cohort named **25 and over** with a filter on Age greater than or equal to 25.\n",
        "6. Review the **Aggregate feature importance** visualization and compare the relative feature importance for the two cohorts you have defined. The ability to compare cohorts makes it possible to see how the features influence preedictions differently for multiple subsets of the data population.\n",
        "\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "**More Information**: For more information about using explainers in Azure ML, see [the documentation](https://docs.microsoft.com/azure/machine-learning/how-to-machine-learning-interpretability). "
      ],
      "metadata": {}
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}