{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Work with Data\n",
        "\n",
        "Data is the foundation on which machine learning models are built. Managing data centrally in the cloud, and making it accessible to teams of data scientists who are running experiments and training models on multiple workstations and compute targets is an important part of any professional data science solution.\n",
        "\n",
        "In this notebook, you'll explore two Azure Machine Learning objects for working with data: *datastores*, and *datasets*."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Connect to your workspace\n",
        "\n",
        "To get started, connect to your workspace.\n",
        "\n",
        "> **Note**: If you haven't already established an authenticated session with your Azure subscription, you'll be prompted to authenticate by clicking a link, entering an authentication code, and signing into Azure."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import azureml.core\n",
        "from azureml.core import Workspace\n",
        "\n",
        "# Load the workspace from the saved config file\n",
        "ws = Workspace.from_config()\n",
        "print('Ready to use Azure ML {} to work with {}'.format(azureml.core.VERSION, ws.name))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Ready to use Azure ML 1.51.0 to work with mlw-dp100-labs\n"
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1697919682069
        },
        "vscode": {
          "languageId": "python"
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "## Create a compute cluster\n",
        "\n",
        "To run a script as an experiment using the ScriptRunConfig, you'll need a compute target.\n",
        "\n",
        "> **Important**: Change *your-compute-cluster* to a suitable name for your compute cluster in the code below before running it - you can specify the name of an existing cluster if you have one. Cluster names must be globally unique names between 2 to 16 characters in length. Valid characters are letters, digits, and the - character."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.compute import ComputeTarget, AmlCompute\n",
        "from azureml.core.compute_target import ComputeTargetException\n",
        "\n",
        "cluster_name = \"coursera-cluster\"\n",
        "\n",
        "try:\n",
        "    # Check for existing compute target\n",
        "    training_cluster = ComputeTarget(workspace=ws, name=cluster_name)\n",
        "    print('Found existing cluster, use it.')\n",
        "except ComputeTargetException:\n",
        "    # If it doesn't already exist, create it\n",
        "    try:\n",
        "        compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_DS11_V2', max_nodes=2)\n",
        "        training_cluster = ComputeTarget.create(ws, cluster_name, compute_config)\n",
        "        training_cluster.wait_for_completion(show_output=True)\n",
        "    except Exception as ex:\n",
        "        print(ex)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Found existing cluster, use it.\n"
        }
      ],
      "execution_count": 2,
      "metadata": {
        "vscode": {
          "languageId": "python"
        },
        "gather": {
          "logged": 1697919725798
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Work with datastores\n",
        "\n",
        "In Azure ML, *datastores* are references to storage locations, such as Azure Storage blob containers. Every workspace has a default datastore - usually the Azure storage blob container that was created with the workspace. If you need to work with data that is stored in different locations, you can add custom datastores to your workspace and set any of them to be the default.\n",
        "\n",
        "### View datastores\n",
        "\n",
        "Run the following code to determine the datastores in your workspace:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the default datastore\n",
        "default_ds = ws.get_default_datastore()\n",
        "\n",
        "# Enumerate all datastores, indicating which is the default\n",
        "for ds_name in ws.datastores:\n",
        "    print(ds_name, \"- Default =\", ds_name == default_ds.name)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "workspaceblobstore - Default = True\nworkspacefilestore - Default = False\nworkspaceartifactstore - Default = False\nworkspaceworkingdirectory - Default = False\n"
        }
      ],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1697919754980
        },
        "vscode": {
          "languageId": "python"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can also view and manage datastores in your workspace on the **Datastores** page for your workspace in [Azure Machine Learning studio](https://ml.azure.com).\n",
        "\n",
        "### Upload data to a datastore\n",
        "\n",
        "Now that you have determined the available datastores, you can upload files from your local file system to a datastore so that it will be accessible to experiments running in the workspace, regardless of where the experiment script is actually being run."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Dataset\n",
        "from azureml.data.datapath import DataPath\n",
        "\n",
        "Dataset.File.upload_directory(src_dir='data',\n",
        "                              target=DataPath(default_ds, 'diabetes-data/')\n",
        "                              )"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Validating arguments.\nArguments validated.\nUploading file to diabetes-data/\nUploading an estimated of 4 files\nUploading data/.amlignore\nUploaded data/.amlignore, 1 files out of an estimated total of 4\nUploading data/.amlignore.amltmp\nUploaded data/.amlignore.amltmp, 2 files out of an estimated total of 4\nUploading data/diabetes.csv\nUploaded data/diabetes.csv, 3 files out of an estimated total of 4\nUploading data/diabetes2.csv\nUploaded data/diabetes2.csv, 4 files out of an estimated total of 4\nUploaded 4 files\nCreating new dataset\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 4,
          "data": {
            "text/plain": "{\n  \"source\": [\n    \"('workspaceblobstore', '/diabetes-data/')\"\n  ],\n  \"definition\": [\n    \"GetDatastoreFiles\"\n  ]\n}"
          },
          "metadata": {}
        }
      ],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1697919912098
        },
        "vscode": {
          "languageId": "python"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Work with datasets\n",
        "\n",
        "Azure Machine Learning provides an abstraction for data in the form of *datasets*. A dataset is a versioned reference to a specific set of data that you may want to use in an experiment. Datasets can be *tabular* or *file*-based.\n",
        "\n",
        "### Create a tabular dataset\n",
        "\n",
        "Let's create a dataset from the diabetes data you uploaded to the datastore, and view the first 20 records. In this case, the data is in a structured format in a CSV file, so we'll use a *tabular* dataset."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Dataset\n",
        "\n",
        "# Get the default datastore\n",
        "default_ds = ws.get_default_datastore()\n",
        "\n",
        "#Create a tabular dataset from the path on the datastore (this may take a short while)\n",
        "tab_data_set = Dataset.Tabular.from_delimited_files(path=(default_ds, 'diabetes-data/*.csv'))\n",
        "\n",
        "# Display the first 20 rows as a Pandas dataframe\n",
        "tab_data_set.take(20).to_pandas_dataframe()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 5,
          "data": {
            "text/plain": "    PatientID  Pregnancies  PlasmaGlucose  DiastolicBloodPressure  \\\n0     1354778            0            171                      80   \n1     1147438            8             92                      93   \n2     1640031            7            115                      47   \n3     1883350            9            103                      78   \n4     1424119            1             85                      59   \n5     1619297            0             82                      92   \n6     1660149            0            133                      47   \n7     1458769            0             67                      87   \n8     1201647            8             80                      95   \n9     1403912            1             72                      31   \n10    1943830            1             88                      86   \n11    1824483            3             94                      96   \n12    1848869            5            114                     101   \n13    1669231            7            110                      82   \n14    1683688            0            148                      58   \n15    1738587            3            109                      77   \n16    1884264            3            106                      64   \n17    1485251            1            156                      53   \n18    1536832            8            117                      39   \n19    1438701            3            102                     100   \n\n    TricepsThickness  SerumInsulin        BMI  DiabetesPedigree  Age  Diabetic  \n0                 34            23  43.509726          1.213191   21         0  \n1                 47            36  21.240576          0.158365   23         0  \n2                 52            35  41.511523          0.079019   23         0  \n3                 25           304  29.582192          1.282870   43         1  \n4                 27            35  42.604536          0.549542   22         0  \n5                  9           253  19.724160          0.103424   26         0  \n6                 19           227  21.941357          0.174160   21         0  \n7                 43            36  18.277723          0.236165   26         0  \n8                 33            24  26.624929          0.443947   53         1  \n9                 40            42  36.889576          0.103944   26         0  \n10                11            58  43.225041          0.230285   22         0  \n11                31            36  21.294479          0.259020   23         0  \n12                43            70  36.495320          0.079190   38         1  \n13                16            44  36.089293          0.281276   25         0  \n14                11           179  39.192076          0.160829   45         0  \n15                46            61  19.847312          0.204345   21         1  \n16                25            51  29.044573          0.589188   42         1  \n17                15           226  29.786192          0.203824   41         1  \n18                32           164  21.230996          0.089363   25         0  \n19                25           289  42.185720          0.175593   43         1  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PatientID</th>\n      <th>Pregnancies</th>\n      <th>PlasmaGlucose</th>\n      <th>DiastolicBloodPressure</th>\n      <th>TricepsThickness</th>\n      <th>SerumInsulin</th>\n      <th>BMI</th>\n      <th>DiabetesPedigree</th>\n      <th>Age</th>\n      <th>Diabetic</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1354778</td>\n      <td>0</td>\n      <td>171</td>\n      <td>80</td>\n      <td>34</td>\n      <td>23</td>\n      <td>43.509726</td>\n      <td>1.213191</td>\n      <td>21</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1147438</td>\n      <td>8</td>\n      <td>92</td>\n      <td>93</td>\n      <td>47</td>\n      <td>36</td>\n      <td>21.240576</td>\n      <td>0.158365</td>\n      <td>23</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1640031</td>\n      <td>7</td>\n      <td>115</td>\n      <td>47</td>\n      <td>52</td>\n      <td>35</td>\n      <td>41.511523</td>\n      <td>0.079019</td>\n      <td>23</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1883350</td>\n      <td>9</td>\n      <td>103</td>\n      <td>78</td>\n      <td>25</td>\n      <td>304</td>\n      <td>29.582192</td>\n      <td>1.282870</td>\n      <td>43</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1424119</td>\n      <td>1</td>\n      <td>85</td>\n      <td>59</td>\n      <td>27</td>\n      <td>35</td>\n      <td>42.604536</td>\n      <td>0.549542</td>\n      <td>22</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>1619297</td>\n      <td>0</td>\n      <td>82</td>\n      <td>92</td>\n      <td>9</td>\n      <td>253</td>\n      <td>19.724160</td>\n      <td>0.103424</td>\n      <td>26</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>1660149</td>\n      <td>0</td>\n      <td>133</td>\n      <td>47</td>\n      <td>19</td>\n      <td>227</td>\n      <td>21.941357</td>\n      <td>0.174160</td>\n      <td>21</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>1458769</td>\n      <td>0</td>\n      <td>67</td>\n      <td>87</td>\n      <td>43</td>\n      <td>36</td>\n      <td>18.277723</td>\n      <td>0.236165</td>\n      <td>26</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>1201647</td>\n      <td>8</td>\n      <td>80</td>\n      <td>95</td>\n      <td>33</td>\n      <td>24</td>\n      <td>26.624929</td>\n      <td>0.443947</td>\n      <td>53</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>1403912</td>\n      <td>1</td>\n      <td>72</td>\n      <td>31</td>\n      <td>40</td>\n      <td>42</td>\n      <td>36.889576</td>\n      <td>0.103944</td>\n      <td>26</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>1943830</td>\n      <td>1</td>\n      <td>88</td>\n      <td>86</td>\n      <td>11</td>\n      <td>58</td>\n      <td>43.225041</td>\n      <td>0.230285</td>\n      <td>22</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>1824483</td>\n      <td>3</td>\n      <td>94</td>\n      <td>96</td>\n      <td>31</td>\n      <td>36</td>\n      <td>21.294479</td>\n      <td>0.259020</td>\n      <td>23</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>1848869</td>\n      <td>5</td>\n      <td>114</td>\n      <td>101</td>\n      <td>43</td>\n      <td>70</td>\n      <td>36.495320</td>\n      <td>0.079190</td>\n      <td>38</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>1669231</td>\n      <td>7</td>\n      <td>110</td>\n      <td>82</td>\n      <td>16</td>\n      <td>44</td>\n      <td>36.089293</td>\n      <td>0.281276</td>\n      <td>25</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>1683688</td>\n      <td>0</td>\n      <td>148</td>\n      <td>58</td>\n      <td>11</td>\n      <td>179</td>\n      <td>39.192076</td>\n      <td>0.160829</td>\n      <td>45</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>1738587</td>\n      <td>3</td>\n      <td>109</td>\n      <td>77</td>\n      <td>46</td>\n      <td>61</td>\n      <td>19.847312</td>\n      <td>0.204345</td>\n      <td>21</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>1884264</td>\n      <td>3</td>\n      <td>106</td>\n      <td>64</td>\n      <td>25</td>\n      <td>51</td>\n      <td>29.044573</td>\n      <td>0.589188</td>\n      <td>42</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>1485251</td>\n      <td>1</td>\n      <td>156</td>\n      <td>53</td>\n      <td>15</td>\n      <td>226</td>\n      <td>29.786192</td>\n      <td>0.203824</td>\n      <td>41</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>1536832</td>\n      <td>8</td>\n      <td>117</td>\n      <td>39</td>\n      <td>32</td>\n      <td>164</td>\n      <td>21.230996</td>\n      <td>0.089363</td>\n      <td>25</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>1438701</td>\n      <td>3</td>\n      <td>102</td>\n      <td>100</td>\n      <td>25</td>\n      <td>289</td>\n      <td>42.185720</td>\n      <td>0.175593</td>\n      <td>43</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1697920228039
        },
        "vscode": {
          "languageId": "python"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see in the code above, it's easy to convert a tabular dataset to a Pandas dataframe, enabling you to work with the data using common python techniques.\n",
        "\n",
        "### Create a file Dataset\n",
        "\n",
        "The dataset you created is a *tabular* dataset that can be read as a dataframe containing all of the data in the structured files that are included in the dataset definition. This works well for tabular data, but in some machine learning scenarios you might need to work with data that is unstructured; or you may simply want to handle reading the data from files in your own code. To accomplish this, you can use a *file* dataset, which creates a list of file paths in a virtual mount point, which you can use to read the data in the files."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a file dataset from the path on the datastore (this may take a short while)\n",
        "file_data_set = Dataset.File.from_files(path=(default_ds, 'diabetes-data/*.csv'))\n",
        "\n",
        "# Get the files in the dataset\n",
        "for file_path in file_data_set.to_path():\n",
        "    print(file_path)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "/diabetes.csv\n/diabetes2.csv\n"
        }
      ],
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1697920306858
        },
        "vscode": {
          "languageId": "python"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Register datasets\n",
        "\n",
        "Now that you have created datasets that reference the diabetes data, you can register them to make them easily accessible to any experiment being run in the workspace.\n",
        "\n",
        "We'll register the tabular dataset as **diabetes dataset**, and the file dataset as **diabetes files**."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Register the tabular dataset\n",
        "try:\n",
        "    tab_data_set = tab_data_set.register(workspace=ws, \n",
        "                                        name='diabetes dataset',\n",
        "                                        description='diabetes data',\n",
        "                                        tags = {'format':'CSV'},\n",
        "                                        create_new_version=True)\n",
        "except Exception as ex:\n",
        "    print(ex)\n",
        "\n",
        "# Register the file dataset\n",
        "try:\n",
        "    file_data_set = file_data_set.register(workspace=ws,\n",
        "                                            name='diabetes file dataset',\n",
        "                                            description='diabetes files',\n",
        "                                            tags = {'format':'CSV'},\n",
        "                                            create_new_version=True)\n",
        "except Exception as ex:\n",
        "    print(ex)\n",
        "\n",
        "print('Datasets registered')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Datasets registered\n"
        }
      ],
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1697920381149
        },
        "vscode": {
          "languageId": "python"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can view and manage datasets on the **Datasets** page for your workspace in [Azure Machine Learning studio](https://ml.azure.com). You can also get a list of datasets from the workspace object:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Datasets:\")\n",
        "for dataset_name in list(ws.datasets.keys()):\n",
        "    dataset = Dataset.get_by_name(ws, dataset_name)\n",
        "    print(\"\\t\", dataset.name, 'version', dataset.version)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Datasets:\n\t diabetes file dataset version 1\n\t diabetes dataset version 1\n"
        }
      ],
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1697920507952
        },
        "vscode": {
          "languageId": "python"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The ability to version datasets enables you to redefine datasets without breaking existing experiments or pipelines that rely on previous definitions. By default, the latest version of a named dataset is returned, but you can retrieve a specific version of a dataset by specifying the version number, like this:\n",
        "\n",
        "```python\n",
        "dataset_v1 = Dataset.get_by_name(ws, 'diabetes dataset', version = 1)\n",
        "```\n",
        "\n",
        "\n",
        "### Train a model from a tabular dataset\n",
        "\n",
        "Now that you have datasets, you're ready to start training models from them. You can pass datasets to scripts as *inputs* in the estimator being used to run the script.\n",
        "\n",
        "Run the following two code cells to create:\n",
        "\n",
        "1. A folder named **diabetes_training_from_tab_dataset**\n",
        "2. A script that trains a classification model by using a tabular dataset that is passed to it as an argument."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Create a folder for the experiment files\n",
        "experiment_folder = 'diabetes_training_from_tab_dataset'\n",
        "os.makedirs(experiment_folder, exist_ok=True)\n",
        "print(experiment_folder, 'folder created')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "diabetes_training_from_tab_dataset folder created\n"
        }
      ],
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1697920785879
        },
        "vscode": {
          "languageId": "python"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile $experiment_folder/diabetes_training.py\n",
        "# Import libraries\n",
        "import os\n",
        "import argparse\n",
        "from azureml.core import Run, Dataset\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import roc_curve\n",
        "\n",
        "# Get the script arguments (regularization rate and training dataset ID)\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('--regularization', type=float, dest='reg_rate', default=0.01, help='regularization rate')\n",
        "parser.add_argument(\"--input-data\", type=str, dest='training_dataset_id', help='training dataset')\n",
        "args = parser.parse_args()\n",
        "\n",
        "# Set regularization hyperparameter (passed as an argument to the script)\n",
        "reg = args.reg_rate\n",
        "\n",
        "# Get the experiment run context\n",
        "run = Run.get_context()\n",
        "\n",
        "# Get the training dataset\n",
        "print(\"Loading Data...\")\n",
        "diabetes = run.input_datasets['training_data'].to_pandas_dataframe()\n",
        "\n",
        "# Separate features and labels\n",
        "X, y = diabetes[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']].values, diabetes['Diabetic'].values\n",
        "\n",
        "# Split data into training set and test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
        "\n",
        "# Train a logistic regression model\n",
        "print('Training a logistic regression model with regularization rate of', reg)\n",
        "run.log('Regularization Rate',  np.float(reg))\n",
        "model = LogisticRegression(C=1/reg, solver=\"liblinear\").fit(X_train, y_train)\n",
        "\n",
        "# calculate accuracy\n",
        "y_hat = model.predict(X_test)\n",
        "acc = np.average(y_hat == y_test)\n",
        "print('Accuracy:', acc)\n",
        "run.log('Accuracy', np.float(acc))\n",
        "\n",
        "# calculate AUC\n",
        "y_scores = model.predict_proba(X_test)\n",
        "auc = roc_auc_score(y_test,y_scores[:,1])\n",
        "print('AUC: ' + str(auc))\n",
        "run.log('AUC', np.float(auc))\n",
        "\n",
        "os.makedirs('outputs', exist_ok=True)\n",
        "# note file saved in the outputs folder is automatically uploaded into experiment record\n",
        "joblib.dump(value=model, filename='outputs/diabetes_model.pkl')\n",
        "\n",
        "run.complete()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Writing diabetes_training_from_tab_dataset/diabetes_training.py\n"
        }
      ],
      "execution_count": 10,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Note**: In the script, the dataset is passed as a parameter (or argument). In the case of a tabular dataset, this argument will contain the ID of the registered dataset; so you could write code in the script to get the experiment's workspace from the run context, and then get the dataset using its ID; like this:\n",
        ">\n",
        "> ```\n",
        "> run = Run.get_context()\n",
        "> ws = run.experiment.workspace\n",
        "> dataset = Dataset.get_by_id(ws, id=args.training_dataset_id)\n",
        "> diabetes = dataset.to_pandas_dataframe()\n",
        "> ```\n",
        ">\n",
        "> However, Azure Machine Learning runs automatically identify arguments that reference named datasets and add them to the run's **input_datasets** collection, so you can also retrieve the dataset from this collection by specifying its \"friendly name\" (which as you'll see shortly, is specified in the argument definition in the script run configuration for the experiment). This is the approach taken in the script above.\n",
        "\n",
        "Now you can run a script as an experiment, defining an argument for the training dataset, which is read by the script.\n",
        "\n",
        "> **Note**: The **Dataset** class depends on some components in the **azureml-dataprep** package, so you need to include this package in the environment where the training experiment will be run. The **azureml-dataprep** package is included in the **azure-defaults** package."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Experiment, ScriptRunConfig, Environment\n",
        "from azureml.core.runconfig import DockerConfiguration\n",
        "from azureml.widgets import RunDetails\n",
        "\n",
        "\n",
        "# Create a Python environment for the experiment (from a .yml file)\n",
        "env = Environment.from_conda_specification(\"experiment_env\", \"environment.yml\")\n",
        "\n",
        "# Get the training dataset\n",
        "diabetes_ds = ws.datasets.get(\"diabetes dataset\")\n",
        "\n",
        "# Create a script config\n",
        "script_config = ScriptRunConfig(source_directory=experiment_folder,\n",
        "                              script='diabetes_training.py',\n",
        "                              arguments = ['--regularization', 0.1, # Regularizaton rate parameter\n",
        "                                           '--input-data', diabetes_ds.as_named_input('training_data')], # Reference to dataset\n",
        "                              environment=env,\n",
        "                              docker_runtime_config=DockerConfiguration(use_docker=True),\n",
        "                              compute_target=cluster_name) \n",
        "\n",
        "# submit the experiment\n",
        "experiment_name = 'mslearn-train-diabetes'\n",
        "experiment = Experiment(workspace=ws, name=experiment_name)\n",
        "run = experiment.submit(config=script_config)\n",
        "RunDetails(run).show()\n",
        "run.wait_for_completion()"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "_UserRunWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', '…",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c7099aa6866a4f0e9c7112242acbec01"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/aml.mini.widget.v1": "{\"status\": \"Completed\", \"workbench_run_details_uri\": \"https://ml.azure.com/runs/mslearn-train-diabetes_1697920846_3af532a1?wsid=/subscriptions/42233ac3-1d6b-40e9-920d-ae1ce13376ed/resourcegroups/rg-dp100-labs/workspaces/mlw-dp100-labs&tid=54f76ea3-fed9-41fc-a628-e91383900a39\", \"run_id\": \"mslearn-train-diabetes_1697920846_3af532a1\", \"run_properties\": {\"run_id\": \"mslearn-train-diabetes_1697920846_3af532a1\", \"created_utc\": \"2023-10-21T20:40:48.409063Z\", \"properties\": {\"_azureml.ComputeTargetType\": \"amlctrain\", \"ContentSnapshotId\": \"2054ba58-a7b8-4f74-9c13-a219ab100b97\", \"ProcessInfoFile\": \"azureml-logs/process_info.json\", \"ProcessStatusFile\": \"azureml-logs/process_status.json\"}, \"tags\": {\"_aml_system_ComputeTargetStatus\": \"{\\\"AllocationState\\\":\\\"steady\\\",\\\"PreparingNodeCount\\\":0,\\\"RunningNodeCount\\\":0,\\\"CurrentNodeCount\\\":0}\", \"mlflow.source.type\": \"JOB\", \"mlflow.source.name\": \"diabetes_training.py\"}, \"script_name\": null, \"arguments\": null, \"end_time_utc\": \"2023-10-21T20:46:15.497487Z\", \"status\": \"Completed\", \"log_files\": {\"logs/azureml/dataprep/0/backgroundProcess.log\": \"https://mlwdp100labs0576378376.blob.core.windows.net/azureml/ExperimentRun/dcid.mslearn-train-diabetes_1697920846_3af532a1/logs/azureml/dataprep/0/backgroundProcess.log?sv=2019-07-07&sr=b&sig=o%2FzoKIYnsw3YzuzZm1EpK89lXItPjcduGQFkGg07B68%3D&skoid=b22ab211-1a77-4e41-b54e-76819173f4ea&sktid=54f76ea3-fed9-41fc-a628-e91383900a39&skt=2023-10-21T20%3A35%3A11Z&ske=2023-10-23T04%3A45%3A11Z&sks=b&skv=2019-07-07&st=2023-10-21T21%3A13%3A18Z&se=2023-10-22T05%3A23%3A18Z&sp=r\", \"logs/azureml/dataprep/0/backgroundProcess_Telemetry.log\": \"https://mlwdp100labs0576378376.blob.core.windows.net/azureml/ExperimentRun/dcid.mslearn-train-diabetes_1697920846_3af532a1/logs/azureml/dataprep/0/backgroundProcess_Telemetry.log?sv=2019-07-07&sr=b&sig=nrLI8WHXVW1g4RGaQ8XU2Xrr%2BX%2F%2BrS%2Fio26W2xcoVmk%3D&skoid=b22ab211-1a77-4e41-b54e-76819173f4ea&sktid=54f76ea3-fed9-41fc-a628-e91383900a39&skt=2023-10-21T20%3A35%3A11Z&ske=2023-10-23T04%3A45%3A11Z&sks=b&skv=2019-07-07&st=2023-10-21T21%3A13%3A18Z&se=2023-10-22T05%3A23%3A18Z&sp=r\", \"logs/azureml/dataprep/0/rslex.log.2023-10-21-20\": \"https://mlwdp100labs0576378376.blob.core.windows.net/azureml/ExperimentRun/dcid.mslearn-train-diabetes_1697920846_3af532a1/logs/azureml/dataprep/0/rslex.log.2023-10-21-20?sv=2019-07-07&sr=b&sig=xaqtsz1oY4VKDlo3cWC5aIFenV6WQ%2FBO5kiNwvzObSg%3D&skoid=b22ab211-1a77-4e41-b54e-76819173f4ea&sktid=54f76ea3-fed9-41fc-a628-e91383900a39&skt=2023-10-21T20%3A35%3A11Z&ske=2023-10-23T04%3A45%3A11Z&sks=b&skv=2019-07-07&st=2023-10-21T21%3A13%3A18Z&se=2023-10-22T05%3A23%3A18Z&sp=r\", \"user_logs/std_log.txt\": \"https://mlwdp100labs0576378376.blob.core.windows.net/azureml/ExperimentRun/dcid.mslearn-train-diabetes_1697920846_3af532a1/user_logs/std_log.txt?sv=2019-07-07&sr=b&sig=vDAwZRmviffk8nFUARK5aF%2FuF61KTikfu1qTEMgz%2FLY%3D&skoid=b22ab211-1a77-4e41-b54e-76819173f4ea&sktid=54f76ea3-fed9-41fc-a628-e91383900a39&skt=2023-10-21T20%3A35%3A09Z&ske=2023-10-23T04%3A45%3A09Z&sks=b&skv=2019-07-07&st=2023-10-21T21%3A15%3A31Z&se=2023-10-22T05%3A25%3A31Z&sp=r\", \"system_logs/cs_capability/cs-capability.log\": \"https://mlwdp100labs0576378376.blob.core.windows.net/azureml/ExperimentRun/dcid.mslearn-train-diabetes_1697920846_3af532a1/system_logs/cs_capability/cs-capability.log?sv=2019-07-07&sr=b&sig=ffqS8Uch6grtrRvg7j1YzOTNymAfRZaabIApxrj%2Bml0%3D&skoid=b22ab211-1a77-4e41-b54e-76819173f4ea&sktid=54f76ea3-fed9-41fc-a628-e91383900a39&skt=2023-10-21T20%3A35%3A09Z&ske=2023-10-23T04%3A45%3A09Z&sks=b&skv=2019-07-07&st=2023-10-21T21%3A15%3A31Z&se=2023-10-22T05%3A25%3A31Z&sp=r\", \"system_logs/hosttools_capability/hosttools-capability.log\": \"https://mlwdp100labs0576378376.blob.core.windows.net/azureml/ExperimentRun/dcid.mslearn-train-diabetes_1697920846_3af532a1/system_logs/hosttools_capability/hosttools-capability.log?sv=2019-07-07&sr=b&sig=00WhMlDnosd4WAGX%2BYlAmeU7iGEAopKqEUSJFhd%2BHcI%3D&skoid=b22ab211-1a77-4e41-b54e-76819173f4ea&sktid=54f76ea3-fed9-41fc-a628-e91383900a39&skt=2023-10-21T20%3A35%3A09Z&ske=2023-10-23T04%3A45%3A09Z&sks=b&skv=2019-07-07&st=2023-10-21T21%3A15%3A31Z&se=2023-10-22T05%3A25%3A31Z&sp=r\", \"system_logs/lifecycler/execution-wrapper.log\": \"https://mlwdp100labs0576378376.blob.core.windows.net/azureml/ExperimentRun/dcid.mslearn-train-diabetes_1697920846_3af532a1/system_logs/lifecycler/execution-wrapper.log?sv=2019-07-07&sr=b&sig=WRuLucdkJUOBtLA7j52ycq5OzZhCWw5oIY3OjR3wgZA%3D&skoid=b22ab211-1a77-4e41-b54e-76819173f4ea&sktid=54f76ea3-fed9-41fc-a628-e91383900a39&skt=2023-10-21T20%3A35%3A09Z&ske=2023-10-23T04%3A45%3A09Z&sks=b&skv=2019-07-07&st=2023-10-21T21%3A15%3A31Z&se=2023-10-22T05%3A25%3A31Z&sp=r\", \"system_logs/lifecycler/lifecycler.log\": \"https://mlwdp100labs0576378376.blob.core.windows.net/azureml/ExperimentRun/dcid.mslearn-train-diabetes_1697920846_3af532a1/system_logs/lifecycler/lifecycler.log?sv=2019-07-07&sr=b&sig=reLr1sRUOKSbJcxyEY2Tbnyi%2FmFeGL4hoLngi79AbFo%3D&skoid=b22ab211-1a77-4e41-b54e-76819173f4ea&sktid=54f76ea3-fed9-41fc-a628-e91383900a39&skt=2023-10-21T20%3A35%3A09Z&ske=2023-10-23T04%3A45%3A09Z&sks=b&skv=2019-07-07&st=2023-10-21T21%3A15%3A31Z&se=2023-10-22T05%3A25%3A31Z&sp=r\", \"system_logs/metrics_capability/metrics-capability.log\": \"https://mlwdp100labs0576378376.blob.core.windows.net/azureml/ExperimentRun/dcid.mslearn-train-diabetes_1697920846_3af532a1/system_logs/metrics_capability/metrics-capability.log?sv=2019-07-07&sr=b&sig=ghjf11%2FcotYt7AHod5L1glsoljgN8FhBrle8iCggERg%3D&skoid=b22ab211-1a77-4e41-b54e-76819173f4ea&sktid=54f76ea3-fed9-41fc-a628-e91383900a39&skt=2023-10-21T20%3A35%3A09Z&ske=2023-10-23T04%3A45%3A09Z&sks=b&skv=2019-07-07&st=2023-10-21T21%3A15%3A31Z&se=2023-10-22T05%3A25%3A31Z&sp=r\", \"system_logs/snapshot_capability/snapshot-capability.log\": \"https://mlwdp100labs0576378376.blob.core.windows.net/azureml/ExperimentRun/dcid.mslearn-train-diabetes_1697920846_3af532a1/system_logs/snapshot_capability/snapshot-capability.log?sv=2019-07-07&sr=b&sig=9p2Tr2ktgjis5XLaNMmWA9QxHZ9hGht2RcvgHLnoX3A%3D&skoid=b22ab211-1a77-4e41-b54e-76819173f4ea&sktid=54f76ea3-fed9-41fc-a628-e91383900a39&skt=2023-10-21T20%3A35%3A09Z&ske=2023-10-23T04%3A45%3A09Z&sks=b&skv=2019-07-07&st=2023-10-21T21%3A15%3A31Z&se=2023-10-22T05%3A25%3A31Z&sp=r\"}, \"log_groups\": [[\"user_logs/std_log.txt\", \"system_logs/cs_capability/cs-capability.log\", \"system_logs/hosttools_capability/hosttools-capability.log\", \"system_logs/lifecycler/execution-wrapper.log\", \"system_logs/lifecycler/lifecycler.log\", \"system_logs/metrics_capability/metrics-capability.log\", \"system_logs/snapshot_capability/snapshot-capability.log\"], [\"logs/azureml/dataprep/0/backgroundProcess.log\", \"logs/azureml/dataprep/0/backgroundProcess_Telemetry.log\", \"logs/azureml/dataprep/0/rslex.log.2023-10-21-20\"]], \"run_duration\": \"0:05:27\", \"run_number\": \"1697920848\", \"run_queued_details\": {\"status\": \"Completed\", \"details\": null}}, \"child_runs\": [], \"children_metrics\": {}, \"run_metrics\": [{\"name\": \"Accuracy\", \"run_id\": \"mslearn-train-diabetes_1697920846_3af532a1\", \"categories\": [0], \"series\": [{\"data\": [0.7893333333333333]}]}, {\"name\": \"Regularization Rate\", \"run_id\": \"mslearn-train-diabetes_1697920846_3af532a1\", \"categories\": [0], \"series\": [{\"data\": [0.1]}]}, {\"name\": \"AUC\", \"run_id\": \"mslearn-train-diabetes_1697920846_3af532a1\", \"categories\": [0], \"series\": [{\"data\": [0.8568650620553335]}]}], \"run_logs\": \"2023-10-21 20:45:58.8805|DEBUG|EngineHost|l_77a5dc93-b9d6-4a9b-aeb8-a0965aa78b4d|Startup|MessageParser initialized|\\n2023-10-21 20:45:58.8986|DEBUG|EngineHost|l_77a5dc93-b9d6-4a9b-aeb8-a0965aa78b4d|Startup|MessageLoop initialized|\\n2023-10-21 20:45:59.1070|DEBUG|Telemetry|l_77a5dc93-b9d6-4a9b-aeb8-a0965aa78b4d|event: ActivityMigration|metrics: {}, properties: {\\\"prevState\\\":\\\"No version\\\",\\\"newState\\\":\\\"1\\\",\\\"success\\\":\\\"True\\\"}|\\n2023-10-21 20:45:59.7000|DEBUG|Telemetry|l_77a5dc93-b9d6-4a9b-aeb8-a0965aa78b4d|event: StepInfo|metrics: {}, properties: {\\\"blockType\\\":\\\"Microsoft.DPrep.GetDatastoreFilesBlock\\\",\\\"id\\\":\\\"0\\\"}|\\n2023-10-21 20:45:59.7000|DEBUG|Telemetry|l_77a5dc93-b9d6-4a9b-aeb8-a0965aa78b4d|event: StepInfo|metrics: {}, properties: {\\\"blockType\\\":\\\"Microsoft.DPrep.ParseDelimitedBlock\\\",\\\"id\\\":\\\"1\\\"}|\\n2023-10-21 20:45:59.7000|DEBUG|Telemetry|l_77a5dc93-b9d6-4a9b-aeb8-a0965aa78b4d|event: StepInfo|metrics: {}, properties: {\\\"blockType\\\":\\\"Microsoft.DPrep.DropColumnsBlock\\\",\\\"id\\\":\\\"2\\\"}|\\n2023-10-21 20:45:59.7000|DEBUG|Telemetry|l_77a5dc93-b9d6-4a9b-aeb8-a0965aa78b4d|event: StepInfo|metrics: {}, properties: {\\\"blockType\\\":\\\"Microsoft.DPrep.SetColumnTypesBlock\\\",\\\"id\\\":\\\"3\\\"}|\\n2023-10-21 20:45:59.7881|DEBUG|Telemetry|l_77a5dc93-b9d6-4a9b-aeb8-a0965aa78b4d|event: YamlConverter|metrics: {\\\"duration\\\":46.0}, properties: {\\\"hadException\\\":\\\"False\\\",\\\"success\\\":\\\"True\\\",\\\"conversionOperations\\\":\\\"  paths:\\\\n  - pattern: azureml://subscriptions/REDACTED/resourcegroups/REDACTED/workspaces/REDACTED/datastores/REDACTED/paths/REDACTED\\\\n\\\\ntransformations:\\\\n  - read_files:\\\\n      path_column: REDACTED\\\\n      keep_existing_columns: false\\\\n      reader: textLines\\\\n      reader_arguments:\\\\n        encoding: utf-8\\\\n        support_multi_line: false\\\\n        delimiter: ','\\\\n\\\\n  - split_by_delimiter:\\\\n      source_column: REDACTED\\\\n      delimiter: ','\\\\n      empty_as_string: false\\\\n\\\\n  - promote_headers: all_files_same_headers\\\\n\\\\n  - convert_column_types:\\\\n    - columns: REDACTED\\\\n      column_type: int\\\\n    - columns: REDACTED\\\\n      column_type: int\\\\n    - columns: REDACTED\\\\n      column_type: int\\\\n    - columns: REDACTED\\\\n      column_type: int\\\\n    - columns: REDACTED\\\\n      column_type: int\\\\n    - columns: REDACTED\\\\n      column_type: int\\\\n    - columns: REDACTED\\\\n      column_type: float\\\\n    - columns: REDACTED\\\\n      column_type: float\\\\n    - columns: REDACTED\\\\n      column_type: int\\\\n    - columns: REDACTED\\\\n      column_type: int\\\\n\\\\n\\\"}|\\n\\nRun is completed.\", \"graph\": {}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.51.0\"}, \"loading\": false}"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "execution_count": 11,
          "data": {
            "text/plain": "{'runId': 'mslearn-train-diabetes_1697920846_3af532a1',\n 'target': 'coursera-cluster',\n 'status': 'Completed',\n 'startTimeUtc': '2023-10-21T20:44:48.965002Z',\n 'endTimeUtc': '2023-10-21T20:46:15.497487Z',\n 'services': {},\n 'properties': {'_azureml.ComputeTargetType': 'amlctrain',\n  'ContentSnapshotId': '2054ba58-a7b8-4f74-9c13-a219ab100b97',\n  'ProcessInfoFile': 'azureml-logs/process_info.json',\n  'ProcessStatusFile': 'azureml-logs/process_status.json'},\n 'inputDatasets': [{'dataset': {'id': '007692f3-f89e-452c-9865-05a49e7a4c50'}, 'consumptionDetails': {'type': 'RunInput', 'inputName': 'training_data', 'mechanism': 'Direct'}}],\n 'outputDatasets': [],\n 'runDefinition': {'script': 'diabetes_training.py',\n  'command': '',\n  'useAbsolutePath': False,\n  'arguments': ['--regularization',\n   '0.1',\n   '--input-data',\n   'DatasetConsumptionConfig:training_data'],\n  'sourceDirectoryDataStore': None,\n  'framework': 'Python',\n  'communicator': 'None',\n  'target': 'coursera-cluster',\n  'dataReferences': {},\n  'data': {'training_data': {'dataLocation': {'dataset': {'id': '007692f3-f89e-452c-9865-05a49e7a4c50',\n      'name': 'diabetes dataset',\n      'version': '1'},\n     'dataPath': None,\n     'uri': None,\n     'type': None},\n    'mechanism': 'Direct',\n    'environmentVariableName': 'training_data',\n    'pathOnCompute': None,\n    'overwrite': False,\n    'options': None}},\n  'outputData': {},\n  'datacaches': [],\n  'jobName': None,\n  'maxRunDurationSeconds': 2592000,\n  'nodeCount': 1,\n  'instanceTypes': [],\n  'priority': None,\n  'credentialPassthrough': False,\n  'identity': None,\n  'environment': {'name': 'experiment_env',\n   'version': 'Autosave_2023-10-20T17:56:40Z_36c27fbb',\n   'assetId': 'azureml://locations/eastus2/workspaces/699734a3-1bff-45ae-b4a4-07c66269f461/environments/experiment_env/versions/Autosave_2023-10-20T17:56:40Z_36c27fbb',\n   'autoRebuild': True,\n   'python': {'interpreterPath': 'python',\n    'userManagedDependencies': False,\n    'condaDependencies': {'dependencies': ['python=3.6.2',\n      'scikit-learn',\n      'pandas',\n      'pip',\n      {'pip': ['azureml-defaults', 'azureml-mlflow']}],\n     'name': 'simple_environment'},\n    'baseCondaEnvironment': None},\n   'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'},\n   'docker': {'baseImage': 'mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:20230509.v1',\n    'platform': {'os': 'Linux', 'architecture': 'amd64'},\n    'baseDockerfile': None,\n    'baseImageRegistry': {'address': None, 'username': None, 'password': None},\n    'enabled': False,\n    'arguments': []},\n   'spark': {'repositories': [], 'packages': [], 'precachePackages': True},\n   'inferencingStackVersion': None},\n  'history': {'outputCollection': True,\n   'directoriesToWatch': ['logs'],\n   'enableMLflowTracking': True,\n   'snapshotProject': True},\n  'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment',\n    'spark.yarn.maxAppAttempts': '1'}},\n  'parallelTask': {'maxRetriesPerWorker': 0,\n   'workerCountPerNode': 1,\n   'terminalExitCodes': None,\n   'configuration': {}},\n  'amlCompute': {'name': None,\n   'vmSize': None,\n   'retainCluster': False,\n   'clusterMaxNodeCount': None},\n  'aiSuperComputer': {'instanceType': 'D2',\n   'imageVersion': None,\n   'location': None,\n   'aiSuperComputerStorageData': None,\n   'interactive': False,\n   'scalePolicy': None,\n   'virtualClusterArmId': None,\n   'tensorboardLogDirectory': None,\n   'sshPublicKey': None,\n   'sshPublicKeys': None,\n   'enableAzmlInt': True,\n   'priority': 'Medium',\n   'slaTier': 'Standard',\n   'userAlias': None},\n  'kubernetesCompute': {'instanceType': None},\n  'tensorflow': {'workerCount': 1, 'parameterServerCount': 1},\n  'mpi': {'processCountPerNode': 1},\n  'pyTorch': {'communicationBackend': 'nccl', 'processCount': None},\n  'hdi': {'yarnDeployMode': 'Cluster'},\n  'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5},\n  'exposedPorts': None,\n  'docker': {'useDocker': True,\n   'sharedVolumes': True,\n   'shmSize': '2g',\n   'arguments': []},\n  'cmk8sCompute': {'configuration': {}},\n  'commandReturnCodeConfig': {'returnCode': 'Zero',\n   'successfulReturnCodes': []},\n  'environmentVariables': {},\n  'applicationEndpoints': {},\n  'parameters': []},\n 'logFiles': {'logs/azureml/dataprep/0/backgroundProcess.log': 'https://mlwdp100labs0576378376.blob.core.windows.net/azureml/ExperimentRun/dcid.mslearn-train-diabetes_1697920846_3af532a1/logs/azureml/dataprep/0/backgroundProcess.log?sv=2019-07-07&sr=b&sig=t2zuMOsYaeJU9l8QWBoje0KwpjzmP68J4vCyjWkWvDE%3D&skoid=b22ab211-1a77-4e41-b54e-76819173f4ea&sktid=54f76ea3-fed9-41fc-a628-e91383900a39&skt=2023-10-21T20%3A35%3A11Z&ske=2023-10-23T04%3A45%3A11Z&sks=b&skv=2019-07-07&st=2023-10-21T20%3A36%3A17Z&se=2023-10-22T04%3A46%3A17Z&sp=r',\n  'logs/azureml/dataprep/0/backgroundProcess_Telemetry.log': 'https://mlwdp100labs0576378376.blob.core.windows.net/azureml/ExperimentRun/dcid.mslearn-train-diabetes_1697920846_3af532a1/logs/azureml/dataprep/0/backgroundProcess_Telemetry.log?sv=2019-07-07&sr=b&sig=Wq7WBi3slScZ8V8Eg4AotBJjojXOGwiyuDkQS%2BXtAhU%3D&skoid=b22ab211-1a77-4e41-b54e-76819173f4ea&sktid=54f76ea3-fed9-41fc-a628-e91383900a39&skt=2023-10-21T20%3A35%3A11Z&ske=2023-10-23T04%3A45%3A11Z&sks=b&skv=2019-07-07&st=2023-10-21T20%3A36%3A17Z&se=2023-10-22T04%3A46%3A17Z&sp=r',\n  'logs/azureml/dataprep/0/rslex.log.2023-10-21-20': 'https://mlwdp100labs0576378376.blob.core.windows.net/azureml/ExperimentRun/dcid.mslearn-train-diabetes_1697920846_3af532a1/logs/azureml/dataprep/0/rslex.log.2023-10-21-20?sv=2019-07-07&sr=b&sig=QfpKH6kwiBRnnRkhkHzBOCRt0Y33Ekba4O6wS%2B3pSes%3D&skoid=b22ab211-1a77-4e41-b54e-76819173f4ea&sktid=54f76ea3-fed9-41fc-a628-e91383900a39&skt=2023-10-21T20%3A35%3A11Z&ske=2023-10-23T04%3A45%3A11Z&sks=b&skv=2019-07-07&st=2023-10-21T20%3A36%3A17Z&se=2023-10-22T04%3A46%3A17Z&sp=r',\n  'user_logs/std_log.txt': 'https://mlwdp100labs0576378376.blob.core.windows.net/azureml/ExperimentRun/dcid.mslearn-train-diabetes_1697920846_3af532a1/user_logs/std_log.txt?sv=2019-07-07&sr=b&sig=64MZI%2BOpkx%2BHB6CP9SXmCccenHScph3frPDGRn27QFM%3D&skoid=b22ab211-1a77-4e41-b54e-76819173f4ea&sktid=54f76ea3-fed9-41fc-a628-e91383900a39&skt=2023-10-21T20%3A35%3A11Z&ske=2023-10-23T04%3A45%3A11Z&sks=b&skv=2019-07-07&st=2023-10-21T20%3A36%3A48Z&se=2023-10-22T04%3A46%3A48Z&sp=r',\n  'system_logs/cs_capability/cs-capability.log': 'https://mlwdp100labs0576378376.blob.core.windows.net/azureml/ExperimentRun/dcid.mslearn-train-diabetes_1697920846_3af532a1/system_logs/cs_capability/cs-capability.log?sv=2019-07-07&sr=b&sig=UH6c5NyvGxGgRtmYPVVVfHV3S%2BiYNvBTeIcpYVHKJF4%3D&skoid=b22ab211-1a77-4e41-b54e-76819173f4ea&sktid=54f76ea3-fed9-41fc-a628-e91383900a39&skt=2023-10-21T20%3A35%3A09Z&ske=2023-10-23T04%3A45%3A09Z&sks=b&skv=2019-07-07&st=2023-10-21T20%3A36%3A48Z&se=2023-10-22T04%3A46%3A48Z&sp=r',\n  'system_logs/hosttools_capability/hosttools-capability.log': 'https://mlwdp100labs0576378376.blob.core.windows.net/azureml/ExperimentRun/dcid.mslearn-train-diabetes_1697920846_3af532a1/system_logs/hosttools_capability/hosttools-capability.log?sv=2019-07-07&sr=b&sig=1BM6qJelfkbzH%2BumhREfQfEFQiYX5P0a9hF2w8KSeWg%3D&skoid=b22ab211-1a77-4e41-b54e-76819173f4ea&sktid=54f76ea3-fed9-41fc-a628-e91383900a39&skt=2023-10-21T20%3A35%3A09Z&ske=2023-10-23T04%3A45%3A09Z&sks=b&skv=2019-07-07&st=2023-10-21T20%3A36%3A48Z&se=2023-10-22T04%3A46%3A48Z&sp=r',\n  'system_logs/lifecycler/execution-wrapper.log': 'https://mlwdp100labs0576378376.blob.core.windows.net/azureml/ExperimentRun/dcid.mslearn-train-diabetes_1697920846_3af532a1/system_logs/lifecycler/execution-wrapper.log?sv=2019-07-07&sr=b&sig=VPHDSKUpJGY%2FhKUZb5iNqgamppnW5W4ZNSumwF2Levs%3D&skoid=b22ab211-1a77-4e41-b54e-76819173f4ea&sktid=54f76ea3-fed9-41fc-a628-e91383900a39&skt=2023-10-21T20%3A35%3A09Z&ske=2023-10-23T04%3A45%3A09Z&sks=b&skv=2019-07-07&st=2023-10-21T20%3A36%3A48Z&se=2023-10-22T04%3A46%3A48Z&sp=r',\n  'system_logs/lifecycler/lifecycler.log': 'https://mlwdp100labs0576378376.blob.core.windows.net/azureml/ExperimentRun/dcid.mslearn-train-diabetes_1697920846_3af532a1/system_logs/lifecycler/lifecycler.log?sv=2019-07-07&sr=b&sig=9n0%2BGdrYQHOdb8W7H7d5CSIYeq1StLrxuQltfhGBjtY%3D&skoid=b22ab211-1a77-4e41-b54e-76819173f4ea&sktid=54f76ea3-fed9-41fc-a628-e91383900a39&skt=2023-10-21T20%3A35%3A09Z&ske=2023-10-23T04%3A45%3A09Z&sks=b&skv=2019-07-07&st=2023-10-21T20%3A36%3A48Z&se=2023-10-22T04%3A46%3A48Z&sp=r',\n  'system_logs/metrics_capability/metrics-capability.log': 'https://mlwdp100labs0576378376.blob.core.windows.net/azureml/ExperimentRun/dcid.mslearn-train-diabetes_1697920846_3af532a1/system_logs/metrics_capability/metrics-capability.log?sv=2019-07-07&sr=b&sig=83MrvNK2jHDvM1lWcC1TCNKlZRjPDl8aKiFLFY4iNZg%3D&skoid=b22ab211-1a77-4e41-b54e-76819173f4ea&sktid=54f76ea3-fed9-41fc-a628-e91383900a39&skt=2023-10-21T20%3A35%3A09Z&ske=2023-10-23T04%3A45%3A09Z&sks=b&skv=2019-07-07&st=2023-10-21T20%3A36%3A48Z&se=2023-10-22T04%3A46%3A48Z&sp=r',\n  'system_logs/snapshot_capability/snapshot-capability.log': 'https://mlwdp100labs0576378376.blob.core.windows.net/azureml/ExperimentRun/dcid.mslearn-train-diabetes_1697920846_3af532a1/system_logs/snapshot_capability/snapshot-capability.log?sv=2019-07-07&sr=b&sig=ILnRgc%2FOqyklDP6AGx0W0FmxG0x4J0WFvUrqO0ASk2I%3D&skoid=b22ab211-1a77-4e41-b54e-76819173f4ea&sktid=54f76ea3-fed9-41fc-a628-e91383900a39&skt=2023-10-21T20%3A35%3A09Z&ske=2023-10-23T04%3A45%3A09Z&sks=b&skv=2019-07-07&st=2023-10-21T20%3A36%3A48Z&se=2023-10-22T04%3A46%3A48Z&sp=r'},\n 'submittedBy': 'Gabriel Ichcanziho Pérez Landa'}"
          },
          "metadata": {}
        }
      ],
      "execution_count": 11,
      "metadata": {
        "gather": {
          "logged": 1697921208974
        },
        "scrolled": true,
        "vscode": {
          "languageId": "python"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Note:** The **--input-data** argument passes the dataset as a *named input* that includes a *friendly name* for the dataset, which is used by the script to read it from the **input_datasets** collection in the experiment run. The string value in the **--input-data** argument is actually the registered dataset's ID.  As an alternative approach, you could simply pass `diabetes_ds.id`, in which case the script can access the dataset ID from the script arguments and use it to get the dataset from the workspace, but not from the **input_datasets** collection.\n",
        "\n",
        "The first time the experiment is run, it may take some time to set up the Python environment - subsequent runs will be quicker.\n",
        "\n",
        "When the experiment has completed, in the widget, view the **azureml-logs/70_driver_log.txt** output log and the metrics generated by the run.\n",
        "\n",
        "### Register the trained model\n",
        "\n",
        "As with any training experiment, you can retrieve the trained model and register it in your Azure Machine Learning workspace."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Model\n",
        "\n",
        "run.register_model(model_path='outputs/diabetes_model.pkl', model_name='diabetes_model',\n",
        "                   tags={'Training context':'Tabular dataset'}, properties={'AUC': run.get_metrics()['AUC'], 'Accuracy': run.get_metrics()['Accuracy']})\n",
        "\n",
        "for model in Model.list(ws):\n",
        "    print(model.name, 'version:', model.version)\n",
        "    for tag_name in model.tags:\n",
        "        tag = model.tags[tag_name]\n",
        "        print ('\\t',tag_name, ':', tag)\n",
        "    for prop_name in model.properties:\n",
        "        prop = model.properties[prop_name]\n",
        "        print ('\\t',prop_name, ':', prop)\n",
        "    print('\\n')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "diabetes_model version: 3\n\t Training context : Tabular dataset\n\t AUC : 0.8568650620553335\n\t Accuracy : 0.7893333333333333\n\n\ndiabetes_model version: 2\n\t Training context : Parameterized script\n\t AUC : 0.8484377332205582\n\t Accuracy : 0.774\n\t Regularization Rate : 0.1\n\n\ndiabetes_model version: 1\n\t Training context : Script\n\t AUC : 0.8483441962286681\n\t Accuracy : 0.774\n\n\n"
        }
      ],
      "execution_count": 12,
      "metadata": {
        "gather": {
          "logged": 1697922729563
        },
        "vscode": {
          "languageId": "python"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train a model from a file dataset\n",
        "\n",
        "You've seen how to train a model using training data in a *tabular* dataset; but what about a *file* dataset?\n",
        "\n",
        "When you're using a file dataset, the dataset argument passed to the script represents a mount point containing file paths. How you read the data from these files depends on the kind of data in the files and what you want to do with it. In the case of the diabetes CSV files, you can use the Python **glob** module to create a list of files in the virtual mount point defined by the dataset, and read them all into Pandas dataframes that are concatenated into a single dataframe.\n",
        "\n",
        "Run the following two code cells to create:\n",
        "\n",
        "1. A folder named **diabetes_training_from_file_dataset**\n",
        "2. A script that trains a classification model by using a file dataset that is passed to is as an *input*."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Create a folder for the experiment files\n",
        "experiment_folder = 'diabetes_training_from_file_dataset'\n",
        "os.makedirs(experiment_folder, exist_ok=True)\n",
        "print(experiment_folder, 'folder created')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "diabetes_training_from_file_dataset folder created\n"
        }
      ],
      "execution_count": 13,
      "metadata": {
        "gather": {
          "logged": 1697922862394
        },
        "vscode": {
          "languageId": "python"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile $experiment_folder/diabetes_training.py\n",
        "# Import libraries\n",
        "import os\n",
        "import argparse\n",
        "from azureml.core import Dataset, Run\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import roc_curve\n",
        "import glob\n",
        "\n",
        "# Get script arguments (rgularization rate and file dataset mount point)\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('--regularization', type=float, dest='reg_rate', default=0.01, help='regularization rate')\n",
        "parser.add_argument('--input-data', type=str, dest='dataset_folder', help='data mount point')\n",
        "args = parser.parse_args()\n",
        "\n",
        "# Set regularization hyperparameter (passed as an argument to the script)\n",
        "reg = args.reg_rate\n",
        "\n",
        "# Get the experiment run context\n",
        "run = Run.get_context()\n",
        "\n",
        "# load the diabetes dataset\n",
        "print(\"Loading Data...\")\n",
        "data_path = run.input_datasets['training_files'] # Get the training data path from the input\n",
        "# (You could also just use args.dataset_folder if you don't want to rely on a hard-coded friendly name)\n",
        "\n",
        "# Read the files\n",
        "all_files = glob.glob(data_path + \"/*.csv\")\n",
        "diabetes = pd.concat((pd.read_csv(f) for f in all_files), sort=False)\n",
        "\n",
        "# Separate features and labels\n",
        "X, y = diabetes[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']].values, diabetes['Diabetic'].values\n",
        "\n",
        "# Split data into training set and test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
        "\n",
        "# Train a logistic regression model\n",
        "print('Training a logistic regression model with regularization rate of', reg)\n",
        "run.log('Regularization Rate',  np.float(reg))\n",
        "model = LogisticRegression(C=1/reg, solver=\"liblinear\").fit(X_train, y_train)\n",
        "\n",
        "# calculate accuracy\n",
        "y_hat = model.predict(X_test)\n",
        "acc = np.average(y_hat == y_test)\n",
        "print('Accuracy:', acc)\n",
        "run.log('Accuracy', np.float(acc))\n",
        "\n",
        "# calculate AUC\n",
        "y_scores = model.predict_proba(X_test)\n",
        "auc = roc_auc_score(y_test,y_scores[:,1])\n",
        "print('AUC: ' + str(auc))\n",
        "run.log('AUC', np.float(auc))\n",
        "\n",
        "os.makedirs('outputs', exist_ok=True)\n",
        "# note file saved in the outputs folder is automatically uploaded into experiment record\n",
        "joblib.dump(value=model, filename='outputs/diabetes_model.pkl')\n",
        "\n",
        "run.complete()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Writing diabetes_training_from_file_dataset/diabetes_training.py\n"
        }
      ],
      "execution_count": 14,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Just as with tabular datasets, you can retrieve a file dataset from the **input_datasets** collection by using its friendly name. You can also retrieve it from the script argument, which in the case of a file dataset contains a mount path to the files (rather than the dataset ID passed for a tabular dataset).\n",
        "\n",
        "Next we need to change the way we pass the dataset to the script - it needs to define a path from which the script can read the files. You can use either the **as_download** or **as_mount** method to do this. Using **as_download** causes the files in the file dataset to be downloaded to a temporary location on the compute where the script is being run, while **as_mount** creates a mount point from which the files can be streamed directly from the datastore.\n",
        "\n",
        "You can combine the access method with the **as_named_input** method to include the dataset in the **input_datasets** collection in the experiment run (if you omit this, for example by setting the argument to `diabetes_ds.as_mount()`, the script will be able to access the dataset mount point from the script arguments, but not from the **input_datasets** collection)."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Experiment\n",
        "from azureml.core.runconfig import DockerConfiguration\n",
        "from azureml.widgets import RunDetails\n",
        "\n",
        "\n",
        "# Get the training dataset\n",
        "diabetes_ds = ws.datasets.get(\"diabetes file dataset\")\n",
        "\n",
        "# Create a script config\n",
        "script_config = ScriptRunConfig(source_directory=experiment_folder,\n",
        "                                script='diabetes_training.py',\n",
        "                                arguments = ['--regularization', 0.1, # Regularizaton rate parameter\n",
        "                                             '--input-data', diabetes_ds.as_named_input('training_files').as_download()], # Reference to dataset location\n",
        "                                environment=env, # Use the environment created previously\n",
        "                                docker_runtime_config=DockerConfiguration(use_docker=True),\n",
        "                                compute_target=cluster_name)\n",
        "\n",
        "# submit the experiment\n",
        "experiment_name = 'mslearn-train-diabetes'\n",
        "experiment = Experiment(workspace=ws, name=experiment_name)\n",
        "run = experiment.submit(config=script_config)\n",
        "RunDetails(run).show()\n",
        "run.wait_for_completion()"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "_UserRunWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', '…",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5c975b5c021249688e3aff2361271713"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/aml.mini.widget.v1": "{\"status\": \"Completed\", \"workbench_run_details_uri\": \"https://ml.azure.com/runs/mslearn-train-diabetes_1697922920_5eb49cd0?wsid=/subscriptions/42233ac3-1d6b-40e9-920d-ae1ce13376ed/resourcegroups/rg-dp100-labs/workspaces/mlw-dp100-labs&tid=54f76ea3-fed9-41fc-a628-e91383900a39\", \"run_id\": \"mslearn-train-diabetes_1697922920_5eb49cd0\", \"run_properties\": {\"run_id\": \"mslearn-train-diabetes_1697922920_5eb49cd0\", \"created_utc\": \"2023-10-21T21:15:22.339352Z\", \"properties\": {\"_azureml.ComputeTargetType\": \"amlctrain\", \"ContentSnapshotId\": \"16a9e46a-b440-48ae-bfcf-d13b6029f6b5\", \"ProcessInfoFile\": \"azureml-logs/process_info.json\", \"ProcessStatusFile\": \"azureml-logs/process_status.json\"}, \"tags\": {\"_aml_system_ComputeTargetStatus\": \"{\\\"AllocationState\\\":\\\"steady\\\",\\\"PreparingNodeCount\\\":0,\\\"RunningNodeCount\\\":0,\\\"CurrentNodeCount\\\":1}\", \"mlflow.source.type\": \"JOB\", \"mlflow.source.name\": \"diabetes_training.py\"}, \"script_name\": null, \"arguments\": null, \"end_time_utc\": \"2023-10-21T21:17:02.703051Z\", \"status\": \"Completed\", \"log_files\": {\"user_logs/std_log.txt\": \"https://mlwdp100labs0576378376.blob.core.windows.net/azureml/ExperimentRun/dcid.mslearn-train-diabetes_1697922920_5eb49cd0/user_logs/std_log.txt?sv=2019-07-07&sr=b&sig=HszQLrGFlc6YBodkPw6Z00t4PSIBq1bxz7iCDj70aJ4%3D&skoid=b22ab211-1a77-4e41-b54e-76819173f4ea&sktid=54f76ea3-fed9-41fc-a628-e91383900a39&skt=2023-10-21T20%3A35%3A11Z&ske=2023-10-23T04%3A45%3A11Z&sks=b&skv=2019-07-07&st=2023-10-21T21%3A15%3A59Z&se=2023-10-22T05%3A25%3A59Z&sp=r\", \"system_logs/cs_capability/cs-capability.log\": \"https://mlwdp100labs0576378376.blob.core.windows.net/azureml/ExperimentRun/dcid.mslearn-train-diabetes_1697922920_5eb49cd0/system_logs/cs_capability/cs-capability.log?sv=2019-07-07&sr=b&sig=KLCiLKWQgaKdt%2FAWv4hh6nbHPtNHR6iYS8W4jWoDbjE%3D&skoid=b22ab211-1a77-4e41-b54e-76819173f4ea&sktid=54f76ea3-fed9-41fc-a628-e91383900a39&skt=2023-10-21T20%3A35%3A11Z&ske=2023-10-23T04%3A45%3A11Z&sks=b&skv=2019-07-07&st=2023-10-21T21%3A15%3A59Z&se=2023-10-22T05%3A25%3A59Z&sp=r\", \"system_logs/data_capability/data-capability.log\": \"https://mlwdp100labs0576378376.blob.core.windows.net/azureml/ExperimentRun/dcid.mslearn-train-diabetes_1697922920_5eb49cd0/system_logs/data_capability/data-capability.log?sv=2019-07-07&sr=b&sig=TW3GHKLyhQCkmLu60wDVqmLqybl1yHFMi7iwD5TgT1o%3D&skoid=b22ab211-1a77-4e41-b54e-76819173f4ea&sktid=54f76ea3-fed9-41fc-a628-e91383900a39&skt=2023-10-21T20%3A35%3A11Z&ske=2023-10-23T04%3A45%3A11Z&sks=b&skv=2019-07-07&st=2023-10-21T21%3A15%3A59Z&se=2023-10-22T05%3A25%3A59Z&sp=r\", \"system_logs/data_capability/rslex.log.2023-10-21-21\": \"https://mlwdp100labs0576378376.blob.core.windows.net/azureml/ExperimentRun/dcid.mslearn-train-diabetes_1697922920_5eb49cd0/system_logs/data_capability/rslex.log.2023-10-21-21?sv=2019-07-07&sr=b&sig=JcFwtyZyH5gxY5A9oxH2HFIk3zeS%2B4xpMdEvNdDzp98%3D&skoid=b22ab211-1a77-4e41-b54e-76819173f4ea&sktid=54f76ea3-fed9-41fc-a628-e91383900a39&skt=2023-10-21T20%3A35%3A11Z&ske=2023-10-23T04%3A45%3A11Z&sks=b&skv=2019-07-07&st=2023-10-21T21%3A15%3A59Z&se=2023-10-22T05%3A25%3A59Z&sp=r\", \"system_logs/hosttools_capability/hosttools-capability.log\": \"https://mlwdp100labs0576378376.blob.core.windows.net/azureml/ExperimentRun/dcid.mslearn-train-diabetes_1697922920_5eb49cd0/system_logs/hosttools_capability/hosttools-capability.log?sv=2019-07-07&sr=b&sig=dyiKCTcUoA4j7ds9wQuAjrAw5KT6GAQyIqC7XlOTIzE%3D&skoid=b22ab211-1a77-4e41-b54e-76819173f4ea&sktid=54f76ea3-fed9-41fc-a628-e91383900a39&skt=2023-10-21T20%3A35%3A11Z&ske=2023-10-23T04%3A45%3A11Z&sks=b&skv=2019-07-07&st=2023-10-21T21%3A15%3A59Z&se=2023-10-22T05%3A25%3A59Z&sp=r\", \"system_logs/lifecycler/execution-wrapper.log\": \"https://mlwdp100labs0576378376.blob.core.windows.net/azureml/ExperimentRun/dcid.mslearn-train-diabetes_1697922920_5eb49cd0/system_logs/lifecycler/execution-wrapper.log?sv=2019-07-07&sr=b&sig=jQSVf8jBSRKzA5n0m7z1RlvE%2FSNXabb4j1TJ0EL%2FA6c%3D&skoid=b22ab211-1a77-4e41-b54e-76819173f4ea&sktid=54f76ea3-fed9-41fc-a628-e91383900a39&skt=2023-10-21T20%3A35%3A11Z&ske=2023-10-23T04%3A45%3A11Z&sks=b&skv=2019-07-07&st=2023-10-21T21%3A15%3A59Z&se=2023-10-22T05%3A25%3A59Z&sp=r\", \"system_logs/lifecycler/lifecycler.log\": \"https://mlwdp100labs0576378376.blob.core.windows.net/azureml/ExperimentRun/dcid.mslearn-train-diabetes_1697922920_5eb49cd0/system_logs/lifecycler/lifecycler.log?sv=2019-07-07&sr=b&sig=srH2kl1nt62uizgzLr5RvU551dSK9Y9sbQDXNt9S1%2Fo%3D&skoid=b22ab211-1a77-4e41-b54e-76819173f4ea&sktid=54f76ea3-fed9-41fc-a628-e91383900a39&skt=2023-10-21T20%3A35%3A11Z&ske=2023-10-23T04%3A45%3A11Z&sks=b&skv=2019-07-07&st=2023-10-21T21%3A15%3A59Z&se=2023-10-22T05%3A25%3A59Z&sp=r\", \"system_logs/metrics_capability/metrics-capability.log\": \"https://mlwdp100labs0576378376.blob.core.windows.net/azureml/ExperimentRun/dcid.mslearn-train-diabetes_1697922920_5eb49cd0/system_logs/metrics_capability/metrics-capability.log?sv=2019-07-07&sr=b&sig=fB2CiKoy6ldIpCRAteelDhx4W01k0o2tp5EmgnnVpTs%3D&skoid=b22ab211-1a77-4e41-b54e-76819173f4ea&sktid=54f76ea3-fed9-41fc-a628-e91383900a39&skt=2023-10-21T20%3A35%3A11Z&ske=2023-10-23T04%3A45%3A11Z&sks=b&skv=2019-07-07&st=2023-10-21T21%3A15%3A59Z&se=2023-10-22T05%3A25%3A59Z&sp=r\", \"system_logs/snapshot_capability/snapshot-capability.log\": \"https://mlwdp100labs0576378376.blob.core.windows.net/azureml/ExperimentRun/dcid.mslearn-train-diabetes_1697922920_5eb49cd0/system_logs/snapshot_capability/snapshot-capability.log?sv=2019-07-07&sr=b&sig=qPA4A%2Ft%2FlMl4XD1ZD%2Bdyl26oCcZnChWb3jt5I3fErsw%3D&skoid=b22ab211-1a77-4e41-b54e-76819173f4ea&sktid=54f76ea3-fed9-41fc-a628-e91383900a39&skt=2023-10-21T20%3A35%3A11Z&ske=2023-10-23T04%3A45%3A11Z&sks=b&skv=2019-07-07&st=2023-10-21T21%3A15%3A59Z&se=2023-10-22T05%3A25%3A59Z&sp=r\"}, \"log_groups\": [[\"user_logs/std_log.txt\", \"system_logs/cs_capability/cs-capability.log\", \"system_logs/data_capability/data-capability.log\", \"system_logs/hosttools_capability/hosttools-capability.log\", \"system_logs/lifecycler/execution-wrapper.log\", \"system_logs/lifecycler/lifecycler.log\", \"system_logs/metrics_capability/metrics-capability.log\", \"system_logs/snapshot_capability/snapshot-capability.log\"], [\"system_logs/data_capability/rslex.log.2023-10-21-21\"]], \"run_duration\": \"0:01:40\", \"run_number\": \"1697922922\", \"run_queued_details\": {\"status\": \"Completed\", \"details\": null}}, \"child_runs\": [], \"children_metrics\": {}, \"run_metrics\": [{\"name\": \"Regularization Rate\", \"run_id\": \"mslearn-train-diabetes_1697922920_5eb49cd0\", \"categories\": [0], \"series\": [{\"data\": [0.1]}]}, {\"name\": \"AUC\", \"run_id\": \"mslearn-train-diabetes_1697922920_5eb49cd0\", \"categories\": [0], \"series\": [{\"data\": [0.8468514889078735]}]}, {\"name\": \"Accuracy\", \"run_id\": \"mslearn-train-diabetes_1697922920_5eb49cd0\", \"categories\": [0], \"series\": [{\"data\": [0.7788888888888889]}]}], \"run_logs\": \"2023-10-21T21:16:43.783607Z  INFO rslex: [init_environment()] initializing Environment\\n2023-10-21T21:16:43.787774Z  INFO rslex_azure_storage::adls_gen1_stream_handler::retry_strategy: [rslex-azure-storage::adls_gen1_stream_handler::AdlsGen1RetryCondition] retry on append is set to true retry_on_append_timeout=true\\n2023-10-21T21:16:43.788814Z  INFO rslex_azureml::azureml::handler: [AzureMLHandler::uri_scheme()]\\n2023-10-21T21:16:43.789838Z  INFO rslex_azure_storage::adls_gen1_stream_handler::retry_strategy: [rslex-azure-storage::adls_gen1_stream_handler::AdlsGen1RetryCondition] retry on append is set to true retry_on_append_timeout=true\\n2023-10-21T21:16:43.792341Z  INFO rslex: [init_environment] using os managed compute resources\\n2023-10-21T21:16:45.649813Z  INFO execute: rslex: [execute_dataflow()] Starting execute sessionId=b73f9e3b-2383-423d-af6c-8af4fb3ab60a\\n2023-10-21T21:16:45.650460Z  INFO execute: rslex_script::dataflow: Dataflow::from_yaml_string::transformations: [ \\\"add_columns, write_streams_to_files, write_files\\\" ]     sessionId=b73f9e3b-2383-423d-af6c-8af4fb3ab60a\\n2023-10-21T21:16:45.651589Z  INFO rslex_azureml::azureml::handler: [AzureMLHandler::parse_uri()] Parse uri [azureml://subscriptions/42233ac3-1d6b-40e9-920d-ae1ce13376ed/resourcegroups/rg-dp100-labs/workspaces/mlw-dp100-labs/datastores/workspaceblobstore/paths/diabetes-data/*.csv]\\n2023-10-21T21:16:45.713896Z  INFO find_streams: rslex_azureml::data_store::resolver: [CachedResolver::resolve()] datastore resolved datastore_name=Some(\\\"workspaceblobstore\\\") datastore_type=Some(AzureBlob) resource_id=\\\"workspaceblobstore/diabetes-data/*.csv\\\"\\n2023-10-21T21:16:45.733244Z  INFO search: rslex_azure_storage::blob_stream_handler::searcher: [Searcher::search()] scan diabetes-data/(*.csv) 4 files and 0 dirs, matching 2 files, 0 more searches\\n2023-10-21T21:16:45.733285Z  INFO search: rslex_azure_storage::blob_stream_handler::searcher: close time.busy=2.18ms time.idle=16.7ms\\n2023-10-21T21:16:45.733317Z  INFO find_streams: rslex_azureml::data_store::stream_handler::handler: close time.busy=80.1ms time.idle=4.40\\u00b5s resource_id=\\\"workspaceblobstore/diabetes-data/*.csv\\\"\\n2023-10-21T21:16:45.733358Z  INFO execute:get_files: rslex::execution::operations::get_files: close time.busy=46.0\\u00b5s time.idle=82.6ms sessionId=b73f9e3b-2383-423d-af6c-8af4fb3ab60a\\n2023-10-21T21:16:45.733382Z  INFO execute:add_columns: rslex::execution::operations::add_columns: close time.busy=2.70\\u00b5s time.idle=3.60\\u00b5s sessionId=b73f9e3b-2383-423d-af6c-8af4fb3ab60a source_dataset=Dataset[Partitions: 1, Sources: 1]\\n2023-10-21T21:16:45.734117Z  INFO execute:write_streams_to_files:collect:reduce:reduce_and_combine:reduce:get_iter: rslex::prefetching: close time.busy=41.3\\u00b5s time.idle=2.30\\u00b5s sessionId=b73f9e3b-2383-423d-af6c-8af4fb3ab60a source=Dataset[Partitions: 1, Sources: 1] file_name_column=Some(\\\"Portable Path\\\") break_on_first_error=false skip_existing_files=false parallelization_degree=2 self=Dataset[Partitions: 1, Sources: 1] parallelization_degree=2 self=Dataset[Partitions: 1, Sources: 1] parallelization_degree=2 self=Dataset[Partitions: 1, Sources: 1] parallelization_degree=2 i=0 index=0\\n2023-10-21T21:16:45.734175Z  INFO execute:write_streams_to_files:collect:reduce:reduce_and_combine:reduce: rslex::dataset: close time.busy=111\\u00b5s time.idle=7.30\\u00b5s sessionId=b73f9e3b-2383-423d-af6c-8af4fb3ab60a source=Dataset[Partitions: 1, Sources: 1] file_name_column=Some(\\\"Portable Path\\\") break_on_first_error=false skip_existing_files=false parallelization_degree=2 self=Dataset[Partitions: 1, Sources: 1] parallelization_degree=2 self=Dataset[Partitions: 1, Sources: 1] parallelization_degree=2 self=Dataset[Partitions: 1, Sources: 1] parallelization_degree=2 i=0\\n2023-10-21T21:16:45.735964Z  INFO execute:write_streams_to_files:collect:reduce:reduce_and_combine:combine: rslex::dataset: close time.busy=1.96ms time.idle=9.90\\u00b5s sessionId=b73f9e3b-2383-423d-af6c-8af4fb3ab60a source=Dataset[Partitions: 1, Sources: 1] file_name_column=Some(\\\"Portable Path\\\") break_on_first_error=false skip_existing_files=false parallelization_degree=2 self=Dataset[Partitions: 1, Sources: 1] parallelization_degree=2 self=Dataset[Partitions: 1, Sources: 1] parallelization_degree=2 self=Dataset[Partitions: 1, Sources: 1] parallelization_degree=2\\n2023-10-21T21:16:45.736669Z  INFO execute:write_streams_to_files:collect:reduce:reduce_and_combine: rslex::dataset: close time.busy=3.24ms time.idle=2.30\\u00b5s sessionId=b73f9e3b-2383-423d-af6c-8af4fb3ab60a source=Dataset[Partitions: 1, Sources: 1] file_name_column=Some(\\\"Portable Path\\\") break_on_first_error=false skip_existing_files=false parallelization_degree=2 self=Dataset[Partitions: 1, Sources: 1] parallelization_degree=2 self=Dataset[Partitions: 1, Sources: 1] parallelization_degree=2 self=Dataset[Partitions: 1, Sources: 1] parallelization_degree=2\\n2023-10-21T21:16:45.736683Z  INFO execute:write_streams_to_files:collect:reduce: rslex::dataset: close time.busy=3.26ms time.idle=2.30\\u00b5s sessionId=b73f9e3b-2383-423d-af6c-8af4fb3ab60a source=Dataset[Partitions: 1, Sources: 1] file_name_column=Some(\\\"Portable Path\\\") break_on_first_error=false skip_existing_files=false parallelization_degree=2 self=Dataset[Partitions: 1, Sources: 1] parallelization_degree=2 self=Dataset[Partitions: 1, Sources: 1] parallelization_degree=2\\n2023-10-21T21:16:45.736689Z  INFO execute:write_streams_to_files:collect: rslex::dataset: close time.busy=3.27ms time.idle=2.70\\u00b5s sessionId=b73f9e3b-2383-423d-af6c-8af4fb3ab60a source=Dataset[Partitions: 1, Sources: 1] file_name_column=Some(\\\"Portable Path\\\") break_on_first_error=false skip_existing_files=false parallelization_degree=2 self=Dataset[Partitions: 1, Sources: 1] parallelization_degree=2\\n2023-10-21T21:16:45.736934Z  INFO execute:write_streams_to_files:reduce:reduce_and_combine:reduce:get_iter: rslex::prefetching: close time.busy=1.90\\u00b5s time.idle=1.40\\u00b5s sessionId=b73f9e3b-2383-423d-af6c-8af4fb3ab60a source=Dataset[Partitions: 1, Sources: 1] file_name_column=Some(\\\"Portable Path\\\") break_on_first_error=false skip_existing_files=false parallelization_degree=2 self=Dataset[Partitions: 2, Sources: 1] parallelization_degree=2 self=Dataset[Partitions: 2, Sources: 1] parallelization_degree=2 i=1 index=0\\n2023-10-21T21:16:45.736961Z  INFO execute:write_streams_to_files:reduce:reduce_and_combine:reduce:get_iter: rslex::prefetching: close time.busy=2.00\\u00b5s time.idle=2.00\\u00b5s sessionId=b73f9e3b-2383-423d-af6c-8af4fb3ab60a source=Dataset[Partitions: 1, Sources: 1] file_name_column=Some(\\\"Portable Path\\\") break_on_first_error=false skip_existing_files=false parallelization_degree=2 self=Dataset[Partitions: 2, Sources: 1] parallelization_degree=2 self=Dataset[Partitions: 2, Sources: 1] parallelization_degree=2 i=0 index=1\\n2023-10-21T21:16:45.762650Z  INFO execute:write_streams_to_files:reduce:reduce_and_combine:reduce:do_sequential_copy: rslex_core::file_io::stream_copier: close time.busy=21.5ms time.idle=2.50\\u00b5s sessionId=b73f9e3b-2383-423d-af6c-8af4fb3ab60a source=Dataset[Partitions: 1, Sources: 1] file_name_column=Some(\\\"Portable Path\\\") break_on_first_error=false skip_existing_files=false parallelization_degree=2 self=Dataset[Partitions: 2, Sources: 1] parallelization_degree=2 self=Dataset[Partitions: 2, Sources: 1] parallelization_degree=2 i=0 file_size=258786\\n2023-10-21T21:16:45.762677Z  INFO execute:write_streams_to_files:reduce:reduce_and_combine:reduce: rslex_core::file_io::stream_copier: [StreamCopier::copy()] copied file size=258786 source_handler=\\\"AmlDatastore\\\" source_resource_id=workspaceblobstore/diabetes-data/diabetes2.csv destination=diabetes2.csv duration=0.021524565 sequential=true sessionId=b73f9e3b-2383-423d-af6c-8af4fb3ab60a source=Dataset[Partitions: 1, Sources: 1] file_name_column=Some(\\\"Portable Path\\\") break_on_first_error=false skip_existing_files=false parallelization_degree=2 self=Dataset[Partitions: 2, Sources: 1] parallelization_degree=2 self=Dataset[Partitions: 2, Sources: 1] parallelization_degree=2 i=0\\n2023-10-21T21:16:45.762727Z  INFO execute:write_streams_to_files:reduce:reduce_and_combine:reduce: rslex::dataset: close time.busy=25.8ms time.idle=6.60\\u00b5s sessionId=b73f9e3b-2383-423d-af6c-8af4fb3ab60a source=Dataset[Partitions: 1, Sources: 1] file_name_column=Some(\\\"Portable Path\\\") break_on_first_error=false skip_existing_files=false parallelization_degree=2 self=Dataset[Partitions: 2, Sources: 1] parallelization_degree=2 self=Dataset[Partitions: 2, Sources: 1] parallelization_degree=2 i=0\\n2023-10-21T21:16:45.773965Z  INFO execute:write_streams_to_files:reduce:reduce_and_combine:reduce:do_sequential_copy: rslex_core::file_io::stream_copier: close time.busy=32.8ms time.idle=1.90\\u00b5s sessionId=b73f9e3b-2383-423d-af6c-8af4fb3ab60a source=Dataset[Partitions: 1, Sources: 1] file_name_column=Some(\\\"Portable Path\\\") break_on_first_error=false skip_existing_files=false parallelization_degree=2 self=Dataset[Partitions: 2, Sources: 1] parallelization_degree=2 self=Dataset[Partitions: 2, Sources: 1] parallelization_degree=2 i=1 file_size=517752\\n2023-10-21T21:16:45.773993Z  INFO execute:write_streams_to_files:reduce:reduce_and_combine:reduce: rslex_core::file_io::stream_copier: [StreamCopier::copy()] copied file size=517752 source_handler=\\\"AmlDatastore\\\" source_resource_id=workspaceblobstore/diabetes-data/diabetes.csv destination=diabetes.csv duration=0.0328526 sequential=true sessionId=b73f9e3b-2383-423d-af6c-8af4fb3ab60a source=Dataset[Partitions: 1, Sources: 1] file_name_column=Some(\\\"Portable Path\\\") break_on_first_error=false skip_existing_files=false parallelization_degree=2 self=Dataset[Partitions: 2, Sources: 1] parallelization_degree=2 self=Dataset[Partitions: 2, Sources: 1] parallelization_degree=2 i=1\\n2023-10-21T21:16:45.774041Z  INFO execute:write_streams_to_files:reduce:reduce_and_combine:reduce: rslex::dataset: close time.busy=37.1ms time.idle=15.8\\u00b5s sessionId=b73f9e3b-2383-423d-af6c-8af4fb3ab60a source=Dataset[Partitions: 1, Sources: 1] file_name_column=Some(\\\"Portable Path\\\") break_on_first_error=false skip_existing_files=false parallelization_degree=2 self=Dataset[Partitions: 2, Sources: 1] parallelization_degree=2 self=Dataset[Partitions: 2, Sources: 1] parallelization_degree=2 i=1\\n2023-10-21T21:16:45.774065Z  INFO execute:write_streams_to_files:reduce:reduce_and_combine:combine: rslex::dataset: close time.busy=37.2ms time.idle=13.2\\u00b5s sessionId=b73f9e3b-2383-423d-af6c-8af4fb3ab60a source=Dataset[Partitions: 1, Sources: 1] file_name_column=Some(\\\"Portable Path\\\") break_on_first_error=false skip_existing_files=false parallelization_degree=2 self=Dataset[Partitions: 2, Sources: 1] parallelization_degree=2 self=Dataset[Partitions: 2, Sources: 1] parallelization_degree=2\\n2023-10-21T21:16:45.774154Z  INFO execute:write_streams_to_files:reduce:reduce_and_combine: rslex::dataset: close time.busy=37.4ms time.idle=2.00\\u00b5s sessionId=b73f9e3b-2383-423d-af6c-8af4fb3ab60a source=Dataset[Partitions: 1, Sources: 1] file_name_column=Some(\\\"Portable Path\\\") break_on_first_error=false skip_existing_files=false parallelization_degree=2 self=Dataset[Partitions: 2, Sources: 1] parallelization_degree=2 self=Dataset[Partitions: 2, Sources: 1] parallelization_degree=2\\n2023-10-21T21:16:45.774164Z  INFO execute:write_streams_to_files:reduce: rslex::dataset: close time.busy=37.5ms time.idle=2.10\\u00b5s sessionId=b73f9e3b-2383-423d-af6c-8af4fb3ab60a source=Dataset[Partitions: 1, Sources: 1] file_name_column=Some(\\\"Portable Path\\\") break_on_first_error=false skip_existing_files=false parallelization_degree=2 self=Dataset[Partitions: 2, Sources: 1] parallelization_degree=2\\n2023-10-21T21:16:45.774169Z  INFO execute:write_streams_to_files: rslex::execution::operations::write_streams_to_files: Files copied=2, skipped=0, failed=0 sessionId=b73f9e3b-2383-423d-af6c-8af4fb3ab60a source=Dataset[Partitions: 1, Sources: 1] file_name_column=Some(\\\"Portable Path\\\") break_on_first_error=false skip_existing_files=false parallelization_degree=2\\n2023-10-21T21:16:45.774196Z  INFO execute:write_streams_to_files: rslex::execution::operations::write_streams_to_files: close time.busy=40.8ms time.idle=3.10\\u00b5s sessionId=b73f9e3b-2383-423d-af6c-8af4fb3ab60a source=Dataset[Partitions: 1, Sources: 1] file_name_column=Some(\\\"Portable Path\\\") break_on_first_error=false skip_existing_files=false parallelization_degree=2\\n2023-10-21T21:16:45.774425Z  INFO execute:write_to_files:reduce_and_combine:reduce:get_iter: rslex::prefetching: close time.busy=2.00\\u00b5s time.idle=1.90\\u00b5s sessionId=b73f9e3b-2383-423d-af6c-8af4fb3ab60a source=Dataset[Partitions: 2, Sources: 1] writer=PreppyRecordWriter { profile_fields: KINDS | MISSING_AND_EMPTY, columns_to_intern: [] } parallelization_degree=2 self=Dataset[Partitions: 2, Sources: 1] parallelization_degree=2 i=1 index=0\\n2023-10-21T21:16:45.774586Z  INFO execute:write_to_files:reduce_and_combine:reduce: rslex::execution::serialization::preppy::write: [write_to()] write to preppy, num_records=1, metadata_size=153, file_size=161 sessionId=b73f9e3b-2383-423d-af6c-8af4fb3ab60a source=Dataset[Partitions: 2, Sources: 1] writer=PreppyRecordWriter { profile_fields: KINDS | MISSING_AND_EMPTY, columns_to_intern: [] } parallelization_degree=2 self=Dataset[Partitions: 2, Sources: 1] parallelization_degree=2 i=1\\n2023-10-21T21:16:45.774634Z  INFO execute:write_to_files:reduce_and_combine:reduce:get_iter: rslex::prefetching: close time.busy=800ns time.idle=1.70\\u00b5s sessionId=b73f9e3b-2383-423d-af6c-8af4fb3ab60a source=Dataset[Partitions: 2, Sources: 1] writer=PreppyRecordWriter { profile_fields: KINDS | MISSING_AND_EMPTY, columns_to_intern: [] } parallelization_degree=2 self=Dataset[Partitions: 2, Sources: 1] parallelization_degree=2 i=1 index=1\\n2023-10-21T21:16:45.774681Z  INFO execute:write_to_files:reduce_and_combine:reduce: rslex::execution::serialization::preppy::write: [write_to()] write to preppy, num_records=1, metadata_size=153, file_size=161 sessionId=b73f9e3b-2383-423d-af6c-8af4fb3ab60a source=Dataset[Partitions: 2, Sources: 1] writer=PreppyRecordWriter { profile_fields: KINDS | MISSING_AND_EMPTY, columns_to_intern: [] } parallelization_degree=2 self=Dataset[Partitions: 2, Sources: 1] parallelization_degree=2 i=1\\n2023-10-21T21:16:45.774706Z  INFO execute:write_to_files:reduce_and_combine:reduce: rslex::dataset: close time.busy=295\\u00b5s time.idle=15.3\\u00b5s sessionId=b73f9e3b-2383-423d-af6c-8af4fb3ab60a source=Dataset[Partitions: 2, Sources: 1] writer=PreppyRecordWriter { profile_fields: KINDS | MISSING_AND_EMPTY, columns_to_intern: [] } parallelization_degree=2 self=Dataset[Partitions: 2, Sources: 1] parallelization_degree=2 i=1\\n2023-10-21T21:16:45.774816Z  INFO execute:write_to_files:reduce_and_combine:reduce: rslex::dataset: close time.busy=800ns time.idle=9.70\\u00b5s sessionId=b73f9e3b-2383-423d-af6c-8af4fb3ab60a source=Dataset[Partitions: 2, Sources: 1] writer=PreppyRecordWriter { profile_fields: KINDS | MISSING_AND_EMPTY, columns_to_intern: [] } parallelization_degree=2 self=Dataset[Partitions: 2, Sources: 1] parallelization_degree=2 i=0\\n2023-10-21T21:16:45.774867Z  INFO execute:write_to_files:reduce_and_combine:combine: rslex::dataset: close time.busy=458\\u00b5s time.idle=20.3\\u00b5s sessionId=b73f9e3b-2383-423d-af6c-8af4fb3ab60a source=Dataset[Partitions: 2, Sources: 1] writer=PreppyRecordWriter { profile_fields: KINDS | MISSING_AND_EMPTY, columns_to_intern: [] } parallelization_degree=2 self=Dataset[Partitions: 2, Sources: 1] parallelization_degree=2\\n2023-10-21T21:16:45.774946Z  INFO execute:write_to_files:reduce_and_combine: rslex::dataset: close time.busy=671\\u00b5s time.idle=1.50\\u00b5s sessionId=b73f9e3b-2383-423d-af6c-8af4fb3ab60a source=Dataset[Partitions: 2, Sources: 1] writer=PreppyRecordWriter { profile_fields: KINDS | MISSING_AND_EMPTY, columns_to_intern: [] } parallelization_degree=2 self=Dataset[Partitions: 2, Sources: 1] parallelization_degree=2\\n2023-10-21T21:16:45.774980Z  INFO execute:write_to_files: rslex::execution::operations::write_files: close time.busy=708\\u00b5s time.idle=4.90\\u00b5s sessionId=b73f9e3b-2383-423d-af6c-8af4fb3ab60a source=Dataset[Partitions: 2, Sources: 1] writer=PreppyRecordWriter { profile_fields: KINDS | MISSING_AND_EMPTY, columns_to_intern: [] } parallelization_degree=2\\n2023-10-21T21:16:45.775008Z  INFO execute: rslex: [execute()] Converting RecordBatches to CDataArrays and CDataSchemas sessionId=b73f9e3b-2383-423d-af6c-8af4fb3ab60a\\n2023-10-21T21:16:45.775209Z  INFO execute: rslex: [execute_dataflow()] Finish execute num_batches=0 fields=[] partitions=2 sessionId=b73f9e3b-2383-423d-af6c-8af4fb3ab60a\\n2023-10-21T21:16:45.775236Z  INFO execute: rslex: close time.busy=125ms time.idle=23.9\\u00b5s sessionId=b73f9e3b-2383-423d-af6c-8af4fb3ab60a\\n2023-10-21T21:16:45.859373Z  INFO execute: rslex: [execute_dataflow()] Starting execute sessionId=b73f9e3b-2383-423d-af6c-8af4fb3ab60a\\n2023-10-21T21:16:45.859554Z  INFO execute: rslex_script::dataflow: Dataflow::from_yaml_string::transformations: [ \\\"take, add_columns, write_files\\\" ]     sessionId=b73f9e3b-2383-423d-af6c-8af4fb3ab60a\\n2023-10-21T21:16:45.859726Z  INFO rslex_azureml::azureml::handler: [AzureMLHandler::parse_uri()] Parse uri [azureml://subscriptions/42233ac3-1d6b-40e9-920d-ae1ce13376ed/resourcegroups/rg-dp100-labs/workspaces/mlw-dp100-labs/datastores/workspaceblobstore/paths/diabetes-data/*.csv]\\n2023-10-21T21:16:45.909705Z  INFO search: rslex_azure_storage::blob_stream_handler::searcher: [Searcher::search()] scan diabetes-data/(*.csv) 4 files and 0 dirs, matching 2 files, 0 more searches\\n2023-10-21T21:16:45.909747Z  INFO search: rslex_azure_storage::blob_stream_handler::searcher: close time.busy=313\\u00b5s time.idle=49.4ms\\n2023-10-21T21:16:45.909780Z  INFO find_streams: rslex_azureml::data_store::stream_handler::handler: close time.busy=50.0ms time.idle=2.20\\u00b5s resource_id=\\\"workspaceblobstore/diabetes-data/*.csv\\\"\\n2023-10-21T21:16:45.909835Z  INFO execute:get_files: rslex::execution::operations::get_files: close time.busy=17.5\\u00b5s time.idle=50.1ms sessionId=b73f9e3b-2383-423d-af6c-8af4fb3ab60a\\n2023-10-21T21:16:45.909896Z  INFO execute:take: rslex::execution::operations::take: close time.busy=28.8\\u00b5s time.idle=12.2\\u00b5s sessionId=b73f9e3b-2383-423d-af6c-8af4fb3ab60a source=Dataset[Partitions: 1, Sources: 1] count=1 parallelization_degree=2\\n2023-10-21T21:16:45.909914Z  INFO execute:add_columns: rslex::execution::operations::add_columns: close time.busy=1.10\\u00b5s time.idle=1.60\\u00b5s sessionId=b73f9e3b-2383-423d-af6c-8af4fb3ab60a source_dataset=Dataset[Partitions: 1, Sources: 1]\\n2023-10-21T21:16:45.910145Z  INFO execute:write_to_files:reduce_and_combine:reduce:get_iter: rslex::prefetching: close time.busy=29.5\\u00b5s time.idle=1.70\\u00b5s sessionId=b73f9e3b-2383-423d-af6c-8af4fb3ab60a source=Dataset[Partitions: 1, Sources: 1] writer=PreppyRecordWriter { profile_fields: KINDS | MISSING_AND_EMPTY, columns_to_intern: [] } parallelization_degree=2 self=Dataset[Partitions: 1, Sources: 1] parallelization_degree=2 i=0 index=0\\n2023-10-21T21:16:45.910300Z  INFO execute:write_to_files:reduce_and_combine:reduce: rslex::execution::serialization::preppy::write: [write_to()] write to preppy, num_records=1, metadata_size=262, file_size=270 sessionId=b73f9e3b-2383-423d-af6c-8af4fb3ab60a source=Dataset[Partitions: 1, Sources: 1] writer=PreppyRecordWriter { profile_fields: KINDS | MISSING_AND_EMPTY, columns_to_intern: [] } parallelization_degree=2 self=Dataset[Partitions: 1, Sources: 1] parallelization_degree=2 i=0\\n2023-10-21T21:16:45.910356Z  INFO execute:write_to_files:reduce_and_combine:reduce: rslex::dataset: close time.busy=250\\u00b5s time.idle=17.7\\u00b5s sessionId=b73f9e3b-2383-423d-af6c-8af4fb3ab60a source=Dataset[Partitions: 1, Sources: 1] writer=PreppyRecordWriter { profile_fields: KINDS | MISSING_AND_EMPTY, columns_to_intern: [] } parallelization_degree=2 self=Dataset[Partitions: 1, Sources: 1] parallelization_degree=2 i=0\\n2023-10-21T21:16:45.910394Z  INFO execute:write_to_files:reduce_and_combine:combine: rslex::dataset: close time.busy=318\\u00b5s time.idle=21.6\\u00b5s sessionId=b73f9e3b-2383-423d-af6c-8af4fb3ab60a source=Dataset[Partitions: 1, Sources: 1] writer=PreppyRecordWriter { profile_fields: KINDS | MISSING_AND_EMPTY, columns_to_intern: [] } parallelization_degree=2 self=Dataset[Partitions: 1, Sources: 1] parallelization_degree=2\\n2023-10-21T21:16:45.912028Z  INFO execute:write_to_files:reduce_and_combine: rslex::dataset: close time.busy=2.10ms time.idle=2.80\\u00b5s sessionId=b73f9e3b-2383-423d-af6c-8af4fb3ab60a source=Dataset[Partitions: 1, Sources: 1] writer=PreppyRecordWriter { profile_fields: KINDS | MISSING_AND_EMPTY, columns_to_intern: [] } parallelization_degree=2 self=Dataset[Partitions: 1, Sources: 1] parallelization_degree=2\\n2023-10-21T21:16:45.912079Z  INFO execute:write_to_files: rslex::execution::operations::write_files: close time.busy=2.15ms time.idle=2.70\\u00b5s sessionId=b73f9e3b-2383-423d-af6c-8af4fb3ab60a source=Dataset[Partitions: 1, Sources: 1] writer=PreppyRecordWriter { profile_fields: KINDS | MISSING_AND_EMPTY, columns_to_intern: [] } parallelization_degree=2\\n2023-10-21T21:16:45.912116Z  INFO execute: rslex: [execute()] Converting RecordBatches to CDataArrays and CDataSchemas sessionId=b73f9e3b-2383-423d-af6c-8af4fb3ab60a\\n2023-10-21T21:16:45.912273Z  INFO execute: rslex: [execute_dataflow()] Finish execute num_batches=0 fields=[] partitions=1 sessionId=b73f9e3b-2383-423d-af6c-8af4fb3ab60a\\n2023-10-21T21:16:45.912301Z  INFO execute: rslex: close time.busy=52.9ms time.idle=6.80\\u00b5s sessionId=b73f9e3b-2383-423d-af6c-8af4fb3ab60a\\n\\nRun is completed.\", \"graph\": {}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.51.0\"}, \"loading\": false}"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "execution_count": 15,
          "data": {
            "text/plain": "{'runId': 'mslearn-train-diabetes_1697922920_5eb49cd0',\n 'target': 'coursera-cluster',\n 'status': 'Completed',\n 'startTimeUtc': '2023-10-21T21:15:39.180862Z',\n 'endTimeUtc': '2023-10-21T21:17:02.703051Z',\n 'services': {},\n 'properties': {'_azureml.ComputeTargetType': 'amlctrain',\n  'ContentSnapshotId': '16a9e46a-b440-48ae-bfcf-d13b6029f6b5',\n  'ProcessInfoFile': 'azureml-logs/process_info.json',\n  'ProcessStatusFile': 'azureml-logs/process_status.json'},\n 'inputDatasets': [{'dataset': {'id': '61b5f62b-9636-473e-bd16-9d7054cf841d'}, 'consumptionDetails': {'type': 'RunInput', 'inputName': 'training_files', 'mechanism': 'Download'}}],\n 'outputDatasets': [],\n 'runDefinition': {'script': 'diabetes_training.py',\n  'command': '',\n  'useAbsolutePath': False,\n  'arguments': ['--regularization',\n   '0.1',\n   '--input-data',\n   'DatasetConsumptionConfig:training_files'],\n  'sourceDirectoryDataStore': None,\n  'framework': 'Python',\n  'communicator': 'None',\n  'target': 'coursera-cluster',\n  'dataReferences': {},\n  'data': {'training_files': {'dataLocation': {'dataset': {'id': '61b5f62b-9636-473e-bd16-9d7054cf841d',\n      'name': 'diabetes file dataset',\n      'version': '1'},\n     'dataPath': None,\n     'uri': None,\n     'type': None},\n    'mechanism': 'Download',\n    'environmentVariableName': 'training_files',\n    'pathOnCompute': None,\n    'overwrite': False,\n    'options': None}},\n  'outputData': {},\n  'datacaches': [],\n  'jobName': None,\n  'maxRunDurationSeconds': 2592000,\n  'nodeCount': 1,\n  'instanceTypes': [],\n  'priority': None,\n  'credentialPassthrough': False,\n  'identity': None,\n  'environment': {'name': 'experiment_env',\n   'version': 'Autosave_2023-10-20T17:56:40Z_36c27fbb',\n   'assetId': 'azureml://locations/eastus2/workspaces/699734a3-1bff-45ae-b4a4-07c66269f461/environments/experiment_env/versions/Autosave_2023-10-20T17:56:40Z_36c27fbb',\n   'autoRebuild': True,\n   'python': {'interpreterPath': 'python',\n    'userManagedDependencies': False,\n    'condaDependencies': {'dependencies': ['python=3.6.2',\n      'scikit-learn',\n      'pandas',\n      'pip',\n      {'pip': ['azureml-defaults', 'azureml-mlflow']}],\n     'name': 'simple_environment'},\n    'baseCondaEnvironment': None},\n   'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'},\n   'docker': {'baseImage': 'mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:20230509.v1',\n    'platform': {'os': 'Linux', 'architecture': 'amd64'},\n    'baseDockerfile': None,\n    'baseImageRegistry': {'address': None, 'username': None, 'password': None},\n    'enabled': False,\n    'arguments': []},\n   'spark': {'repositories': [], 'packages': [], 'precachePackages': True},\n   'inferencingStackVersion': None},\n  'history': {'outputCollection': True,\n   'directoriesToWatch': ['logs'],\n   'enableMLflowTracking': True,\n   'snapshotProject': True},\n  'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment',\n    'spark.yarn.maxAppAttempts': '1'}},\n  'parallelTask': {'maxRetriesPerWorker': 0,\n   'workerCountPerNode': 1,\n   'terminalExitCodes': None,\n   'configuration': {}},\n  'amlCompute': {'name': None,\n   'vmSize': None,\n   'retainCluster': False,\n   'clusterMaxNodeCount': None},\n  'aiSuperComputer': {'instanceType': 'D2',\n   'imageVersion': None,\n   'location': None,\n   'aiSuperComputerStorageData': None,\n   'interactive': False,\n   'scalePolicy': None,\n   'virtualClusterArmId': None,\n   'tensorboardLogDirectory': None,\n   'sshPublicKey': None,\n   'sshPublicKeys': None,\n   'enableAzmlInt': True,\n   'priority': 'Medium',\n   'slaTier': 'Standard',\n   'userAlias': None},\n  'kubernetesCompute': {'instanceType': None},\n  'tensorflow': {'workerCount': 1, 'parameterServerCount': 1},\n  'mpi': {'processCountPerNode': 1},\n  'pyTorch': {'communicationBackend': 'nccl', 'processCount': None},\n  'hdi': {'yarnDeployMode': 'Cluster'},\n  'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5},\n  'exposedPorts': None,\n  'docker': {'useDocker': True,\n   'sharedVolumes': True,\n   'shmSize': '2g',\n   'arguments': []},\n  'cmk8sCompute': {'configuration': {}},\n  'commandReturnCodeConfig': {'returnCode': 'Zero',\n   'successfulReturnCodes': []},\n  'environmentVariables': {},\n  'applicationEndpoints': {},\n  'parameters': []},\n 'logFiles': {'user_logs/std_log.txt': 'https://mlwdp100labs0576378376.blob.core.windows.net/azureml/ExperimentRun/dcid.mslearn-train-diabetes_1697922920_5eb49cd0/user_logs/std_log.txt?sv=2019-07-07&sr=b&sig=BQhNsm3VC2bkdBV5VVNNGqDqqlvSoqzmW8CJ86IbDWU%3D&skoid=b22ab211-1a77-4e41-b54e-76819173f4ea&sktid=54f76ea3-fed9-41fc-a628-e91383900a39&skt=2023-10-21T20%3A35%3A09Z&ske=2023-10-23T04%3A45%3A09Z&sks=b&skv=2019-07-07&st=2023-10-21T21%3A07%3A08Z&se=2023-10-22T05%3A17%3A08Z&sp=r',\n  'system_logs/cs_capability/cs-capability.log': 'https://mlwdp100labs0576378376.blob.core.windows.net/azureml/ExperimentRun/dcid.mslearn-train-diabetes_1697922920_5eb49cd0/system_logs/cs_capability/cs-capability.log?sv=2019-07-07&sr=b&sig=klxLWcvCoUgCX%2BU4LUmiIyzvYSFk7aFTRzN7BwKYCFo%3D&skoid=b22ab211-1a77-4e41-b54e-76819173f4ea&sktid=54f76ea3-fed9-41fc-a628-e91383900a39&skt=2023-10-21T20%3A35%3A11Z&ske=2023-10-23T04%3A45%3A11Z&sks=b&skv=2019-07-07&st=2023-10-21T21%3A07%3A08Z&se=2023-10-22T05%3A17%3A08Z&sp=r',\n  'system_logs/data_capability/data-capability.log': 'https://mlwdp100labs0576378376.blob.core.windows.net/azureml/ExperimentRun/dcid.mslearn-train-diabetes_1697922920_5eb49cd0/system_logs/data_capability/data-capability.log?sv=2019-07-07&sr=b&sig=cIxmZqODevgHMuzONfEbi3c13Rw5Avk1aKnoYgLnEx8%3D&skoid=b22ab211-1a77-4e41-b54e-76819173f4ea&sktid=54f76ea3-fed9-41fc-a628-e91383900a39&skt=2023-10-21T20%3A35%3A11Z&ske=2023-10-23T04%3A45%3A11Z&sks=b&skv=2019-07-07&st=2023-10-21T21%3A07%3A08Z&se=2023-10-22T05%3A17%3A08Z&sp=r',\n  'system_logs/data_capability/rslex.log.2023-10-21-21': 'https://mlwdp100labs0576378376.blob.core.windows.net/azureml/ExperimentRun/dcid.mslearn-train-diabetes_1697922920_5eb49cd0/system_logs/data_capability/rslex.log.2023-10-21-21?sv=2019-07-07&sr=b&sig=OR%2FDITXx97kz58k9AhQ1GSaOKiqxoITRnS3GQ0lVIoI%3D&skoid=b22ab211-1a77-4e41-b54e-76819173f4ea&sktid=54f76ea3-fed9-41fc-a628-e91383900a39&skt=2023-10-21T20%3A35%3A11Z&ske=2023-10-23T04%3A45%3A11Z&sks=b&skv=2019-07-07&st=2023-10-21T21%3A07%3A08Z&se=2023-10-22T05%3A17%3A08Z&sp=r',\n  'system_logs/hosttools_capability/hosttools-capability.log': 'https://mlwdp100labs0576378376.blob.core.windows.net/azureml/ExperimentRun/dcid.mslearn-train-diabetes_1697922920_5eb49cd0/system_logs/hosttools_capability/hosttools-capability.log?sv=2019-07-07&sr=b&sig=%2B7jgUGTi%2F2SUBiQVFEcRx7mUheED72gTt8WzYbkj9kM%3D&skoid=b22ab211-1a77-4e41-b54e-76819173f4ea&sktid=54f76ea3-fed9-41fc-a628-e91383900a39&skt=2023-10-21T20%3A35%3A11Z&ske=2023-10-23T04%3A45%3A11Z&sks=b&skv=2019-07-07&st=2023-10-21T21%3A07%3A08Z&se=2023-10-22T05%3A17%3A08Z&sp=r',\n  'system_logs/lifecycler/execution-wrapper.log': 'https://mlwdp100labs0576378376.blob.core.windows.net/azureml/ExperimentRun/dcid.mslearn-train-diabetes_1697922920_5eb49cd0/system_logs/lifecycler/execution-wrapper.log?sv=2019-07-07&sr=b&sig=3B1Qb%2F5Y98drr6%2BgzN52dKjNv1rHUZS5RvP7zU5dr%2Bk%3D&skoid=b22ab211-1a77-4e41-b54e-76819173f4ea&sktid=54f76ea3-fed9-41fc-a628-e91383900a39&skt=2023-10-21T20%3A35%3A11Z&ske=2023-10-23T04%3A45%3A11Z&sks=b&skv=2019-07-07&st=2023-10-21T21%3A07%3A08Z&se=2023-10-22T05%3A17%3A08Z&sp=r',\n  'system_logs/lifecycler/lifecycler.log': 'https://mlwdp100labs0576378376.blob.core.windows.net/azureml/ExperimentRun/dcid.mslearn-train-diabetes_1697922920_5eb49cd0/system_logs/lifecycler/lifecycler.log?sv=2019-07-07&sr=b&sig=3sZToJiLEgoY6%2FEltADylf5XHeEJqTCxN%2Fs1NzKWrfQ%3D&skoid=b22ab211-1a77-4e41-b54e-76819173f4ea&sktid=54f76ea3-fed9-41fc-a628-e91383900a39&skt=2023-10-21T20%3A35%3A11Z&ske=2023-10-23T04%3A45%3A11Z&sks=b&skv=2019-07-07&st=2023-10-21T21%3A07%3A08Z&se=2023-10-22T05%3A17%3A08Z&sp=r',\n  'system_logs/metrics_capability/metrics-capability.log': 'https://mlwdp100labs0576378376.blob.core.windows.net/azureml/ExperimentRun/dcid.mslearn-train-diabetes_1697922920_5eb49cd0/system_logs/metrics_capability/metrics-capability.log?sv=2019-07-07&sr=b&sig=uDvAT5xEDKPF347vGbaTIEh0FRL9q5IPHrOEV4Zvyu0%3D&skoid=b22ab211-1a77-4e41-b54e-76819173f4ea&sktid=54f76ea3-fed9-41fc-a628-e91383900a39&skt=2023-10-21T20%3A35%3A11Z&ske=2023-10-23T04%3A45%3A11Z&sks=b&skv=2019-07-07&st=2023-10-21T21%3A07%3A08Z&se=2023-10-22T05%3A17%3A08Z&sp=r',\n  'system_logs/snapshot_capability/snapshot-capability.log': 'https://mlwdp100labs0576378376.blob.core.windows.net/azureml/ExperimentRun/dcid.mslearn-train-diabetes_1697922920_5eb49cd0/system_logs/snapshot_capability/snapshot-capability.log?sv=2019-07-07&sr=b&sig=gGgbdn7FfLauaG1k5vwlecKsOv5eHs6ijMhQFojrpX0%3D&skoid=b22ab211-1a77-4e41-b54e-76819173f4ea&sktid=54f76ea3-fed9-41fc-a628-e91383900a39&skt=2023-10-21T20%3A35%3A11Z&ske=2023-10-23T04%3A45%3A11Z&sks=b&skv=2019-07-07&st=2023-10-21T21%3A07%3A08Z&se=2023-10-22T05%3A17%3A08Z&sp=r'},\n 'submittedBy': 'Gabriel Ichcanziho Pérez Landa'}"
          },
          "metadata": {}
        }
      ],
      "execution_count": 15,
      "metadata": {
        "gather": {
          "logged": 1697923029042
        },
        "scrolled": true,
        "vscode": {
          "languageId": "python"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "When the experiment has completed, in the widget, view the **azureml-logs/70_driver_log.txt** output log to verify that the files in the file dataset were downloaded to a temporary folder to enable the script to read the files.\n",
        "\n",
        "### Register the trained model\n",
        "\n",
        "Once again, you can register the model that was trained by the experiment."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Model\n",
        "\n",
        "run.register_model(model_path='outputs/diabetes_model.pkl', model_name='diabetes_model',\n",
        "                   tags={'Training context':'File dataset'}, properties={'AUC': run.get_metrics()['AUC'], 'Accuracy': run.get_metrics()['Accuracy']})\n",
        "\n",
        "for model in Model.list(ws):\n",
        "    print(model.name, 'version:', model.version)\n",
        "    for tag_name in model.tags:\n",
        "        tag = model.tags[tag_name]\n",
        "        print ('\\t',tag_name, ':', tag)\n",
        "    for prop_name in model.properties:\n",
        "        prop = model.properties[prop_name]\n",
        "        print ('\\t',prop_name, ':', prop)\n",
        "    print('\\n')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "diabetes_model version: 4\n\t Training context : File dataset\n\t AUC : 0.8468514889078735\n\t Accuracy : 0.7788888888888889\n\n\ndiabetes_model version: 3\n\t Training context : Tabular dataset\n\t AUC : 0.8568650620553335\n\t Accuracy : 0.7893333333333333\n\n\ndiabetes_model version: 2\n\t Training context : Parameterized script\n\t AUC : 0.8484377332205582\n\t Accuracy : 0.774\n\t Regularization Rate : 0.1\n\n\ndiabetes_model version: 1\n\t Training context : Script\n\t AUC : 0.8483441962286681\n\t Accuracy : 0.774\n\n\n"
        }
      ],
      "execution_count": 16,
      "metadata": {
        "gather": {
          "logged": 1697923525038
        },
        "vscode": {
          "languageId": "python"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **More Information**: For more information about training with datasets, see [Training with Datasets](https://docs.microsoft.com/azure/machine-learning/how-to-train-with-datasets) in the Azure ML documentation."
      ],
      "metadata": {}
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "f2b2cd046deda8eabef1e765a11d0ec9aa9bd1d31d56ce79c815a38c323e14ec"
      }
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}