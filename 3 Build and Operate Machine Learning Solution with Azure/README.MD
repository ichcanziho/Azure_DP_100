# Build and Operate Machine Learning Solutions with Azure

## 0 INDEX:

- [1 Welcome to the Course](#1-welcome-to-the-course)
- [2 Introduction to the Azure Machine Learning SDK](#2-introduction-to-the-azure-machine-learning-sdk)
- [3 Train a machine learning model with Azure Machine Learning](#3-train-a-machine-learning-model-with-azure-machine-learning)
- [4 Work with Data in Azure Machine Learning](#4-work-with-data-in-azure-machine-learning)
- [5 Work with Compute in Azure Machine Learning](#5-work-with-compute-in-azure-machine-learning)
- [6 Orchestrate Machine Learning with Pipelines](#6-orchestrate-machine-learning-with-pipelines)
- [7 Deploy real-time machine learning services with Azure Machine Learning](#7-deploy-real-time-machine-learning-services-with-azure-machine-learning)
- [8 Deploy batch inference pipelines with Azure Machine Learning](#8-deploy-batch-inference-pipelines-with-azure-machine-learning)
- [9 Tune hyperparameters with Azure Machine Learning](#9-tune-hyperparameters-with-azure-machine-learning)
- [10 Automate machine learning model selection with Azure Machine Learning](#10-automate-machine-learning-model-selection-with-azure-machine-learning)
- [11 Explore differential privacy](#11-explore-differential-privacy)
- [12 Explain machine learning models with Azure Machine Learning](#12-explain-machine-learning-models-with-azure-machine-learning)
- [13 Detect and mitigate unfairness in models with Azure Machine Learning](#13-detect-and-mitigate-unfairness-in-models-with-azure-machine-learning)
- [14 Monitor Models with Azure Machine Learning](#14-monitor-models-with-azure-machine-learning)
- [15 Monitor data drift with Azure Machine Learning](#15-monitor-data-drift-with-azure-machine-learning)

# 1 Welcome to the Course

## 1 INDEX:

- [Introduction to Modern Data Warehouse Analytics in Azure](#introduction-to-modern-data-warehouse-analytics-in-azure)
- [Course Syllabus](#course-syllabus)
- [How to be successful in this course](#how-to-be-successful-in-this-course)

[< Back to index](#0-index)

## Introduction to Modern Data Warehouse Analytics in Azure
[< Back to Local Index](#1-index)

![1.png](ims%2FC1%2F1.png)

Hola y bienvenido a este curso, construir y operar soluciones de aprendizaje automático con Azure Machine Learning. En este curso, 
aprenderá a utilizar el Python Azure Machine Learning, SDK, para crear y gestionar soluciones ML listas para la empresa. 

![2.png](ims%2FC1%2F2.png)

Este curso se compone de los siguientes módulos. 

- Utilice el SDK de Azure Machine Learning para entrenar un modelo.
- Trabaje con datos y computación en Azure Machine Learning.
- Orqueste pipelines y despliegue servicios de aprendizaje automático en tiempo real con Azure Machine Learning.
- Despliegue pipelines de inferencia por lotes y ajuste hiperparámetros con Azure Machine Learning. 
- Seleccione modelos y proteja datos sensibles.
- Monitorice despliegues de aprendizaje automático. 

![3.png](ims%2FC1%2F3.png)

Comencemos con el primer módulo. Utilice el SDK de Azure Machine Learning para entrenar un modelo.

![4.png](ims%2FC1%2F4.png)

En este curso, aprovisionará un espacio de trabajo de Azure Machine Learning, utilizará herramientas e interfaces para 
trabajar con Azure Machine Learning, ejecutará experimentos basados en código en espacio de trabajo de Azure Machine Learning. 
Utilice una configuración de ejecución de secuencias de comandos para ejecutar una secuencia de comandos de entrenamiento 
de modelos como Azure Machine Learning, crear secuencias de comandos de entrenamiento parametrizadas reutilizables, y 
registrar modelos entrenados.

![5.png](ims%2FC1%2F5.png)

En el siguiente módulo, explorará cómo entrenar y evaluar modelos de clasificación y agrupación.

![6.png](ims%2FC1%2F6.png)

Los datos son la base del aprendizaje automático. En este módulo, aprenderá a trabajar con almacenes de datos en conjuntos 
de datos en Azure Machine Learning, lo que le permitirá construir soluciones escalables de entrenamiento de modelos basadas 
en la nube. También aprenderá a utilizar Cloud Compute en Azure Machine Learning para ejecutar experimentos de entrenamiento 
a escala. 

![7.png](ims%2FC1%2F7.png)

A continuación, aprenderá a orquestar pipelines y desplegar servicios de aprendizaje automático en tiempo real 
con Azure Machine Learning.

![8.png](ims%2FC1%2F8.png)

En este módulo, aprenderá a crear, publicar, y ejecutar pipelines para entrenar modelos en Azure Machine Learning. 

![9.png](ims%2FC1%2F9.png)

También aprenderá a registrar y desplegar modelos ML con el servicio Azure Machine Learning.


![10.png](ims%2FC1%2F10.png)

A continuación, aprenderá a desplegar pipelines de inferencia por lotes y ajustar hiperparámetros con Azure Machine Learning. 


![11.png](ims%2FC1%2F11.png)

Los modelos de aprendizaje automático se utilizan a menudo para generar predicciones a partir de un gran número de observaciones 
en un proceso por lotes. En este módulo, logrará esto utilizando Azure Machine Learning para publicar un pipeline de inferencia por 
lotes. También aprovechará los experimentos a escala de la nube para elegir los valores óptimos de los hiperparámetros 
para el entrenamiento del modelo

![12.png](ims%2FC1%2F12.png)

A continuación, aprenderá a seleccionar modelos y proteger datos sensibles. 

![13.png](ims%2FC1%2F13.png)

En este módulo, aprenderá a utilizar el aprendizaje automático automatizado en Azure Machine Learning para encontrar el 
mejor modelo para sus datos. Aprenderá cómo la privacidad diferencial es un enfoque de vanguardia que permite un análisis 
útil a la vez que protege los valores de los datos identificables individualmente. También conocerá los factores que influyen 
en las predicciones que hacen los modelos. 

![14.png](ims%2FC1%2F14.png)

Por último, aprenderá a supervisar las implantaciones de aprendizaje automático. Los modelos de aprendizaje automático a 
menudo pueden encapsular sesgos involuntarios que resultan injustos. 

![15.png](ims%2FC1%2F15.png)

En este módulo, aprenderá a utilizar Fairlearn en Azure Machine Learning para detectar y mitigar la injusticia en sus modelos. 
Aprenderá a utilizar la telemetría para comprender cómo se está utilizando un modelo de aprendizaje automático una vez que 
se ha desplegado en producción. Por último, aprenderá a supervisar la deriva de los datos para asegurarse de que su modelo 
sigue prediciendo con precisión.

![16.png](ims%2FC1%2F16.png)

Además, a lo largo de este curso, tendrá la oportunidad de explorar los modelos de aprendizaje automático en Microsoft Azure 
a través de ejercicios interactivos y ejemplos reales de ciencia de datos en acción, comprobaciones de conocimientos y 
exámenes de práctica. Le deseamos mucho éxito al iniciar este viaje de aprendizaje.

## Course Syllabus
[< Back to Local Index](#1-index)

Azure Machine Learning es una plataforma en la nube para entrenar, desplegar, gestionar y monitorizar modelos de aprendizaje 
automático. En este módulo, aprenderá a utilizar el SDK Python de Azure Machine Learning para crear y gestionar soluciones ML 
listas para la empresa.

### Módulo 1 - Utilizar el SDK de Azure Machine Learning para entrenar un modelo
Azure Machine Learning proporciona una plataforma basada en la nube para entrenar, desplegar y gestionar modelos de aprendizaje 
automático. En este módulo, aprenderá a aprovisionar un espacio de trabajo de Azure Machine Learning. Utilizará herramientas 
e interfaces para trabajar con Azure Machine Learning y ejecutar experimentos basados en código en un espacio de trabajo de 
Azure Machine Learning. Por último, aprenderá a utilizar Azure Machine Learning para entrenar un modelo y registrarlo en 
un espacio de trabajo.

### Módulo 2 - Trabajar con datos y computación en Azure Machine Learning
Los datos son la base del aprendizaje automático. En este módulo, aprenderá a trabajar con almacenes de datos y conjuntos 
de datos en Azure Machine Learning, lo que le permitirá construir soluciones de entrenamiento de modelos escalables y 
basadas en la nube. También aprenderá a utilizar la computación en la nube en Azure Machine Learning para ejecutar experimentos 
de entrenamiento a escala.

### Módulo 3 - Orquestrar pipelines y desplegar servicios de aprendizaje automático en tiempo real con Azure Machine Learning
Orquestar el entrenamiento de aprendizaje automático con pipelines es un elemento clave de DevOps para el aprendizaje automático. 
En este módulo, aprenderá a crear, publicar y ejecutar canalizaciones para entrenar modelos en Azure Machine Learning. 
También aprenderá a registrar y desplegar modelos ML con el servicio Azure Machine Learning.

### Módulo 4 - Despliegue pipelines de inferencia por lotes y ajuste hiperparámetros con Azure Machine Learning
Los modelos de aprendizaje automático se utilizan a menudo para generar predicciones a partir de un gran número de observaciones 
en un proceso por lotes. Logrará esto utilizando Azure Machine Learning para publicar una canalización de inferencia por lotes. 
También aprovechará los experimentos a escala de la nube para elegir los valores óptimos de hiperparámetros para el entrenamiento de modelos.

### Módulo 5 - Seleccionar modelos y proteger datos sensibles
En este módulo, aprenderá a utilizar el aprendizaje automático en Azure Machine Learning para encontrar el mejor modelo 
para sus datos. Aprenderá cómo la privacidad diferencial es un enfoque de vanguardia que permite realizar análisis útiles 
a la vez que protege los valores de datos identificables individualmente. También conocerá los factores que influyen en las 
predicciones que realizan los modelos.

### Módulo 6 - Supervisar los despliegues de aprendizaje automático
Los modelos de aprendizaje automático a menudo pueden encapsular sesgos involuntarios que dan lugar a injusticias. En este módulo, 
aprenderá a utilizar Fairlearn y Azure Machine Learning para detectar y mitigar la injusticia en sus modelos. Aprenderá a 
utilizar la telemetría para comprender cómo se está utilizando un modelo de aprendizaje automático una vez desplegado en producción. 
Por último, aprenderá a supervisar la deriva de los datos para asegurarse de que su modelo sigue prediciendo con precisión.

## How to be successful in this course
[< Back to Local Index](#1-index)

Hacer un curso en línea puede resultar abrumador. ¿Cómo puede aprender a su propio ritmo y alcanzar con éxito sus objetivos?

He aquí algunos consejos generales que pueden ayudarle a mantenerse centrado y en el buen camino:

#### 1: Fíjese objetivos diarios de estudio
Pregúntese qué espera conseguir en su curso cada día. Establecer un objetivo claro puede ayudarle a mantenerse motivado y 
a vencer la procrastinación. El objetivo debe ser específico y fácil de medir, como "Veré todos los vídeos del módulo 2 
y completaré la primera tarea de programación" Y no olvide recompensarse cuando avance hacia su objetivo.

### 2: Cree un espacio dedicado al estudio
Es más fácil recordar la información si se está en el mismo lugar donde se aprendió por primera vez, por lo que tener un 
espacio dedicado en casa para tomar cursos en línea puede hacer que su aprendizaje sea más eficaz. Elimine cualquier 
distracción del espacio y, si es posible, sepárelo de su cama o sofá. Una clara distinción entre el lugar donde estudia 
y el lugar donde se toma los descansos puede ayudarle a concentrarse.

### 3: Programe tiempo para estudiar en su calendario
Abra su calendario y elija un horario predecible y fiable que pueda dedicar a ver las clases y completar las tareas. 
Esto le ayudará a asegurarse de que sus cursos no se conviertan en la última cosa de su lista de tareas.

> Consejo: Puede añadir las fechas límite de un curso de Coursera su calendario de Google, al calendario de Apple o a otra aplicación de calendario.

### 4: Hágase responsable
Cuénteles a sus amigos los cursos que está realizando, publique sus logros en sus cuentas de las redes sociales o publique 
en un blog sus tareas. Contar con una comunidad y una red de apoyo de amigos y familiares que le animen marca la diferencia.

### 5: Tome notas activamente
Tomar apuntes puede fomentar el pensamiento activo, impulsar la comprensión y ampliar su capacidad de atención. Es una 
buena estrategia para interiorizar los conocimientos tanto si aprende en línea como en el aula. Así pues, coja un cuaderno 
o encuentre la aplicación digital que mejor se adapte a usted y empiece a sintetizar los puntos clave.

> Consejo: Mientras ve una clase en Coursera, puede hacer clic en el botón "Guardar nota" situado debajo del vídeo para guardar una captura de pantalla en sus notas del curso y añadir sus propios comentarios.

### 6: Únase a la discusión
Los foros de discusión del curso son un lugar estupendo para hacer preguntas sobre las tareas, discutir temas, compartir 
recursos y hacer amigos. Nuestras investigaciones demuestran que los alumnos que participan en los foros de debate tienen 
un 37% más de probabilidades de completar un curso. Así que ¡haga un post hoy mismo!

### 7: Haga una cosa cada vez
La multitarea es menos productiva que centrarse en una sola tarea a la vez. Investigadores de la Universidad de Stanford 
descubrieron que "las personas que son bombardeadas regularmente con varios flujos de información electrónica no pueden 
prestar atención, recordar información o cambiar de un trabajo a otro tan bien como los que completan una tarea a la vez" 
Concéntrese en una cosa cada vez. Absorberá más información y completará las tareas con mayor productividad y facilidad 
que si intentara hacer muchas cosas a la vez.

### 8: Tómese descansos
Descansar el cerebro después de aprender es fundamental para un alto rendimiento. Si se encuentra trabajando en un problema 
difícil sin avanzar mucho durante una hora, tómese un descanso. Caminar al aire libre, darse una ducha o hablar con un amigo 
puede re-energizarle e incluso darle nuevas ideas sobre cómo abordar ese proyecto.

¡Su viaje de aprendizaje de Microsoft Azure comienza ahora!
Mientras se prepara para el examen o trabaja en la consecución de sus objetivos de aprendizaje, le animamos a:

- Revise las directrices del examen y las habilidades medidas como punto de partida.
- Trabaje a través de cada lección del itinerario de aprendizaje. 
- Intente no saltarse ninguna actividad o lección a menos que esté seguro de que ya conoce esta información lo suficientemente bien como para seguir adelante.
- Aproveche la oportunidad para volver atrás y ver un vídeo o leer la información adicional que se le proporcione antes de pasar a la siguiente lección o módulo.
- Complete todos los cuestionarios, las preguntas de práctica del examen y los ejercicios. Durante las sesiones de práctica, tendrá la oportunidad de volver a repasar las preguntas para asegurarse de que está satisfecho con su progreso.
- Lea atentamente los comentarios cuando responda a los cuestionarios o a los exámenes prácticos, ya que le ayudarán a reforzar lo que está aprendiendo.

Aproveche el entorno de aprendizaje práctico que le proporcionan los ejercicios. Podrá obtener un refuerzo sustancial de su aprendizaje mediante la aplicación paso a paso de sus conocimientos.

# 2 Introduction to the Azure Machine Learning SDK

## 2 INDEX:

- [2 Lesson Introduction](#2-lesson-introduction)
- [2 Azure Machine Learning Workspaces](#2-azure-machine-learning-workspaces)
- [2 Exercise - Create a Workspace](#2-exercise---create-a-workspace)
- [2 Exercise Quiz 1](#2-exercise-quiz-1)
- [2 Azure Machine Learning tools and interfaces](#2-azure-machine-learning-tools-and-interfaces)
- [2 Azure Machine Learning experiments](#2-azure-machine-learning-experiments)
- [2 Exercise - Run experiments](#2-exercise---run-experiments)
- [2 Exercise Quiz 2](#2-exercise-quiz-2)
- [2 Knowledge Check](#2-knowledge-check)
- [2 Lesson summary](#2-lesson-summary)
- [2 Additional Reading](#2-additional-reading)

[< Back to index](#0-index)

## 2 Lesson Introduction
[< Back to Local Index](#2-index)

![1.png](ims%2FC2%2F1.png)

Hola, y bienvenido a esta lección, donde aprenderá sobre el Kit de Desarrollo de Software Azure Machine Learning. 
Azure Machine Learning es una plataforma para operar cargas de trabajo de Machine Learning en la Nube. Construida sobre 
la Plataforma en la Nube Microsoft Azure, Azure Machine Learning le permite gestionar computación escalable bajo demanda 
para cargas de trabajo de aprendizaje automático, almacenamiento de datos, y conectividad para ingerir datos desde una 
amplia gama de fuentes. Orquestación de flujos de trabajo de Machine Learning para automatizar el entrenamiento de modelos, 
despliegue, y procesos de gestión, registro de modelos, y gestión. Así podrá realizar un seguimiento de múltiples versiones 
de modelos sobre los datos en los que fueron entrenados. Métricas y monitorización para experimentos de entrenamiento, 
conjuntos de datos y servicios publicados, y despliegue de modelos para inferencias en tiempo real sobre lotes. 

![2.png](ims%2FC2%2F2.png)

En esta lección, aprenderá a aprovisionar un espacio de trabajo de Azure Machine Learning. Utilizar herramientas, e interfaces 
para trabajar con Azure Machine Learning y ejecutar experimentos basados en código en un espacio de trabajo de Azure Machine Learning.

## 2 Azure Machine Learning Workspaces
[< Back to Local Index](#2-index)

![3.png](ims%2FC2%2F3.png)

Bienvenido a esta sección, donde explorará los espacios de trabajo de Azure Machine Learning. Un espacio de trabajo es un 
contexto para los experimentos, datos, objetivos de cálculo y otros activos asociados con la carga de trabajo de aprendizaje automático. 

![4.png](ims%2FC2%2F4.png)

Un espacio de trabajo define el límite para un conjunto de activos de aprendizaje automático relacionados. Puede utilizar 
espacios de trabajo para agrupar activos de aprendizaje automático basados en proyectos, entornos de despliegue, por ejemplo, 
prueba y producción, equipos, o algún otro principio de organización. 

![5.png](ims%2FC2%2F5.png)

Los activos de un espacio de trabajo incluyen: objetivos de cálculo para el desarrollo, la formación y el despliegue, 
datos para la experimentación y la formación de modelos, cuadernos que contienen código compartido y documentación, 
experimentos, incluido el historial de ejecución con métricas y resultados registrados, canalizaciones que definen procesos 
orquestados de varios pasos y modelos que ha entrenado.

![6.png](ims%2FC2%2F6.png)

Los espacios de trabajo son recursos Azure y, como tales, se definen dentro de un grupo de recursos en una suscripción Azure, 
junto con otros recursos Azure relacionados que son necesarios para dar soporte al espacio de trabajo. 

Los recursos Azure creados junto a un espacio de trabajo incluyen; 

- **Una cuenta de almacenamiento**, que se utiliza para almacenar archivos utilizados por el espacio de trabajo así como datos para 
experimentos y entrenamiento de modelos. 
- **Una instancia de Application Insights**, que se utiliza para supervisar servicios predictivos en el espacio de trabajo. 
- **Una instancia de Azure Key Vault**, que se utiliza para gestionar secretos como claves de autenticación y credenciales utilizadas 
por el espacio de trabajo, y 
- **Un registro de contenedores** que se crea según sea necesario para gestionar contenedores para modelos desplegados.

![7.png](ims%2FC2%2F7.png)

Puede asignar políticas de autorización basadas en roles a un espacio de trabajo que le permitan gestionar permisos que 
restrinjan qué acciones específicas de Azure Active Directory o principales de AAD pueden realizar. 

Por ejemplo, podría crear una política que permita sólo a los usuarios del grupo de operaciones de TI crear, objetivos de 
cálculo y almacenes de datos. 

Mientras que permite a los usuarios del grupo de científicos de datos crear y ejecutar experimentos y registrar modelos. 

![8.png](ims%2FC2%2F8.png)

![9.png](ims%2FC2%2F9.png)

Puede crear un espacio de trabajo de varias maneras. En el portal de Microsoft Azure, cree un nuevo recurso de aprendizaje 
automático especificando el grupo de recursos de suscripción y el nombre del espacio de trabajo. 

![10.png](ims%2FC2%2F10.png)

O puede utilizar el SDK de Python de aprendizaje automático de Azure para ejecutar código que cree un espacio de trabajo. 
Por ejemplo, puede crear un espacio de trabajo denominado aml-workspace, suponiendo que el SDK de Azure Machine Learning 
para Python esté instalado y se haya especificado un ID de suscripción válido. 

![11.png](ims%2FC2%2F11.png)

Utilice la interfaz de línea de comandos de Azure o CLI con la extensión Azure Machine Learning CLI. Por ejemplo, podría 
utilizar un comando aml-workspace, que asume que ya se ha creado un grupo de recursos denominado aml-resources. 

![12.png](ims%2FC2%2F12.png)

Para obtener más información sobre el formato de plantilla para un espacio de trabajo de Azure Machine Learning, 
consulte la documentación de Azure Machine Learning en el sitio web de Microsoft. Puede encontrar un enlace a este documento en 
las [lecturas adicionales](#2-additional-reading) al final de esta lección.



## 2 Exercise - Create a Workspace
[< Back to Local Index](#2-index)

Ahora es su oportunidad de empezar con Azure Machine Learning por sí mismo mediante la creación de un espacio de trabajo.

En este ejercicio, usted:

- Aprovisionar un espacio de trabajo de Azure Machine Learning.

- Crear una instancia de computación.

- Ejecutar un cuaderno.

### Instrucciones
Siga estas instrucciones para completar el ejercicio.

1. Si aún no tiene una suscripción a Azure, regístrese para una prueba gratuita en https://azure.microsoft.com.

2. Consulte el repositorio del ejercicio en https://aka.ms/mslearn-dp100.

3. Complete el ejercicio Crear un espacio de trabajo de Azure Machine Learning.

### Create and Explore an Azure Machine Learning Workspace

Enlace: [https://microsoftlearning.github.io/mslearn-dp100/instructions/01-create-a-workspace.html](https://microsoftlearning.github.io/mslearn-dp100/instructions/01-create-a-workspace.html)

Como su nombre indica, un espacio de trabajo es un lugar centralizado para administrar todos los activos de Azure ML que necesita para trabajar en un proyecto de aprendizaje automático.

![m1.gif](ims%2FC2%2Fgifs%2Fm1.gif)

1. En el [portal de Azure](https://portal.azure.com/#home), cree un nuevo recurso de **Aprendizaje automático (Machine Learning)**, especificando la siguiente configuración:

   ![m2.gif](ims%2FC2%2Fgifs%2Fm2.gif)

   - **Subscription:** Su suscripción de Azure
   - **Resource group:** rg-dp100-labs
   - **Workspace name:** mlw-dp100-labs
   - **Region:** Seleccione la región geográfica más cercana a usted
   - **Storage account:** Tenga en cuenta la nueva cuenta de almacenamiento que se creará de forma predeterminada para su espacio de trabajo
   - **Key vault:** Tenga en cuenta el nuevo almacén de claves que se creará de forma predeterminada para su espacio de trabajo
   - **Application insights:** Tenga en cuenta el nuevo recurso de Aplicación Insights que se creará de forma predeterminada para su espacio de trabajo
   - **Container registry:** Ninguno (uno se creará automáticamente la primera vez que implemente un modelo en un contenedor)

    >**Nota:** Cuando crea un espacio de trabajo de Azure Machine Learning, puede utilizar algunas opciones avanzadas para restringir el acceso a través de un punto de conexión privado y especificar claves personalizadas para la encriptación de datos. No utilizaremos estas opciones en este ejercicio, pero debe estar al tanto de ellas.

2. Cuando se hayan creado el espacio de trabajo y sus recursos asociados, vea el espacio de trabajo en el portal.

### Explore Azure Machine Learning studio

Puede administrar algunos activos del espacio de trabajo en el portal de Azure, pero para los científicos de datos, esta herramienta contiene mucha información irrelevante y enlaces que se relacionan con la administración de recursos generales de Azure. Azure Machine Learning Studio proporciona un portal web dedicado para trabajar con su espacio de trabajo.

   ![m3.gif](ims%2FC2%2Fgifs%2Fm3.gif)

1. En la cuchilla del **portal de Azure** para su espacio de trabajo de Azure Machine Learning, haga clic en el enlace para iniciar el estudio; o, alternativamente, en una nueva pestaña del navegador, abra [https://ml.azure.com](https://ml.azure.com). Si se le solicita, inicie sesión con la cuenta de Microsoft que utilizó en la tarea anterior y seleccione su suscripción de Azure y espacio de trabajo.

   > **Consejo** Si tiene varias suscripciones de Azure, debe elegir el directorio de Azure en el que se define la suscripción; luego elija la suscripción y, finalmente, el espacio de trabajo.

2. Vea la interfaz de Azure Machine Learning Studio para su espacio de trabajo; puede administrar todos los activos en su espacio de trabajo desde aquí.

3. En Azure Machine Learning Studio, active el icono ☰ en la parte superior izquierda para mostrar y ocultar las distintas páginas de la interfaz. Puede utilizar estas páginas para administrar los recursos en su espacio de trabajo.

### Create a compute instance

Una de las ventajas de Azure Machine Learning es la capacidad de crear cálculos basados en la nube en los que puede ejecutar experimentos y scripts de formación a escala.

1. En Azure Machine Learning Studio, vea la página de **Compute** page. Aquí es donde administrará los recursos de cálculo 
para sus actividades de ciencia de datos. Hay cuatro tipos de recursos de cálculo que puede crear:

   - **Compute instances:** Estaciones de trabajo de desarrollo que los científicos de datos pueden utilizar para trabajar con datos y modelos.
   - **Compute clusters:** Grupos escalables de máquinas virtuales para el procesamiento bajo demanda del código de experimento.
   - **Inference clusters:** Objetivos de implementación para servicios predictivos que utilizan sus modelos entrenados.
   - **Attached compute:** Vínculos a otros recursos de cálculo de Azure, como máquinas virtuales o grupos de Azure Databricks.

   Para este ejercicio, creará una instancia de cálculo para ejecutar código en sus cuadernos.

2. En la pestaña **Compute instances** agregue una nueva instancia de cálculo con la siguiente configuración. Utilizará esto como una estación de trabajo para ejecutar código en cuadernos.

   ![m4.gif](ims%2FC2%2Fgifs%2Fm4.gif)

   - **Compute name:** ingrese un nombre único
   - **Location:** La misma ubicación que su espacio de trabajo
   - **Virtual machine type:** CPU
   - **Virtual machine size:** Standard_DS11_v2
   - **Total Available Quotas:** Esto muestra núcleos dedicados disponibles.
   - **Show advanced settings:** Tenga en cuenta la siguientes configuraciones, pero no las seleccione:
     - **Enable SSH access:** No seleccionado (puede usar esto para habilitar el acceso directo a la máquina virtual mediante un cliente SSH)
     - **Enable virtual network:** No seleccionado (típicamente se utilizaría esto en un entorno empresarial para mejorar la seguridad de la red)
     - **Assign to another user:** No seleccionado (puede usar esto para asignar una instancia de cálculo a un científico de datos)
     - **Provision with setup script:** No seleccionado (puede usar esto para agregar un script para ejecutar en la instancia remota cuando se crea)

3. Espere a que la instancia de cálculo se inicie y su estado cambie a **En ejecución**.

   ![13.png](ims%2FC2%2F13.png)

> **Nota:** Las instancias de cálculo y los grupos se basan en imágenes estándar de máquinas virtuales de Azure. Para este ejercicio, se recomienda la imagen Standard_DS11_v2 para lograr el equilibrio óptimo entre costos y rendimiento. Si su suscripción no incluye una cuota que no tenga esta imagen, elija una imagen alternativa; pero tenga en cuenta que una imagen más grande puede incurrir en mayores costos y una imagen más pequeña puede no ser suficiente para completar las tareas. Alternativamente, solicite a su administrador de Azure que amplíe su cuota.


### Clone and run a notebook

Gran parte de la experimentación en ciencia de datos y aprendizaje automático se realiza ejecutando código en cuadernos. Su instancia de cálculo incluye entornos de cuaderno Python completamente equipados (_Jupyter y JupyterLab_) que puede utilizar para trabajos extensos; pero para la edición básica de cuadernos, puede utilizar la página integrada de **Cuadernos** en Azure Machine Learning Studio.

> Nota: Puedes encontrar el Notebook en: [01 - Get Started with Notebooks.ipynb](ims%2FC2%2Fnotebooks%2F01%20-%20Get%20Started%20with%20Notebooks.ipynb)

1. En Azure Machine Learning Studio, vea la página de **Cuadernos**.
2. Si se muestra un mensaje que describe las nuevas características, cierre el mensaje.
3. Seleccione **Terminal** o el icono **Abrir terminal** para abrir un terminal y asegúrese de que su Cálculo esté configurado en su instancia de cálculo y que la ruta actual sea la carpeta **/users/your-user-name**.
4. Ingrese el siguiente comando para clonar un repositorio Git que contiene cuadernos, datos y otros archivos en su espacio de trabajo:

   ![m5.gif](ims%2FC2%2Fgifs%2Fm5.gif)

    ```commandline
    git clone https://github.com/MicrosoftLearning/mslearn-dp100 mslearn-dp100
    ```

5. Cuando el comando haya terminado, en el panel de **Archivos**, haga clic en ↻ para actualizar la vista y verifique que se haya creado una nueva carpeta **/users/your-user-name/mslearn-dp100**. Esta carpeta contiene múltiples archivos de cuaderno **.ipynb**.
6. Cierre el panel del terminal para finalizar la sesión.
7. En la carpeta **/users/your-user-name/mslearn-dp100**, abra el cuaderno **Get Started with Notebooks notebook**. Luego, lea las notas y siga las instrucciones que contiene.

   ![m6.gif](ims%2FC2%2Fgifs%2Fm6.gif)

> **Consejo:** Para ejecutar una celda de código, seleccione la celda que desea ejecutar y luego utilice el botón ▷ para ejecutarla.

> **¿Nuevo en Python?** Utilice la [hoja de trucos de Python](https://microsoftlearning.github.io/mslearn-dp100/instructions/cheat-sheets/dp100-cheat-sheet-python.pdf) para entender el código.

> **¿Nuevo en el aprendizaje automático?** Utilice la [descripción general del aprendizaje automático](https://microsoftlearning.github.io/mslearn-dp100/instructions/cheat-sheets/dp100-cheat-sheet-machine-learning.pdf) para obtener una visión general simplificada del proceso de aprendizaje automático en Azure Machine Learning.

### Delete Azure resources

Cuando termine de explorar Azure Machine Learning, debe eliminar los recursos que ha creado para evitar costos innecesarios de Azure.

![m8.gif](ims%2FC2%2Fgifs%2Fm8.gif)

1. Cierre la pestaña de Azure Machine Learning Studio y vuelva al portal de Azure.
2. En el portal de Azure, en la página de **Inicio**, seleccione **Grupos de recursos**.
3. Seleccione el grupo de recursos **rg-dp100-labs**.
4. En la parte superior de la página **Descripción general** de su grupo de recursos, seleccione **Eliminar grupo de recursos**.
5. Ingrese el nombre del grupo de recursos para confirmar que desea eliminarlo y seleccione **Eliminar**.


### Obteniendo el archivo CONFIG.json Manualmente

Puedes crear manualmente este archivo o descargarlo desde el portal de Azure siguiendo estos pasos:

![m7.gif](ims%2FC2%2Fgifs%2Fm7.gif)

1. Ve al portal de Azure (https://portal.azure.com).
2. Navega a tu espacio de trabajo de Azure Machine Learning.

3. En la página de inicio de tu espacio de trabajo, busca la opción "Configuración" o "Información general".

4. En esa sección, deberías encontrar una opción para descargar el archivo de configuración. Este archivo será un archivo JSON que contiene los detalles de conexión necesarios.

Una vez tengas este archivo JSON de configuración, asegúrate de que esté en la misma ubicación que tu notebook local y puedes usar el código que proporcionaste para cargar el espacio de trabajo de Azure Machine Learning en tu entorno local.

Es importante destacar que necesitas tener instalado el SDK de Azure Machine Learning en tu entorno local para que este código funcione. Puedes instalarlo utilizando pip:

```bash
pip install azureml-sdk
```

## 2 Exercise Quiz 1
[< Back to Local Index](#2-index)

![14.png](ims%2FC2%2F14.png)

## 2 Azure Machine Learning tools and interfaces
[< Back to Local Index](#2-index)

![15.png](ims%2FC2%2F15.png)

Azure Machine Learning proporciona un servicio basado en la nube que ofrece flexibilidad en la forma de utilizarlo. 
Existen interfaces de usuario diseñadas específicamente para Azure Machine Learning, o puede utilizar una interfaz 
programática para gestionar recursos del espacio de trabajo y ejecutar operaciones de aprendizaje automático. 

![16.png](ims%2FC2%2F16.png)

Puede gestionar los recursos de su espacio de trabajo de Azure Machine Learning en el portal de Azure. Sin embargo, 
como se trata de una interfaz general para gestionar todos los recursos en Azure, los científicos de datos y otros usuarios 
implicados en operaciones de aprendizaje automático pueden preferir utilizar una interfaz dedicada más centrada. 

![17.png](ims%2FC2%2F17.png)

Azure Machine Learning Studio es una herramienta basada en web para gestionar un espacio de trabajo de Azure Machine Learning. 
Le permite crear, gestionar, y ver todos los activos de su espacio de trabajo y proporciona las siguientes herramientas gráficas: 

![18.png](ims%2FC2%2F18.png)

Diseñador. Se trata de una interfaz de arrastrar y soltar para el desarrollo de modelos de aprendizaje automático sin código.

![19.png](ims%2FC2%2F19.png)

Aprendizaje automático automatizado. Se trata de una interfaz de asistente que le permite entrenar un modelo, utilizando 
una combinación de algoritmos y técnicas de preprocesamiento de datos para encontrar el mejor modelo para sus datos. 

![20.png](ims%2FC2%2F20.png)

Es importante señalar que una herramienta lanzada anteriormente llamada Azure Machine Learning Studio proporcionaba un 
servicio gratuito para el desarrollo de modelos de aprendizaje automático de arrastrar y soltar. La interfaz del estudio 
para el servicio Azure Machine Learning incluye esta capacidad en la herramienta de diseño, así como otras capacidades de 
gestión de activos del espacio de trabajo.

![21.png](ims%2FC2%2F21.png)

Para utilizar Azure Machine Learning Studio, utilice un navegador web para navegar a ml.azure.com e inicie sesión utilizando 
las credenciales asociadas a su suscripción Azure. A continuación, puede seleccionar la suscripción y el espacio de trabajo 
que desea gestionar. 

![22.png](ims%2FC2%2F22.png)

Aunque las interfaces gráficas como Azure Machine Learning Studio facilitan la creación y la gestión de activos de aprendizaje 
automático, a menudo resulta ventajoso utilizar un enfoque basado en código para gestionar los recursos.

Escribiendo scripts para crear y gestionar recursos, puede ejecutar operaciones de aprendizaje automático desde su entorno 
de desarrollo preferido. Automatice la creación y configuración de activos para que sea repetible, asegure la coherencia 
de los recursos que deben replicarse en múltiples entornos. Por ejemplo, desarrollo, pruebas y producción. Incorpore la 
configuración de activos de aprendizaje automático en operaciones de desarrollo o flujos de trabajo DevOps, como integración 
continua, despliegue continuo o conductos CICD.

![23.png](ims%2FC2%2F23.png)

Azure Machine Learning proporciona kits de desarrollo de software o SDK para Python y R, que puede utilizar para crear, 
gestionar, y utilizar activos en un espacio de trabajo de Azure Machine Learning. Tenga en cuenta que este curso se centra 
en el SDK de Python porque tiene capacidades más amplias que el SDK de R. 

![24.png](ims%2FC2%2F24.png)

Aprendamos ahora a instalar el SDK de Azure Machine Learning para Python. Puede instalar el SDK de Azure Machine Learning 
para Python utilizando la utilidad de gestión de paquetes pip y utilizando el comando pip install. El SDK se instala 
utilizando la utilidad pip para Python y consta de el paquete principal azureml-sdk, así como de otros numerosos paquetes 
auxiliares que contienen funcionalidad especializada.

![25.png](ims%2FC2%2F25.png)

Por ejemplo, el paquete Azure-ml widgets proporciona soporte para widgets interactivos en un entorno Jupyter Notebook.

![26.png](ims%2FC2%2F26.png)

Para instalar paquetes adicionales, inclúyalos en el comando pip install. 

![27.png](ims%2FC2%2F27.png)

Para obtener más información sobre la instalación del 
SDK Azure Machine Learning para Python, consulte la documentación del SDK en el sitio web de Microsoft. Puede encontrar un 
enlace a este documento desde las lecturas adicionales al final de esta lección. 

![28.png](ims%2FC2%2F28.png)

Además, debe tener en cuenta que el SDK se actualiza en forma regular y revisar las notas de la versión para conocer la 
última versión. Puede encontrar un enlace a este documento desde las lecturas adicionales al final de esta lección.

![29.png](ims%2FC2%2F29.png)

Después de instalar el paquete SDK en su entorno Python, puede escribir código para conectarse a su espacio de trabajo y 
realizar operaciones de aprendizaje automático. La forma más sencilla de conectarse a un espacio de trabajo es utilizar 
un archivo de configuración del espacio de trabajo, que incluye la suscripción a Azure, el grupo de recursos y los detalles 
del espacio de trabajo.

![30.png](ims%2FC2%2F30.png)

Puede descargar un archivo de configuración para un espacio de trabajo desde la página de resumen de su hoja en el portal 
de Azure o desde Azure Machine Learning Studio. Para conectarse al espacio de trabajo utilizando el archivo de configuración, 
puede utilizar el método from_config de la clase del espacio de trabajo en el SDK. Por defecto, el método from_config 
busca un archivo llamado config.json en la carpeta que contiene el archivo de código Python, pero puede especificar otra 
ruta si es necesario.

![31.png](ims%2FC2%2F31.png)

Como alternativa al uso de un archivo de configuración, puede utilizar el método Get de la clase del espacio de trabajo, 
que especifica explícitamente la suscripción, el grupo de recursos y los detalles del espacio de trabajo. 

![32.png](ims%2FC2%2F32.png)

Sin embargo, la técnica del archivo de configuración suele preferirse debido a su mayor flexibilidad cuando se utilizan varios scripts. 

![33.png](ims%2FC2%2F33.png)

Sea cual sea la técnica que utilice, si no hay una sesión activa con su suscripción Azure, se le pedirá que se autentique. 
La clase del espacio de trabajo es el punto de partida para la mayoría de las operaciones de código. Por ejemplo, puede 
utilizar sus atributos de objetivos de cálculo para recuperar un objeto de diccionario, que contiene los objetivos de cálculo 
definidos en el espacio de trabajo. 

El SDK contiene una rica biblioteca de clases que puede utilizar para crear, gestionar y utilizar muchos activos en el espacio de trabajo de Azure Machine Learning. 

![34.png](ims%2FC2%2F34.png)

Para obtener más información sobre los objetivos de cómputo, Azure Machine Learning SDK, consulte la documentación del SDK 
en el sitio web de Microsoft. Puede encontrar un enlace a este documento en las lecturas adicionales al final de esta lección.

![35.png](ims%2FC2%2F35.png)

La interfaz de línea de comandos de Azure, o CLI, es una herramienta de línea de comandos multiplataforma para gestionar 
los recursos de Azure. La extensión Azure Machine Learning CLI es un paquete adicional que proporciona comandos para trabajar 
con Azure Machine Learning.

![36.png](ims%2FC2%2F36.png)

Para instalar la extensión Azure Machine Learning CLI, primero debe instalar Azure CLI. Consulte las instrucciones de instalación 
completas para todas las plataformas compatibles para obtener más detalles. Puede encontrar un enlace a este documento desde 
las lecturas adicionales al final de esta lección. 

![37.png](ims%2FC2%2F37.png)

Después de instalar la CLI de Azure, puede añadir la extensión CLI de Azure Machine Learning ejecutando un comando de extensión az. 
Para utilizar la extensión Azure Machine Learning CLI, ejecute el comando az ml con los parámetros adecuados para la acción 
que desee realizar. 

![38.png](ims%2FC2%2F38.png)

Es importante tener en cuenta lo siguiente, en el ejemplo de código anterior, el parámetro -g especifica el nombre del 
grupo de recursos en el que se define el espacio de trabajo Azure Machine Learning especificado en el parámetro -w. Estos 
parámetros son alias abreviados para --resource group y --workspace name. 

![39.png](ims%2FC2%2F39.png)

Para más información sobre la extensión CLI de Azure Machine Learning, consulte la documentación. Puede encontrar un enlace a este documento desde las lecturas adicionales al final de esta lección. 

![40.png](ims%2FC2%2F40.png)

Azure Machine Learning incluye la capacidad de crear instancias de cómputo en un espacio de trabajo, para proporcionar un 
entorno de desarrollo que se gestiona con todos los demás activos del espacio de trabajo. Las instancias de computación 
incluyen, Jupyter Notebook y Jupyter instalaciones de laboratorio que puede utilizar para escribir y ejecutar código que 
utiliza el SDK de Azure Machine Learning para trabajar con activos en su espacio de trabajo. 

![41.png](ims%2FC2%2F41.png)

Puede elegir una imagen de instancia de computación que proporcione la especificación de computación que necesite, desde 
pequeñas máquinas virtuales de sólo CPU hasta grandes estaciones de trabajo con GPU.

![42.png](ims%2FC2%2F42.png)

Dado que las instancias de computación se alojan en Azure, sólo paga por los recursos de computación cuando están en 
funcionamiento, por lo que puede crear una instancia de computación que se adapte a sus necesidades. Deténgala cuando su 
carga de trabajo haya finalizado para minimizar los costes. Puede almacenar blocs de notas de forma independiente en el 
almacenamiento del espacio de trabajo y abrirlos en cualquier instancia de computación.

![43.png](ims%2FC2%2F43.png)

Visual Studio Code es un entorno ligero de edición de código para Microsoft Windows, Apple MAC OS y Linux. Proporciona una 
interfaz visual para muchos tipos de código, incluidos Microsoft C#, JavaScript, Python y otros. También proporciona 
Intellisense y formato de sintaxis para formatos de datos comunes como JSON y XML. 

![44.png](ims%2FC2%2F44.png)

La flexibilidad de Visual Studio Code se basa en la capacidad de instalar extensiones modulares que añaden interfaces de 
comprobación de sintaxis, depuración y gestión visual para cargas de trabajo específicas. 

![45.png](ims%2FC2%2F45.png)

Por ejemplo, la extensión Microsoft Python para Visual Studio Code, añade soporte para escribir y ejecutar código Python y 
scripts o cuadernos dentro de la interfaz de Visual Studio Code. 

![46.png](ims%2FC2%2F46.png)

La extensión Azure Machine Learning para Visual Studio Code proporciona una interfaz gráfica para trabajar con activos en 
un espacio de trabajo Azure Machine Learning. Puede combinar las capacidades de las extensiones Azure Machine Learning y 
Python para gestionar una carga de trabajo completa de aprendizaje automático de extremo a extremo en Azure Machine Learning 
desde el entorno de Visual Studio Code.

Para obtener más información sobre el uso de la extensión Azure Machine Learning para Visual Studio Code, consulte la 
documentación. Puede encontrar un enlace a este documento en las lecturas adicionales al final de esta lección.

## 2 Azure Machine Learning experiments
[< Back to Local Index](#2-index)

![47.png](ims%2FC2%2F47.png)

Como cualquier disciplina científica, la ciencia de datos implica la ejecución de experimentos normalmente para explorar 
datos o para construir y evaluar modelos predictivos. En Azure Machine Learning un experimento es un proceso con nombre. 
Normalmente, la ejecución de un script o un pipeline que puede generar métricas y resultados y ser rastreado en el espacio 
de trabajo de Azure Machine Learning. 

![48.png](ims%2FC2%2F48.png)

Este experimento puede ejecutarse varias veces con diferentes datos, código o configuraciones. Azure Machine Learning realiza 
un seguimiento de cada ejecución, lo que le permite ver el historial de ejecución y comparar los resultados de cada ejecución. 

![49.png](ims%2FC2%2F49.png)

Ahora, echemos un vistazo a cómo se controlan los experimentos en Azure Machine Learning. Cuando envía un experimento, 
utiliza su contexto de ejecución para inicializar y finalizar la ejecución del experimento que se rastrea en Azure Machine Learning. 

![50.png](ims%2FC2%2F50.png)

Una vez finalizada la ejecución del experimento, puede ver los detalles de la ejecución la pestaña de experimentos en Azure 
Machine Learning studio. 

![51.png](ims%2FC2%2F51.png)

Los experimentos son más útiles cuando producen métricas y resultados que pueden rastrearse a través de las ejecuciones. 
Cada experimento genera archivos de registro que incluyen los mensajes que se escribirán en el terminal durante la ejecución 
interactiva. Esto le permite utilizar simples sentencias de impresión para escribir mensajes en el registro. Sin embargo, 
si desea registrar métricas con nombre para compararlas entre ejecuciones, puede hacerlo utilizando el objeto run, que 
proporciona una serie de funciones de registro específicas para este fin. 

![52.png](ims%2FC2%2F52.png)

Entre ellas se incluyen: 
- **Log:** registrar un único valor con nombre.
- **Log_list:** registrar una lista de valores con nombre. 
- **Log_row:** registra una fila con múltiples columnas. 
- **Log_table:** registra el diccionario como una tabla. 
- **Log_image:** registra un archivo de imagen o un gráfico. 

![53.png](ims%2FC2%2F53.png)

Para obtener más información sobre el registro de métricas durante las ejecuciones de experimentos, consulte Monitorizar 
ejecuciones y métricas de experimentos Azure ML en el sitio web de Microsoft. Puede encontrar un enlace a este recurso en 
las lecturas adicionales al final de esta lección.

![54.png](ims%2FC2%2F54.png)

Por ejemplo, puede utilizar un código que registre el número de observaciones registradas en un archivo CSV. 

![55.png](ims%2FC2%2F55.png)

Puede ver las métricas registradas por una ejecución de experimento en Azure Machine Learning studio o utilizando el widget 
RunDetails en un cuaderno. 

![56.png](ims%2FC2%2F56.png)

También puede recuperar las métricas utilizando el método run objects get metrics. Este método devuelve una representación 
json de las métricas. A continuación, puede generar observaciones de salida. Además de registrar métricas, un experimento 
puede generar archivos de salida.

![57.png](ims%2FC2%2F57.png)

A menudo, se trata de modelos de aprendizaje automático entrenados, pero puede guardar cualquier tipo de archivo y ponerlo 
a disposición como salida de la ejecución de su experimento. Los archivos de salida de un experimento se guardan en su 
carpeta de salidas. La técnica que utilice para añadir archivos a las salidas de un experimento, depende de cómo esté 
ejecutando el experimento. 

![58.png](ims%2FC2%2F58.png)

Los ejemplos mencionados aquí hasta ahora controlan el ciclo de vida del experimento alineando su código. Si adopta este 
enfoque, puede subir archivos locales a la carpeta de salidas de la ejecución utilizando el método upload file de los 
objetos de ejecución en el código de su experimento. Si ejecuta un experimento en un contexto de cálculo remoto, del que 
hablaremos más adelante en este curso. Cualquier archivo escrito en la carpeta de salidas en el contexto de cálculo se 
sube automáticamente a la carpeta de salidas de la ejecución cuando ésta finaliza. 

![m9.gif](ims%2FC2%2Fgifs%2Fm9.gif)

Sea cual sea el enfoque que utilice para ejecutar sus experimentos, puede recuperar una lista de archivos de salida del 
objeto de ejecución, que produciría una salida, mostrando output/sample.csv. 

![59.png](ims%2FC2%2F59.png)

Puede ejecutar un experimento en línea utilizando el método start_logging del objeto de experimento , pero es más común 
encapsular la lógica del experimento en un script y ejecutar el script como un experimento. El script puede ejecutarse en 
cualquier contexto de computación válido, lo que lo convierte en una solución más flexible para ejecutar experimentos a 
escala. Un script de experimento no es más que un archivo de código python que contiene el código que desea ejecutar en 
el experimento.

![60.png](ims%2FC2%2F60.png)

Para acceder al contexto de ejecución del experimento, necesario para registrar métricas, el script debe importar la clase 
azureml.core.run class y codificar su método get context. 

![61.png](ims%2FC2%2F61.png)

El script puede entonces utilizar el contexto de ejecución para registrar métricas, cargar archivos y completar el experimento.

![62.png](ims%2FC2%2F62.png)

Para ejecutar un script como un experimento, debe definir una configuración de script que defina el script a ejecutar y 
el entorno python en el que ejecutarlo. Esto se implementa utilizando un objeto ScriptRunConfig. Por ejemplo, el código 
podría utilizarse para ejecutar un experimento basado en un script en la carpeta de archivos del experimento, que también 
debe contener cualquier archivo utilizado por el script, como el archivo data.csv del ejemplo de código de script anterior. 

![63.png](ims%2FC2%2F63.png)

Es importante tener en cuenta y objeto de configuración de ejecución creado implícitamente, define el entorno python para 
el experimento, incluyendo los paquetes disponibles para el script. Además, si su script depende de paquetes que no están 
incluidos en el entorno por defecto. Debe asociar el ScriptRunConfig con un objeto de entorno que haga uso de un objeto 
CondaDependencies para especificar los paquetes python necesarios. Los entornos de ejecución se tratan con más detalle 
más adelante en este curso.

## 2 Exercise - Run experiments
[< Back to Local Index](#2-index)

Ahora es su oportunidad de probar Azure Machine Learning por sí mismo.

En este ejercicio, usted:

- Ejecutar un experimento de Azure Machine Learning.
- Ejecutar un script como experimento.
- Utilizar MLflow para realizar un seguimiento de las métricas del experimento.

### Instrucciones
Siga estas instrucciones para completar el ejercicio.

1. Si aún no tiene una suscripción a Azure, regístrese para una prueba gratuita en https://azure.microsoft.com.

2. Consulte el repositorio del ejercicio en https://aka.ms/mslearn-dp100.

3. Si aún no lo ha hecho, complete el ejercicio Crear un espacio de trabajo de Azure Machine Learning para aprovisionar 
un espacio de trabajo de Azure Machine Learning, crear una instancia de cálculo y clonar los archivos necesarios.

4. Complete el ejercicio Ejecutar experimentos

Liga para el tutorial en inglés: https://microsoftlearning.github.io/mslearn-dp100/instructions/04-run-experiments.html

Vamos a omitir los pasos:


- Before you start
- Provision an Azure Machine Learning workspace
- Clone the lab materials

Puesto que estos ya se hicieron en el tutorial anterior.

### Verificar que el SDK de Azure Machine Learning esté instalado

El SDK de Azure Machine Learning se instala de forma predeterminada en su instancia de cálculo. Siga estos pasos para verificar la instalación.

![m10.gif](ims%2FC2%2Fgifs%2Fm10.gif)

1. En la página de **Cuadernos**, cree un nuevo **Terminal** si ya no está abierto. Esto abrirá una nueva pestaña con una shell de comandos.
2. Ingrese el siguiente comando para instalar el SDK de Azure ML:

   ![m11.gif](ims%2FC2%2Fgifs%2Fm11.gif)

   ```bash
   pip install azureml-sdk
   ```
   Tenga en cuenta la versión del paquete SDK instalado.

3. El paquete SDK **azureml-sdk** proporciona las bibliotecas más importantes necesarias para trabajar con Azure Machine Learning. Sin embargo, existen algunos paquetes adicionales que contienen otras bibliotecas útiles que no se incluyen en el paquete principal del SDK. Use el siguiente comando para instalar el paquete **azureml-widgets**, que contiene bibliotecas para mostrar información de Azure Machine Learning en cuadernos:
   ```bash
   pip install azureml-widgets
   ```
4. Cierre la pestaña del **Terminal**.
   > **Más información:** Para obtener más detalles sobre la instalación del SDK de Azure ML y sus componentes opcionales, consulte la [Documentación del SDK de Azure ML](https://learn.microsoft.com/es-mx/python/api/overview/azure/ml/install?view=azure-ml-py).

### Ejecutar experimentos en un cuaderno

Los experimentos en Azure Machine Learning necesitan ser iniciados desde algún tipo de capa de control; a menudo un script o programa. 
En este ejercicio, utilizará un cuaderno para controlar los experimentos.

1. En la **página de Cuadernos**, navegue hasta la carpeta **/users/your-user-name/mslearn-dp100** donde clonó el repositorio de cuadernos y abra el cuaderno **Run Experiments**.
   
   ![m12.gif](ims%2FC2%2Fgifs%2Fm12.gif)   

2. Luego lea las notas en el cuaderno, ejecutando cada celda de código de manera consecutiva.

> ### Nota:
> El notebook completo de esta sección está en: [04 - Run Experiments.ipynb](ims%2FC2%2Fnotebooks%2F04%20-%20Run%20Experiments.ipynb)


### Eliminar los recursos de Azure

Cuando termine de explorar Azure Machine Learning, debe eliminar los recursos que ha creado para evitar costos innecesarios de Azure.

1. Cierre la pestaña de Azure Machine Learning Studio y regrese al portal de Azure.
2. En el portal de Azure, en la **página de Inicio**, seleccione **Grupos de recursos**.
3. Seleccione el grupo de recursos **rg-dp100-labs**.
4. En la parte superior de la **página Descripción general** de su grupo de recursos, seleccione **Eliminar grupo de recursos**.
5. Ingrese el nombre del grupo de recursos para confirmar que desea eliminarlo y seleccione **Eliminar**.


## 2 Exercise Quiz 2
[< Back to Local Index](#2-index)

![64.png](ims%2FC2%2F64.png)

## 2 Knowledge Check
[< Back to Local Index](#2-index)

![t1.png](ims%2FC2%2Ftest%2Ft1.png)

![t2.png](ims%2FC2%2Ftest%2Ft2.png)

![t3.png](ims%2FC2%2Ftest%2Ft3.png)

![t4.png](ims%2FC2%2Ftest%2Ft4.png)

## 2 Lesson summary
[< Back to Local Index](#2-index)

![65.png](ims%2FC2%2F65.png)

En esta lección, aprendiste cómo usar Python para explorar , visualizar y manipular datos o, más específicamente, 
aprovisionar una máquina de Azure Espacio de trabajo de aprendizaje, uso de herramientas e interfaces para trabajar con Azure Aprendizaje automático y ejecución de experimentos basados en código en una máquina de Azure Espacio de trabajo de aprendizaje.


## 2 Additional Reading
[< Back to Local Index](#2-index)

**Azure Machine Learning workspaces**

[Use an Azure Resource Manager template to create a workspace for Azure Machine Learning](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-create-workspace-template?tabs=azcli)

**Azure Machine Learning tools and interfaces**

[Azure Machine Learning release notes](https://docs.microsoft.com/en-us/azure/machine-learning/azure-machine-learning-release-notes)

[What is the Azure Machine Learning SDK for Python?](https://docs.microsoft.com/en-us/python/api/overview/azure/ml/?view=azure-ml-py)

[How to install the Azure CLI](https://docs.microsoft.com/en-us/cli/azure/install-azure-cli?view=azure-cli-latest)

[Install & use the CLI extension for Azure Machine Learning](https://docs.microsoft.com/en-us/azure/machine-learning/reference-azure-machine-learning-cli)

[Manage Azure Machine Learning resources with the VS Code Extension (preview)](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-manage-resources-vscode)

**Azure Machine Learning experiments**

[Log & view metrics and log files](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-log-view-metrics)

# 3 Train a machine learning model with Azure Machine Learning

## 3 INDEX

- [3 Lesson introduction](#3-lesson-introduction)
- [3 Run a training script](#3-run-a-training-script)
- [3 Using script parameters](#3-using-script-parameters)
- [3 Registering models](#3-registering-models)
- [3 Exercise Training and registering a model](#3-exercise-training-and-registering-a-model)
- [3 Exercise quiz](#3-exercise-quiz)
- [3 Knowledge Check](#3-knowledge-check)
- [3 Test prep](#3-test-prep)
- [3 Lesson Summary](#3-lesson-summary)

[< Back to index](#0-index)

## 3 Lesson introduction
[< Back to Local Index](#3-index)

![1.png](ims%2FC3%2Fims%2F1%2F1.png)

El entrenamiento en el modelo de aprendizaje automático puede ser tan fácil como cargar datos y ejecutar una línea de código 
utilizando paquetes como scikit learn. Sin embargo, en un escenario de aprendizaje automático de producción, debe considerar 
la creación de scripts de entrenamiento reutilizables para múltiples entornos informáticos. Registrar las métricas de 
rendimiento del modelo durante los procesos de entrenamiento y evaluación, y realizar un seguimiento de las versiones del 
modelo. 

![2.png](ims%2FC3%2Fims%2F1%2F2.png)

En esta lección, aprenderá a utilizar una configuración de ejecución de script para ejecutar un script de entrenamiento 
de modelo como un experimento de Azure Machine Learning. Crear scripts de entrenamiento reutilizables y parametrizados y 
registrar los modelos entrenados.

## 3 Run a training script
[< Back to Local Index](#3-index)

Puede utilizar un ScriptRunConfig para ejecutar un experimento basado en un script que entrene un modelo de aprendizaje automático.

### Escribir un script para entrenar un modelo

Cuando utilice un experimento para entrenar un modelo, su script debe guardar el modelo entrenado en la carpeta de salidas. 
Por ejemplo, el siguiente script entrena un modelo utilizando Scikit-Learn, y lo guarda en la carpeta de salidas utilizando 
el paquete **joblib**:

Podemos ver el archivo [diabetes.csv](ims%2FC3%2Fdata%2Fdiabetes.csv)
```csv
PatientID,Pregnancies,PlasmaGlucose,DiastolicBloodPressure,TricepsThickness,SerumInsulin,BMI,DiabetesPedigree,Age,Diabetic
1354778,0,171,80,34,23,43.50972593,1.213191354,21,0
1147438,8,92,93,47,36,21.24057571,0.158364981,23,0
1640031,7,115,47,52,35,41.51152348,0.079018568,23,0
```

```python
from azureml.core import Run
import pandas as pd
import numpy as np
import joblib
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression

# Get the experiment run context
run = Run.get_context()

# Prepare the dataset
diabetes = pd.read_csv('data/diabetes.csv')
X, y = diabetes[['Feature1','Feature2','Feature3']].values, diabetes['Label'].values
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30)

# Train a logistic regression model
reg = 0.1
model = LogisticRegression(C=1/reg, solver="liblinear").fit(X_train, y_train)

# calculate accuracy
y_hat = model.predict(X_test)
acc = np.average(y_hat == y_test)
run.log('Accuracy', np.float(acc))

# Save the trained model
os.makedirs('outputs', exist_ok=True)
joblib.dump(value=model, filename='outputs/model.pkl')

run.complete()
```

Para preparar un experimento que entrene un modelo, se crea un script como éste y se guarda en una carpeta. Por ejemplo, 
podría guardar este script como **training_script.py** en una carpeta llamada **training_folder**. Dado que el script 
incluye código para cargar los datos de entrenamiento **diabetes.csv**, este archivo también debe guardarse en la carpeta.

### Ejecutar el script como experimento

Para ejecutar el script, cree una **ScriptRunConfig** que haga referencia a la carpeta y al archivo de script. Por lo general, 
también deberá definir un entorno Python (Conda) que incluya cualquier paquete requerido por el script. En este ejemplo, 
el script utiliza Scikit-Learn por lo que debe crear un entorno que lo incluya. 

El script también utiliza Azure Machine Learning para registrar métricas, por lo que debe acordarse de incluir el paquete
azureml-defaults en el entorno.

```python
from azureml.core import Experiment, ScriptRunConfig, Environment
from azureml.core.conda_dependencies import CondaDependencies

# Create a Python environment for the experiment
sklearn_env = Environment("sklearn-env")

# Ensure the required packages are installed
packages = CondaDependencies.create(conda_packages=['scikit-learn','pip'],
                                    pip_packages=['azureml-defaults'])
sklearn_env.python.conda_dependencies = packages

# Create a script config
script_config = ScriptRunConfig(source_directory='training_folder',
                                script='training.py',
                                environment=sklearn_env) 

# Submit the experiment
experiment = Experiment(workspace=ws, name='training-experiment')
run = experiment.submit(config=script_config)
run.wait_for_completion()
```

> Nota, tambien podemos crear un archivo .yml y crear el ambiente desde el archivo .yml

Con el siguiente código podemos crear el archivo: `environment_test.yml` a partir de la variable `packages` creada anteriormente:

```python
with open('environment_test.yml', 'w') as f:
    f.write(packages.serialize_to_string())
```
La respuesta generada sería:
```yml
# Conda environment specification. The dependencies defined in this file will
# be automatically provisioned for runs with userManagedDependencies=False.

# Details about the Conda environment file format:
# https://conda.io/docs/user-guide/tasks/manage-environments.html#create-env-file-manually

name: project_environment
dependencies:
  # The python interpreter version.
  # Currently Azure ML only supports 3.8 and later.
- python=3.8.13

- pip:
  - azureml-defaults~=1.53.0
- scikit-learn
- pip
channels:
- anaconda
- conda-forge
```
Entonces para crear el `sklearn_env` desde el archivo `.yml`:
```python
# Create a Python environment for the experiment (from a .yml file)
sklearn_env = Environment.from_conda_specification("experiment_env", "environment_test.yml")
```

## 3 Using script parameters
[< Back to Local Index](#3-index)

Puede aumentar la flexibilidad de los experimentos basados en scripts utilizando argumentos para establecer variables en 
el script.

### Trabajar con argumentos de script

Para utilizar parámetros en un script, debe utilizar una biblioteca como **argparse** para leer los argumentos pasados al 
script y asignarlos a variables. Por ejemplo, el siguiente script lee un argumento llamado **--reg-rate**, que se utiliza 
para establecer el hiperparámetro de tasa de regularización para el algoritmo de regresión logística utilizado para entrenar 
un modelo.

```python
from azureml.core import Run
import argparse
import pandas as pd
import numpy as np
import joblib
import os
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression

# Get the experiment run context
run = Run.get_context()

# Set regularization hyperparameter
parser = argparse.ArgumentParser()
parser.add_argument('--reg-rate', type=float, dest='reg_rate', default=0.01)
args = parser.parse_args()
reg = args.reg_rate

# Prepare the dataset
diabetes = pd.read_csv('data/diabetes.csv')
X, y = data[['Feature1','Feature2','Feature3']].values, data['Label'].values
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30)

# Train a logistic regression model
model = LogisticRegression(C=1/reg, solver="liblinear").fit(X_train, y_train)

# calculate accuracy
y_hat = model.predict(X_test)
acc = np.average(y_hat == y_test)
run.log('Accuracy', np.float(acc))

# Save the trained model
os.makedirs('outputs', exist_ok=True)
joblib.dump(value=model, filename='outputs/model.pkl')

run.complete()
```

### Pasar argumentos a un script de experimento

Para pasar valores de parámetros a un script que se está ejecutando en un experimento, necesita proporcionar un valor de 
argumentos que contenga una lista de argumentos separados por comas y sus valores al **ScriptRunConfig**, de la siguiente manera:

```python
# Create a script config
script_config = ScriptRunConfig(source_directory='training_folder',
                                script='training.py',
                                arguments = ['--reg-rate', 0.1],
                                environment=sklearn_env)
```

## 3 Registering models
[< Back to Local Index](#3-index)

Después de ejecutar un experimento que entrena un modelo, puede utilizar una referencia al objeto Ejecutar para recuperar 
sus resultados, incluido el modelo entrenado.

### Recuperación de archivos de modelo

Una vez finalizada la ejecución de un experimento, puede utilizar el método **get_file_names** de los objetos run para 
listar los archivos generados. La práctica estándar es que los scripts que entrenan modelos los guarden en la carpeta de
salidas de la ejecución.

También puede utilizar los métodos **download_file** y **download_files** del objeto run para descargar los archivos de 
salida al sistema de archivos local.

```python
# "run" is a reference to a completed experiment run

# List the files generated by the experiment
for file in run.get_file_names():
    print(file)

# Download a named file
run.download_file(name='outputs/model.pkl', output_file_path='model.pkl')
```

### Registro de un modelo

El registro de modelos le permite realizar un seguimiento de varias versiones de un modelo y recuperar modelos para
inferencias(predicción de valores de etiquetas a partir de nuevos datos). Cuando registra un modelo, puede especificar un 
nombre, una descripción, etiquetas, un marco (como Scikit-Learn o PyTorch), una versión del marco, propiedades personalizadas 
y otros metadatos útiles. Al registrar un modelo con el mismo nombre que un modelo existente, se crea automáticamente una 
nueva versión del modelo, empezando por 1 y aumentando en unidades de 1.

Para registrar un modelo desde un archivo local, puede utilizar el método **register** del objeto **Model** como se muestra aquí:

```python
from azureml.core import Model

model = Model.register(workspace=ws,
                       model_name='classification_model',
                       model_path='model.pkl', # local path
                       description='A classification model',
                       tags={'data-format': 'CSV'},
                       model_framework=Model.Framework.SCIKITLEARN,
                       model_framework_version='0.20.3')
```

Alternativamente, si tiene una referencia a la **Ejecución** utilizada para entrenar el modelo, puede utilizar su método
**register_model** como se muestra aquí:

```python
run.register_model( model_name='classification_model',
                    model_path='outputs/model.pkl', # run outputs path
                    description='A classification model',
                    tags={'data-format': 'CSV'},
                    model_framework=Model.Framework.SCIKITLEARN,
                    model_framework_version='0.20.3')
```

### Visualización de modelos registrados

Puede ver los modelos registrados en Azure Machine Learning studio. También puede utilizar el objeto **Model** para recuperar 
los detalles de los modelos registrados como se muestra aquí:

```python
from azureml.core import Model

for model in Model.list(ws):
    # Get model name and auto-generated version
    print(model.name, 'version:', model.version)
```


## 3 Exercise Training and registering a model
[< Back to Local Index](#3-index)

Ahora es su oportunidad de utilizar Azure Machine Learning para entrenar un modelo de aprendizaje automático

En este ejercicio, usted:


- Utilizar un script para entrenar un modelo
- Utilizar un script parametrizado para entrenar un modelo
- Registrar un modelo.


### Instrucciones

Siga estas instrucciones para completar el ejercicio.

1. Si aún no dispone de una suscripción a Azure, regístrese para obtener una prueba gratuita en 
https://azure.microsoft.com

2. Vea el repositorio del ejercicio en 
https://aka.ms/mslearn-dp100

3. Si aún no lo ha hecho, complete el ejercicio Crear un espacio de trabajo de Azure Machine Learning para aprovisionar un espacio de trabajo de Azure Machine Learning, crear una instancia de cálculo y clonar los archivos necesarios

4. Complete el ejercicio Entrenar modelos.

### Train models using the Azure Machine Learning SDK

![m1.gif](ims%2FC3%2Fgifs%2Fm1.gif)

![m2.gif](ims%2FC3%2Fgifs%2Fm2.gif)

![m3.gif](ims%2FC3%2Fgifs%2Fm3.gif)

![m4.gif](ims%2FC3%2Fgifs%2Fm4.gif)

![m5.gif](ims%2FC3%2Fgifs%2Fm5.gif)

![m6.gif](ims%2FC3%2Fgifs%2Fm6.gif)

![m7.gif](ims%2FC3%2Fgifs%2Fm7.gif)

![m8.gif](ims%2FC3%2Fgifs%2Fm8.gif)

![m9.gif](ims%2FC3%2Fgifs%2Fm9.gif)

![m10.gif](ims%2FC3%2Fgifs%2Fm10.gif)

![m11.gif](ims%2FC3%2Fgifs%2Fm11.gif)

> ### Nota:
> El notebook de esta clase está en: [05 - Train Models.ipynb](ims%2FC3%2Fnotebooks%2F05%20-%20Train%20Models.ipynb)

## 3 Exercise quiz
[< Back to Local Index](#3-index)

![3.png](ims%2FC3%2Fims%2F1%2F3.png)

## 3 Knowledge Check
[< Back to Local Index](#3-index)

![q1.png](ims%2FC3%2Ftest%2Fq1.png)

![q2.png](ims%2FC3%2Ftest%2Fq2.png)

![q3.png](ims%2FC3%2Ftest%2Fq3.png)

## 3 Test prep
[< Back to Local Index](#3-index)

![q4.png](ims%2FC3%2Ftest%2Fq4.png)

![q5.png](ims%2FC3%2Ftest%2Fq5.png)

![q6.png](ims%2FC3%2Ftest%2Fq6.png)

![q7.png](ims%2FC3%2Ftest%2Fq7.png)



## 3 Lesson Summary
[< Back to Local Index](#3-index)

![4.png](ims%2FC3%2Fims%2F1%2F4.png)

En este módulo, ha aprendido a entrenar un modelo de aprendizaje automático con Azure machine learning. O, más concretamente, 
ha aprendido a utilizar un script, run Config para ejecutar un script de entrenamiento de modelos como un experimento de 
aprendizaje automático de Azure. Cree scripts de restricción de parámetros reutilizables y modelos entrenados registrados.

# 4 Work with Data in Azure Machine Learning

## 4 INDEX

- [4 Lesson Introduction](#4-lesson-introduction)
- [4 Introduction to datastores](#4-introduction-to-datastores)
- [4 Use datastores](#4-use-datastores)
- [4 Introduction to datasets](#4-introduction-to-datasets)
- [4 Use datasets](#4-use-datasets)
- [4 Exercise Work with data](#4-exercise-work-with-data)
- [4 Exercise quiz](#4-exercise-quiz)
- [4 Knowledge check](#4-knowledge-check)
- [4 Lesson summary](#4-lesson-summary)
- [4 Additional Reading](#4-additional-reading)

[< Back to index](#0-index)

## 4 Lesson Introduction
[< Back to Local Index](#4-index)

![1.png](ims%2FC4%2Fims%2F1%2F1.png)

Hola, en esta lección, aprenderá a trabajar con datos en el aprendizaje automático de Azure. Los datos son un elemento 
fundamental en cualquier carga de trabajo de aprendizaje automático. 

En esta lección, aprenderá a crear y gestionar almacenes de datos y conjuntos de datos en un espacio de trabajo de 
aprendizaje automático de Azure. Y a utilizarlos en experimentos de entrenamiento de modelos. 

![2.png](ims%2FC4%2Fims%2F1%2F2.png)

En esta lección, aprenderá a crear y utilizar almacenes de datos, y a crear y utilizar conjuntos de datos.

## 4 Introduction to datastores
[< Back to Local Index](#4-index)

![1.png](ims%2FC4%2Fims%2F2%2F1.png)

En Azure machine Learning los almacenes de datos o abstracciones para fuentes de datos en la nube, encapsulan la información 
necesaria para conectarse a las fuentes de datos. Puede acceder a los almacenes de datos directamente codificar utilizando 
el SDK de Azure Machine Learning y utilizarlo para cargar o descargar datos.

![2.png](ims%2FC4%2Fims%2F2%2F2.png)

A medida que su machine learning soporta la creación de almacenes de datos de múltiples tipos de fuente de datos Azure, 
incluyendo Azure storage blob y contenedores de archivos. Almacenes Azure data Lake como su base de datos SQL y Azure data 
bricks, sistema de archivos o D B F S

![3.png](ims%2FC4%2Fims%2F2%2F3.png)

para una lista completa de los almacenes de datos soportados, consulte la documentación de Azure machine Learning de la 
página web de Microsoft, puede encontrar un enlace a esta página web desde las lecturas adicionales al final de esta lección.

![4.png](ims%2FC4%2Fims%2F2%2F4.png)

Cada espacio de trabajo tiene dos almacenes de datos incorporados y como su contenedor de almacenamiento blob y un contenedor 
de archivos de almacenamiento Azure que son utilizados como sistema de almacenamiento por Azure Machine Learning también 
hay un tercer almacén de datos que se añade a su espacio de trabajo. Si hace uso de los conjuntos de datos abiertos 
proporcionados como muestras, por ejemplo, creando un pipeline de diseño basado en un conjunto de datos de muestra. 

![5.png](ims%2FC4%2Fims%2F2%2F5.png)

![6.png](ims%2FC4%2Fims%2F2%2F6.png)

En la mayoría de los proyectos de aprendizaje automático, es probable que necesite trabajar con fuentes de datos propias. 
Esto se debe a que necesitará almacenar volúmenes de datos mayores que los que admite el almacén de datos incorporado o 
porque necesita integrar su solución de aprendizaje automático con datos de aplicaciones existentes

## 4 Use datastores
[< Back to Local Index](#4-index)

![1.png](ims%2FC4%2Fims%2F3%2F1.png)

Para añadir un banco de datos a su espacio de trabajo, puede registrarlo mediante la interfaz gráfica de Azure Machine 
Learning Studio, o puede usar Azure SDK de aprendizaje automático. Por ejemplo, registrar un almacenamiento de Azure 
Contenedores de blobs, nombres de un almacén de datos datos de subrayado de blob.

![2.png](ims%2FC4%2Fims%2F3%2F2.png)

Puede ver y administrar almacenes de datos en Azure Machine Learning Studio o puede usar Azure Machine SDK de aprendizaje. 
Por ejemplo, usar un bucle para enumerar los nombres de cada almacén de datos en el espacio de trabajo

![3.png](ims%2FC4%2Fims%2F3%2F3.png)

puede obtener una referencia a cualquier almacén de datos utilizando el método datastore get.

![4.png](ims%2FC4%2Fims%2F3%2F4.png)

El espacio de trabajo siempre incluye un almacén de datos predeterminado, que puede recuperar mediante el método get default 
datastore de un objeto de espacio de trabajo. El almacén de datos predeterminado está integrado inicialmente en el espacio 
de trabajo almacén de datos de blob store.

![5.png](ims%2FC4%2Fims%2F3%2F5.png)

Cuando planifique un almacén de datos, tenga en cuenta la siguientes pautas : Al usar Azure Blob Storage, nivel premium el 
almacenamiento puede proporcionar un rendimiento de E/S mejorado para conjuntos de datos de gran tamaño. Sin embargo, esta 
opción lo hará incrementará los costos y puede limitar las opciones de replicación para redundancia de datos.

![6.png](ims%2FC4%2Fims%2F3%2F6.png)

Cuando se trabaja con archivos de datos: aunque el formato CSV es muy común, el formato Parquet generalmente da como resultado 
un mejor rendimiento. 

![7.png](ims%2FC4%2Fims%2F3%2F7.png)

![8.png](ims%2FC4%2Fims%2F3%2F8.png)

Puedes acceder a cualquier el almacén de datos por nombre, pero quizá le interese cambiar el almacén 
de datos predeterminado, que inicialmente era el almacén de datos integrado en el espacio de trabajo.

![9.png](ims%2FC4%2Fims%2F3%2F9.png)

Para cambiar el almacén de datos predeterminado, usa el valor predeterminado establecido método de almacén de datos.

## 4 Introduction to datasets
[< Back to Local Index](#4-index)

Los conjuntos de datos son objetos de datos empaquetados y versionados que pueden consumirse fácilmente en experimentos y 
pipelines. Los conjuntos de datos son la forma recomendada de trabajar con los datos, y son el mecanismo principal para 
las capacidades avanzadas de Azure Machine Learning, como el etiquetado de datos y la supervisión de la deriva de los datos.

### Tipos de conjuntos de datos

Los conjuntos de datos suelen basarse en archivos de un almacén de datos, aunque también pueden basarse en URL y otras fuentes. 
Puede crear los siguientes tipos de conjuntos de datos:

- **Tabular:** Los datos se leen del conjunto de datos como una tabla. Debe utilizar este tipo de conjunto de datos cuando 
sus datos estén estructurados de forma consistente y desee trabajar con ellos en estructuras de datos tabulares comunes, 
como los dataframes de Pandas.

- **Archivo:** El conjunto de datos presenta una lista de rutas de archivos que pueden leerse como si procedieran del sistema 
de archivos. Utilice este tipo de conjunto de datos cuando sus datos no estén estructurados, o cuando necesite procesar 
los datos a nivel de archivo (por ejemplo, para entrenar una red neuronal convolucional a partir de un conjunto de archivos 
de imágenes).

### Creación y registro de conjuntos de datos

Puede utilizar la interfaz visual de Azure Machine Learning studio o el SDK de Azure Machine Learning para crear conjuntos 
de datos a partir de archivos individuales o de varias rutas de archivos. Las rutas pueden incluir comodines (por ejemplo
,/archivos/*.csv), lo que permite encapsular datos de un gran número de archivos en un único conjunto de datos.

Una vez creado un conjunto de datos, puede registrarlo en el espacio de trabajo para que esté disponible para su uso posterior 
en experimentos y canalizaciones de procesamiento de datos.

### Creación y registro de conjuntos de datos tabulares

Para crear un conjunto de datos tabular utilizando el SDK, utilice el método **from_delimited_files** de la clase 
**Dataset.Tabular**, como se muestra a continuación:

```python
from azureml.core import Dataset

blob_ds = ws.get_default_datastore()
csv_paths = [(blob_ds, 'data/files/current_data.csv'),
             (blob_ds, 'data/files/archive/*.csv')]
tab_ds = Dataset.Tabular.from_delimited_files(path=csv_paths)
tab_ds = tab_ds.register(workspace=ws, name='csv_table')
```

El conjunto de datos de este ejemplo incluye datos de dos rutas de archivos dentro del almacén de datos predeterminado:

- El archivo **current_data.csv** de la carpeta **data/files**.

- Todos los archivos **.csv** de la carpeta **data/files/archive/.**

Tras crear el conjunto de datos, el código lo registra en el espacio de trabajo con el nombre **csv_table**.

### Creación y registro de conjuntos de datos de archivos

Para crear un conjunto de datos de archivo utilizando el SDK, utilice el método **from_files** de la clase 
**Dataset.File**, como se muestra a continuación:

```python
from azureml.core import Dataset

blob_ds = ws.get_default_datastore()
file_ds = Dataset.File.from_files(path=(blob_ds, 'data/files/images/*.jpg'))
file_ds = file_ds.register(workspace=ws, name='img_files')
```

El conjunto de datos de este ejemplo incluye todos los archivos **.jpg** de la ruta **data/files/images** dentro del almacén 
de datos predeterminado:

Después de crear el conjunto de datos, el código lo registra en el área de trabajo con el nombre **img_files**.

### Recuperación de un conjunto de datos registrado

Después de registrar un conjunto de datos, puede recuperarlo utilizando cualquiera de las siguientes técnicas:

- El atributo de **diccionario datasets** de un objeto **Espacio de trabajo**.

- El método **get_by_name** o **get_by_id** de la claseDataset.

Ambas técnicas se muestran en el siguiente código:

```python
import azureml.core
from azureml.core import Workspace, Dataset

# Load the workspace from the saved config file
ws = Workspace.from_config()

# Get a dataset from the workspace datasets collection
ds1 = ws.datasets['csv_table']

# Get a dataset by name from the datasets class
ds2 = Dataset.get_by_name(ws, 'img_files')
```

### Versionado de conjuntos de datos

Los conjuntos de datos pueden versionarse, lo que le permite realizar un seguimiento de las versiones históricas de los 
conjuntos de datos que se utilizaron en experimentos y reproducir dichos experimentos con datos en el mismo estado.

Puede crear una nueva versión de un conjunto de datos registrándolo con el mismo nombre que un conjunto de datos previamente 
registrado y especificando la propiedad **create_new_version**:

```python
img_paths = [(blob_ds, 'data/files/images/*.jpg'),
             (blob_ds, 'data/files/images/*.png')]
file_ds = Dataset.File.from_files(path=img_paths)
file_ds = file_ds.register(workspace=ws, name='img_files', create_new_version=True)
```

En este ejemplo, los archivos .png de la carpeta **images** se han añadido a la definición del ejemplo de conjunto de datos
**img_paths** utilizado en el tema anterior.

### Recuperación de una versión específica del conjunto de datos

Puede recuperar una versión específica de un conjunto de datos especificando el parámetro **version** en el método 
**get_by_name** de la clase **Dataset**.

```python
img_ds = Dataset.get_by_name(workspace=ws, name='img_files', version=2)
```

## 4 Use datasets
[< Back to Local Index](#4-index)

Los conjuntos de datos son la forma principal de pasar datos a los experimentos que entrenan modelos.

### Trabajar con conjuntos de datos tabulares

Puede leer los datos directamente desde un conjunto de datos tabular convirtiéndolo en un marco de datos Pandas o Spark:

```python
df = tab_ds.to_pandas_dataframe()
# code to work with dataframe goes here, for example:
print(df.head())
```

### Pasar un conjunto de datos tabular a un script de experimento

Cuando necesite acceder a un conjunto de datos en un script de experimento, debe pasar el conjunto de datos al script. 
Hay dos formas de hacerlo.

### Utilizar un argumento de script para un conjunto de datos tabular

Puede pasar un conjunto de datos tabular como argumento de script. Cuando adopta este enfoque, el argumento que recibe el 
script es el ID único para el conjunto de datos en su espacio de trabajo. En el script, puede entonces obtener el espacio 
de trabajo del contexto de ejecución y utilizarlo para recuperar el conjunto de datos por su ID.

_ScriptRunConfig_:

```python
env = Environment('my_env')
packages = CondaDependencies.create(conda_packages=['pip'],
                                    pip_packages=['azureml-defaults',
                                                  'azureml-dataprep[pandas]'])
env.python.conda_dependencies = packages

script_config = ScriptRunConfig(source_directory='my_dir',
                                script='script.py',
                                arguments=['--ds', tab_ds],
                                environment=env)
```
_Script:_

```python
from azureml.core import Run, Dataset

parser.add_argument('--ds', type=str, dest='dataset_id')
args = parser.parse_args()

run = Run.get_context()
ws = run.experiment.workspace
dataset = Dataset.get_by_id(ws, id=args.dataset_id)
data = dataset.to_pandas_dataframe()
```

### Utilizar una entrada con nombre para un conjunto de datos tabular

Como alternativa, puede pasar un conjunto de datos tabular como una entrada con **nombre**. En este enfoque, usted utiliza el 
método **as_named_input** del conjunto de datos para especificar un nombre para el conjunto de datos. 

A continuación, en el script, puede recuperar el conjunto de datos por su nombre de la colección **input_datasets** del contexto 
de ejecución sin necesidad de recuperarlo del espacio de trabajo. Tenga en cuenta que si utiliza este enfoque, seguirá 
necesitando incluir un argumento de script para el conjunto de datos, aunque en realidad no lo utilice para recuperar el 
conjunto de datos.

_ScriptRunConfig:_

```python
env = Environment('my_env')
packages = CondaDependencies.create(conda_packages=['pip'],
                                    pip_packages=['azureml-defaults',
                                                  'azureml-dataprep[pandas]'])
env.python.conda_dependencies = packages

script_config = ScriptRunConfig(source_directory='my_dir',
                                script='script.py',
                                arguments=['--ds', tab_ds.as_named_input('my_dataset')],
                                environment=env)
```

_Script:_

```python
from azureml.core import Run

parser.add_argument('--ds', type=str, dest='ds_id')
args = parser.parse_args()

run = Run.get_context()
dataset = run.input_datasets['my_dataset']
data = dataset.to_pandas_dataframe()
```

### Trabajar con conjuntos de datos de archivos

Cuando trabaje con un conjunto de datos de archivo, puede utilizar el método **to_path()** para devolver una lista de las 
rutas de archivo encapsuladas por el conjunto de datos:

```python
for file_path in file_ds.to_path():
    print(file_path)
```

### Pasar un conjunto de datos de archivo a un script de experimento

Al igual que con un conjunto de datos Tabular, existen dos formas de pasar un conjunto de datos de archivo a un script. 
Sin embargo, existen algunas diferencias clave en la forma de pasar el conjunto de datos.

### Utilizar un argumento de script para un conjunto de datos de archivo

Puede pasar un conjunto de datos de archivo como argumento de script. A diferencia de lo que ocurre con un conjunto de datos 
tabular, debe especificar un modo para el argumento del conjunto de datos de archivo, que puede ser **as_download** o 
**as_mount**. Esto proporciona un punto de acceso que el script puede utilizar para leer los archivos del conjunto de datos. 

En la mayoría de los casos, debería utilizar **as_download**, que copia los archivos a una ubicación temporal en el 
ordenador donde se está ejecutando el script. Sin embargo, si está trabajando con una gran cantidad de datos para los que 
puede no haber suficiente espacio de almacenamiento en el ordenador del experimento, utilice **as_mount** para transmitir 
los archivos directamente desde su fuente.

_ScriptRunConfig:_

```python
env = Environment('my_env')
packages = CondaDependencies.create(conda_packages=['pip'],
                                    pip_packages=['azureml-defaults',
                                                  'azureml-dataprep[pandas]'])
env.python.conda_dependencies = packages

script_config = ScriptRunConfig(source_directory='my_dir',
                                script='script.py',
                                arguments=['--ds', file_ds.as_download()],
                                environment=env)
```

_Script:_

```python
from azureml.core import Run
import glob

parser.add_argument('--ds', type=str, dest='ds_ref')
args = parser.parse_args()
run = Run.get_context()

imgs = glob.glob(args.ds_ref + "/*.jpg")
```

### Utilizar una entrada con nombre para un conjunto de datos de archivo

También puede pasar un conjunto de datos de archivos como una entrada con **nombre**. En este enfoque, utilice el método
**as_named_input** del conjunto de datos para especificar un nombre antes de especificar el modo de acceso. A continuación, 
en el script, puede recuperar el conjunto de datos por su nombre de la colección **input_datasets** del contexto de ejecución 
y leer los archivos desde allí. 

Al igual que con los conjuntos de datos tabulares, si utiliza una entrada con nombre, deberá incluir un argumento de script 
para el conjunto de datos, aunque en realidad no lo utilice para recuperar el conjunto de datos.

_ScriptRunConfig:_

```python
env = Environment('my_env')
packages = CondaDependencies.create(conda_packages=['pip'],
                                    pip_packages=['azureml-defaults',
                                                  'azureml-dataprep[pandas]'])
env.python.conda_dependencies = packages

script_config = ScriptRunConfig(source_directory='my_dir',
                                script='script.py',
                                arguments=['--ds', file_ds.as_named_input('my_ds').as_download()],
                                environment=env)
```

_Script:_

```python
from azureml.core import Run
import glob

parser.add_argument('--ds', type=str, dest='ds_ref')
args = parser.parse_args()
run = Run.get_context()

dataset = run.input_datasets['my_ds']
imgs= glob.glob(dataset + "/*.jpg")
```

## 4 Exercise Work with data
[< Back to Local Index](#4-index)

Ahora es su oportunidad de trabajar con datos en Azure Machine Learning.

En este ejercicio, usted

- Cargar datos en un almacén de datos
- Crear conjuntos de datos
- Utilizar conjuntos de datos para entrenar un modelo

### Instrucciones

1. Si aún no dispone de una suscripción a Azure, suscríbase a una prueba gratuita en
https://azure.microsoft.com.

2. Consulte el repositorio del ejercicio en
https://aka.ms/mslearn-dp100.

3. Si aún no lo ha hecho, complete el ejercicio Crear un espacio de trabajo de Azure Machine Learning para aprovisionar un espacio de trabajo de Azure Machine Learning, crear una instancia de cálculo y clonar los archivos necesarios.

4. Complete el ejercicio Trabajar con datos.

Como ya es costumbre, vamos a iniciar Corriendo nuestro: `Compute-instance` -> `Coursera-cpu`

![1.png](ims%2FC4%2Fims%2F4%2F1.png)

Y ahora vayamos al `Notebook` de: `06 - Work with Data.ipynb`

> ### Nota:
> El Notebook completo de esta clase está en: [06 - Work with Data.ipynb](ims%2FC4%2FNotebooks%2F06%20-%20Work%20with%20Data.ipynb)

![2.png](ims%2FC4%2Fims%2F4%2F2.png)

1. Como ya sabemos el primer paso sería abrir el Notebook de esta clase y verificar la versión de AML que estamos utilizando,
   asi como crear nuestro `ws` a partir de nuestro `config.json`:

   ![m1.gif](ims%2FC4%2Fgifs%2Fm1.gif)

2. Ahora en lugar de crear un nuevo `cluster` vamos a aprovechar que en la sesión anterior, ya habiamos creado uno llamado: `coursera-clsuter`
   el cuál sin problemas podemos volver a usar para esta clase:   
   ![m2.gif](ims%2FC4%2Fgifs%2Fm2.gif)

3. En el momento que creamos un `ws` se nos asigna por defecto un `datastore`al inicio cuando creamos el workspace: `mlw-dp100-labs`
   se nos asignaron un par de datastores.
   ![m3.gif](ims%2FC4%2Fgifs%2Fm3.gif)

4. Esto tambien lo podemos ver en: `Data/datastores` y notar los mismos nombres de datastores

   ![m4.gif](ims%2FC4%2Fgifs%2Fm4.gif)

5. Ahora veamos como nuestro repositorio clonado de `GitHub` ya contiene una carpeta llamada `Data` la cuál contiene dos archivos
   `.csv` sobre diabetes. Nuestro objetivo será sencillo: subir esos documentos a una carpeta llamada `diabetes-data` a nustro 
   `datastore` por defecto, podemos validar que el proceso es éxitoso entrando al mismo:

   ![m5.gif](ims%2FC4%2Fgifs%2Fm5.gif)

6. Ahora, una cosa es que el archivo ya este en la "nube" ya éxiste dentro del datastore default, pero debemos convertirlo en un `tabular dataset`,
   para eso de forma sencilla, apuntamos a nuestro `datastore` a la carpeta `diabetes-data` y podemos emplear todos los archivos que sean `.csv`

   ![m6.gif](ims%2FC4%2Fgifs%2Fm6.gif)

   De forma simple podemos ver las primeras 20 filas de nuestro ahora, tabular dataset 

7. Sin embargo, no siempre nuestros datos tendrán forma tabular, a veces serán archivos, y lo que debemos construir entonces es un `file Dataset` 
   que a diferencia del anterior lo que almacena es una lista que contiene la dirección a cada archivo:

   ![m7.gif](ims%2FC4%2Fgifs%2Fm7.gif)

8. Como ya hemos creado los datasets que vamos a utilizar uno `tabular` y otro del tipo `file` el siguiente paso es `registrarlos` para que esten
   `disponibles` para nuestros futuros experimentos

   ![m8.gif](ims%2FC4%2Fgifs%2Fm8.gif)

9. Podemos observar que ahora que han sido registrados podemos enlistarlos y no solo eso, ahora también éxisten dentro de `Data`, podemos ver
   cada uno de ellos de forma individual y ver como `Tabular` directamente nos regresa una vista del csv mientras que `File` nos regresa una vista previa de cada archivo.

   ![m9.gif](ims%2FC4%2Fgifs%2Fm9.gif)

10. **Entrenar un modelo con un dataset:**
   
   > Atención:
   > 
   > Este proceso puede parecer un poco rebuscado, pero en realidad NO es tan díficil como parece.  

   En las clases anteriores, habíamos visto que para entrenar un modelo, teníamos que tener un archivo de `training.py` que es el que 
   eventualmente crea un archivo .pkl, elige el modelo de scikit lear para entrenar, procesa los datos del dataframe etc.

   Sabíamos que teníamos que crear una carpeta y en dicha carpeta tenía que éxistir tanto el archivo .csv del dataset que iba a entrenar
   al modelo, como el código que generase el modelo. 
   
   Sin embargo, todo lo que hemos echo hasta ahora, ha sido para tener el dataset en la nube ya disponible en AZURE, entonces sería interesante
   que para entrenar el modelo utilicemos información que ya está en la nube.

   Lo que vamos a hacer entonces es que nuestro archivo de entrenamiento, contenga como parámetro un `alias` al dataset que vamos a utilizar que existe en AZURE. 

   ![m10.gif](ims%2FC4%2Fgifs%2Fm10.gif)

   _esto es como decirle que vas a utilizar un dataset a partir de su id_
   ```python
   parser.add_argument("--input-data", type=str, dest='training_dataset_id', help='training dataset')
   ```
   Sin embargo, en el proceso de `ScriptRunConfig`, NO es que pasemos literalmente un `id` al parámetro `--input-data` lo que hacemos es un poco más rebuscado. 

   _primero creamos un apuntador al dataset que nos interesa_

   ```python
   # Get the training dataset
   diabetes_ds = ws.datasets.get("diabetes dataset")
   ```
   
   _después, ahora vamos a enviar el id del dataset, pero con un nombre `alias` que en este caso es `training_data`_

   ```python
   # Create a script config
   script_config = ScriptRunConfig(source_directory=experiment_folder,
                                 script='diabetes_training.py',
                                 arguments = ['--regularization', 0.1, # Regularizaton rate parameter
                                              '--input-data', diabetes_ds.as_named_input('training_data')],
   ```

   Ahora efectivamente podemos crear nuestro experimento: `experiment_name = 'mslearn-train-diabetes'` y entrenar al modelo :D

11. Ahora, ya hemos corrido el experimento, pero le hemos puesto un nombre que ya habíamos utilizado en anteriores clases. Por eso cuando vayamos al apartado de `Jobs` veremos como
   ya teníamos experimentos anteriores asociados al mismo nombre, Pero eso no es mayor problema, solamente tenemos que ir al experimento más reciente, y podemos notar sus métricas
   y adicionalmente en `Code` observamos como es el código más reciente que hemos creado.
   ![m11.gif](ims%2FC4%2Fgifs%2Fm11.gif)

12. Ahora solo nos queda registrar el modelo, sabemos que podemos ponerle cualquier nombre, pero como a fin de cuentas todo lo que hemos hecho corresponde
   a un mismo dataset y a un mismo experimento, le vamos a poner el mismo nombre del modelo, con lo cuál creará una versión 3 del modelo `diabetes_model`
   podemos ir a la pestaña `Models` antes de correr el código para percatarnos de que antes no éxiste y después sí.
   ![m12.gif](ims%2FC4%2Fgifs%2Fm12.gif)

13. Ahora vamos a repetir básicamente el mismo proceso, pero en lugar de utilizar un `Tabular` dataset  estamos empleando un `File` dataset.

   ![m13.gif](ims%2FC4%2Fgifs%2Fm13.gif)

   Lo que más vale la pena destacar aqui. que es diferente al ejemplo pasado, es que ahora NO tuvimos directamente un `dataframe`, si no una lista que contiene los 
   directorios a diferentes archivos .csv, por eso usamos `blob` para ver la ruta a cada archivo, y cada uno de forma independiente lo abrimos y usamos pd.concat para 
   juntar todos en un solo dataframe:

   ```python
   # load the diabetes dataset
   print("Loading Data...")
   data_path = run.input_datasets['training_files'] # Get the training data path from the input
   # (You could also just use args.dataset_folder if you don't want to rely on a hard-coded friendly name)
   
   # Read the files
   all_files = glob.glob(data_path + "/*.csv")
   diabetes = pd.concat((pd.read_csv(f) for f in all_files), sort=False)
   ```
   Básicamente, esa es la principal diferencia, para cada `f` dentro de `all_files` leímos el archivo csv y lo concatenamos para finalmente rear `diabetes

14. Podemos correr el experimento con el mismo nombre, y observar los cambios.

   ![m14.gif](ims%2FC4%2Fgifs%2Fm14.gif)

15. Ahora, veamos los resultados del nuevo experimento, vemos como los resultados de AUC son ligeramente inferiores al experimento anterior.

   ![m15.gif](ims%2FC4%2Fgifs%2Fm15.gif)

16. Lo registramos para tener una versión 4 del modelo:

   ![m16.gif](ims%2FC4%2Fgifs%2Fm16.gif)

17. No olvidemos detener la instancia `compute` para que no nos cobren extra:

   ![m17.gif](ims%2FC4%2Fgifs%2Fm17.gif)

## 4 Exercise quiz
[< Back to Local Index](#4-index)

![1.png](ims%2FC4%2Ftest%2F1.png)

## 4 Knowledge check
[< Back to Local Index](#4-index)

![q1.png](ims%2FC4%2Ftest%2Fq1.png)

![q2.png](ims%2FC4%2Ftest%2Fq2.png)

![q3.png](ims%2FC4%2Ftest%2Fq3.png)

## 4 Lesson summary
[< Back to Local Index](#4-index)

![1.png](ims%2FC4%2Fims%2F5%2F1.png)

En esta lección, ha aprendido cómo trabajar con datos en Azure Machine Learning. Más concretamente, ha aprendido cómo crear y utilizar almacenes de datos, y crear y utilizar conjuntos de datos. 

![2.png](ims%2FC4%2Fims%2F5%2F2.png)

Para más detalles sobre cómo trabajar con datos en Azure Machine Learning, consulte la página web sobre acceso a datos en Azure Machine Learning, que está disponible en el sitio web de Microsoft. Puede encontrar un enlace a esta página web desde las lecturas adicionales al final de esta lección.

## 4 Additional Reading
[< Back to Local Index](#4-index)

**Introduction to datastores**

[Secure data access in Azure Machine Learning](https://docs.microsoft.com/en-us/azure/machine-learning/concept-data#access-data-in-storage)
**Working with data**

[Secure data access in Azure Machine Learning](https://docs.microsoft.com/en-us/azure/machine-learning/concept-data#access-data-in-storage)

# 5 Work with Compute in Azure Machine Learning

## 5 INDEX

- [5 Lesson introduction](#5-lesson-introduction)
- [5 Environments in Azure Machine Learning](#5-environments-in-azure-machine-learning)
- [5 Creating environments](#5-creating-environments)
- [5 Introduction to compute targets](#5-introduction-to-compute-targets)
- [5 Create compute targets](#5-create-compute-targets)
- [5 Use compute targets](#5-use-compute-targets)
- [5 Exercise Work with Compute Contexts](#5-exercise-work-with-compute-contexts)
- [5 Exercise quiz](#5-exercise-quiz)
- [5 Knowledge check](#5-knowledge-check)
- [5 Test prep](#5-test-prep)
- [5 Lesson summary](#5-lesson-summary)
- [5 Additional reading](#5-additional-reading)

[< Back to index](#0-index)

## 5 Lesson introduction
[< Back to Local Index](#5-index)

![1.png](ims%2FC5%2Fims%2F1%2F1.png)

Hola. En esta lección, aprenderá a trabajar con computación en Azure Machine Learning. En Azure Machine Learning, los 
científicos de datos pueden ejecutar experimentos basados en scripts que procesan datos, entrenan modelos de aprendizaje 
automático y realizan otras tareas de ciencia de datos. 

![2.png](ims%2FC5%2Fims%2F1%2F2.png)

El contexto de ejecución de cada experimento consta de dos elementos. El **entorno para el script**, que incluye todos los 
paquetes de los que depende el script y **el objetivo de computación** en el que se desplegará el entorno y ejecutará el script. 

![3.png](ims%2FC5%2Fims%2F1%2F3.png)

En esta lección, aprenderá a crear y utilizar entornos y a crear y utilizar objetivos de computación.

## 5 Environments in Azure Machine Learning
[< Back to Local Index](#5-index)

![1.png](ims%2FC5%2Fims%2F2%2F1.png)

El código Python se ejecuta en el contexto de un entorno virtual que define la versión de el tiempo de ejecución de Python 
que se utilizará, así como los paquetes instalados disponibles para el código. En la mayoría de las instalaciones de Python, 
los paquetes se instalan y gestionan en entornos utilizando Conda o Pip.

![2.png](ims%2FC5%2Fims%2F2%2F2.png)

Para mejorar la portabilidad, solemos crear entornos en contenedores docker que a su vez se alojan en objetivos informáticos 
como su ordenador de desarrollo, máquinas virtuales o clústeres en la Nube. 

![3.png](ims%2FC5%2Fims%2F2%2F3.png)

n general, Azure Machine Learning gestiona la creación de entornos y la instalación de paquetes por usted, normalmente a 
través de la creación de contenedores docker. 

![4.png](ims%2FC5%2Fims%2F2%2F4.png)

Puede especificar los paquetes Conda o Pip que necesite, y hacer que Azure Machine Learning cree un entorno para el experimento. 

![5.png](ims%2FC5%2Fims%2F2%2F5.png)

En una solución de aprendizaje automático empresarial, donde los experimentos pueden ejecutarse en una variedad de contextos 
informáticos, puede ser importante ser consciente de los entornos en los que se ejecuta el código de su experimento. Los 
entornos están encapsulados por la clase environment, que puede utilizar para crear entornos y especificar la configuración 
de tiempo de ejecución para un experimento. Puede hacer que Azure Machine Learning gestione la creación de entornos, y la 
instalación de paquetes para definir un entorno, y luego registrarlo para su reutilización. 

![6.png](ims%2FC5%2Fims%2F2%2F6.png)

![7.png](ims%2FC5%2Fims%2F2%2F7.png)

Alternativamente, puede gestionar sus propios entornos y registrarlos. Esto hace posible definir contextos de tiempo de 
ejecución reutilizables y consistentes para sus experimentos, independientemente de dónde se ejecute el script del experimento.

## 5 Creating environments
[< Back to Local Index](#5-index)

Hay varias formas de crear entornos en Azure Machine Learning.

### Creación de un entorno a partir de un archivo de especificación

Puede utilizar un archivo de especificación Conda o pip para definir los paquetes necesarios en un entorno Python, y 
utilizarlo para crear un objeto **Entorno**.

Por ejemplo, podría guardar los siguientes ajustes de configuración de Conda en un archivo llamado **conda.yml**:

```yaml
name: py_env
dependencies:
  - numpy
  - pandas
  - scikit-learn
  - pip:
    - azureml-defaults
```

A continuación, podría utilizar el siguiente código para crear un entorno Azure Machine Learning a partir del archivo de 
especificaciones guardado:

```python
from azureml.core import Environment

env = Environment.from_conda_specification(name='training_environment',
                                           file_path='./conda.yml')
```

### Creación de un entorno a partir de un entorno Conda existente

Si tiene un entorno **Conda** existente definido en su estación de trabajo, puede utilizarlo para definir un entorno 
Azure Machine Learning:

```python
from azureml.core import Environment

env = Environment.from_existing_conda_environment(name='training_environment',
                                                  conda_environment_name='py_env')
```

### Creación de un entorno especificando paquetes

Puede definir un entorno especificando los paquetes Conda y pip que necesita en un objeto **CondaDependencies**, de esta forma:

```python
from azureml.core import Environment
from azureml.core.conda_dependencies import CondaDependencies

env = Environment('training_environment')
deps = CondaDependencies.create(conda_packages=['scikit-learn','pandas','numpy'],
                                pip_packages=['azureml-defaults'])
env.python.conda_dependencies = deps
```

### Configuración de contenedores de entorno

Normalmente, los entornos para experimentos script se crean en **contenedores**. El siguiente código configura un experimento 
basado en script para alojar el entorno env creado previamente en un contenedor (esto es lo predeterminado a menos que 
utilice un **DockerConfiguration** con un atributo **use_docker** de **False**, en cuyo caso el entorno se crea directamente 
en el objetivo de computación)

```python
from azureml.core import Experiment, ScriptRunConfig
from azureml.core.runconfig import DockerConfiguration

docker_config = DockerConfiguration(use_docker=True)

script_config = ScriptRunConfig(source_directory='my_folder',
                                script='my_script.py',
                                environment=env,
                                docker_runtime_config=docker_config)
```

Azure Machine Learning utiliza una biblioteca de imágenes base para contenedores, eligiendo la base apropiada para el 
objetivo de computación que especifique (por ejemplo, incluyendo soporte Cuda para computación basada en GPU). Si ha creado 
imágenes de contenedor personalizadas y las ha registrado en un registro de contenedores, puede anular las imágenes base 
predeterminadas y utilizar las suyas propias modificando los atributos de la propiedad **docker** del entorno.

```python
env.docker.base_image='my-base-image'
env.docker.base_image_registry='myregistry.azurecr.io/myimage'
```

Alternativamente, puede hacer que se cree una imagen bajo demanda basada en la imagen base y en ajustes adicionales en un archivo dockerfile.

```python
env.docker.base_image = None
env.docker.base_dockerfile = './Dockerfile'
```

Por defecto, Azure machine Learning gestiona las rutas de Python y las dependencias de los paquetes. Si su imagen ya incluye 
una instalación de Python con las dependencias que necesita, puede anular este comportamiento estableciendo **python.user_managed_dependencies** 
en **True** y estableciendo una ruta Python explícita para su instalación.

```python
env.python.user_managed_dependencies=True
env.python.interpreter_path = '/opt/miniconda/bin/python'
```

### Registro y reutilización de entornos

Después de haber creado un entorno, puede registrarlo en su espacio de trabajo y reutilizarlo para futuros experimentos 
que tengan las mismas dependencias de Python.

### Registrar un entorno

Utilice el método **register** de un objeto **Environment** para registrar un entorno:

```python
env.register(workspace=ws)
```

Así puede ver los entornos registrados en su espacio de trabajo:

```python
from azureml.core import Environment

env_names = Environment.list(workspace=ws)
for env_name in env_names:
    print('Name:',env_name)
```

### Recuperar y utilizar un entorno

Puede recuperar un entorno registrado utilizando el método **get** de la clase **Environment** y, a continuación, asignarlo 
a un **ScriptRunConfig**.

Por ejemplo, el siguiente ejemplo de código recupera el entorno registrado **training_environment**, y lo asigna a una 
configuración de ejecución de script:

```python
from azureml.core import Environment, ScriptRunConfig

training_env = Environment.get(workspace=ws, name='training_environment')

script_config = ScriptRunConfig(source_directory='my_folder',
                                script='my_script.py',
                                environment=training_env)
```

Cuando se ejecute un experimento basado en el estimador, Azure Machine Learning buscará un entorno existente que coincida 
con la definición y, si no se encuentra ninguno, se creará un nuevo entorno basado en la especificación del entorno registrado.

## 5 Introduction to compute targets
[< Back to Local Index](#5-index)

![1.png](ims%2FC5%2Fims%2F3%2F1.png)

Bienvenido a esta sección en la que aprenderá sobre los objetivos de computación. En Azure Machine Learning, los objetivos 
de computación son ordenadores físicos o virtuales en los que se ejecutan los experimentos.

![2.png](ims%2FC5%2Fims%2F3%2F2.png)

Azure Machine Learning admite múltiples tipos de computación para la experimentación y el entrenamiento. Esto le permite 
seleccionar el tipo de objetivo de computación más apropiado para sus necesidades particulares. Estos tipos incluyen: 
computación local, clusters de computación y computación adjunta. Veamos ahora cada uno de ellos con un poco más de detalle.

![3.png](ims%2FC5%2Fims%2F3%2F3.png)

Puede especificar un objetivo de computación local para la mayoría de las tareas de procesamiento en Azure Machine Learning. 
Esto ejecuta el experimento en el mismo objetivo de computación que el código utilizado para iniciar el experimento. 
Esta puede ser su estación de trabajo física o una máquina virtual como una instancia de computación de Azure Machine 
Learning en la que esté ejecutando un cuaderno. La computación local es generalmente una gran elección durante el desarrollo 
y las pruebas, con volúmenes de datos de bajos a moderados.

![4.png](ims%2FC5%2Fims%2F3%2F4.png)

Para cargas de trabajo de experimentos con altos requisitos de escalabilidad, puede utilizar los clústeres de computación 
de Azure Machine Learning, que son clústeres de múltiples nodos de máquinas virtuales que se escalan automáticamente hacia 
arriba o hacia abajo para satisfacer la demanda. Esta es una forma rentable de ejecutar experimentos que necesitan manejar 
grandes volúmenes de datos, o utilizar el procesamiento paralelo para distribuir la carga de trabajo y reducir el tiempo 
que tarda en ejecutarse. 

![5.png](ims%2FC5%2Fims%2F3%2F5.png)

Si ya utiliza un entorno de computación basado en Azure para la ciencia de datos, como una máquina virtual o un clúster 
Azure Databricks, puede adjuntarlo a su espacio de trabajo Azure Machine Learning y utilizarlo como objetivo de computación 
para determinados tipos de carga de trabajo.

![6.png](ims%2FC5%2Fims%2F3%2F6.png)

Es importante señalar que en Azure Machine Learning Studio, puede crear otro tipo de computación denominada clústeres de 
inferencia. Este tipo de computación representa un clúster de Azure Kubernetes Service, y sólo puede utilizarse para 
desplegar modelos entrenados como servicios de inferencia. Exploraremos el despliegue más adelante, pero por ahora nos 
centramos en la computación para experimentos y entrenamiento de modelos. 

![7.png](ims%2FC5%2Fims%2F3%2F7.png)

La capacidad de asignar ejecuciones de experimentos a objetivos de computación específicos le ayuda a implementar un ecosistema 
de ciencia de datos flexible de las siguientes maneras. El código puede desarrollarse y probarse en computación local o 
de bajo coste y luego trasladarse a computación más escalable para cargas de trabajo de producción.

![8.png](ims%2FC5%2Fims%2F3%2F8.png)

Puede ejecutar procesos individuales en el objetivo de computación que mejor se adapte a sus necesidades. Por ejemplo, 
utilizando computación basada en CPU para entrenar modelos de aprendizaje profundo, y cambiando a computación basada 
únicamente en CPU de menor coste para probar y registrar el modelo entrenado. 

![9.png](ims%2FC5%2Fims%2F3%2F9.png)

Una de las principales ventajas de la computación en nube es la capacidad de gestionar los costes pagando sólo por lo que se utiliza.

![10.png](ims%2FC5%2Fims%2F3%2F10.png)

En Azure Machine Learning, puede aprovechar este principio definiendo objetivos de computación que se inician bajo demanda 
y se detienen automáticamente cuando ya no son necesarios, y se escalan automáticamente basándose en las necesidades de 
procesamiento de la carga de trabajo.

## 5 Create compute targets
[< Back to Local Index](#5-index)

Las formas más comunes de crear o adjuntar un objetivo de cómputo son utilizar la página de **cómputo** en Azure Machine 
Learning studio, o utilizar el SDK de Azure Machine Learning para aprovisionar objetivos de cómputo en código.

### Creación de un objetivo de cálculo gestionado con el SDK

Un objetivo de computación _gestionado_ es aquel que está gestionado por Azure Machine Learning, como un clúster de 
computación de Azure Machine Learning.

Para crear un clúster de computación de Azure Machine Learning, utilice la clase **azureml.core.compute.ComputeTarget** y 
la clase **AmlCompute**, como en este ejemplo.

```python
from azureml.core import Workspace
from azureml.core.compute import ComputeTarget, AmlCompute

# Load the workspace from the saved config file
ws = Workspace.from_config()

# Specify a name for the compute (unique within the workspace)
compute_name = 'aml-cluster'

# Define compute configuration
compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_DS11_V2',
                                                       min_nodes=0, max_nodes=4,
                                                       vm_priority='dedicated')

# Create the compute
aml_cluster = ComputeTarget.create(ws, compute_name, compute_config)
aml_cluster.wait_for_completion(show_output=True)
```

En este ejemplo, se creará un clúster con hasta cuatro nodos basado en la imagen de máquina virtual **STANDARD_DS12_v2.** 
La prioridad para las máquinas virtuales (VM) se establece en **dedicada**, lo que significa que están reservadas para su 
uso en este clúster (la alternativa es especificar prioridad baja, que tiene un coste **menor** pero significa que las VM 
pueden ser adelantadas si una carga de trabajo de mayor prioridad requiere el cómputo).

> Nota:
> 
> Para obtener una lista completa de las opciones de configuración de [AmlCompute](https://aka.ms/AA70zfq),
> consulte la documentación del SDK de la clase [AmlCompute](https://aka.ms/AA70zfq).

### Adjuntar un objetivo de computación no gestionado con el SDK

Un objetivo de cálculo _no gestionado_ es aquel que se define y gestiona fuera del espacio de trabajo de Azure Machine Learning; 
por ejemplo, una máquina virtual Azure o un clúster Azure Databricks.

El código para adjuntar un objetivo de cómputo no gestionado existente es similar al código utilizado para crear un objetivo 
de cómputo gestionado, excepto que debe utilizar el método **ComputeTarget.attach()** para adjuntar el cómputo existente 
basándose en sus ajustes de configuración específicos del objetivo.

Por ejemplo, el siguiente código puede utilizarse para adjuntar un clúster Azure Databricks existente:

```python
from azureml.core import Workspace
from azureml.core.compute import ComputeTarget, DatabricksCompute

# Load the workspace from the saved config file
ws = Workspace.from_config()

# Specify a name for the compute (unique within the workspace)
compute_name = 'db_cluster'

# Define configuration for existing Azure Databricks cluster
db_workspace_name = 'db_workspace'
db_resource_group = 'db_resource_group'
db_access_token = '1234-abc-5678-defg-90...'
db_config = DatabricksCompute.attach_configuration(resource_group=db_resource_group,
                                                   workspace_name=db_workspace_name,
                                                   access_token=db_access_token)

# Create the compute
databricks_compute = ComputeTarget.attach(ws, compute_name, db_config)
databricks_compute.wait_for_completion(True)
```

### Comprobación de un objetivo de computación existente

En muchos casos, querrá comprobar la existencia de un objetivo de cómputo, y sólo crear uno nuevo si no hay ya uno con 
el nombre especificado. Para lograrlo, puede capturar la excepción **ComputeTargetException**, de la siguiente manera:

```python
from azureml.core.compute import ComputeTarget, AmlCompute
from azureml.core.compute_target import ComputeTargetException

compute_name = "aml-cluster"

# Check if the compute target exists
try:
    aml_cluster = ComputeTarget(workspace=ws, name=compute_name)
    print('Found existing cluster.')
except ComputeTargetException:
    # If not, create it
    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_DS11_V2',
                                                           max_nodes=4)
    aml_cluster = ComputeTarget.create(ws, compute_name, compute_config)

aml_cluster.wait_for_completion(show_output=True)
```

> **Más información:** Para obtener más información sobre la creación de objetivos de cálculo, consulte
[Configurar y utilizar objetivos de cálculo para el entrenamiento de modelos](https://aka.ms/AA70rrg)
 en la documentación de Azure Machine Learning.

## 5 Use compute targets
[< Back to Local Index](#5-index)

Después de haber creado o adjuntado objetivos de cálculo en su espacio de trabajo, puede utilizarlos para ejecutar cargas 
de trabajo específicas; como experimentos.

Para utilizar un objetivo de cálculo concreto, puede especificarlo en el parámetro adecuado para una configuración de 
ejecución de experimentos o un estimador. Por ejemplo, el siguiente código configura un estimador para que utilice el 
objetivo de cálculo denominado _aml-cluster_:

```python
from azureml.core import Environment, ScriptRunConfig

compute_name = 'aml-cluster'

training_env = Environment.get(workspace=ws, name='training_environment')

script_config = ScriptRunConfig(source_directory='my_dir',
                                script='script.py',
                                environment=training_env,
                                compute_target=compute_name)
```

Cuando se envíe un experimento, la ejecución se pondrá en cola mientras se inicia el objetivo de cálculo _aml-cluster_ y 
se crea en él el entorno especificado, y luego la ejecución se procesará en el entorno de cálculo.

En lugar de especificar el nombre del objetivo de cómputo, puede especificar un objeto _ComputeTarget_, así:

```python
from azureml.core import Environment, ScriptRunConfig
from azureml.core.compute import ComputeTarget

compute_name = "aml-cluster"

training_cluster = ComputeTarget(workspace=ws, name=compute_name)

training_env = Environment.get(workspace=ws, name='training_environment')

script_config = ScriptRunConfig(source_directory='my_dir',
                                script='script.py',
                                environment=training_env,
                                compute_target=training_cluster)
```

## 5 Exercise Work with Compute Contexts
[< Back to Local Index](#5-index)

Ahora es su oportunidad de trabajar con entornos y objetivos de computación en Azure Machine Learning.

En este ejercicio, usted podrá:

- Crear y utilizar un entorno.

- Crear y utilizar un objetivo de cómputo.

### Instrucciones

Siga estas instrucciones para completar el ejercicio.

1. Si aún no tiene una suscripción a Azure, regístrese para una prueba gratuita en
https://azure.microsoft.com.

2. Consulte el repositorio del ejercicio en
https://aka.ms/mslearn-dp100.

3. Si aún no lo ha hecho, complete el ejercicioCrear un espacio de trabajo de Azure Machine Learning para aprovisionar un espacio de trabajo de Azure Machine Learning, crear una instancia de computación y clonar los archivos necesarios.

4. Complete el ejercicio **Trabajar con computación**.

### Notebook

Como ya es costumbre, vamos a iniciar Corriendo nuestro: `Compute-instance` -> `Coursera-cpu`

> ### Nota
> El notebook de esta clase está en: [07 - Work with Compute.ipynb](ims%2FC5%2FNotebooks%2F07%20-%20Work%20with%20Compute.ipynb)

![1.png](ims%2FC4%2Fims%2F4%2F1.png)

1. Empezamos con lo básico: creamos nuestro `ws` a partir de nuestra configuración y checamos la versión de AML que usamos

   ![m1.gif](ims%2FC5%2Fgifs%2Fm1.gif)

2. En el notebook anterior ya habiamos registrado un `tabular dataset` de `diabetes dataset`, el cuál podemos verificar en la pestaña de `Data`
   como ya éxiste, entonces sol estamos comprobando que esté registrado, sino entonces lo hubieramos creado con ese código.
   ![m2.gif](ims%2FC5%2Fgifs%2Fm2.gif)

3. Como ya es común, vamos a crear una nueva carpeta `diabetes_training_logistic` para entrenar a nuestro modelo de confianza `logistic_regerssion`
   para este punto ya somos conscientes de como se usa un script con parámetros y que uno de esos parámetros sea el `dataset` y que tenga un:
   `alias` en este caso llamado `training_data
   ![m3.gif](ims%2FC5%2Fgifs%2Fm3.gif)

4. Ahora, vamos a crear un archivo `.yml` (env.yml) que contiene la versión de python a utilizar así como los paquetes `conda` a instalar y los paquetes `pip`
   > Nota: no queda claro porque algunos paquetes son con Conda y otros con Pip
   ![m4.gif](ims%2FC5%2Fgifs%2Fm4.gif)

5. Creamos un `experiment_env` a partir de nuestro `env.yml` que esta en la carpeta `diabetes_training_logistic` y vamos a hacer que la gestion de paquetes NO sea por el contenedor Docker, sino por AZURE.

   ![m5.gif](ims%2FC5%2Fgifs%2Fm5.gif)

6. Con el environment creado ya podemos correr el `RunScriptConfig`, apuntamos al folder, al archivo `.py` obtenemos con un `get` el `diabetes dataset` que esta cargado en Azure, 
   le ponemos como `alias`: `training dataset`, especificamos el `.env` que ya creamos, y finalmente, usamos un `contenedor Docker`

   ![m6.gif](ims%2FC5%2Fgifs%2Fm6.gif)

7. **Veamos los resultados:**
   Podemos ver los resultados de ACU y ACC y en `Jobs` podemos ver nuestro último experimento, con sus métricas e imágenes creadas y también en outputs el modelo `.pkl` generado y en `code` también vemos
   NO solo el archivo .py sino también el archivo `.yml` que usamos para crear el `.env`
   ![m7.gif](ims%2FC5%2Fgifs%2Fm7.gif)

8. Vamos a registrar nuestro nuevo `custom environment` para después usarlo en posteriores proyectos:

   ![m8.gif](ims%2FC5%2Fgifs%2Fm8.gif)  
   
   Podemos observar como realmente nuestro `environment` se ha registrado con éxito :D

9. Nuestro objetivo ahora es crear un nuevo experimento, usar el mismo dataset PERO utilizar un nuevo modelo: `DecisionTreeClassifier`
   Ya conocemos el path: crear un folder y crear el `training.py` y poner como argumento el dataset. Al utilizar un `DTC` NO pasamos el parámetro `--regularization` porque NO tiene ese parámetro.
   ![m9.gif](ims%2FC5%2Fgifs%2Fm9.gif)

10. El objetivo es utilizar `Environment.get(ws, nombre)` para obtener el `environment` que ya creamos anteriormente. De ahí en fuera todo igual

   ![m10.gif](ims%2FC5%2Fgifs%2Fm10.gif)

11. Veamos los resultados del modelo. Ahora nuestro ACC ha aumentado ligeramente a 0.89 y AUC a 0.88 

   ![m11.gif](ims%2FC5%2Fgifs%2Fm11.gif)

12. Vamos a asegurarnos de enlistar los ambientes registrados y ver como sí éxiste `experiment env`

   ![m12.gif](ims%2FC5%2Fgifs%2Fm12.gif)

13. Vamos a crear un nuevo `Cluster`, esto ya lo hemos hecho antes, de echo lo hicimos para crear nuestro `coursera-cluster` ahora hacemos lo mismo para crear un `test-cluster` 

   ![m13.gif](ims%2FC5%2Fgifs%2Fm13.gif)

14. Lo interesante NO es solo checar que hicimos un nuevo `cluster` sino ahora utilizarlo explícitamente para correr un nuevo experimento.

   ![m14.gif](ims%2FC5%2Fgifs%2Fm14.gif)

15. vemos como ahora hemos declarado explícitamente nuestro `compute target`

   ![m15.gif](ims%2FC5%2Fgifs%2Fm15.gif)

16. Efectivamente el `cluster` está corriendo:

   ![m16.gif](ims%2FC5%2Fgifs%2Fm16.gif)

17. Finalmente, veamos los resultados del experimento y registremos nuestro más reciente modelo:

   ![m17.gif](ims%2FC5%2Fgifs%2Fm17.gif)

18. Adicionalmente, podemos ver algo muy interesante:
   Podemos comprobar como hemos utilizado específicamente el `custom environment` que hemos creado anteriormente.
   ![m18.gif](ims%2FC5%2Fgifs%2Fm18.gif)

19. Como paso final, debemos detener nuestro `compute instance`:

   ![1.png](ims%2FC5%2Fgifs%2F1.png)


## 5 Exercise quiz
[< Back to Local Index](#5-index)

![0.png](ims%2FC5%2Ftest%2F0.png)

## 5 Knowledge check
[< Back to Local Index](#5-index)

![q1.png](ims%2FC5%2Ftest%2Fq1.png)

![q2.png](ims%2FC5%2Ftest%2Fq2.png)

![q3.png](ims%2FC5%2Ftest%2Fq3.png)

![q4.png](ims%2FC5%2Ftest%2Fq4.png)

## 5 Test prep
[< Back to Local Index](#5-index)

![w1.png](ims%2FC5%2Ftest%2Fw1.png)

![w2.png](ims%2FC5%2Ftest%2Fw2.png)

![w3.png](ims%2FC5%2Ftest%2Fw3.png)

![w4.png](ims%2FC5%2Ftest%2Fw4.png)

![w5.png](ims%2FC5%2Ftest%2Fw5.png)

![w6.png](ims%2FC5%2Ftest%2Fw6.png)

## 5 Lesson summary
[< Back to Local Index](#5-index)

![1.png](ims%2FC5%2Fims%2F4%2F1.png)

En este módulo, ha aprendido cómo trabajar con computación en Azure Machine Learning. Más concretamente, ha aprendido cómo crear y utilizar entornos, y crear y utilizar objetivos de computación.

![2.png](ims%2FC5%2Fims%2F4%2F2.png)

Para obtener más información sobre entornos en Azure Machine Learning, consulte reutilizar entornos para la formación y el despliegue mediante Azure Machine Learning.

![3.png](ims%2FC5%2Fims%2F4%2F3.png)

Para más información sobre los objetivos de computación en Azure Machine Learning, consulte qué son los objetivos de computación en Azure Machine Learning. Puede encontrar un enlace a estos recursos desde las lecturas adicionales al final de esta lección.

## 5 Additional reading
[< Back to Local Index](#5-index)

**Environments in Azure Machine Learning** 

[Reuse environments for training and deployment by using Azure Machine Learning](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-use-environments)

**Compute targets in Azure Machine Learning**

[What are compute targets in Azure Machine Learning](https://docs.microsoft.com/en-us/azure/machine-learning/concept-compute-target)

# 6 Orchestrate Machine Learning with Pipelines


## 6 INDEX

- [6 Lesson introduction](#6-lesson-introduction)
- [6 Introduction to pipelines](#6-introduction-to-pipelines)
- [6 Pass data between pipeline steps](#6-pass-data-between-pipeline-steps)
- [6 OutputFileDatasetConfig Step Inputs and Outputs](#6-outputfiledatasetconfig-step-inputs-and-outputs)
- [6 Reuse pipeline steps](#6-reuse-pipeline-steps)
- [6 Publish pipelines](#6-publish-pipelines)
- [6 Use pipelines parameters](#6-use-pipelines-parameters)
- [6 Schedule pipelines](#6-schedule-pipelines)
- [6 Exercise Create a pipeline](#6-exercise-create-a-pipeline)
- [6 Exercise quiz](#6-exercise-quiz)
- [6 Knowledge Check](#6-knowledge-check)
- [6 Lesson summary](#6-lesson-summary)
- [6 Additional Reading](#6-additional-reading)

[< Back to index](#0-index)

## 6 Lesson introduction
[< Back to Local Index](#6-index)

![1.png](ims%2FC6%2Fims%2F1%2F1.png)

Hola. En Azure Machine Learning, usted ejecuta cargas de trabajo como experimentos, pero aprovechando los activos de 
datos y los recursos de computación. En un proceso de ciencia de datos empresarial, generalmente querrá separar el proceso 
general en tareas individuales y orquestar estas tareas como Pipelines de pasos conectados.

![2.png](ims%2FC6%2Fims%2F1%2F2.png)

Los pipelines son clave para implementar una solución eficaz de aprendizaje automático operacionalización o MLOps en Azure. 
Explorará cómo definirlos y ejecutarlos en este módulo. 

![3.png](ims%2FC6%2Fims%2F1%2F3.png)

Es importante tener en cuenta que el término pipeline se utiliza ampliamente en el aprendizaje automático, a menudo con 
diferentes significados. Por ejemplo, en Scikit-learn, puede definir pipelines que combinen transformaciones de 
preprocesamiento de datos con un algoritmo de entrenamiento, y en Azure DevOps, puede definir un pipeline de construcción 
o lanzamiento para realizar las tareas de construcción y configuración necesarias para entregar software. Este módulo se 
centra en pipelines de aprendizaje automático de Azure, que encapsula pasos que pueden ejecutarse como un experimento.

![4.png](ims%2FC6%2Fims%2F1%2F4.png)

Sin embargo, es importante tener en mente que es perfectamente factible tener un canal Azure DevOps con una tarea que inicie 
un canal Azure Machine Learning, que a su vez incluya un paso que entrene un modelo que esté basado en un canal Scikit-learn. 

![5.png](ims%2FC6%2Fims%2F1%2F5.png)

En esta lección, aprenderá a crear un canal de Azure Machine Learning, publicar en canal de Azure Machine Learning, y 
programar un canal de Azure Machine Learning.

## 6 Introduction to pipelines
[< Back to Local Index](#6-index)

![1.png](ims%2FC6%2Fims%2F2%2F1.png)

En el aprendizaje automático de Azure, una canalización es un tipo de flujo de trabajo, es un flujo de trabajo de tareas 
de aprendizaje automático en el que cada tarea se implementa como un paso. 

![2.png](ims%2FC6%2Fims%2F2%2F2.png)

Estos pasos pueden organizarse secuencialmente o en paralelo, lo que le permite construir una sofisticada lógica de flujo 
para orquestar las operaciones de aprendizaje automático.

![3.png](ims%2FC6%2Fims%2F2%2F3.png)

Cada paso puede ejecutarse en un objetivo de cómputo específico, lo que hace posible combinar diferentes tipos de 
procesamiento según sea necesario para lograr un objetivo general. 

![4.png](ims%2FC6%2Fims%2F2%2F4.png)

Una canalización puede ejecutarse como un proceso ejecutando la canalización como un experimento. Entonces, cada paso de 
la canalización se ejecuta en su objetivo de computación asignado como parte de la ejecución general del experimento.

![5.png](ims%2FC6%2Fims%2F2%2F5.png)

Una canalización de aprendizaje automático de Azure consta de uno o más pasos que realizan tareas. Existen muchos tipos 
de pasos admitidos por las canalizaciones de aprendizaje automático de Azure, cada uno con su propio propósito especializado 
y opciones de configuración. 

![6.png](ims%2FC6%2Fims%2F2%2F6.png)

Los tipos comunes de pasos en una canalización de aprendizaje automático de Azure incluyen:

- **PythonScriptStep**, ejecuta un script Python especificado. 
- **DataTransferStep**, utiliza la fábrica de datos de Azure para copiar datos entre almacenes de datos. 
- **DataBrickStep**, ejecuta un script de cuaderno o un jar compilado en un clúster de ladrillos de datos. 
- **AdlaStep**, ejecuta un trabajo de secuela de uso en Azure Data lake analytics. 
- **ParallelRunStep**, ejecuta un script Python como una tarea distribuida en múltiples nodos de computación. 

![7.png](ims%2FC6%2Fims%2F2%2F7.png)

Es importante tener en cuenta que para obtener una lista completa de los tipos de pasos soportados, consulte 
[Azure.pipeline.steps](https://docs.microsoft.com/en-us/python/api/azureml-pipeline-steps/azureml.pipeline.steps?view=azure-ml-py) package documentation. Puede encontrar un enlace a este documento en las lecturas adicionales al final de esta lección. 

![8.png](ims%2FC6%2Fims%2F2%2F8.png)


![9.png](ims%2FC6%2Fims%2F2%2F9.png)

Para crear una canalización, primero debe definir cada paso y después crear una canalización que incluya los pasos. 

![10.png](ims%2FC6%2Fims%2F2%2F10.png)

La configuración específica de cada paso depende del tipo de paso, por ejemplo, puede utilizar un código que defina dos 
pasos de script Python para preparar los datos y luego entrenar un modelo. 

![11.png](ims%2FC6%2Fims%2F2%2F11.png)

Una vez definidos estos pasos, puede asignarlos a una canalización y ejecutarla como un experimento.

## 6 Pass data between pipeline steps
[< Back to Local Index](#6-index)

![1.png](ims%2FC6%2Fims%2F3%2F1.png)

A menudo, una canalización incluye al menos un paso que depende de la salida de un paso anterior. 
![2.png](ims%2FC6%2Fims%2F3%2F2.png)

Por ejemplo, puede utilice un paso que desee que un script de Python preprocesar algunos datos, que luego deben usarse en 
un paso posterior para entrenar un modelo.


![3.png](ims%2FC6%2Fims%2F3%2F3.png)

El **OutputFileDatasetConfig** es un conjunto de datos especial. Es el conjunto de datos que hace referencia a una ubicación 
en un almacén de datos para el almacenamiento provisional de datos y crea una dependencia de datos entre los pasos de la canalización.

![4.png](ims%2FC6%2Fims%2F3%2F4.png)

Puede ver un archivo de salida objeto de configuración del conjunto de datos como almacén intermediario para los datos que 
deben pasarse de un paso a un paso posterior.


![5.png](ims%2FC6%2Fims%2F3%2F5.png)

Como se recomienda, puede usar **OutputFileDatasetConfig** para pasar datos entre los pasos. Para ello, debe 

- Definir un archivo de salida con nombre objeto de configuración de conjunto de datos que hace referencia a ubicación en un almacén de datos.
  (Si no es explícito Se especifica el almacén de datos, se utiliza el almacén de datos predeterminado.)
- Pase el archivo de salida el objeto de configuración del conjunto de datos como argumento de script en pasos que ejecutan 
scripts.
- Incluya código en ellos scripts para escribir en el conjunto de datos del archivo de salida argumento de configuración 
como salida o lectura como entrada.

  
![6.png](ims%2FC6%2Fims%2F3%2F6.png)

Por ejemplo, puedes usar código que defina un **OutputFileDatasetConfig**  para los datos preprocesados. 

![7.png](ims%2FC6%2Fims%2F3%2F7.png)

En los propios scripts, puede obtener una referencia **OutputFileDatasetConfig**  el objeto a partir del argumento del 
script y utilice es como una carpeta local. Puede acceder al versión completa de este código desde la lectura al final 
de esta lección.

## 6 OutputFileDatasetConfig Step Inputs and Outputs
[< Back to Local Index](#6-index)

Para utilizar un objeto **OutputFileDatasetConfig** para pasar datos entre pasos, debes:

1. Definir un objeto **OutputFileDatasetConfig** con nombre que haga referencia a una ubicación en un almacén de datos. 
Si no se especifica un almacén de datos explícito, se usará el almacén de datos predeterminado.

2. Pasar el objeto **OutputFileDatasetConfig** como argumento de script en los pasos que ejecuten scripts.

3. Incluir código en esos scripts para escribir en el objeto **OutputFileDatasetConfig** como salida o leerlo como entrada.

Por ejemplo, el siguiente código define un objeto **OutputFileDatasetConfig** para los datos preprocesados que deben 
pasarse entre los pasos.

```python
from azureml.data import OutputFileDatasetConfig
from azureml.pipeline.steps import PythonScriptStep, EstimatorStep

# Get a dataset for the initial data
raw_ds = Dataset.get_by_name(ws, 'raw_dataset')

# Define a PipelineData object to pass data between steps
data_store = ws.get_default_datastore()
prepped_data = OutputFileDatasetConfig('prepped')

# Step to run a Python script
step1 = PythonScriptStep(name = 'prepare data',
                         source_directory = 'scripts',
                         script_name = 'data_prep.py',
                         compute_target = 'aml-cluster',
                         # Script arguments include PipelineData
                         arguments = ['--raw-ds', raw_ds.as_named_input('raw_data'),
                                      '--out_folder', prepped_data])

# Step to run an estimator
step2 = PythonScriptStep(name = 'train model',
                         source_directory = 'scripts',
                         script_name = 'train_model.py',
                         compute_target = 'aml-cluster',
                         # Pass as script argument
                         arguments=['--training-data', prepped_data.as_input()])
```

Dentro de los propios scripts, puedes obtener una referencia al objeto **OutputFileDatasetConfig** a partir del argumento 
de script y usarlo como si fuera una carpeta local.

```python
# code in data_prep.py
from azureml.core import Run
import argparse
import os

# Get the experiment run context
run = Run.get_context()

# Get arguments
parser = argparse.ArgumentParser()
parser.add_argument('--raw-ds', type=str, dest='raw_dataset_id')
parser.add_argument('--out_folder', type=str, dest='folder')
args = parser.parse_args()
output_folder = args.folder

# Get input dataset as dataframe
raw_df = run.input_datasets['raw_data'].to_pandas_dataframe()

# code to prep data (in this case, just select specific columns)
prepped_df = raw_df[['col1', 'col2', 'col3']]

# Save prepped data to the PipelineData location
os.makedirs(output_folder, exist_ok=True)
output_path = os.path.join(output_folder, 'prepped_data.csv')
prepped_df.to_csv(output_path)
```

## 6 Reuse pipeline steps
[< Back to Local Index](#6-index)

Los **pipelines** con múltiples pasos de larga ejecución pueden tardar un tiempo considerable en completarse. 
Azure Machine Learning incluye algunas funciones de almacenamiento en caché y reutilización para reducir este tiempo.

### Gestión de la reutilización de la salida de pasos

Por defecto, la salida del paso de una ejecución anterior del pipeline se reutiliza sin necesidad de volver a ejecutar el 
paso siempre que el script, el directorio de origen y otros parámetros del paso no hayan cambiado. La reutilización de 
pasos puede reducir el tiempo que se tarda en ejecutar una canalización, pero puede dar lugar a resultados obsoletos cuando 
no se han tenido en cuenta los cambios en las fuentes de datos posteriores.

Para controlar la reutilización de un paso individual, puede establecer el parámetro **allow_reuse** en la configuración 
del paso, de la siguiente manera:

```python
step1 = PythonScriptStep(name = 'prepare data',
                         source_directory = 'scripts',
                         script_name = 'data_prep.py',
                         compute_target = 'aml-cluster',
                         runconfig = run_config,
                         inputs=[raw_ds.as_named_input('raw_data')],
                         outputs=[prepped_data],
                         arguments = ['--folder', prepped_data]),
                         # Disable step reuse
                         allow_reuse = False)
```

### Forzar la ejecución de todos los pasos

Cuando tenga varios pasos, puede forzar la ejecución de todos ellos independientemente de la configuración de reutilización 
individual estableciendo el parámetro **regenerate_outputs** al enviar el experimento de canalización:

```python
pipeline_run = experiment.submit(train_pipeline, regenerate_outputs=True)
```

## 6 Publish pipelines
[< Back to Local Index](#6-index)

Después de haber creado una canalización, puede publicarla para crear un punto final REST a través del cual se pueda ejecutar 
la canalización bajo demanda.

### Publicación de una canalización

Para publicar una canalización, puede llamar a su método **publish**, como se muestra aquí:

```python
published_pipeline = pipeline.publish(name='training_pipeline',
                                          description='Model training pipeline',
                                          version='1.0')
```

Alternativamente, puede llamar al método de publicación en una ejecución exitosa de la canalización:

```python
# Get the most recent run of the pipeline
pipeline_experiment = ws.experiments.get('training-pipeline')
run = list(pipeline_experiment.get_runs())[0]

# Publish the pipeline from the run
published_pipeline = run.publish_pipeline(name='training_pipeline',
                                          description='Model training pipeline',
                                          version='1.0')
```

Una vez publicada la canalización, puede verla en Azure Machine Learning studio. También puede determinar el URI 
de su endpoint de esta forma:

```python
rest_endpoint = published_pipeline.endpoint
print(rest_endpoint)
```

### Uso de una canalización publicada

Para iniciar un endpoint publicado, realice una solicitud HTTP a su endpoint REST, pasando una cabecera de autorización 
con un token para un service principal con permiso para ejecutar el pipeline, y una carga útil JSON especificando el 
nombre del experimento. La canalización se ejecuta de forma asíncrona, por lo que la respuesta de una llamada 
REST exitosa incluye el ID de ejecución. Puede utilizarlo para realizar un seguimiento de la ejecución en Azure Machine 
Learning studio.

Por ejemplo, el siguiente código Python realiza una solicitud REST para ejecutar una canalización y muestra el ID de 
ejecución devuelto.

```python
import requests

response = requests.post(rest_endpoint,
                         headers=auth_header,
                         json={"ExperimentName": "run_training_pipeline"})
run_id = response.json()["Id"]
print(run_id)
```

## 6 Use pipelines parameters
[< Back to Local Index](#6-index)

Puede aumentar la flexibilidad de una canalización definiendo parámetros.

### Definición de parámetros para una canalización

Para definir parámetros para una canalización, cree un objeto **PipelineParameter** para cada parámetro y especifique cada 
parámetro en al menos un paso.

Por ejemplo, puede utilizar el siguiente código para incluir un parámetro para una tasa de regularización en el script 
utilizado por un estimador:

```python
from azureml.pipeline.core.graph import PipelineParameter

reg_param = PipelineParameter(name='reg_rate', default_value=0.01)

...

step2 = PythonScriptStep(name = 'train model',
                         source_directory = 'scripts',
                         script_name = 'data_prep.py',
                         compute_target = 'aml-cluster',
                         # Pass parameter as script argument
                         arguments=['--in_folder', prepped_data,
                                    '--reg', reg_param],
                         inputs=[prepped_data])
```

> Nota
>
> Debe definir los parámetros para una canalización antes de publicarla.

### Ejecutar una canalización con un parámetro

Después de publicar una canalización parametrizada, puede pasar valores de parámetros en la carga útil JSON para la 
interfaz REST:

```python
response = requests.post(rest_endpoint,
                         headers=auth_header,
                         json={"ExperimentName": "run_training_pipeline",
                               "ParameterAssignments": {"reg_rate": 0.1}})
```

## 6 Schedule pipelines
[< Back to Local Index](#6-index)

Una vez publicada una canalización, puede iniciarla a petición a través de su punto final REST, o puede hacer que se 
ejecute automáticamente en función de una programación periódica o en respuesta a actualizaciones de datos.

### Programación de una canalización para intervalos periódicos

Para programar una canalización para que se ejecute a intervalos periódicos, debe definir una **ScheduleRecurrence** que 
determine la frecuencia de ejecución, y utilizarla para crear una **Schedule**.

Por ejemplo, el siguiente código programa una ejecución diaria de una canalización publicada.

```python
from azureml.pipeline.core import ScheduleRecurrence, Schedule

daily = ScheduleRecurrence(frequency='Day', interval=1)
pipeline_schedule = Schedule.create(ws, name='Daily Training',
                                        description='trains model every day',
                                        pipeline_id=published_pipeline.id,
                                        experiment_name='Training_Pipeline',
                                        recurrence=daily)
```

### Activar la ejecución de una canalización cuando cambian los datos

Para programar una canalización para que se ejecute cada vez que cambien los datos, debe crear un **Schedule** que supervise 
una ruta especificada en un almacén de datos, de la siguiente manera:

```python
from azureml.core import Datastore
from azureml.pipeline.core import Schedule

training_datastore = Datastore(workspace=ws, name='blob_data')
pipeline_schedule = Schedule.create(ws, name='Reactive Training',
                                    description='trains model on data change',
                                    pipeline_id=published_pipeline_id,
                                    experiment_name='Training_Pipeline',
                                    datastore=training_datastore,
                                    path_on_datastore='data/training')
```

## 6 Exercise Create a pipeline
[< Back to Local Index](#6-index)

En este ejercicio, usted


- Crear un pipeline de Azure Machine Learning

- Publicar un pipeline como un servicio REST

- Programar un pipeline.

### Instrucciones

Siga estas instrucciones para completar el ejercicio.


1. Si aún no tiene una suscripción a Azure, regístrese para una prueba gratuita en 
https://azure.microsoft.com

2. Consulte el repositorio del ejercicio en 
https://aka.ms/mslearn-dp100

3. Si aún no lo ha hecho, complete el ejercicio Crear un espacio de trabajo de Azure Machine Learning para aprovisionar un espacio de trabajo de Azure Machine Learning, crear una instancia de cálculo y clonar los archivos necesarios

4. Complete el ejercicio Crear una canalización.

### Notebook

Como ya es costumbre, vamos a iniciar Corriendo nuestro: `Compute-instance` -> `Coursera-cpu`

> ### Nota
> El notebook de esta clase está en: [08 - Create a Pipeline.ipynb](ims%2FC6%2Fnotebook%2F08%20-%20Create%20a%20Pipeline.ipynb)

![1.png](ims%2FC4%2Fims%2F4%2F1.png)


1. Como ya es costumbre, vamos a empezar definiendo nuestro `ws` y verificando nuestra versión de `AML`:

   ![m1.gif](ims%2FC6%2Fgifs%2Fm1.gif)

2. Ahora vamos a seguir utilizando el `diabetes dataset` que ya hemos registrado anteriormente.

   ![m2.gif](ims%2FC6%2Fgifs%2Fm2.gif)

3. El primer paso para crear nuestro `pipeline` es pensarlo como un `experimento` eso significa que debemos empezar creando
   un folder en donde vamos a tener nuestros scripts de python que vamos a ir ejecutando.

   ![m3.gif](ims%2FC6%2Fgifs%2Fm3.gif)

   El script `prep_diabetes.py` contiene una metodología ya bien conocida en este curso, pero agrega un paso interesante y es
   el de crear un `folder` temporal que necesitan los `pipeline` para poder intercambiar información entre los diferentes pasos del proceso.

   El objetivo del script es simple, preprocesar un `tabular dataset` utilizando un `MinMaxScaler`, una vez que este ha sido pre-procesado correctamente, 
   la salida (el dataset procesado) se guardara en una ruta `save_folder` notar específicamente esta sección:

   ```python
   # se leen los argumentos
   parser = argparse.ArgumentParser()
   # se prepara el argumento de folder temporal:
   parser.add_argument('--prepped-data', type=str, dest='prepped_data', default='prepped_data', help='Folder for results')
   # los argumentos quedan como un diccionario
   args = parser.parse_args()
   # y ahora podemos crear una variable con la dirección del folder temporal
   save_folder = args.prepped_data
   # eventualmente vamos a usar esta variable para crear una carpeta y ahí guardar el dataset procesado
   ```
   Después de procesar el dataset, para utilizar correctamente la metodología del `pipeline` de pasar información entre `steps` tenemos que
   guardar el dato en una ruta específica:

   ```python
   # Save the prepped data
   print("Saving Data...")
   os.makedirs(save_folder, exist_ok=True)
   save_path = os.path.join(save_folder,'data.csv')
   diabetes.to_csv(save_path, index=False, header=True)
   ```

4. El siguiente `step` es crear un script que entrene un modelo de `ML`para la clasificación de diabetes, en este caso usaremos un `DecisionTreeClassifier`

   ![m4.gif](ims%2FC6%2Fgifs%2Fm4.gif)

   > Nota: aqui hay un pequeño `truquito` hardcodeado

   ```python
    # Get parameters
    parser = argparse.ArgumentParser()
    parser.add_argument("--training-data", type=str, dest='training_data', help='training data')
    args = parser.parse_args()
    training_data = args.training_data
    
    # load the prepared data file in the training folder
    print("Loading Data...")
    file_path = os.path.join(training_data,'data.csv')
    diabetes = pd.read_csv(file_path)
   ```
   Técnicamente el argumento recibe la dirección del folder temporal NO el dataset tal cual, es por eso que el `file_path` tiene `hardcodeado` la palabra `data.csv`
   porque eso fue lo que escribimos en el script de python anterior. Esto me parece algo cuestionable pero digno de mencionar.

5. Este paso ya lo conocemos, simplemente es elegir un `ComputeTarget` que en este caso vamos a utilizar el que ya hemos creado anteriormente `coursera-cluster`

   ![m5.gif](ims%2FC6%2Fgifs%2Fm5.gif)

6. Este paso también ya lo conocemos que es crear nuestro archivo `experiment_env.yml` que vamos a utilizar para crear nuestro entorno virtual conda.

   ![m6.gif](ims%2FC6%2Fgifs%2Fm6.gif)

   Aquí asignamos y registramos nuestro `experiment_env`

   ```python
   # Create a Python environment for the experiment (from a .yml file)
   experiment_env = Environment.from_conda_specification("experiment_env", experiment_folder + "/experiment_env.yml")
   
   # Register the environment 
   experiment_env.register(workspace=ws)
   registered_env = Environment.get(ws, 'experiment_env')
   ```

7. Ahora, el punto es que antes de definir propiamente los pasos que van a componer al `pipeline` vamos a configurar sus parámetros, que en este caso
   serán, su `compute cluster` y su `environment`:

   ![m7.gif](ims%2FC6%2Fgifs%2Fm7.gif)

   ```python
    # Create a new runconfig object for the pipeline
    pipeline_run_config = RunConfiguration()
   
    # Use the compute you created above. 
    pipeline_run_config.target = pipeline_cluster
   
    # Assign the environment to the run configuration
    pipeline_run_config.environment = registered_env
   
    print("Run configuration created.")
   ```   

8. Propiamente, no podemos directamente utilizar los scripts de python como `steps` estos deben ser configurados como: `PythonScriptStep` 
   para efectivamente convertirlo a un formato que pueda ser utilizado en un `pipeline`.

   Entre las notas importantes que debemos aclarar es que este es el punto ideal para crear nuestra variable para compartir información:

   ```python
    # Create an OutputFileDatasetConfig (temporary Data Reference) for data passed from step 1 to step 2
    prepped_data = OutputFileDatasetConfig("prepped_data")
   ```

   ![m8.gif](ims%2FC6%2Fgifs%2Fm8.gif)

   > Notas interesantes en este paso:
   > 
   > -  En el Step 1: el argumento  '--prepped-data', es directamente la variable `prepped_data` que es un folder temporal
   > - No me queda super claro si en `compute_target` podría poner un `target` diferente para cada paso
   > - `Allow_reuse` como esta en `True` es para intentar ahorrar recursos si se vuelven a correr estos mismos pasos en futuros experimentos
   > - En el segundo paso del pipeline algo muy interesante es que el argumento que recibe como entra: arguments = ['--training-data', prepped_data.as_input() esta como `as_input()`
   
9. Nuestro pipeline no es más que una lsita de `steps` que ya han sido definidos, vamos a crear el `pipeline` y correr el experimento:

   ```python
    from azureml.core import Experiment
    from azureml.pipeline.core import Pipeline
    from azureml.widgets import RunDetails
   
    # Construct the pipeline
    pipeline_steps = [prep_step, train_step]
    pipeline = Pipeline(workspace=ws, steps=pipeline_steps)
    print("Pipeline is built.")
    
    # Create an experiment and run the pipeline
    experiment = Experiment(workspace=ws, name = 'mslearn-diabetes-pipeline')
    pipeline_run = experiment.submit(pipeline, regenerate_outputs=True)
    print("Pipeline submitted for execution.")
    RunDetails(pipeline_run).show()
    pipeline_run.wait_for_completion(show_output=True)
   ```

   ![m9.gif](ims%2FC6%2Fgifs%2Fm9.gif)

10. Un pipeline contiene varios scripts y cada uno de ellos con logs y metrics diferentes, por eso una vez que el `pipeline` se ha ejecutado por completo
   para revisar los resultados debemos hacerlo script a script:

   ```python
    for run in pipeline_run.get_children():
        print(run.name, ':')
        metrics = run.get_metrics()
        for metric_name in metrics:
            print('\t',metric_name, ":", metrics[metric_name])
   ```

   ![m10.gif](ims%2FC6%2Fgifs%2Fm10.gif)

11. El punto de publicar el `Pipeline` como un `rest endpoint` es poder hacer eventualmente un `request` y correr automáticamente todo el flujo del pipeline
   esto presenta varias ventajas, como por ejemplo poder hacer un `schedule` de cada cuanto ejecutar el pipeline

   ![m11.gif](ims%2FC6%2Fgifs%2Fm11.gif)

12. Básicamente para consumir el `pipeline` debemos obtener un `run_id` y ya con eso es como si fuera nuestro `Api key` que nos identifica a nosotros y al `pipeline` que queremos correr

   ![m12.gif](ims%2FC6%2Fgifs%2Fm12.gif)

13. Perfecto logramos ejecutar el `pipeline` desde un api rest, y ahora podemos proceder haciendo un `schedule` que lo ejecute una vez a la semana

   ![m13.gif](ims%2FC6%2Fgifs%2Fm13.gif)

14. Como paso final, debemos detener nuestro `compute instance`:

   ![1.png](ims%2FC5%2Fgifs%2F1.png)


## 6 Exercise quiz
[< Back to Local Index](#6-index)

![1.png](ims%2FC6%2Ftest%2F1.png)

## 6 Knowledge Check
[< Back to Local Index](#6-index)

![q1.png](ims%2FC6%2Ftest%2Fq1.png)

![q2.png](ims%2FC6%2Ftest%2Fq2.png)

## 6 Lesson summary
[< Back to Local Index](#6-index)

![2.png](ims%2FC6%2Ftest%2F2.png)

En esta lección, aprendió a crear una canalización de Azure Machine Learning, publicar una canalización de Azure Machine Learning, y programar una canalización de Azure Machine Learning.

## 6 Additional Reading
[< Back to Local Index](#6-index)

**Introduction to pipelines:**

[steps Package](https://docs.microsoft.com/en-us/python/api/azureml-pipeline-steps/azureml.pipeline.steps?view=azure-ml-py)

# 7 Deploy real-time machine learning services with Azure Machine Learning

## 7 INDEX

- [7 Lesson introduction](#7-lesson-introduction)
- [7 Deploy a model as a real-time service](#7-deploy-a-model-as-a-real-time-service)
- [7 Consume a real-time inferencing service](#7-consume-a-real-time-inferencing-service)
- [7 Troubleshoot service deployment](#7-troubleshoot-service-deployment)
- [7 Exercise Deploy a model as a real-time service](#7-exercise-deploy-a-model-as-a-real-time-service)
- [7 Exercise quiz](#7-exercise-quiz)
- [7 Knowledge Check](#7-knowledge-check)
- [7 Test prep](#7-test-prep)
- [7 Lesson summary](#7-lesson-summary)

[< Back to index](#0-index)

## 7 Lesson introduction
[< Back to Local Index](#7-index)

![1.png](ims%2FC7%2Fims%2F1.png)

En el aprendizaje automático, la inferencia se refiere al uso de un modelo entrenado para predecir etiquetas para nuevos datos en los que el modelo no ha sido entrenado. 

![2.png](ims%2FC7%2Fims%2F2.png)

A menudo, el modelo se despliega como parte de un servicio que permite a las aplicaciones solicitar predicciones inmediatas o en tiempo real para observaciones de datos individuales o en pequeño número.

![3.png](ims%2FC7%2Fims%2F3.png)

 En Azure Machine Learning, puede crear soluciones de inferencia en tiempo real desplegando un modelo como servicio alojado en una plataforma en contenedores como Azure Kubernetes Services o AKS. 

![4.png](ims%2FC7%2Fims%2F4.png)

En esta lección, aprenderá a desplegar un modelo como servicio de inferencia en tiempo real, servicio de inferencia en tiempo real del consumidor, y a solucionar problemas de despliegue del servicio.

## 7 Deploy a model as a real-time service
[< Back to Local Index](#7-index)

Puede desplegar un modelo como servicio web en tiempo real en varios tipos de destino de cómputo, incluido el cómputo local, 
una instancia de cómputo de Azure Machine Learning, una instancia de contenedor de Azure (ACI), un clúster de Azure Kubernetes 
Service (AKS), una función de Azure o un módulo de Internet de las cosas (IoT). Azure Machine Learning utiliza contenedores 
como mecanismo de despliegue, empaquetando el modelo y el código para utilizarlo como una imagen que puede desplegarse 
en un contenedor en su destino de computación elegido.

> ### Nota
>
> El despliegue en un servicio local, una instancia de computación o un ACI es una buena opción para pruebas y desarrollo. 
> Para producción, debe desplegar en un destino que satisfaga las necesidades específicas de rendimiento, escalabilidad y 
> seguridad de la arquitectura de su aplicación.

Para desplegar un modelo como servicio de inferencia en tiempo real, debe realizar las siguientes tareas:

### Registrar un modelo entrenado

Después de entrenar con éxito un modelo, debe registrarlo en su espacio de trabajo de Azure Machine Learning. Su servicio 
en tiempo real podrá entonces cargar el modelo cuando sea necesario.

Para registrar un modelo desde un archivo local, puede utilizar el método register del objetoModel como se muestra aquí:

```python
from azureml.core import Model

classification_model = Model.register(workspace=ws,
                       model_name='classification_model',
                       model_path='model.pkl', # local path
                       description='A classification model')
```

Alternativamente, si tiene una referencia a laEjecución utilizada para entrenar el modelo, puede utilizar su método
register_model como se muestra aquí:

```python
run.register_model( model_name='classification_model',
                    model_path='outputs/model.pkl', # run outputs path
                    description='A classification model')
```

### Definir una configuración de inferencia

El modelo se desplegará como un servicio que constará de:

- Un script para cargar el modelo y devolver predicciones para los datos enviados.

- Un entorno en el que se ejecutará el script.

Por lo tanto, debe definir el script y el entorno para el servicio.

### Crear un script de entrada

Cree el _script_ de entrada (a veces denominado _script de puntuación_) para el servicio como un archivo Python (.py). 
Debe incluir dos funciones:

- `init():` Llamada cuando se inicializa el servicio.

- `run(raw_data):` Llamada cuando se envían nuevos datos al servicio.

Normalmente, se utiliza la función **init** para cargar el modelo desde el registro de modelos, y se utiliza la función
**run** para generar predicciones a partir de los datos de entrada. El siguiente script de ejemplo muestra este patrón:

```python
import json
import joblib
import numpy as np
from azureml.core.model import Model

# Called when the service is loaded
def init():
    global model
    # Get the path to the registered model file and load it
    model_path = Model.get_model_path('classification_model')
    model = joblib.load(model_path)

# Called when a request is received
def run(raw_data):
    # Get the input data as a numpy array
    data = np.array(json.loads(raw_data)['data'])
    # Get a prediction from the model
    predictions = model.predict(data)
    # Return the predictions as any JSON serializable format
    return predictions.tolist()
```

### Crear un entorno

Su servicio requiere un entorno Python en el que ejecutar el script de entrada, que puede configurar utilizando el archivo de 
configuración **Conda**. Una forma sencilla de crear este archivo es utilizar una clase **CondaDependencies** para crear un entorno 
predeterminado (que incluye el paquete **azureml-defaults** y paquetes de uso común como **numpy** y **pandas**), añadir 
cualquier otro paquete necesario y, a continuación, serializar el entorno a una cadena y guardarlo:

```python
from azureml.core.conda_dependencies import CondaDependencies

# Add the dependencies for your model
myenv = CondaDependencies()
myenv.add_conda_package("scikit-learn")

# Save the environment config as a .yml file
env_file = 'service_files/env.yml'
with open(env_file,"w") as f:
    f.write(myenv.serialize_to_string())
print("Saved dependency info in", env_file)
```

### Combinar el script y el entorno en un InferenceConfig

Después de crear el script de entrada y el archivo de configuración del entorno, puede combinarlos en una **InferenceConfig** 
para el servicio de la siguiente manera:

```python
from azureml.core.model import InferenceConfig

classifier_inference_config = InferenceConfig(runtime= "python",
                                              source_directory = 'service_files',
                                              entry_script="score.py",
                                              conda_file="env.yml")
```

### Definir una configuración de despliegue

Ahora que tiene el script de entrada y el entorno, necesita configurar el ordenador en el que se desplegará el servicio. 
Si va a realizar el despliegue en un clúster AKS, deberá crear el clúster y un objetivo de cómputo para él antes de realizar 
el despliegue:

```python
from azureml.core.compute import ComputeTarget, AksCompute

cluster_name = 'aks-cluster'
compute_config = AksCompute.provisioning_configuration(location='eastus')
production_cluster = ComputeTarget.create(ws, cluster_name, compute_config)
production_cluster.wait_for_completion(show_output=True)
```

Con el objetivo de cómputo creado, ahora puede definir la configuración de despliegue, que establece la especificación de 
cómputo específica del objetivo para el despliegue en contenedor:

```python
from azureml.core.webservice import AksWebservice

classifier_deploy_config = AksWebservice.deploy_configuration(cpu_cores = 1,
                                                              memory_gb = 1)
```

El código para configurar un despliegue ACI es similar, salvo que no necesita crear explícitamente un objetivo de cómputo ACI 
y debe utilizar la clase **deploy_configuration** del espacio de nombres **azureml.core.webservice.AciWebservice**. Del mismo modo, 
puede utilizar el espacio de nombres **azureml.core.webservice.LocalWebservice** para configurar un servicio local basado en Docker.

> Nota
> 
> Para desplegar un modelo en una Azure Function, no necesita crear una configuración de despliegue. En su lugar, necesita 
> empaquetar el modelo en función del tipo de activador de función que desee utilizar. Esta funcionalidad se encuentra en 
> fase de previsualización en el momento de redactar este documento. Para más detalles, consulte
[Desplegar un modelo de aprendizaje automático en Azure Functions](https://aka.ms/AA70rrn)
 en la documentación de Azure Machine Learning.

### Desplegar el modelo

Una vez preparada toda la configuración, puede desplegar el modelo. La forma más sencilla de hacerlo es llamar al método
**deploy** de la clase **Model**, de esta manera:

```python
from azureml.core.model import Model

model = ws.models['classification_model']
service = Model.deploy(workspace=ws,
                       name = 'classifier-service',
                       models = [model],
                       inference_config = classifier_inference_config,
                       deployment_config = classifier_deploy_config,
                       deployment_target = production_cluster)
service.wait_for_deployment(show_output = True)
```

Para ACI o servicios locales, puede omitir el parámetro **deployment_target**(o establecerlo enNone).

Para obtener más información sobre el despliegue de modelos con Azure Machine Learning, consulte
[Despliegue de modelos de aprendizaje automático en Azure](https://aka.ms/AA70zfv)
 en la documentación.

## 7 Consume a real-time inferencing service
[< Back to Local Index](#7-index)

Tras desplegar un servicio en tiempo real, puede consumirlo desde aplicaciones cliente para predecir etiquetas para nuevos casos de datos.

### Utilizar el SDK de aprendizaje automático de Azure

Para realizar pruebas, puede utilizar el SDK de aprendizaje automático de Azure para llamar a un servicio web a través del 
método de ejecución de un objeto WebService que haga referencia al servicio desplegado. Normalmente, usted envía datos al 
método de ejecución en formato JSON con la siguiente estructura:

```json
{
  "data":[
      [0.1,2.3,4.1,2.0], // 1st case
      [0.2,1.8,3.9,2.1],  // 2nd case,
      ...
  ]
}
```

La respuesta del método de ejecución es una colección JSON con una predicción para cada caso que se envió en los datos. 
El siguiente ejemplo de código llama a un servicio y muestra la respuesta:

```python
import json

# An array of new data cases
x_new = [[0.1,2.3,4.1,2.0],
         [0.2,1.8,3.9,2.1]]

# Convert the array to a serializable list in a JSON document
json_data = json.dumps({"data": x_new})

# Call the web service, passing the input data
response = service.run(input_data = json_data)

# Get the predictions
predictions = json.loads(response)

# Print the predicted class for each case.
for i in range(len(x_new)):
    print (x_new[i], predictions[i])
```

### Utilizar un punto final REST 

En producción, la mayoría de las aplicaciones cliente no incluirán el SDK de Azure Machine Learning, y consumirán el servicio 
a través de su interfaz REST. Puede determinar el punto final de un servicio desplegado en Azure Machine Learning studio, 
o recuperando la propiedad **scoring_uri** del objetoWebservice en el SDK, como se muestra a continuación:

```python
endpoint = service.scoring_uri
print(endpoint)
```

Con el endpoint conocido, puede utilizar una solicitud HTTP POST con datos JSON para llamar al servicio. El siguiente 
ejemplo muestra cómo hacerlo utilizando Python:

```python
import requests
import json

# An array of new data cases
x_new = [[0.1,2.3,4.1,2.0],
         [0.2,1.8,3.9,2.1]]

# Convert the array to a serializable list in a JSON document
json_data = json.dumps({"data": x_new})

# Set the content type in the request headers
request_headers = { 'Content-Type':'application/json' }

# Call the service
response = requests.post(url = endpoint,
                         data = json_data,
                         headers = request_headers)

# Get the predictions from the JSON response
predictions = json.loads(response.json())

# Print the predicted class for each case.
for i in range(len(x_new)):
    print (x_new[i]), predictions[i] )
```

### Autenticación

En producción, es probable que desee restringir el acceso a sus servicios aplicando la autenticación. Hay dos tipos de 
autenticación que puede utilizar:

- **Clave**: Las solicitudes se autentican especificando la clave asociada al servicio.

- **Token**: Las solicitudes se autentican proporcionando un Token Web JSON (JWT).

Por defecto, la autenticación está desactivada para los servicios ACI, y configurada como autenticación basada en clave 
para los servicios AKS (para los que se generan automáticamente claves primarias y secundarias). Opcionalmente, puede 
configurar un servicio AKS para que utilice la autenticación basada en token (que no es compatible con los servicios ACI).

Suponiendo que haya establecido una sesión autenticada con el área de trabajo, puede recuperar las claves de un servicio 
utilizando el método **get_keys** del objeto **WebService** asociado al servicio:

```python
primary_key, secondary_key = service.get_keys()
```

Para la autenticación basada en token, su aplicación cliente necesita utilizar la autenticación de principal de servicio 
para verificar su identidad a través de Azure Active Directory (Azure AD) y llamar al método **get_token** del servicio 
para recuperar un token de tiempo limitado.

Para realizar una llamada autenticada al punto final REST del servicio, debe incluir la clave o el token en la cabecera 
de la solicitud de la siguiente manera:

```python
import requests
import json

# An array of new data cases
x_new = [[0.1,2.3,4.1,2.0],
         [0.2,1.8,3.9,2.1]]

# Convert the array to a serializable list in a JSON document
json_data = json.dumps({"data": x_new})

# Set the content type in the request headers
request_headers = { "Content-Type":"application/json",
                    "Authorization":"Bearer " + key_or_token }

# Call the service
response = requests.post(url = endpoint,
                         data = json_data,
                         headers = request_headers)

# Get the predictions from the JSON response
predictions = json.loads(response.json())

# Print the predicted class for each case.
for i in range(len(x_new)):
    print (x_new[i]), predictions[i] )
```

## 7 Troubleshoot service deployment
[< Back to Local Index](#7-index)

![5.png](ims%2FC7%2Fims%2F5.png)

Hay muchos elementos para un despliegue de servicios en tiempo real. Estos pueden incluir el modelo entrenado, la configuración 
del entorno de ejecución, el script de puntuación, la imagen del contenedor, y el host del contenedor. 

![6.png](ims%2FC7%2Fims%2F6.png)

Solucionar problemas de una implementación fallida o de un error al consumir una implementación el servicio puede ser complejo.

![7.png](ims%2FC7%2Fims%2F7.png)

Como paso inicial de solución de problemas, puede comprobar el estado de un servicio examinando su estado a través de la 
herramienta get el método de servicio implementado.

![8.png](ims%2FC7%2Fims%2F8.png)

Es importante tener en cuenta que para para ver el estado de un servicio, debe usar el cómputo específico tipo de servicio, 
por ejemplo, un servicio web de KS y no es un objeto de servicio web genérico. Para un servicio operativo, el estado debe estar sano.

![9.png](ims%2FC7%2Fims%2F9.png)

Si un servicio no es saludable o si tiene errores al usarlo, puede revisar sus registros. Puede revisar estos registros 
mediante un código, los registros incluyen información detallada sobre el aprovisionamiento del servicio y las solicitudes 
que ha procesado.

![10.png](ims%2FC7%2Fims%2F10.png)

A menudo, pueden proporcionar una idea sobre la causa de los errores inesperados. Despliegue y Los errores de ejecución 
pueden ser más fáciles de diagnosticar, puede hacerlo implementando el servicio como contenedor en una instancia de Docker local.

![11.png](ims%2FC7%2Fims%2F11.png)

A continuación, puede probar el localmente servicio implementado mediante el SDK. 

![12.png](ims%2FC7%2Fims%2F12.png)

A continuación, puede solucionar problemas de tiempo de ejecución realizando cambios en el archivo de puntuación al que 
se hace referencia en la configuración de inferencia.

![13.png](ims%2FC7%2Fims%2F13.png)

Luego, recargando el servicio sin volver a implementarlo, algo que solo puedes hacer hazlo con un servicio local.

## 7 Exercise Deploy a model as a real-time service
[< Back to Local Index](#7-index)

Ahora es su oportunidad de utilizar Azure Machine Learning para desplegar un modelo de aprendizaje automático como un servicio en tiempo real.

### Notebook

Como ya es costumbre, vamos a iniciar Corriendo nuestro: `Compute-instance` -> `Coursera-cpu`

> ### Nota
> El notebook de esta clase está en: [09 - Create a Real-time Inferencing Service.ipynb](ims%2FC7%2Fnotebooks%2F09%20-%20Create%20a%20Real-time%20Inferencing%20Service.ipynb)

![1.png](ims%2FC4%2Fims%2F4%2F1.png)


1. Como ya es costumbre, vamos a empezar definiendo nuestro `ws` y verificando nuestra versión de `AML`:

   ![m1.gif](ims%2FC7%2Fgifs%2Fm1.gif)

2. El notebook tiene una celda adicional para crear un modelo y registrarlo, sin embargo, como ya tenemos varios modelos de diabetes, vamos a omitir la celda y vamos a ver cuáles modelos ya tenemos disponibles:

   ![m2.gif](ims%2FC7%2Fgifs%2Fm2.gif)

3. Vamos a seleccionar nuestro modelo más reciente que en este caso es la versión `8`. Para crear el endpoint, primero debemos preparar un folder para crear el `servicio`

   ![m3.gif](ims%2FC7%2Fgifs%2Fm3.gif)

   > Nota: tenemos una variable llamada `script_file` que solo es el nombre del archivo .py, mientras que `script_file` es la concatenación entre el nombre del folder y el nombre del archivo

4. En el `script_file.py` como ya leímos en las notas de este capítulo, dos funciones: `init()` (para cargar al modelo) y `run(raw_data)` que básicamente, lee los archivos en un formato `crudo`
   y los prepara para ser clasificados por el modelo, finalmente utiliza la predicción 0 o 1 para darle una etiqueta de `non diabetic` vs `diabetic`

   ![m4.gif](ims%2FC7%2Fgifs%2Fm4.gif)

5. Ahora debemos seleccionar el ambiente que utilizará para crear el contenedor, en este caso, simplemente estamos utilizando uno de los que ya vienen por defecto en Azure. Ahora, para crear
   el objeto `inference_config` debemos tener 3 ingredientes, el folder donde esta el script, el nombre del script, y el ambiente creado.

   ![m5.gif](ims%2FC7%2Fgifs%2Fm5.gif)

   También debemos crear el `cluster` donde se va a ejecutar la información, pero este será especial puesto que es para hacer `inferencia`, le asignamos solo un core de cpu y un giga de ram.
   Ahora ya podemos hacer Model.deploy() con todos los incredientes:

   ````python
    service = Model.deploy(ws, service_name, [model], inference_config, deployment_config, overwrite=True)
   ````

6. Una vez que se ha publicado nuestro endpoint podemos consultar sus logs, y ver el nombre del servicio que hemos creado `diabetes-service`, adicionalmente, en la pestaña de
   `endpoints` podemos ver que ya esta públicado nuestro `endpoint` y ahí mismo podemos observar la dirección de nuestra `API`
   ![m6.gif](ims%2FC7%2Fgifs%2Fm6.gif)

7. Podemos probar que el modelo funciona correctamente, tanto para una predicción como para múltiples soluciones, el servicio se esta ejecutando y todo funciona bien.

   ![m7.gif](ims%2FC7%2Fgifs%2Fm7.gif)

   sin embargo, no siempre vamos a disponer del SDK para correr al modelo, es por ello que es buena idea contar con la dirección del endpoint:

   ```python
    endpoint = service.scoring_uri
    print(endpoint)
   ```
   Podemos observar que esta en linea en la dirección:

   ```commandline
    http://d2575064-0c24-4cd8-97b1-9932795ec186.eastus2.azurecontainer.io/score
   ```

8. Una alternativa más interesante, es hacer un `post` para hacer inferencia:

   ![m8.gif](ims%2FC7%2Fgifs%2Fm8.gif)

   este método NO necesita tener el SDK de azure instalando, puesto que solo usa `requests` para hacer una solicitud `post` al `API rest` que hemos creado. 

   Finalmente, podemos eliminar el `servicio` para que no consuma más cargos.

9. No olvidemos de detener nuestro `coursera-cpu`:

      ![1.png](ims%2FC5%2Fgifs%2F1.png)


## 7 Exercise quiz
[< Back to Local Index](#7-index)

![1.png](ims%2FC7%2Ftest%2F1.png)

## 7 Knowledge Check
[< Back to Local Index](#7-index)

![q1.png](ims%2FC7%2Ftest%2Fq1.png)

![q2.png](ims%2FC7%2Ftest%2Fq2.png)

![q3.png](ims%2FC7%2Ftest%2Fq3.png)

![q4.png](ims%2FC7%2Ftest%2Fq4.png)

## 7 Test prep
[< Back to Local Index](#7-index)

![t1.png](ims%2FC7%2Ftest%2Ft1.png)

![t2.png](ims%2FC7%2Ftest%2Ft2.png)

![t3.png](ims%2FC7%2Ftest%2Ft3.png)

![t4.png](ims%2FC7%2Ftest%2Ft4.png)

![t5.png](ims%2FC7%2Ftest%2Ft5.png)

![t6.png](ims%2FC7%2Ftest%2Ft6.png)

## 7 Lesson summary
[< Back to Local Index](#7-index)

![14.png](ims%2FC7%2Fims%2F14.png)

En esta lección, ha aprendido a desplegar servicios de aprendizaje automático en tiempo real con Azure Machine Learning. 
O, más concretamente, desplegar un modelo como servicio de influencia en tiempo real, consumir un servicio de influencia 
en tiempo real y solucionar problemas de despliegue del servicio.

# 8 Deploy batch inference pipelines with Azure Machine Learning


## 8 INDEX

- [8 Lesson introduction](#8-lesson-introduction)
- [8 Creating a batch inference pipeline](#8-creating-a-batch-inference-pipeline)
- [8 Publishing a batch inference pipeline](#8-publishing-a-batch-inference-pipeline)
- [8 Exercise Create a batch inference pipeline](#8-exercise-create-a-batch-inference-pipeline)
- [8 Exercise quiz](#8-exercise-quiz)
- [8 Knowledge Check](#8-knowledge-check)
- [8 Lesson Summary](#8-lesson-summary)

[< Back to index](#0-index)

## 8 Lesson introduction
[< Back to Local Index](#8-index)

![1.png](ims%2FC8%2Fims%2F1%2F1.png)

Hola. En esta lección, aprenderás cómo implementar canalizaciones de inferencia por lotes con Azure Machine Learning. 
En muchos escenarios de producción, tareas de larga duración que se realizan sobre grandes volúmenes de datos como 
operaciones por lotes.

![2.png](ims%2FC8%2Fims%2F1%2F2.png)

En el aprendizaje automático, inferencia por lotes se usa para aplicar un modelo predictivo a múltiples casos de forma 
asincrónica, normalmente escribiendo los resultados a un archivo o base de datos. 

![3.png](ims%2FC8%2Fims%2F1%2F3.png)

En Azure Machine Learning, puede implementar Batch Inferenciar soluciones mediante la creación de una canalización que 
incluya un paso para leer los datos de entrada, cargar un modelo registrado, predecir etiquetas y escribir los resultados como su salida.

![4.png](ims%2FC8%2Fims%2F1%2F4.png)

En esta lección, publicarás una canalización de inferencias por lotes para un modelo entrenado, y utilizará un lote canal 
de inferencia para generar predicciones.

## 8 Creating a batch inference pipeline
[< Back to Local Index](#8-index)

Para crear una canalización de inferencia por lotes, realice las siguientes tareas:

### 1. Registrar un modelo

Para utilizar un modelo entrenado en una canalización de inferencia por lotes, debe registrarlo en su espacio de trabajo 
de Azure Machine Learning.

Para registrar un modelo desde un archivo local, puede utilizar el método **register** del objeto **Model** como se 
muestra en el siguiente código de ejemplo:

```python
from azureml.core import Model

classification_model = Model.register(workspace=your_workspace,
                                      model_name='classification_model',
                                      model_path='model.pkl', # local path
                                      description='A classification model')
```

Alternativamente, si tiene una referencia a la **Ejecución** utilizada para entrenar el modelo, puede utilizar su método
**register_model** como se muestra en el siguiente código de ejemplo:

```python
run.register_model( model_name='classification_model',
                    model_path='outputs/model.pkl', # run outputs path
                    description='A classification model')
```

### 2. Crear un script de calificación

El servicio de inferencia por lotes requiere un script de puntuación para cargar el modelo y utilizarlo para predecir 
nuevos valores. Debe incluir dos funciones

- **init():** Llamada cuando se inicializa la canalización.

- **run(mini_batch):** Llamada para cada lote de datos a procesar.

Normalmente, se utiliza la función **init** para cargar el modelo desde el registro de modelos, y se utiliza la función 
**run** para generar predicciones a partir de cada lote de datos y devolver los resultados. El siguiente script de 
ejemplo muestra este patrón:

```python
import os
import numpy as np
from azureml.core import Model
import joblib

def init():
    # Runs when the pipeline step is initialized
    global model

    # load the model
    model_path = Model.get_model_path('classification_model')
    model = joblib.load(model_path)

def run(mini_batch):
    # This runs for each batch
    resultList = []

    # process each file in the batch
    for f in mini_batch:
        # Read comma-delimited data into an array
        data = np.genfromtxt(f, delimiter=',')
        # Reshape into a 2-dimensional array for model input
        prediction = model.predict(data.reshape(1, -1))
        # Append prediction to results
        resultList.append("{}: {}".format(os.path.basename(f), prediction[0]))
    return resultList
```

### 3. Crear una canalización con un ParallelRunStep

Azure Machine Learning proporciona un tipo de paso de canalización específico para realizar inferencias paralelas por lotes. 
Utilizando la clase **ParallelRunStep**, puede leer lotes de archivos de un conjunto de datos **File** y escribir la salida 
del procesamiento en un **OutputFileDatasetConfig**.

Además, puede establecer el ajuste **output_action** para el paso en "**append_row**", lo que garantizará que todas las 
instancias del paso que se ejecuten en paralelo cotejarán sus resultados en un único archivo de salida denominado 
**parallel_run_step.txt**:

```python
from azureml.pipeline.steps import ParallelRunConfig, ParallelRunStep
from azureml.data import OutputFileDatasetConfig
from azureml.pipeline.core import Pipeline

# Get the batch dataset for input
batch_data_set = ws.datasets['batch-data']

# Set the output location
default_ds = ws.get_default_datastore()
output_dir = OutputFileDatasetConfig(name='inferences')

# Define the parallel run step step configuration
parallel_run_config = ParallelRunConfig(
    source_directory='batch_scripts',
    entry_script="batch_scoring_script.py",
    mini_batch_size="5",
    error_threshold=10,
    output_action="append_row",
    environment=batch_env,
    compute_target=aml_cluster,
    node_count=4)

# Create the parallel run step
parallelrun_step = ParallelRunStep(
    name='batch-score',
    parallel_run_config=parallel_run_config,
    inputs=[batch_data_set.as_named_input('batch_data')],
    output=output_dir,
    arguments=[],
    allow_reuse=True
)
# Create the pipeline
pipeline = Pipeline(workspace=ws, steps=[parallelrun_step])
```

### 4. Ejecutar la canalización y recuperar la salida del paso

Una vez definida su canalización, puede ejecutarla y esperar a que se complete. A continuación, puede recuperar el archivo
**parallel_run_step.txt** de la salida del paso para ver los resultados, como se muestra en el siguiente ejemplo de código:

```python
from azureml.core import Experiment

# Run the pipeline as an experiment
pipeline_run = Experiment(ws, 'batch_prediction_pipeline').submit(pipeline)
pipeline_run.wait_for_completion(show_output=True)

# Get the outputs from the first (and only) step
prediction_run = next(pipeline_run.get_children())
prediction_output = prediction_run.get_output_data('inferences')
prediction_output.download(local_path='results')

# Find the parallel_run_step.txt file
for root, dirs, files in os.walk('results'):
    for file in files:
        if file.endswith('parallel_run_step.txt'):
            result_file = os.path.join(root,file)

# Load and display the results
df = pd.read_csv(result_file, delimiter=":", header=None)
df.columns = ["File", "Prediction"]
print(df)
```


## 8 Publishing a batch inference pipeline
[< Back to Local Index](#8-index)

Puede publicar una canalización de inferencia por lotes como un servicio REST, como se muestra en el siguiente código de ejemplo:

```python
published_pipeline = pipeline_run.publish_pipeline(name='Batch_Prediction_Pipeline',
                                                   description='Batch pipeline',
                                                   version='1.0')
rest_endpoint = published_pipeline.endpoint
```

Una vez publicado, puede utilizar el punto final del servicio para iniciar un trabajo de inferencia por lotes, como se muestra en el siguiente código de ejemplo:

```python
import requests

response = requests.post(rest_endpoint,
                         headers=auth_header,
                         json={"ExperimentName": "Batch_Prediction"})
run_id = response.json()["Id"]
```

También puede programar la canalización publicada para que se ejecute automáticamente, como se muestra en el siguiente 
código de ejemplo:

```python
from azureml.pipeline.core import ScheduleRecurrence, Schedule

weekly = ScheduleRecurrence(frequency='Week', interval=1)
pipeline_schedule = Schedule.create(ws, name='Weekly Predictions',
                                        description='batch inferencing',
                                        pipeline_id=published_pipeline.id,
                                        experiment_name='Batch_Prediction',
                                        recurrence=weekly)
```


## 8 Exercise Create a batch inference pipeline
[< Back to Local Index](#8-index)

Ahora es su oportunidad de crear y ejecutar una canalización de inferencia por lotes

En este ejercicio, deberá:


- Crear una canalización de inferencia por lotes

- Publicar la canalización como un servicio REST

- Ejecutar la canalización a través de su punto final REST.

### Instrucciones

Siga estas instrucciones para completar el ejercicio.


1. Si aún no tiene una suscripción a Azure, regístrese para una prueba gratuita en 
https://azure.microsoft.com

2. Consulte el repositorio del ejercicio en 
https://aka.ms/mslearn-dp100

3. Si aún no lo ha hecho, complete el ejercicio Crear un espacio de trabajo de Azure Machine Learning para aprovisionar un espacio de trabajo de Azure Machine Learning, crear una instancia de cálculo y clonar los archivos necesarios

4. Complete el ejercicio Crear un servicio de inferencia por lotes.

> ### Nota:
> El notebook de esta sección está en: [10 - Create a Batch Inferencing Service.ipynb](ims%2FC8%2Fnotebooks%2F10%20-%20Create%20a%20Batch%20Inferencing%20Service.ipynb)

![s1.gif](ims%2FC8%2Fgifs%2Fs1.gif)

![s2.gif](ims%2FC8%2Fgifs%2Fs2.gif)

![s3.gif](ims%2FC8%2Fgifs%2Fs3.gif)

![s4.gif](ims%2FC8%2Fgifs%2Fs4.gif)

![s5.gif](ims%2FC8%2Fgifs%2Fs5.gif)

![s6.gif](ims%2FC8%2Fgifs%2Fs6.gif)

![s7.gif](ims%2FC8%2Fgifs%2Fs7.gif)

## 8 Exercise quiz
[< Back to Local Index](#8-index)

![0.png](ims%2FC8%2Ftest%2F0.png)

## 8 Knowledge Check
[< Back to Local Index](#8-index)

![q1.png](ims%2FC8%2Ftest%2Fq1.png)

![q2.png](ims%2FC8%2Ftest%2Fq2.png)

![q3.png](ims%2FC8%2Ftest%2Fq3.png)

![q4.png](ims%2FC8%2Ftest%2Fq4.png)

![q5.png](ims%2FC8%2Ftest%2Fq5.png)

## 8 Lesson Summary
[< Back to Local Index](#8-index)

![5.png](ims%2FC8%2Fims%2F1%2F5.png)

En esta lección, ha aprendido a desplegar canalizaciones de inferencia por lotes con el aprendizaje automático de 
Azure. O, más concretamente, a publicar una canalización de inferencia por lotes para un modelo entrenado. Y a utilizar 
una canalización de inferencia por lotes para generar predicciones.

# 9 Tune hyperparameters with Azure Machine Learning

## 9 INDEX

- [9 Lesson introduction](#9-lesson-introduction)
- [9 Defining a search space](#9-defining-a-search-space)
- [9 Configuring sampling](#9-configuring-sampling)
- [9 Configuring early termination](#9-configuring-early-termination)
- [9 Running a hyperparameter tuning experiment](#9-running-a-hyperparameter-tuning-experiment)
- [9 Exercise Tune hyperparameters](#9-exercise-tune-hyperparameters)
- [9 Exercise quiz](#9-exercise-quiz)
- [9 Knowledge check](#9-knowledge-check)
- [9 Test prep](#9-test-prep)
- [9 Lesson summary](#9-lesson-summary)

[< Back to index](#0-index)

## 9 Lesson introduction
[< Back to Local Index](#9-index)

![1.png](ims%2FC9%2Fims%2F1%2F1.png)

Hola, en el aprendizaje automático los modelos se entrenan para predecir etiquetas desconocidas para nuevos datos 
basándose en correlaciones entre etiquetas conocidas y características encontradas en los datos de entrenamiento. 

![2.png](ims%2FC9%2Fims%2F1%2F2.png)

Dependiendo del algoritmo utilizado, puede que necesite especificar hiperparámetros para configurar cómo se entrena el modelo. 

![3.png](ims%2FC9%2Fims%2F1%2F3.png)

Por ejemplo, el algoritmo de regresión logística utiliza una tasa de regularización, hiperparámetro para contrarrestar el 
sobreajuste. Y las técnicas de aprendizaje profundo para redes neuronales convolucionales o CNN utilizan 
hiperparámetros como la tasa de aprendizaje para controlar cómo se ajustan los pesos durante el entrenamiento. Y el 
tamaño del lote para determinar cuántos elementos de datos se incluyen en cada lote de entrenamiento.

![4.png](ims%2FC9%2Fims%2F1%2F4.png)

Es importante señalar que el aprendizaje automático es un campo académico con su propia terminología particular. 
Los científicos de datos se refieren a los valores determinados a partir de las características de entrenamiento 
como parámetros. Así que se requiere un término diferente para los valores que se utilizan para configurar el 
comportamiento de entrenamiento pero que no se derivan de los datos de entrenamiento. De ahí el término 
hiperparámetro. La elección de los valores de los hiperparámetros puede afectar significativamente al modelo resultante. 

![5.png](ims%2FC9%2Fims%2F1%2F5.png)

Por eso es importante seleccionar los mejores valores posibles para sus datos particulares y sus objetivos de rendimiento predictivo.

![6.png](ims%2FC9%2Fims%2F1%2F6.png)

El ajuste de hiperparámetros se consigue entrenando los múltiples modelos utilizando el mismo algoritmo y los mismos datos 
de entrenamiento pero con diferentes valores de hiperparámetros. El modelo resultante de cada ejecución de entrenamiento 
se evalúa a continuación para determinar la métrica de rendimiento para la que desea optimizar, por ejemplo, la precisión. 
Y se selecciona el modelo de mejor rendimiento.

![7.png](ims%2FC9%2Fims%2F1%2F7.png)

En el aprendizaje automático de Azure esto se consigue a través de un experimento que consiste en una ejecución hiper
dirigida que inicia una ejecución hija para cada combinación de hiperparámetros que se va a probar. 

![8.png](ims%2FC9%2Fims%2F1%2F8.png)

Cada una de estas ejecuciones hijas utiliza un script de entrenamiento con valores de hiperparámetros para entrenar un 
modelo y registra la métrica de rendimiento objetivo alcanzada por el modelo entrenado. 

![9.png](ims%2FC9%2Fims%2F1%2F9.png)

En esta lección, aprenderá a sintonizar hiperparámetros con el aprendizaje automático de Azure o, más concretamente, a 

- Definir un espacio de búsqueda de hiperparámetros. 
- Configurar el muestreo de hiperparámetros. 
- Seleccionar una política de terminación anticipada.
- Ejecutar un experimento de sintonización de hiperparámetros.

## 9 Defining a search space
[< Back to Local Index](#9-index)

![1.png](ims%2FC9%2Fims%2F2%2F1.png)

El conjunto de valores de hiperparámetro probados durante el ajuste de hiperparámetros se conoce como espacio de búsqueda. 
La definición del rango de posibles valores que se pueden elegir, depende del tipo de hiperparámetro.

![2.png](ims%2FC9%2Fims%2F2%2F2.png)

Algunos hiperparámetros requieren valores discretos. En otras palabras, debe seleccionar el valor de un conjunto 
concreto de posibilidades.


![4.png](ims%2FC9%2Fims%2F2%2F4.png)

Puede definir un espacio de búsqueda para un parámetro discreto utilizando una elección de una lista de valores explícitos, que puede definir como una lista Python, un rango o un conjunto arbitrario de valores separados por comas.

![5.png](ims%2FC9%2Fims%2F2%2F5.png)

También puede seleccionar valores discretos de cualquiera de las siguientes distribuciones discretas; qnorma, quniforme, 
qlognormal y qloguniforme.

![6.png](ims%2FC9%2Fims%2F2%2F6.png)

Algunos hiperparámetros son continuos. En otras palabras, puede utilizar cualquier valor a lo largo de una escala. Para 
definir un espacio de búsqueda para estos valores, puede utilizar cualquiera de los siguientes tipos de distribución; 
normal, uniforme, lognormal y loguniforme. 

![7.png](ims%2FC9%2Fims%2F2%2F7.png)

Para definir un espacio de búsqueda para el ajuste de hiperparámetros, cree un diccionario con la expresión de parámetros 
apropiada para cada hiperparámetro nombrado. 

Por ejemplo, en el espacio de búsqueda, puede indicar que el hiperparámetro de tamaño de lote puede tener el valor 
`16, 32, o 64`, y el hiperparámetro de tasa de aprendizaje puede tener cualquier valor de una distribución normal con 
una media de `10` y una desviación estándar de `3`.


## 9 Configuring sampling
[< Back to Local Index](#9-index)

Los valores específicos utilizados en una ejecución de ajuste de hiperparámetros dependen del tipo demuestreo utilizado.

### Grid Sampling

El muestreo de cuadrícula sólo puede emplearse cuando todos los hiperparámetros son discretos, y se utiliza para probar 
todas las combinaciones posibles de parámetros en el espacio de búsqueda.

Por ejemplo, en el siguiente ejemplo de código, el muestreo de cuadrícula se utiliza para probar cada combinación 
posible de valor discreto de batch_size y learning_rate:

````python
from azureml.train.hyperdrive import GridParameterSampling, choice

param_space = {
                 '--batch_size': choice(16, 32, 64),
                 '--learning_rate': choice(0.01, 0.1, 1.0)
              }

param_sampling = GridParameterSampling(param_space)
````


### Random sampling

El muestreo aleatorio se utiliza para seleccionar al azar un valor para cada hiperparámetro, que puede ser una mezcla 
de valores discretos y continuos, como se muestra en el siguiente ejemplo de código:

```python
from azureml.train.hyperdrive import RandomParameterSampling, choice, normal

param_space = {
                 '--batch_size': choice(16, 32, 64),
                 '--learning_rate': normal(10, 3)
              }

param_sampling = RandomParameterSampling(param_space)
```

### Bayesian sampling

El muestreo bayesiano elige los valores de los hiperparámetros basándose en el algoritmo de optimización bayesiano, que 
intenta seleccionar las combinaciones de parámetros que darán como resultado un mejor rendimiento respecto a la selección 
anterior. El siguiente ejemplo de código muestra cómo configurar el muestreo bayesiano:

```python
from azureml.train.hyperdrive import BayesianParameterSampling, choice, uniform

param_space = {
                 '--batch_size': choice(16, 32, 64),
                 '--learning_rate': uniform(0.05, 0.1)
              }

param_sampling = BayesianParameterSampling(param_space)
```

Sólo puede utilizar el muestreo bayesiano con expresiones de parámetros de **elección**, **uniformes** y **quniformes**, y 
no puede combinarlo con una política de terminación anticipada.

## 9 Configuring early termination
[< Back to Local Index](#9-index)

![1.png](ims%2FC9%2Fims%2F3%2F1.png)

Con un espacio de búsqueda de hiperparámetros suficientemente grande, podrían necesitarse muchas iteraciones o ejecuciones 
hijo para probar todas las combinaciones posibles.


![2.png](ims%2FC9%2Fims%2F3%2F2.png)

Normalmente, se establece un número máximo de iteraciones, pero esto aún podría dar lugar a un gran número de ejecuciones 
que no produzcan un modelo mejor que una combinación ya probada. 

![3.png](ims%2FC9%2Fims%2F3%2F3.png)

Para evitar la pérdida de tiempo, puede establecer una política de finalización anticipada que abandone las ejecuciones. 
Es poco probable que las ejecuciones que se abandonen produzcan un resultado mejor que las ejecuciones completadas 
anteriormente. 

![4.png](ims%2FC9%2Fims%2F3%2F4.png)

Esta política se evalúa en un intervalo de evaluación que usted especifique en función de cada vez que se registre la métrica de rendimiento objetivo.

![5.png](ims%2FC9%2Fims%2F3%2F5.png)

También puede establecer un parámetro de evaluación de retardo para evitar evaluar la política hasta que se haya completado el número mínimo de iteraciones.

![6.png](ims%2FC9%2Fims%2F3%2F6.png)

Es importante señalar que la terminación anticipada es especialmente útil para escenarios de aprendizaje profundo en 
los que una red neuronal profunda o DNN se entrena iterativamente lee lo largo de varias épocas. El script de 
entrenamiento puede informar de la métrica objetivo después de cada epoch.

![7.png](ims%2FC9%2Fims%2F3%2F7.png)

Y si la ejecución es significativamente inferior a las ejecuciones anteriores después del mismo número de intervalos, puede abandonarse.

![8.png](ims%2FC9%2Fims%2F3%2F8.png)

Puede utilizar una política bandit para detener una ejecución si la métrica de rendimiento objetivo es inferior a la mejor 
ejecución hasta el momento por un margen especificado. 

Este ejemplo aplica la política para cada iteración Después de la 1ª 5. y abandona las ejecuciones en las que la métrica 
objetivo informada es 0.2 o peor que la ejecución con mejor rendimiento después del mismo número de intervalos.


![9.png](ims%2FC9%2Fims%2F3%2F9.png)

También puede aplicar una política bandit utilizando un factor de holgura, que compara la métrica de rendimiento como un 
ratio en lugar de un valor absoluto.

![10.png](ims%2FC9%2Fims%2F3%2F10.png)

![11.png](ims%2FC9%2Fims%2F3%2F11.png)

Una política de detención de la mediana abandona las ejecuciones cuya métrica de rendimiento objetivo es peor que la 
mediana de las medias de todas las ejecuciones.

![12.png](ims%2FC9%2Fims%2F3%2F12.png)

Una política de selección de truncamiento cancela el X por ciento de ejecuciones de menor rendimiento en cada 
intervalo de evaluación, basándose en el valor del porcentaje de truncamiento que especifique para X.

## 9 Running a hyperparameter tuning experiment
[< Back to Local Index](#9-index)

En Azure Machine Learning, puede afinar hiperparámetros ejecutando un experimento de _hiperparámetro_.

### Creación de un script de entrenamiento para el ajuste de hiperparámetros

Para ejecutar un experimento de hiperparámetro, necesita crear un script de entrenamiento de la misma manera que lo 
haría para cualquier otro experimento de entrenamiento, excepto que su script **debe:**

- Incluir un argumento para cada hiperparámetro que desee variar.

- Registrar la métrica de rendimiento objetivo. Esto permite a la ejecución del hiperdireccionamiento evaluar el 
rendimiento de las ejecuciones hijas que inicia, e identificar la que produce el modelo de mejor rendimiento.

Por ejemplo, el siguiente script de ejemplo entrena un modelo de regresión logística utilizando un argumento

--regularization 

para establecer el hiperparámetro de **tasa de regularización**, y registra la métrica de **precisión** con el nombre
**Precisión**:

```python
import argparse
import joblib
from azureml.core import Run
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression

# Get regularization hyperparameter
parser = argparse.ArgumentParser()
parser.add_argument('--regularization', type=float, dest='reg_rate', default=0.01)
args = parser.parse_args()
reg = args.reg_rate

# Get the experiment run context
run = Run.get_context()

# load the training dataset
data = run.input_datasets['training_data'].to_pandas_dataframe()

# Separate features and labels, and split for training/validatiom
X = data[['feature1','feature2','feature3','feature4']].values
y = data['label'].values
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30)

# Train a logistic regression model with the reg hyperparameter
model = LogisticRegression(C=1/reg, solver="liblinear").fit(X_train, y_train)

# calculate and log accuracy
y_hat = model.predict(X_test)
acc = np.average(y_hat == y_test)
run.log('Accuracy', np.float(acc))

# Save the trained model
os.makedirs('outputs', exist_ok=True)
joblib.dump(value=model, filename='outputs/model.pkl')

run.complete()
```

> Nota:
> 
> Tenga en cuenta que en la claseLogisticRegression de Scikit-Learn,C es la inversa de la tasa de regularización; por lo tanto, C=1/reg.

### Configuración y ejecución de un experimento hiperdireccional

Para preparar el experimento hyperdrive, debe utilizar un objeto **HyperDriveConfig** para configurar la ejecución del 
experimento, como se muestra en el siguiente código de ejemplo:

```python
from azureml.core import Experiment
from azureml.train.hyperdrive import HyperDriveConfig, PrimaryMetricGoal

# Assumes ws, script_config and param_sampling are already defined

hyperdrive = HyperDriveConfig(run_config=script_config,
                              hyperparameter_sampling=param_sampling,
                              policy=None,
                              primary_metric_name='Accuracy',
                              primary_metric_goal=PrimaryMetricGoal.MAXIMIZE,
                              max_total_runs=6,
                              max_concurrent_runs=4)

experiment = Experiment(workspace = ws, name = 'hyperdrive_training')
hyperdrive_run = experiment.submit(config=hyperdrive)
```

### Supervisión y revisión de las ejecuciones de hyperdrive

Puede supervisar los experimentos hyperdrive en Azure Machine Learning studio, o utilizando el **widgetRunDetails** de 
Jupyter Notebooks.

El experimento iniciará una ejecución hija para cada combinación de hiperparámetros que se pruebe, y puede recuperar 
las métricas registradas estas ejecuciones utilizando el siguiente código:

```python
for child_run in run.get_children():
    print(child_run.id, child_run.get_metrics())
```

También puede listar todas las ejecuciones en orden descendente de rendimiento de esta forma:

```python
for child_run in hyperdrive_run.get_children_sorted_by_primary_metric():
    print(child_run)
```

Para recuperar la ejecución con mejor rendimiento, puede utilizar el código siguiente:

```python
best_run = hyperdrive_run.get_best_run_by_primary_metric()
```


## 9 Exercise Tune hyperparameters
[< Back to Local Index](#9-index)

Ahora es su oportunidad de realizar un experimento de ajuste de hiperparámetros

En este ejercicio, lo hará


- Ejecutar un experimento de ajuste de hiperparámetros.

- Revisar los resultados del experimento.


### Instrucciones
Siga estas instrucciones para completar el ejercicio

- Si aún no dispone de una suscripción a Azure, suscríbase a una prueba gratuita en https://azure.microsoft.com.

- Consulte el repositorio del ejercicio en https://aka.ms/mslearn-dp100.

- Si aún no lo ha hecho, complete el ejercicio Crear un espacio de trabajo de Azure Machine Learning para aprovisionar un espacio de trabajo de Azure Machine Learning, crear una instancia de cálculo y clonar los archivos necesarios
Complete el ejercicio Afinar hiperparámetros.

> ## Nota:
> El notebook de esta sección está en: [11 - Tune Hyperparameters.ipynb](ims%2FC9%2Fnotebooks%2F11%20-%20Tune%20Hyperparameters.ipynb)

![s1.gif](ims%2FC9%2Fgifs%2Fs1.gif)

![s2.gif](ims%2FC9%2Fgifs%2Fs2.gif)

![s3.gif](ims%2FC9%2Fgifs%2Fs3.gif)

![s4.gif](ims%2FC9%2Fgifs%2Fs4.gif)

![s5.gif](ims%2FC9%2Fgifs%2Fs5.gif)

![s6.gif](ims%2FC9%2Fgifs%2Fs6.gif)

![s7.gif](ims%2FC9%2Fgifs%2Fs7.gif)

![s8.gif](ims%2FC9%2Fgifs%2Fs8.gif)

## 9 Exercise quiz
[< Back to Local Index](#9-index)

![0.png](ims%2FC9%2Ftest%2F0.png)

## 9 Knowledge check
[< Back to Local Index](#9-index)

![q1.png](ims%2FC9%2Ftest%2Fq1.png)

![q2.png](ims%2FC9%2Ftest%2Fq2.png)

![q3.png](ims%2FC9%2Ftest%2Fq3.png)

![q4.png](ims%2FC9%2Ftest%2Fq4.png)

## 9 Test prep
[< Back to Local Index](#9-index)

![p1.png](ims%2FC9%2Ftest%2Fp1.png)

![p2.png](ims%2FC9%2Ftest%2Fp2.png)

![p3.png](ims%2FC9%2Ftest%2Fp3.png)

![p4.png](ims%2FC9%2Ftest%2Fp4.png)

![p5.png](ims%2FC9%2Ftest%2Fp5.png)

## 9 Lesson summary
[< Back to Local Index](#9-index)

![1.png](ims%2FC9%2Ftest%2F1.png)

En esta lección, ha aprendido a sintonizar hiperparámetros con Azure Machine Learning , o más concretamente, definir un 
espacio de búsqueda de hiperparámetros, configurar un muestreo de hiperparámetros, seleccionar una política de terminación 
anticipada, y ejecutar un experimento de sintonización de hiperparámetros.

# 10 Automate machine learning model selection with Azure Machine Learning

## 10 INDEX

- [10 Lesson introduction](#10-lesson-introduction)
- [10 Automated machine learning tasks and algorithms](#10-automated-machine-learning-tasks-and-algorithms)
- [10 Preprocessing and featurization](#10-preprocessing-and-featurization)
- [10 Running an automated machine learning experiment](#10-running-an-automated-machine-learning-experiment)
- [10 Exercise Using automated machine learning](#10-exercise-using-automated-machine-learning)
- [10 Exercise quiz](#10-exercise-quiz)
- [10 Knowledge check](#10-knowledge-check)
- [10 Lesson summary](#10-lesson-summary)
- [10 Additional Reading](#10-additional-reading)

[< Back to index](#0-index)

## 10 Lesson introduction
[< Back to Local Index](#10-index)

![1.png](ims%2FC10%2Fims%2F1%2F1.png)

Hola. En esta lección, aprenderá a automatizar la selección de modelos de aprendizaje automático con Azure Machine 
Learning. El aprendizaje automático le permite probar múltiples algoritmos en transformaciones de preprocesamiento 
con sus datos.

![2.png](ims%2FC10%2Fims%2F1%2F2.png)

Esto, combinado con la computación escalable basada en la nube, hace posible encontrar el modelo de mejor rendimiento 
para sus datos sin la enorme cantidad de ensayo y error manual que consumiría mucho tiempo y que de otro modo sería 
necesario.

![3.png](ims%2FC10%2Fims%2F1%2F3.png)

Azure Machine Learning incluye soporte para el aprendizaje automático de máquinas a través de una interfaz visual en Azure 
Machine Learning Studio.

![4.png](ims%2FC10%2Fims%2F1%2F4.png)

Puede utilizar el SDK de Azure Machine Learning para ejecutar experimentos automatizados de aprendizaje automático.

![5.png](ims%2FC10%2Fims%2F1%2F5.png)

En este módulo, aprenderá a utilizar las capacidades de aprendizaje automático automatizado de Azure Machine Learning para 
determinar el algoritmo de mejor rendimiento para sus datos, utilizar el aprendizaje automático automatizado para 
preprocesar los datos para el entrenamiento, y ejecutar un experimento de aprendizaje automático automatizado.

## 10 Automated machine learning tasks and algorithms
[< Back to Local Index](#10-index)


![7.png](ims%2FC10%2Fims%2F1%2F7.png)

Puede utilizar el aprendizaje automático en Azure Machine Learning para entrenar modelos para los siguientes tipos de 
tareas de aprendizaje automático, regresión de clasificación y previsión de series temporales. 

![8.png](ims%2FC10%2Fims%2F1%2F8.png)

Azure Machine Learning incluye soporte para numerosos algoritmos de uso común para estas tareas. Entre ellos se incluyen 
algoritmos de clasificación como la regresión logística y el árbol de decisión.

![9.png](ims%2FC10%2Fims%2F1%2F9.png)

Algoritmos de regresión como la regresión lineal, el bosque aleatorio y la red elástica. 

![10.png](ims%2FC10%2Fims%2F1%2F10.png)

Y, por último, algoritmos de previsión como la regresión lineal y el árbol de decisión. 

![11.png](ims%2FC10%2Fims%2F1%2F11.png)

ara obtener una lista completa de los algoritmos admitidos, consulte cómo definir una tarea de aprendizaje automático en 
el sitio web de Microsoft. Puede encontrar un enlace a este recurso en las lecturas adicionales al final de esta lección. 

[What is automated machine learning (AutoML)](https://docs.microsoft.com/en-us/azure/machine-learning/concept-automated-ml)


![12.png](ims%2FC10%2Fims%2F1%2F12.png)

Por defecto, el aprendizaje automático seleccionará aleatoriamente entre toda la gama de algoritmos para la tarea 
especificada. Puede elegir bloquear algoritmos individuales para que no sean seleccionados, lo que puede ser útil si 
sabe que sus datos no se adaptan a un tipo de algoritmo concreto. O tiene que cumplir una política que restrinja el 
tipo de algoritmos de aprendizaje automático que puede utilizar en su organización.

## 10 Preprocessing and featurization
[< Back to Local Index](#10-index)

![13.png](ims%2FC10%2Fims%2F1%2F13.png)

Hola. En esta sección, explorará el preprocesamiento y la featurización, además de probar una selección de algoritmos. 
El aprendizaje automático automatizado puede aplicar transformaciones de preprocesamiento a sus datos, mejorando el 
rendimiento del modelo. 


![15.png](ims%2FC10%2Fims%2F1%2F15.png)

El aprendizaje automático aplica escalado y normalización a los datos numéricos automáticamente, ayudando a evitar 
que cualquier característica a gran escala domine el entrenamiento. Durante un experimento de aprendizaje automático 
automatizado, se aplicarán múltiples técnicas de escalado o normalización

![16.png](ims%2FC10%2Fims%2F1%2F16.png)

Puede elegir que el aprendizaje automático aplique transformaciones de preprocesamiento como: 
- la imputación de valores perdidos para eliminar nulos en el conjunto de datos de entrenamiento 
- codificación categórica para convertir características categóricas en indicadores numéricos
- eliminar características de alta cardinalidad como ID de registros
- ingeniería de características, por ejemplo, derivando partes de fechas individuales de características DateTime
- otras. 

![17.png](ims%2FC10%2Fims%2F1%2F17.png)
Para obtener más información sobre el soporte de preprocesamiento en el aprendizaje automático automatizado, consulte 
qué es el aprendizaje automático automatizado en el sitio web de Microsoft. Puede encontrar un enlace a este recurso en 
las lecturas adicionales al final de esta lección.

**Preprocessing and featurization**
[What is automated machine learning (AutoML)  - How automated ML works](https://docs.microsoft.com/en-us/azure/machine-learning/concept-automated-ml#how-automated-ml-works)


## 10 Running an automated machine learning experiment
[< Back to Local Index](#10-index)

Para ejecutar un experimento automatizado de aprendizaje automático, puede utilizar la interfaz de usuario en Azure 
Machine Learning studio o enviar un experimento utilizando el SDK.

### Configurar un experimento de aprendizaje automático automatizado

La interfaz de usuario proporciona una forma intuitiva de seleccionar opciones para su experimento de aprendizaje 
automático automatizado. Cuando utilice el SDK, dispondrá de mayor flexibilidad, y podrá configurar las opciones del 
experimento utilizando la clase **AutoMLConfig**, como se muestra en el siguiente ejemplo.

```python
from azureml.train.automl import AutoMLConfig

automl_run_config = RunConfiguration(framework='python')
automl_config = AutoMLConfig(name='Automated ML Experiment',
                             task='classification',
                             primary_metric = 'AUC_weighted',
                             compute_target=aml_compute,
                             training_data = train_dataset,
                             validation_data = test_dataset,
                             label_column_name='Label',
                             featurization='auto',
                             iterations=12,
                             max_concurrent_iterations=4)
```

### Especificar los datos para el entrenamiento

El aprendizaje automático automatizado está diseñado para permitirle simplemente aportar sus datos y que Azure Machine 
Learning averigüe cuál es la mejor manera de entrenar un modelo a partir de ellos.

Cuando utilice la interfaz de usuario de aprendizaje automático automatizado en Azure Machine Learning studio, podrá 
crear o seleccionar un [conjunto de datos](https://learn.microsoft.com/es-mx/azure/machine-learning/how-to-create-data-assets?view=azureml-api-2&tabs=cli) de Azure Machine Learning para utilizarlo como entrada para su experimento de aprendizaje automático automatizado.

Cuando utilice el SDK para ejecutar un experimento de aprendizaje automático automatizado, puede enviar los datos de las 
siguientes maneras:

- Especifique un conjunto de datos o marco de datos de datos de entrenamiento que incluya características y la etiqueta 
a predecir.

- Opcionalmente, especifique un segundo conjunto de datos o marco de datos de validación que se utilizará para validar 
el modelo entrenado. si no se proporciona, Azure Machine Learning aplicará la validación cruzada utilizando los datos de 
entrenamiento.

Alternativa:

- Especifique un conjunto de datos, marco de datos o matriz numpy de valores X que contenga las características de 
entrenamiento, con una matriz y correspondiente de valores de etiqueta.

- Opcionalmente, especifique los conjuntos de datos, marcos de datos o matrices numpy X_valid e y_valid de valores X 
que se utilizarán para la validación.

### Especifique la métrica principal

Uno de los ajustes más importantes que debe especificar es la **métrica_principal**. Se trata de la métrica de rendimiento 
objetivo para la que se determinará el modelo óptimo. Azure Machine Learning admite un conjunto de métricas con nombre 
para cada tipo de tarea. Para recuperar la lista de métricas disponibles para un tipo de tarea concreto, puede utilizar 
la función **get_primary_metrics** como se muestra aquí:

```python
from azureml.train.automl.utilities import get_primary_metrics

get_primary_metrics('classification')
```

**Más información:** Puede encontrar una lista completa de las métricas primarias y sus definiciones en
[Comprender los resultados](https://learn.microsoft.com/es-mx/azure/machine-learning/how-to-understand-automated-ml?view=azureml-api-2)
 del aprendizaje automático automatizado.

### Enviar un experimento de aprendizaje automático automatizado

Puede enviar un experimento de aprendizaje automático automatizado como cualquier otro experimento basado en el SDK.

```python
from azureml.core.experiment import Experiment

automl_experiment = Experiment(ws, 'automl_experiment')
automl_run = automl_experiment.submit(automl_config)
```

Puede supervisar las ejecuciones de experimentos de aprendizaje automático automatizado en Azure Machine Learning studio, 
o en el widget **RunDetails** de Jupyter Notebooks.

### Recuperar la mejor ejecución y su modelo

Puede identificar fácilmente la mejor ejecución en Azure Machine Learning studio, y descargar o desplegar el modelo que 
generó. Para lograr esto mediante programación con el SDK, puede utilizar código como el del siguiente ejemplo:

```python
best_run, fitted_model = automl_run.get_output()
best_run_metrics = best_run.get_metrics()
for metric_name in best_run_metrics:
    metric = best_run_metrics[metric_name]
    print(metric_name, metric)
```

### Explorar los pasos del preprocesamiento

El aprendizaje automático utiliza conductos scikit-learn para encapsular los pasos de preprocesamiento con el modelo. 
Puede ver los pasos en el modelo ajustado que obtuvo de la mejor ejecución utilizando el código anterior de esta manera:

```python
for step_ in fitted_model.named_steps:
    print(step_)
```

## 10 Exercise Using automated machine learning
[< Back to Local Index](#10-index)

Ahora es su oportunidad de utilizar las capacidades de aprendizaje automático automatizado de Azure Machine Learning 
para entrenar un modelo de aprendizaje automático.

En este ejercicio, usted:

- Ejecutará un experimento de aprendizaje automático automatizado.

- Revisará el modelo de mejor rendimiento.

### Instrucciones

1. Si aún no tiene una suscripción a Azure, regístrese para una prueba gratuita en
https://azure.microsoft.com.

2. Consulte el repositorio del ejercicio en
https://aka.ms/mslearn-dp100.

3. Si aún no lo ha hecho, complete el ejercicioCrear un espacio de trabajo de Azure Machine Learning para aprovisionar un espacio de trabajo de Azure Machine Learning, crear una instancia de cálculo y clonar los archivos necesarios.

4. Complete el ejercicioUtilizar aprendizaje automático automatizado del SDK.

> Nota
>
> También hay un ejercicio llamado Utilizar aprendizaje automático automatizado, en el que puede utilizar la interfaz visual para el aprendizaje automático automatizado. También puede completarlo si desea explorar el enfoque "sin código".

> ### Nota:
> El notebook de esta sección está en: [12 - Use Automated Machine Learning.ipynb](ims%2FC10%2Fnotebooks%2F12%20-%20Use%20Automated%20Machine%20Learning.ipynb)

![s1.gif](ims%2FC10%2Fgifs%2Fs1.gif)

![s2.gif](ims%2FC10%2Fgifs%2Fs2.gif)

![s3.gif](ims%2FC10%2Fgifs%2Fs3.gif)

![s4.gif](ims%2FC10%2Fgifs%2Fs4.gif)

![s5.gif](ims%2FC10%2Fgifs%2Fs5.gif)

![s6.gif](ims%2FC10%2Fgifs%2Fs6.gif)

![s7.gif](ims%2FC10%2Fgifs%2Fs7.gif)

## 10 Exercise quiz
[< Back to Local Index](#10-index)

![0.png](ims%2FC10%2Ftests%2F0.png)

## 10 Knowledge check
[< Back to Local Index](#10-index)

![q1.png](ims%2FC10%2Ftests%2Fq1.png)

![q2.png](ims%2FC10%2Ftests%2Fq2.png)

![q3.png](ims%2FC10%2Ftests%2Fq3.png)

![q4.png](ims%2FC10%2Ftests%2Fq4.png)

## 10 Lesson summary
[< Back to Local Index](#10-index)

![18.png](ims%2FC10%2Fims%2F1%2F18.png)

En esta lección, ha aprendido a automatizar la selección de modelos de aprendizaje automático con Azure Machine Learning. 
Más concretamente, ha aprendido a utilizar las capacidades de aprendizaje automático automatizado de Azure Machine Learning 
para: 
- determinar el algoritmo de mejor rendimiento para sus datos 
- utilizar el aprendizaje automático automatizado para preprocesar los datos para el entrenamiento
- ejecutar un experimento de aprendizaje automático automatizado.


## 10 Additional Reading
[< Back to Local Index](#10-index)

**Automated machine learning tasks and algorithms**
[What is automated machine learning (AutoML)](https://docs.microsoft.com/en-us/azure/machine-learning/concept-automated-ml)

**Preprocessing and featurization**
[What is automated machine learning (AutoML)  - How automated ML works](https://docs.microsoft.com/en-us/azure/machine-learning/concept-automated-ml#how-automated-ml-works)

# 11 Explore differential privacy

## 11 INDEX

- [11 Lesson introduction](#11-lesson-introduction)
- [11 Understand differential privacy](#11-understand-differential-privacy)
- [11 Configure data privacy parameters](#11-configure-data-privacy-parameters)
- [11 Exercise Use differential privacy](#11-exercise-use-differential-privacy)
- [11 Exercise quiz](#11-exercise-quiz)
- [11 Knowledge Check](#11-knowledge-check)
- [11 Lesson Summary](#11-lesson-summary)
- [11 Additional Reading](#11-additional-reading)

[< Back to index](#0-index)

## 11 Lesson introduction
[< Back to Local Index](#11-index)

![1.png](ims%2FC11%2Fims%2F1%2F1.png)

Hola, en esta lección aprenderá a explorar la privacidad diferencial. Los proyectos de ciencia de datos, incluidos los 
de aprendizaje automático, implican el análisis de datos y, a menudo, esos datos incluyen detalles personales sensibles 
que deberían mantenerse en privado.

![2.png](ims%2FC11%2Fims%2F1%2F2.png)

En la práctica, la mayoría de los informes que se publican a partir de los datos incluyen agregaciones de los datos, 
lo que podría pensar que proporcionaría cierta privacidad. Al fin y al cabo, los resultados agregados no revelan los 
valores de los datos individuales.

![3.png](ims%2FC11%2Fims%2F1%2F3.png)

Sin embargo, consideremos un caso en el que múltiples análisis de los datos dan lugar a informes agregados que, al 
combinarse, podrían utilizarse para averiguar información sobre los individuos del conjunto de datos de origen. 
Supongamos que diez participantes comparten datos sobre su ubicación y salario a partir de los cuales se elaboran 
los informes.

![4.png](ims%2FC11%2Fims%2F1%2F4.png)

Un informe de salarios agregados que nos dice los salarios medios en Nueva York, San Francisco y Seattle. Un informe de 
ubicación de los trabajadores que nos dice que el 10% de los participantes en el estudio. En otras palabras, una 
sola persona tiene su sede en Seattle. 

![5.png](ims%2FC11%2Fims%2F1%2F5.png)

A partir de estos dos informes, podemos determinar fácilmente el salario 
específico del participante con sede en Seattle. Cualquiera que revise ambos estudios y que por casualidad conozca a una 
persona de Seattle que haya participado, ahora conoce el salario de esa persona.

![6.png](ims%2FC11%2Fims%2F1%2F6.png)

En esta lección explorará la privacidad diferencial, una técnica que puede ayudar a proteger los datos de un individuo frente a este tipo de exposición. 
Más concretamente, aprenderá a: 

- articular el problema de la privacidad de los datos 
- describir cómo funciona la privacidad diferencial
- configurar parámetros para la privacidad diferencial
- realizar análisis de datos deferencialmente privados


## 11 Understand differential privacy
[< Back to Local Index](#11-index)

![7.png](ims%2FC11%2Fims%2F1%2F7.png)

La privacidad diferencial busca para proteger los valores de los datos individuales mediante la adición de estadísticas 
ruido en el proceso de análisis. La matemática necesaria para sumar el ruido es complejo, pero el principio es bastante 
intuitivo. El ruido asegura la agregación de datos mantener la coherencia estadística con los valores reales de los datos, 
teniendo en cuenta algunos variación aleatoria, pero NO permiten calcular los valores individuales a partir de los datos agregados. 

![8.png](ims%2FC11%2Fims%2F1%2F8.png)

Además, el ruido es diferente para cada análisis, por lo que los resultados no son deterministas. En otras palabras, a 
los análisis que realizan la misma agregación puede producir resultados ligeramente diferentes.

## 11 Configure data privacy parameters
[< Back to Local Index](#11-index)

![9.png](ims%2FC11%2Fims%2F1%2F9.png)

Una forma en la que un individuo puede proteger sus datos personales es simplemente no participar en un estudio. Esto se 
conoce como la opción de exclusión voluntaria. 

Sin embargo, existen algunas consideraciones para esto como solución. Incluso si decide excluirse de un estudio, éste 
todavía puede producir resultados que le afecten. Por ejemplo, puede optar por excluirse de un estudio que compara 
los diagnósticos de enfermedades cardíacas entre un par de personas basándose en que al hacerlo puede revelar un 
diagnóstico de enfermedad cardíaca que haga que suban las primas de su seguro médico. 

El estudio encuentra una correlación entre las personas que beben café y un mayor riesgo de enfermedad cardiaca, y su 
compañía de seguros sabe que usted es bebedor de café, su tarifa puede subir aunque usted no haya participado personalmente 
en el estudio. 

![10.png](ims%2FC11%2Fims%2F1%2F10.png)

Los beneficios de la participación en el estudio pueden compensar cualquier impacto negativo. Por ejemplo, si le pagan 
100 dólares por participar en un estudio que hace que la tarifa de su seguro médico suba 10 dólares al año, pasarán más 
de 10 años antes de que tenga una pérdida neta.

Puede que para usted sea una compensación que merezca la pena, sobre todo si su tarifa puede subir como resultado del 
estudio, incluso si no participa. 

![11.png](ims%2FC11%2Fims%2F1%2F11.png)

La única forma de que la opción de exclusión funcione para cada individuo es que cada individuo no participe, lo que 
hace que todo el estudio carezca de sentido.

![12.png](ims%2FC11%2Fims%2F1%2F12.png)

La cantidad de llamadas a la variación añadiendo ruido es configurable a través de un parámetro llamado Epsilon. 

![13.png](ims%2FC11%2Fims%2F1%2F13.png)

Este valor rige la cantidad de riesgos adicionales de que sus datos personales puedan ser identificados al rechazar la 
opción de exclusión voluntaria y participar en un estudio. **Lo fundamental es que se aplica este principio de privacidad para todos los que participan en el estudio.**

![14.gif](ims%2FC11%2Fims%2F1%2F14.gif)

Un valor de **Epsilon bajo proporciona la mayor privacidad** a expensas de una **menor precisión** al agregar los datos. 
Un valor de **Epsilon más alto da lugar a agregaciones que son más fieles a la distribución real** de los datos, 
pero en las que la contribución individual de un solo individuo a el valor agregado queda menos oscurecida por el ruido.

## 11 Exercise Use differential privacy
[< Back to Local Index](#11-index)

Ahora tiene la oportunidad de explorar por sí mismo la privacidad diferencial utilizando el paqueteSmartNoise.

En este ejercicio, usted podrá:

- Utilizar **SmartNoise** para generar análisis diferencialmente privados.

- Utilizar **SmartNoise** para enviar consultas diferencialmente privadas.

### Instrucciones
Siga estas instrucciones para completar el ejercicio.

1. Si aún no dispone de una suscripción a Azure, regístrese para una prueba gratuita en
https://azure.microsoft.com.

2. Consulte el repositorio del ejercicio en
https://aka.ms/mslearn-dp100.

3. Si aún no lo ha hecho, complete el ejercicioCrear un espacio de trabajo de Azure Machine Learning para aprovisionar un espacio de trabajo de Azure Machine Learning, crear una instancia de cálculo y clonar los archivos necesarios.

4. Complete el ejercicio **Explorar la privacidad diferencial.**

> Nota:
> 
> El Notebook de esta clase está en: [13 - Explore Differential Privacy.ipynb](ims%2FC11%2Fnotebooks%2F13%20-%20Explore%20Differential%20Privacy.ipynb) 

Es fácil de leer el notebook pero TIENE problemas de compatibilidad entre versiones y no logre ejecutarlo adecuadamente,
sin embargo, la forma en la que esta hecho es muy fácil de leer.

## 11 Exercise quiz
[< Back to Local Index](#11-index)

![0.png](ims%2FC11%2Ftests%2F0.png)

## 11 Knowledge Check
[< Back to Local Index](#11-index)

![q1.png](ims%2FC11%2Ftests%2Fq1.png)

![q2.png](ims%2FC11%2Ftests%2Fq2.png)

![q3.png](ims%2FC11%2Ftests%2Fq3.png)

![q4.png](ims%2FC11%2Ftests%2Fq4.png)

![q5.png](ims%2FC11%2Ftests%2Fq5.png)

## 11 Lesson Summary
[< Back to Local Index](#11-index)

![15.png](ims%2FC11%2Fims%2F1%2F15.png)

En esta lección, ha aprendido a explorar la privacidad diferencial. Ha aprendido a articular el problema de la privacidad 
de los datos, describir cómo funciona la privacidad diferencial, configurar parámetros para la privacidad diferencial, y 
realizar análisis de datos con privacidad diferencial. 

![16.png](ims%2FC11%2Fims%2F1%2F16.png)

Para obtener más información sobre la interpretación de modelos, consulte la privacidad diferencial en la documentación 
de Azure Machine Learning del sitio web de Microsoft. Puede encontrar un enlace a estos recursos en las lecturas 
adicionales al final de esta lección.
[What is differential privacy in machine learning](https://docs.microsoft.com/en-us/azure/machine-learning/concept-differential-privacy)


## 11 Additional Reading
[< Back to Local Index](#11-index)

**Differential privacy**

[What is differential privacy in machine learning](https://docs.microsoft.com/en-us/azure/machine-learning/concept-differential-privacy)

# 12 Explain machine learning models with Azure Machine Learning

## 12 INDEX

- [12 Lesson introduction](#12-lesson-introduction)
- [12 Feature importance](#12-feature-importance)
- [12 Using explainers](#12-using-explainers)
- [12 Creating explanations](#12-creating-explanations)
- [12 Visualizing explanations](#12-visualizing-explanations)
- [12 Exercise Interpret models](#12-exercise-interpret-models)
- [12 Exercise quiz](#12-exercise-quiz)
- [12 Knowledge check](#12-knowledge-check)
- [12 Test prep](#12-test-prep)
- [12 Lesson Summary](#12-lesson-summary)
- [12 Additional Reading](#12-additional-reading)

[< Back to index](#0-index)

## 12 Lesson introduction
[< Back to Local Index](#12-index)

![1.png](ims%2FC12%2Fims%2F1%2F1.png)

Hola. En esta lección, aprenderá a explicar los modelos de aprendizaje automático con Azure Machine Learning. A medida 
que el aprendizaje automático se vuelve cada vez más integral para las decisiones que afectan a la salud, la seguridad, 
el bienestar económico, y otros aspectos de la vida de las personas, es importante poder entender cómo los modelos hacen 
predicciones y poder explicar los fundamentos de las decisiones basadas en el aprendizaje automático.

![2.png](ims%2FC12%2Fims%2F1%2F2.png)

Explicar los modelos es difícil debido a la variedad de tipos de algoritmos de aprendizaje automático y a la naturaleza 
de cómo funciona el aprendizaje automático. Pero la interpretabilidad de los modelos se ha convertido en un elemento clave 
para ayudar a hacer que las predicciones de los modelos sean explicables.

![3.png](ims%2FC12%2Fims%2F1%2F3.png)

En esta lección, aprenderá a: 

- interpretar la importancia global y local de las características. 
- utilizar un explicador para interpretar un modelo
- cree explicaciones de modelos en un experimento de entrenamiento
- visualizar explicaciones de modelos.

## 12 Feature importance
[< Back to Local Index](#12-index)

![4.png](ims%2FC12%2Fims%2F1%2F4.png)

Los explicadores de modelos utilizan técnicas estadísticas para calcular la importancia de las características

Esto permite cuantificar la influencia relativa que tiene cada característica del conjunto de datos de entrenamiento en 
la predicción de etiquetas. Los explicadores funcionan evaluando un conjunto de datos de prueba de casos de 
características y las etiquetas que el modelo predice para ellos. 

![5.png](ims%2FC12%2Fims%2F1%2F5.png)

> La importancia global de las características cuantifica la importancia relativa de cada característica en el conjunto de datos de prueba en su totalidad. Proporciona una comparación general del grado en que cada característica del conjunto de datos influye en la predicción.

Por ejemplo, un modelo de clasificación binaria para predecir el riesgo de impago de un préstamo podría entrenarse a partir 
de características como: **el importe del préstamo, los ingresos, el estado civil y la edad** para predecir una etiqueta 
de `1` para los préstamos que probablemente se devolverán y de `0` para los préstamos que tienen un riesgo significativo 
de impago y, por lo tanto, no deberían aprobarse. 

Un explicador podría entonces utilizar un conjunto de datos de prueba suficientemente representativo para producir los 
siguientes valores de importancia global de las características: 

- ingresos 0.98
- importe del préstamo 0.67
- edad 0.54 
- estado civil 0.32. 

![6.png](ims%2FC12%2Fims%2F1%2F6.png)

De estos valores se deduce claramente que, con respecto a las predicciones globales generadas por el modelo para el 
conjunto de datos de prueba, los ingresos son la característica más importante para predecir si un prestatario 
incumplirá o no un préstamo, seguida de el importe del préstamo, luego la edad y, por último, el estado civil.

![7.png](ims%2FC12%2Fims%2F1%2F7.png)

**La importancia local de las características mide la influencia de cada valor de característica para una predicción individual
específica**. 

Por ejemplo, supongamos que **Sam** solicita un préstamo que el modelo de aprendizaje automático aprueba prediciendo que 
**Sam no incumplirá la devolución del préstamo**. Podría utilizar un **explicador** para calcular **la importancia local** 
de la característica para la solicitud de Sam para determinar qué factores influyen en la predicción. Dado que se trata 
de un modelo de clasificación, **cada característica obtiene un valor de importancia local para cada clase posible**, 
indicando la cantidad de apoyo para esa clase basada en el valor de la característica. Dado que se trata de un modelo de 
clasificación binario, sólo hay dos clases posibles, cero y uno. 

![8.png](ims%2FC12%2Fims%2F1%2F8.png)

El apoyo de cada característica a una clase se traduce en un nivel correlativamente negativo de apoyo a la otra. En el 
caso de Sam, el apoyo global a la clase cero es -1.4 y el apoyo para la clase uno es correspondientemente 1,4. Así pues, 
el apoyo para la clase uno es mayor que para la clase cero y el préstamo se aprueba. 

![9.png](ims%2FC12%2Fims%2F1%2F9.png)

La característica más importante para una predicción de la clase uno es el importe del préstamo, seguido de los ingresos. 
Se trata del orden inverso al de sus valores de importancia global de las características, que indican que los ingresos 
son el factor más importante para la muestra de datos en su conjunto. 

![10.png](ims%2FC12%2Fims%2F1%2F10.png)

Podría haber múltiples razones por las que la importancia local para una predicción individual varía de la importancia 
global para el conjunto de datos en su conjunto.

![11.png](ims%2FC12%2Fims%2F1%2F11.png)

Por ejemplo, Sam podría tener unos ingresos inferiores a la media, pero el importe del préstamo en este caso podría ser 
inusualmente pequeño. 

![12.png](ims%2FC12%2Fims%2F1%2F12.png)

Para un modelo de clasificación multiclase, se calcula un valor de importancia local para cada una de las clases posibles 
para cada característica, siendo siempre cero el total para todas las clases. 

Por ejemplo, un modelo podría predecir la especie de un pingüino basándose en características como: 

- la longitud de su pico
- la anchura de su pico
- la longitud de sus aletas 
- su peso.

![13.png](ims%2FC12%2Fims%2F1%2F13.png) 

Supongamos que hay tres especies de pingüinos. Entonces el modelo predice una de las tres etiquetas de clase 
**cero, uno o dos**. Para una predicción individual, la característica longitud de la aleta podría tener valores de 
importancia local de **0.5 para la clase cero, 0,3 para la clase uno y -0,8 para la clase dos**. 


![14.png](ims%2FC12%2Fims%2F1%2F14.png)

Esto indica que la longitud de la aleta apoya moderadamente una predicción para la clase cero apoya ligeramente una 
predicción de la clase uno, y apoya fuertemente la predicción de este pingüino en particular, no formando parte de la 
clase dos. 

![15.png](ims%2FC12%2Fims%2F1%2F15.png)

Para un modelo de regresión, no hay clases, por lo que el valor de importancia local simplemente indica el nivel de 
influencia que cada característica tiene en la escala o etiqueta predicha.

## 12 Using explainers
[< Back to Local Index](#12-index)

![1.png](ims%2FC12%2Fims%2F2%2F1.png)

Hola y bienvenidos. En esta parte explorará el uso de explicadores. Puede utilizar el SDK de Azure Machine Learning para 
crear explicadores para modelos. Incluso si no fueron entrenados utilizando un experimento de Azure Machine Learning. 

![2.png](ims%2FC12%2Fims%2F2%2F2.png)

Para interpretar un modelo local, debe instalar el paquete azureml-interpret y utilizarlo para crear un explicador. 
Existen varios tipos de explicadores, como MimicExplainer, TabularExplainer y PFIExplainer. Veámoslos ahora con un poco más de detalle. 

![3.png](ims%2FC12%2Fims%2F2%2F3.png)

MimicExplainer es un explicador que crea un modelo sustituto global que se aproxima a su modelo entrenado, y que puede 
utilizarse para generar explicaciones. Este modelo explicable debe tener el mismo tipo de arquitectura que su modelo entrenado, 
por ejemplo, lineal o basado en árboles.

![4.png](ims%2FC12%2Fims%2F2%2F4.png)

TabularExplainer es un explicador que actúa como envoltorio alrededor de varios algoritmos explicadores afilados. Elige 
automáticamente el más adecuado para la arquitectura de su modelo. 

![5.png](ims%2FC12%2Fims%2F2%2F5.png)

PFIExplainer es un explicador de permutación de importancia de características, que analiza la importancia de las características. 
Barajando los valores de las características y midiendo el impacto en el rendimiento de la predicción.

![6.png](ims%2FC12%2Fims%2F2%2F6.png)

Bien, pasemos ahora a la importancia global de las características. Para recuperar los valores de importancia global de las 
características de su modelo, puede llamar al método global explicado de su explicador para obtener una explicación global. 
Y luego utilice el método get_feature_importance_dict() para obtener un diccionario de los valores de importancia de las características. 

![7.png](ims%2FC12%2Fims%2F2%2F7.png)

Es importante tener en cuenta que el código es el mismo para MimicExplainer y TabularExplainer. El PFIExplainer requiere 
las etiquetas reales que corresponden a las características de prueba

![8.png](ims%2FC12%2Fims%2F2%2F8.png)

Por último, veamos cómo explicar la importancia local de las características. Para recuperar la importancia local de las 
características de un MimicExplainer o un TabularExplainer. Debe llamar al método local explicado de su explicador especificando 
el subconjunto de casos que desea explicar. 

![9.png](ims%2FC12%2Fims%2F2%2F9.png)

A continuación, puede utilizar los métodos get_ranked_local_names y get_ranked_local_values. Para recuperar diccionarios de 
los nombres de las características y valores de importancia clasificados por importancia. Es importante tener en cuenta que 
el código es el mismo para MimicExplainer y TabularExplainer. El PFIExplainer no admite explicaciones de importancia de 
características locales.

## 12 Creating explanations
[< Back to Local Index](#12-index)

Cuando utilice un estimador o un script para entrenar un modelo en un experimento de Azure Machine Learning, puede crear 
una explicación y cargar la explicación que genera en la ejecución para su posterior análisis.

### Creación de una explicación en el script del experimento

Para crear una explicación en el script del experimento, deberá asegurarse de que los paquetes **azureml-interpret** y 
**azureml-contrib-interpret** están instalados en el entorno de ejecución. Entonces podrá utilizarlos para crear una explicación 
a partir de su modelo entrenado y cargarla en las salidas de ejecución. 

El siguiente ejemplo de código muestra cómo puede incorporarse a un script de experimento el código para generar y cargar una 
explicación del modelo.

```python
# Import Azure ML run library
from azureml.core.run import Run
from azureml.contrib.interpret.explanation.explanation_client import ExplanationClient
from interpret.ext.blackbox import TabularExplainer
# other imports as required

# Get the experiment run context
run = Run.get_context()

# code to train model goes here

# Get explanation
explainer = TabularExplainer(model, X_train, features=features, classes=labels)
explanation = explainer.explain_global(X_test)

# Get an Explanation Client and upload the explanation
explain_client = ExplanationClient.from_run(run)
explain_client.upload_model_explanation(explanation, comment='Tabular Explanation')

# Complete the run
run.complete()
```

### Visualización de la explicación

Puede ver la explicación que ha creado para su modelo en la pestaña **Explicaciones** de la ejecución en Azure Machine learning studio.

También puede utilizar el objeto **ExplanationClient** para descargar la explicación en Python.

```python
from azureml.contrib.interpret.explanation.explanation_client import ExplanationClient

client = ExplanationClient.from_run_id(workspace=ws,
                                       experiment_name=experiment.experiment_name, 
                                       run_id=run.id)
explanation = client.download_model_explanation()
feature_importances = explanation.get_feature_importance_dict()
```

## 12 Visualizing explanations
[< Back to Local Index](#12-index)

![10.png](ims%2FC12%2Fims%2F2%2F10.png)

Explicaciones de modelos en Azure Machine Learning Studio incluye varias visualizaciones que puedes usar para explorar 
importancia de la función. La primera visualización de la pestaña de explicaciones de una ejecución muestra la importancia 
global de las funciones. Puede usar el control deslizante para mostrar solo las k funciones principales. 

![11.png](ims%2FC12%2Fims%2F2%2F11.png)

Pasar al resumen la visualización de la importancia muestra la distribución de importancia individual, valores para cada 
característica en todo el conjunto de datos de prueba. Puede ver las funciones como un diagrama de enjambres, como se 
muestra arriba, un diagrama de caja o un diagrama de violín. 

![12.png](ims%2FC12%2Fims%2F2%2F12.png)

Selección de un individuo el punto de datos muestra la importancia de la característica local para el caso en el que el 
punto de datos pertenece.

## 12 Exercise Interpret models
[< Back to Local Index](#12-index)

Ahora es su oportunidad de interpretar modelos.

En este ejercicio, usted podrá:

- Generar la importancia de las características de un modelo.

- Generar explicaciones como parte de un experimento de entrenamiento de modelos.

### Instrucciones

Siga estas instrucciones para completar el ejercicio.

1. Si aún no dispone de una suscripción a Azure, suscríbase a una prueba gratuita en
https://azure.microsoft.com.

2. Consulte el repositorio del ejercicio en
https://aka.ms/mslearn-dp100.

3. Si aún no lo ha hecho, complete el ejercicioCrear un espacio de trabajo de Azure Machine Learning para aprovisionar un espacio de trabajo de Azure Machine Learning, crear una instancia de cálculo y clonar los archivos necesarios.

4. Complete el ejercicioInterpretar modelos.

### Notebook

> NOTA:
> 
> El notebook de esta clase está en: [14 - Interpret Models.ipynb](ims%2FC12%2Fnotebooks%2F14%20-%20Interpret%20Models.ipynb)

1. Vamos a empezar instalando la biblioteca que permitirá darle `intrepretabilidad` a nuestros modelos, incluso si estos ya han sido entrenados.

   ![s1.gif](ims%2FC12%2Fgifs%2Fs1.gif)

2. Ahora de forma simple, vamos a crear un clasificador de diabetes basado un `DecisionTreeClassifier`:

   ![s2.gif](ims%2FC12%2Fgifs%2Fs2.gif)

   Podemos observar sus resultados de `Accuracy` y `AUC`, el modelo ha este punto ya ha sido entrenado y validado.

3. Vamos entonces a darle interpretabilidad a l mismo. Para ello y por el tipo de `dataset` que estamos utilizando, vamos a emplear
   un `TabularExplainer`. Vemos como el proceso es sumamente simple, solo podemos el modelo que ya hemos entrenado, los `X_train` y a su vez 
   una lista de `features` que corresponde al nombre de las variables Y. Finalmente, ponemos los `labels`.
   ![s3.gif](ims%2FC12%2Fgifs%2Fs3.gif)

4. Ahora vamos a ver una `Global Feature importance`:

   ![s4.gif](ims%2FC12%2Fgifs%2Fs4.gif)

    Esto corresponde con la importancia de cada Variable a nivel Global para determinar la clase en este problema de clasificación.

5. Algo igual de interesante es ver la importancia a nivel `Local`, quiero decir a nivel de instancia:

   ![s5.gif](ims%2FC12%2Fgifs%2Fs5.gif)
   
   Algo interesante es que la `interpretabilidad` recae directamente en el objeto: `tab_explainer` aunque curiosamente quien pone
   la etiqueta final sigue siendo la predicción del modelo `bbox`

6. Podemos hacer lo mismo pero con un experimento, un modelo creado en Azure:

   Ya conocemos estos pasos básicos para correr un nuevo experimento:

   1. Crear el folder que contenga el dataset:

      ![s6.gif](ims%2FC12%2Fgifs%2Fs6.gif)

   2. Crear el código de python que se va a correr en el experimento:

      ![s7.gif](ims%2FC12%2Fgifs%2Fs7.gif)

      > Nota importante:
      >
      > Es aquí donde ponemos el código para agregar `interpretabilidad`:
      
      ```python
       # Get explanation
       explainer = TabularExplainer(model, X_train, features=features, classes=labels)
       explanation = explainer.explain_global(X_test)
   
       # Get an Explanation Client and upload the explanation
       explain_client = ExplanationClient.from_run(run)
       explain_client.upload_model_explanation(explanation, comment='Tabular Explanation')
      ```
   3. Crear el entorno virtual `.yaml` de conda:

      ![s8.gif](ims%2FC12%2Fgifs%2Fs8.gif)

   4. Correr el experimento:

      ![s9.gif](ims%2FC12%2Fgifs%2Fs9.gif)

7. Observar los resultados en Azure:

   ![s10.gif](ims%2FC12%2Fgifs%2Fs10.gif)

## 12 Exercise quiz
[< Back to Local Index](#12-index)

![0.png](ims%2FC12%2Ftests%2F0.png)

## 12 Knowledge check
[< Back to Local Index](#12-index)

![q1.png](ims%2FC12%2Ftests%2Fq1.png)

![q2.png](ims%2FC12%2Ftests%2Fq2.png)

![q3.png](ims%2FC12%2Ftests%2Fq3.png)

## 12 Test prep
[< Back to Local Index](#12-index)

![t1.png](ims%2FC12%2Ftests%2Ft1.png)

![t2.png](ims%2FC12%2Ftests%2Ft2.png)

![t3.png](ims%2FC12%2Ftests%2Ft3.png)

![t4.png](ims%2FC12%2Ftests%2Ft4.png)

![t5.png](ims%2FC12%2Ftests%2Ft5.png)

![t6.png](ims%2FC12%2Ftests%2Ft6.png)

![t7.png](ims%2FC12%2Ftests%2Ft7.png)

## 12 Lesson Summary
[< Back to Local Index](#12-index)

![1.png](ims%2FC12%2Ftests%2F1.png)


En esta lección, ha aprendido a explicar modelos de aprendizaje automático, con Azure Machine Learning. 
Más concretamente, ha aprendido a: 

- interpretar la importancia global y local de las características
- utilizar un explicador para interpretar un modelo
- crear explicaciones de modelos en un experimento de entrenamiento
- visualizar explicaciones de modelos. 

![2.png](ims%2FC12%2Ftests%2F2.png)

Para obtener más información sobre la interpretación de modelos, consulte la interpretación de modelos en 
Azure Machine Learning, en la documentación de Azure Machine Learning del sitio web de Microsoft. Puede 
encontrar un enlace a este recurso, en las lecturas adicionales al final de esta lección.

## 12 Additional Reading
[< Back to Local Index](#12-index)

**Model interpretability**
[Model interpretability in Azure Machine Learning](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-machine-learning-interpretability)

# 13 Detect and mitigate unfairness in models with Azure Machine Learning

## 13 INDEX

- [13 Lesson introduction](#13-lesson-introduction)
- [13 Consider model fairness](#13-consider-model-fairness)
- [13 Analyze model fairness with Fairlearn](#13-analyze-model-fairness-with-fairlearn)
- [13 Mitigate unfairness with Fairlearn](#13-mitigate-unfairness-with-fairlearn)
- [13 Exercise Use Fairlearn with Azure Machine Learning](#13-exercise-use-fairlearn-with-azure-machine-learning)
- [13 Exercise quiz](#13-exercise-quiz)
- [13 Knowledge Check](#13-knowledge-check)
- [13 Lesson summary](#13-lesson-summary)
- [13 Additional Reading](#13-additional-reading)

[< Back to index](#0-index)

## 13 Lesson introduction
[< Back to Local Index](#13-index)

![1.png](ims%2FC13%2Fims%2F1%2F1.png)

Hola. En esta lección, aprenderá a detectar y mitigar la injusticia En los modelos, con el aprendizaje automático 
de Azure. Los modelos de aprendizaje automático, se utilizan cada vez más para fundamentar decisiones que afectan a la 
vida de las personas. 

![2.png](ims%2FC13%2Fims%2F1%2F2.png)

Por ejemplo, una predicción hecha por un modelo de machine learning puede influenciar la aceptación de un crédito para una
deuda o un seguro médico u otros servicios financieros. Si eres aceptado en una escuela o no. Eligibilidad para un tratamiento
médico o tratamiento experimental. Inclusión en una promoción de marketing. Selección para un aumento de puesto. 

![3.png](ims%2FC13%2Fims%2F1%2F3.png)

Con decisiones tan críticas en la balanza, tenemos que certeza en que los modelos de aprendizaje automático en los 
que confiamos predicen y no discriminen a favor o en contra de subconjuntos de la población en función de su 
origen étnico, sexo, edad u otros factores. 

![4.png](ims%2FC13%2Fims%2F1%2F4.png)

En esta lección, aprenderá a: 

- evaluar los modelos de aprendizaje automático para imparcialidad
- mitigar la disparidad predictiva en un modelo de aprendizaje automático.

## 13 Consider model fairness
[< Back to Local Index](#13-index)

![5.png](ims%2FC13%2Fims%2F1%2F5.png)

Cuando consideramos el concepto de imparcialidad en relación con las predicciones realizadas por los modelos de aprendizaje 
automático, ayuda tener claro lo que entendemos por imparcialidad. 

![6.png](ims%2FC13%2Fims%2F1%2F6.png)

Por ejemplo, supongamos que el modelo de clasificación se utiliza para predecir la probabilidad de que se reembolse con 
éxito el préstamo y, por lo tanto, influye en que se apruebe o no el préstamo.

![7.png](ims%2FC13%2Fims%2F1%2F7.png)

Es probable que el modelo se entrene utilizando características que reflejen las características del solicitante, como la edad, 
la situación laboral, los ingresos, los ahorros y la deuda actual. Estas características se utilizan para entrenar un modelo 
de clasificación binario que predice si un solicitante reembolsará el préstamo.

![8.png](ims%2FC13%2Fims%2F1%2F8.png)

Supongamos que el modelo predice que alrededor del 45% de los solicitantes reembolsarán con éxito sus préstamos. 
Sin embargo, al revisar los registros de aprobación de préstamos, usted empieza a sospechar que se aprueban menos préstamos 
a solicitantes de 25 años o más jóvenes que a solicitantes mayores de 25 años. 

¿Cómo puede estar seguro de que el modelo es justo con los solicitantes de ambos grupos de edad? 

![9.png](ims%2FC13%2Fims%2F1%2F9.png)

Una forma de empezar a evaluar la justicia de un modelo es comparar las predicciones para cada grupo con una característica 
sensible. Para el modelo de aprobación de préstamos, la edad es una característica sensible que nos importa

![10.png](ims%2FC13%2Fims%2F1%2F10.png)

Así que podríamos dividir los datos en subconjuntos para cada grupo de edad y comparar la tasa de selección, la proporción 
de predicciones positivas para cada grupo. 

![11.png](ims%2FC13%2Fims%2F1%2F11.png)

Digamos que encontramos que el modelo predice que el 36% de los solicitantes de 25 años o menos, reembolsarán un préstamo, 
pero predice reembolsos con éxito para el 54% de los solicitantes de más de 25 años. Hay una disparidad en las predicciones 
del 18%. 

![12.png](ims%2FC13%2Fims%2F1%2F12.png)

A primera vista, esta comparación parece **confirmar que hay un sesgo** en el modelo que discrimina a los solicitantes más jóvenes. 
Sin embargo, si se tiene en cuenta a la población en su conjunto, es posible que las personas más jóvenes 

- ganen generalmente menos que las personas más establecidas en sus carreras
- tengan niveles más bajos de ahorros y activos 
- presenten una mayor tasa de impago de los préstamos.

![13.png](ims%2FC13%2Fims%2F1%2F13.png)

El punto importante que hay que considerar aquí es que sólo porque queramos garantizar la equidad con respecto a la edad, 
no se deduce necesariamente que la edad no sea un factor en la probabilidad de reembolso de los préstamos. 

Es posible que, en general, las personas más jóvenes tengan menos probabilidades de reembolsar un préstamo que las de más edad. 
Para hacernos una idea completa, tenemos que profundizar un poco más en el rendimiento predictivo del modelo para cada 
subconjunto de la población. 

![14.png](ims%2FC13%2Fims%2F1%2F14.png)

Cuando se entrena un modelo de aprendizaje automático utilizando una técnica supervisada como regresión o clasificación, 
se utilizan métricas logradas frente a datos de validación retenidos para evaluar el rendimiento predictivo general del 
modelo. Por ejemplo, puede evaluar un modelo de clasificación basándose en la exactitud, la precisión o la recuperación 
para evaluar la equidad de un modelo.

![15.png](ims%2FC13%2Fims%2F1%2F15.png)

Es importante dividir los datos en subconjuntos basados en las características sensibles en las que se agrupa la población. 
Entonces, tras aplicar las mismas métricas de rendimiento predictivo, puede medir la disparidad de esas métricas entre los 
subgrupos.

![16.png](ims%2FC13%2Fims%2F1%2F16.png)

Por ejemplo, supongamos que el modelo de aprobación de préstamos presenta una métrica de recuerdo global de de 0,67. En 
otras palabras, a identifica correctamente el 67% de los casos en los que el solicitante devolvió el préstamo. La cuestión 
es si el modelo proporciona o no una tasa similar de predicciones correctas para los distintos grupos de edad.

![17.png](ims%2FC13%2Fims%2F1%2F17.png)

Para averiguarlo, agrupamos los datos en función de la característica sensible edad y medimos la métrica de rendimiento 
predictivo recuerdo para esos grupos.

![18.png](ims%2FC13%2Fims%2F1%2F18.png)

A continuación, podemos comparar las puntuaciones de las métricas para determinar la disparidad entre ellas. Digamos que 
descubrimos que el recuerdo para los casos de validación en los que el solicitante tiene 25 años o menos es **0.50** y el 
recuerdo para los casos en los que el solicitante tiene más de 25 años **es 0.83**. 

En otras palabras, el modelo identificó correctamente al **50% de las personas del grupo de edad de 25 o más jóvenes** que 
reembolsaron con éxito solos y por lo tanto **clasificó erróneamente al 50%** de ellos como morosos de préstamos, pero encontró 
al **83% de los reparadores de préstamos del grupo de más edad**, clasificando **erróneamente sólo al 17% de ellos**. La 
**disparidad** y el rendimiento de la predicción entre los **grupos es del 33%**.

![19.png](ims%2FC13%2Fims%2F1%2F19.png)

Con el modelo prediciendo significativamente más falsos negativos para el grupo de edad más joven. Cuando encuentre una 
disparidad entre las tasas de predicción o el rendimiento de la predicción métricas a través de grupos de características 
sensibles, vale la pena considerar las causas potenciales.

Entre ellas pueden estar el: 

- desequilibrio de los datos
- correlación directa
- sesgos sociales. 

Echemos ahora un vistazo más de cerca a cada una de ellas:

![20.png](ims%2FC13%2Fims%2F1%2F20.png)

Algunos grupos pueden estar sobrerrepresentados en los datos de entrenamiento o los datos pueden estar sesgados de tal 
manera que los casos dentro de un grupo específico no sean representativos de la población en general. 

![21.png](ims%2FC13%2Fims%2F1%2F21.png)

La característica sensible en sí misma **puede no ser predictiva de la etiqueta**, pero puede haber una **correlación oculta** 
entre la característica sensible y alguna otra característica que influya en la predicción. 

Por ejemplo, es probable que exista una **correlación entre la edad y el historial crediticio** y es probable que exista 
una correlación entre el historial crediticio y los impagos de préstamos. Si la característica del historial crediticio no 
se incluye en los datos de entrenamiento, el algoritmo de entrenamiento puede asignar una espera predictiva a la edad 
sin tener en cuenta el historial crediticio, lo que podría marcar la diferencia en la probabilidad de devolución del préstamo. 

![22.png](ims%2FC13%2Fims%2F1%2F22.png)

Los sesgos subconscientes en la preparación de la recopilación de datos o en el proceso de modelado pueden haber influido 
en la selección de características o en otros aspectos del diseño del modelo. Optimizar la imparcialidad en un modelo de 
aprendizaje automático es un reto socio-técnico.

![23.png](ims%2FC13%2Fims%2F1%2F23.png)

No siempre es algo que se pueda conseguir simplemente aplicando correcciones técnicas a un algoritmo de entrenamiento. 
Sin embargo, hay algunas estrategias que puede adoptar para mitigar el sesgo, entre ellas equilibrar los datos de entrenamiento 
y validación. 

Puede aplicar técnicas de sobremuestreo o submuestreo para equilibrar los datos y utilizar algoritmos de splitting estratificado 
para mantener proporciones representativas para el entrenamiento y la validación.

![24.png](ims%2FC13%2Fims%2F1%2F24.png)

Realizar una amplia selección de características y análisis de ingeniería. Asegúrese de explorar a fondo las correlaciones 
interconectadas en sus datos para intentar diferenciar las características que son directamente predictivas de las 
características que encapsulan relaciones matizadas más complejas.

![25.png](ims%2FC13%2Fims%2F1%2F25.png)

Evalúe la disparidad de los modelos en función de las características significativas. No puede abordar fácilmente el sesgo 
de un modelo si no puede cuantificarlo.

![26.png](ims%2FC13%2Fims%2F1%2F26.png)

Compense el rendimiento predictivo global por la menor disparidad en el rendimiento predictivo entre grupos de características 
sensibles. Un modelo que tiene una precisión del 99,5% con un rendimiento comparable en todos los grupos suele ser más 
deseable que un modelo que tiene una precisión del 99,9%, pero discrimina un subconjunto particular de casos. 

![27.png](ims%2FC13%2Fims%2F1%2F27.png)

El resto de este módulo explora el paquete fair learned, un paquete python que usted puede utilizar para evaluar y mitigar 
la injusticia en los modelos de aprendizaje automático.

## 13 Analyze model fairness with Fairlearn
[< Back to Local Index](#13-index)

![1.png](ims%2FC13%2Fims%2F2%2F1.png)

Fairlearn es un paquete de Python que puede utilizar para analizar modelos y evaluar la disparidad entre las predicciones 
y el rendimiento de la predicción para una o más características sensibles. 

![2.png](ims%2FC13%2Fims%2F2%2F2.png)

Funciona calculando métricas de grupo para las características sensibles que especifique. Las métricas en sí se basan en 
métricas estándar de evaluación de modelos de aprendizaje psíquico como la exactitud, la precisión o el recuerdo para 
modelos de clasificación. 

![3.png](ims%2FC13%2Fims%2F2%2F3.png)

La API de Fairlearn proporciona múltiples formas de detectar disparidades en las métricas a través de agrupaciones de 
características sensibles. 

![4.png](ims%2FC13%2Fims%2F2%2F4.png)

Para un modelo de clasificación binaria, puede empezar comparando la tasa de selección, el número de predicciones positivas 
para cada grupo utilizando la función de tasa de selección. 

![5.png](ims%2FC13%2Fims%2F2%2F5.png)

Esta función devuelve la tasa de selección global para el conjunto de datos de prueba. También puede utilizar las funciones 
estándar de métricas aprendidas de SK como la exactitud, la puntuación, la puntuación de precisión o la puntuación de 
recuperación para obtener una visión general del rendimiento del modelo. 

![6.png](ims%2FC13%2Fims%2F2%2F6.png)

A continuación, puede definir una o varias características sensibles en su conjunto de datos con las que desee agrupar 
subconjuntos de la población y comparar la tasa de selección y el rendimiento predictivo. Fairlearn incluye una función de 
marco métrico que le permite crear un marco de datos de múltiples métricas por el grupo.

![7.png](ims%2FC13%2Fims%2F2%2F7.png)

Por ejemplo, en un modelo de clasificación binaria para la predicción del reembolso de préstamos, donde la característica 
sensible edad consta de dos posibles valores categóricos 25 y menos y más de 25. A continuación, puede crear un marco 
métrico para estos grupos. 

![8.png](ims%2FC13%2Fims%2F2%2F8.png)

A menudo es más fácil comparar métricas visualmente. Por ello, Fairlearn proporciona un widget de cuadro de mando interactivo 
que puede utilizar en un cuaderno para mostrar las métricas de grupo de un modelo. El widget le permite elegir una 
característica sensible y una métrica de rendimiento para comparar y, a continuación, calcula y visualiza las métricas y 
la disparidad. 

![9.png](ims%2FC13%2Fims%2F2%2F9.png)

Fairlearn se integra con el aprendizaje automático de Azure permitiéndole ejecutar un experimento en el que las métricas 
del panel se cargan en su espacio de trabajo de aprendizaje automático de Azure.

## 13 Mitigate unfairness with Fairlearn
[< Back to Local Index](#13-index)

![10.png](ims%2FC13%2Fims%2F2%2F10.png)

Hola. En esta parte, aprenderá a mitigar la injusticia con Fairlearn. Además de permitirle analizar la disparidad en las 
tasas de selección y el rendimiento predictivo a través de características sensibles. 

![11.png](ims%2FC13%2Fims%2F2%2F11.png)

Fairlearn proporciona soporte para mitigar la injusticia en los modelos.

![12.png](ims%2FC13%2Fims%2F2%2F12.png)

El soporte de mitigación en Fairlearn se basa en el uso de algoritmos para crear modelos alternativos que aplican 
restricciones de paridad para producir métricas comparables a través de grupos de características sensibles. 

![13.png](ims%2FC13%2Fims%2F2%2F13.png)

Fairlearn soporta las siguientes técnicas de mitigación. 

- **Gradiente exponenciado**, que es una técnica de reducción que aplica un enfoque de minimización de costes para aprender 
el equilibrio óptimo entre el rendimiento predictivo global y la disparidad de equidad. 
- **Búsqueda de cuadrícula**, que es una versión simplificada del algoritmo de gradiente exponenciado que funciona 
eficazmente con un número reducido de restricciones. 
- **El optimizador de umbral**, que es una técnica de posprocesamiento que aplica una restricción a un clasificador existente, 
transformando la predicción según convenga. 

Es importante señalar que las tres técnicas admiten **la clasificación y la regresión binarias.** Mientras que 
el optimizador de umbral sólo admite el modelo de clasificación binaria.

![14.png](ims%2FC13%2Fims%2F2%2F14.png)

La elección de la restricción de paridad depende de la técnica que se utilice y de los criterios de equidad específicos que 
desee aplicar. Las restricciones en Fairlearn incluyen: 

- la paridad demográfica
- la paridad de la tasa de verdaderos positivos
- la paridad de la tasa de falsos positivos
- las probabilidades igualadas
- la paridad de la tasa de error
- la pérdida de grupo limitada. 

Veamos ahora cada una de ellas un poco más de cerca. 

![15.png](ims%2FC13%2Fims%2F2%2F15.png)

Utilice la restricción de **paridad demográfica** con cualquiera de los algoritmos de mitigación para minimizar la 
disparidad en la tasa de selección entre los grupos de características sensibles. 

Por ejemplo, en un escenario de clasificación binaria esta restricción intenta garantizar que se realice un número igual de predicciones positivas en cada grupo. 

![16.png](ims%2FC13%2Fims%2F2%2F16.png)

Utilice la restricción de **paridad de la tasa de verdaderos positivos** con cualquiera de los algoritmos de mitigación 
para minimizar la disparidad en la tasa de verdaderos positivos entre los grupos de características sensibles. 

Por ejemplo, en un escenario de clasificación binaria esta restricción intenta garantizar que cada grupo contenga una proporción 
comparable de predicciones de verdaderos positivos.

![17.png](ims%2FC13%2Fims%2F2%2F17.png)

Utilice la restricción de paridad de la tasa de falsos positivos con cualquiera de los algoritmos de mitigación para 
minimizar la disparidad en la tasa de falsos positivos entre los grupos de características sensibles. 

Por ejemplo, en un escenario de clasificación binaria, esta restricción intenta garantizar que cada grupo contenga una 
proporción comparable de predicciones de falsos positivos. 

![18.png](ims%2FC13%2Fims%2F2%2F18.png)

Utilice las restricciones de pariedades igualadas con cualquiera de los algoritmos de mitigación para minimizar la disparidad 
en la tasa combinada de verdaderos positivos y falsos positivos entre los grupos de características sensibles. 

Por ejemplo, en un escenario de clasificación binaria, esta restricción intenta garantizar que cada grupo contenga una 
proporción comparable de predicciones positivas verdaderas y positivas falsas. 

![19.png](ims%2FC13%2Fims%2F2%2F19.png)

Utilice la restricción de paridad de la tasa de error con cualquiera de los algoritmos de mitigación basados en la reducción 
gradiente exponenciado y búsqueda en cuadrícula para garantizar que el error de cada grupo de características sensibles no 
se desvíe de la tasa de error global en más de una cantidad especificada. 

![20.png](ims%2FC13%2Fims%2F2%2F20.png)

Por último, utilice la restricción de pérdida de grupo limitada con cualquiera de los algoritmos de mitigación basados en 
la reducción para restringir la pérdida para cada grupo de características sensibles en un modelo de regresión. 

![21.png](ims%2FC13%2Fims%2F2%2F21.png)

Un enfoque común para la mitigación es utilizar uno de los algoritmos y restricciones para entrenar múltiples modelos y 
luego comparar su tasa de selección de rendimiento y métricas de disparidad para encontrar el modelo óptimo para sus necesidades. 

A menudo, la elección del modelo implica un compromiso entre el rendimiento predictivo bruto y la equidad basado en su 
definición de equidad para un escenario dado. 

![22.png](ims%2FC13%2Fims%2F2%2F22.png)

Generalmente, la equidad se mide por una reducción en la disparidad de la selección de características Por ejemplo, 
garantizar que una proporción igual de miembros de cada grupo de género sea aprobada para un préstamo bancario

![23.png](ims%2FC13%2Fims%2F2%2F23.png)

o por una reducción en la disparidad de la métrica de rendimiento. Por ejemplo, garantizando que un modelo sea igual de 
preciso, identificando reparaciones y morosos en cada grupo de edad. 

![24.png](ims%2FC13%2Fims%2F2%2F24.png)

Fairlearn le permite entrenar modelos mitigados y visualizarlos utilizando el panel de control. Puede seleccionar un modelo 
individual en el gráfico de dispersión para ver sus detalles, lo que le permite explorar las opciones y seleccionar el mejor 
modelo para sus requisitos de equidad. 

![25.png](ims%2FC13%2Fims%2F2%2F25.png)

Al igual que cuando analiza un modelo individual, puede registrar todos los modelos encontrados durante sus pruebas de 
mitigación y cargar las métricas del cuadro de mando en Azure machine learning.

## 13 Exercise Use Fairlearn with Azure Machine Learning
[< Back to Local Index](#13-index)

Puede acceder al ejercicio desde el siguiente enlace


**Enlace del ejercicio**

[Ejercicio - Utilizar Fairlearn con Azure Machine Learning](https://docs.microsoft.com/en-us/learn/modules/detect-mitigate-unfairness-models-with-azure-machine-learning/5-exercise-use-fairlearn)

> Nota:
> El notebook de esta sección está en: [15 - Detect Unfairness.ipynb](ims%2FC13%2Fnotebooks%2F15%20-%20Detect%20Unfairness.ipynb)

![s1.gif](ims%2FC13%2Fgifs%2Fs1.gif)

![s2.gif](ims%2FC13%2Fgifs%2Fs2.gif)

![s3.gif](ims%2FC13%2Fgifs%2Fs3.gif)

![s4.gif](ims%2FC13%2Fgifs%2Fs4.gif)

![s5.gif](ims%2FC13%2Fgifs%2Fs5.gif)

![s6.gif](ims%2FC13%2Fgifs%2Fs6.gif)

![s7.gif](ims%2FC13%2Fgifs%2Fs7.gif)

![s8.gif](ims%2FC13%2Fgifs%2Fs8.gif)

![s9.gif](ims%2FC13%2Fgifs%2Fs9.gif)

![s10.png](ims%2FC13%2Fgifs%2Fs10.png)

## 13 Exercise quiz
[< Back to Local Index](#13-index)

![0.png](ims%2FC13%2Ftests%2F0.png)

## 13 Knowledge Check
[< Back to Local Index](#13-index)

![1.png](ims%2FC13%2Ftests%2F1.png)

![2.png](ims%2FC13%2Ftests%2F2.png)

![3.png](ims%2FC13%2Ftests%2F3.png)

## 13 Lesson summary
[< Back to Local Index](#13-index)

![4.png](ims%2FC13%2Ftests%2F4.png)

En esta lección, aprendió a construir y operar soluciones de Aprendizaje Automático con Azure Machine Learning. Aprendió 
a evaluar modelos de Aprendizaje Automático para imparcialidad y mitigar la disparidad predictiva en un modelo de 
Aprendizaje Automático.

![5.png](ims%2FC13%2Ftests%2F5.png)

Para aprender más sobre fairlearn, consulte la documentación de fairlearn en GitHub. Puede encontrar un enlace a estos 
recursos desde las lecturas adicionales al final de esta lección.

## 13 Additional Reading
[< Back to Local Index](#13-index)

Learn more about Fairlearn:

[Fairlearn documentation on GitHub](https://github.com/fairlearn/fairlearn)

# 14 Monitor Models with Azure Machine Learning

## 14 INDEX

- [14 Lesson introduction](#14-lesson-introduction)
- [14 Enable Application Insights](#14-enable-application-insights)
- [14 Capture and view telemetry](#14-capture-and-view-telemetry)
- [14 Exercise Monitor a model](#14-exercise-monitor-a-model)
- [14 Exercise quiz](#14-exercise-quiz)
- [14 Knowledge Check](#14-knowledge-check)
- [14 Lesson summary](#14-lesson-summary)
- [14 Additional Reading](#14-additional-reading)

[< Back to index](#0-index)

## 14 Lesson introduction
[< Back to Local Index](#14-index)

![1.png](ims%2FC14%2Fims%2F1%2F1.png)

Hola. En esta lección, aprenderá a supervisar modelos con Azure Machine Learning. Application Insights es un servicio de 
gestión del rendimiento de aplicaciones en Microsoft Azure. 

![2.png](ims%2FC14%2Fims%2F1%2F2.png)

Permite la captura, el almacenamiento, y el análisis de datos de telemetría de aplicaciones. Puede utilizar Application 
Insights para supervisar la telemetría de muchos tipos de aplicaciones, incluidas las aplicaciones que no se ejecutan en 
Azure. 

![3.png](ims%2FC14%2Fims%2F1%2F3.png)

Todo lo que se necesita es un paquete de instrumentación de baja sobrecarga para capturar y enviar los datos de telemetría a 
Application Insights. El paquete necesario ya está incluido en los servicios web de Azure Machine Learning, por lo que puede 
utilizarlo para capturar y revisar la telemetría de los modelos publicados con Azure Machine Learning.

![4.png](ims%2FC14%2Fims%2F1%2F4.png)

En esta lección, aprenderá cómo habilitar la monitorización de Application Insights para un servicio web de Azure Machine 
Learning y capturar y ver la telemetría de los modelos.

## 14 Enable Application Insights
[< Back to Local Index](#14-index)

![5.png](ims%2FC14%2Fims%2F1%2F5.png)

En esta sección, aprenderá cómo habilitar Application Insights. Para registrar telemetría y Application Insights desde un 
servicio Azure Machine Learning, debe tener un recurso Application Insights asociado a su Azure Machine Learning Workspace, 
y debe configurar su servicio para utilizarlo para el registro de telemetría.

![6.png](ims%2FC14%2Fims%2F1%2F6.png)

Cuando crea un Azure Machine Learning Workspace, puede seleccionar un recurso Azure Application Insights para asociarlo a 
él. Si no selecciona un recurso Application Insights existente, se crea uno nuevo en el mismo grupo de recursos que su 
espacio de trabajo. 

![7.png](ims%2FC14%2Fims%2F1%2F7.png)

Puede determinar el recurso de Application Insights asociado a su espacio de trabajo consultando la página Descripción 
general de la hoja del espacio de trabajo en el portal Azure

![8.png](ims%2FC14%2Fims%2F1%2F8.png)

O puede utilizar el método de `get_details()` de un objeto de espacio de trabajo. 

![9.png](ims%2FC14%2Fims%2F1%2F9.png)

Veamos ahora cómo habilitar Application Insights para un servicio. Al desplegar un nuevo servicio en tiempo real, 
puede habilitar Application Insights en la configuración de despliegue para el servicio.

![10.png](ims%2FC14%2Fims%2F1%2F10.png)

Si desea habilitar Application Insights para un servicio que ya está desplegado, puede modificar la configuración de 
despliegue para Azure Kubernetes Service o AKS, servicios basados en el portal Azure.

![11.png](ims%2FC14%2Fims%2F1%2F11.png)

Alternativamente, puede actualizar cualquier servicio web utilizando el Azure Machine Learning, SDK.

## 14 Capture and view telemetry
[< Back to Local Index](#14-index)

Application Insights captura automáticamente cualquier información escrita en la salida estándar y en los registros de errores, 
y proporciona una capacidad de consulta para ver los datos de estos registros.

### Escribir datos de registro

Para capturar datos de telemetría para Application insights, puede escribir cualquier valor en el registro de salida estándar 
en el script de puntuación para su servicio utilizando una sentencia print, como se muestra en el siguiente ejemplo:

```python
def init():
    global model
    model = joblib.load(Model.get_model_path('my_model'))
def run(raw_data):
    data = json.loads(raw_data)['data']
    predictions = model.predict(data)
    log_txt = 'Data:' + str(data) + ' - Predictions:' + str(predictions)
    print(log_txt)
    return predictions.tolist()
```

_Azure Machine Learning crea unadimensión personalizada en el modelo de datos de Application Insights para la salida que usted escriba._

### Consultar registros en Application Insights

Para analizar los datos de registro capturados, puede utilizar la interfaz de consulta **Log Analytics** para Application 
Insights en el portal Azure. Esta interfaz admite una sintaxis de consulta similar a SQL que puede utilizar para extraer 
campos de los datos registrados, incluidas las dimensiones personalizadas creadas por su servicio Azure Machine Learning.

Por ejemplo, la siguiente consulta devuelve los campos **timestamp** y **customDimensions**. Content de las trazas de 
registro que tienen un valor de campo **message** de **STDOUT** (que indica que los datos están en el registro de salida 
estándar) y un valor de campo **customDimensions**.["Service Name"] demy-svc.

```
traces
|where message == "STDOUT"
  and customDimensions.["Service Name"] = "my-svc"
| project  timestamp, customDimensions.Content
```

Esta consulta devuelve los datos registrados en forma de tabla:

| **timestamp** |                   **customDimension_Content**                   |
|:-------------:|:---------------------------------------------------------------:|
|   01/02/2020  | Datos:[[1, 2, 2,5, 3,1], [0, 1, 1,7, 2,1]] - Predicciones:[0 1] |
|   01/02/2020  |           Datos:[[3, 2, 1,7, 2,0]] - Predicciones:[0]           |


## 14 Exercise Monitor a model
[< Back to Local Index](#14-index)

> Nota: 
> el notebook de esta clase está en: [16 - Monitor a Model.ipynb](ims%2FC14%2Fnotebooks%2F16%20-%20Monitor%20a%20Model.ipynb)

No pude correr éxitosamente el notebook, pero adjunto los pasos que pude cumplir:

![s1.gif](ims%2FC14%2Fgifs%2Fs1.gif)

![s2.gif](ims%2FC14%2Fgifs%2Fs2.gif)

![s3.gif](ims%2FC14%2Fgifs%2Fs3.gif)

![s4.gif](ims%2FC14%2Fgifs%2Fs4.gif)

![s5.gif](ims%2FC14%2Fgifs%2Fs5.gif)

![s6.gif](ims%2FC14%2Fgifs%2Fs6.gif)


## 14 Exercise quiz
[< Back to Local Index](#14-index)

![0.png](ims%2FC14%2Ftests%2F0.png)

## 14 Knowledge Check
[< Back to Local Index](#14-index)

![q1.png](ims%2FC14%2Ftests%2Fq1.png)

![q2.png](ims%2FC14%2Ftests%2Fq2.png)

![q3.png](ims%2FC14%2Ftests%2Fq3.png)

## 14 Lesson summary
[< Back to Local Index](#14-index)

![1.png](ims%2FC14%2Ftests%2F1.png)

En este módulo, ha aprendido a supervisar modelos con Azure Machine Learning. Más concretamente, ha aprendido a 

- Habilitar la supervisión de Application Insights para un servicio web de Azure Machine Learning
- Capturar y ver telemetría de modelos. 

Para obtener más información sobre la supervisión de modelos con Azure Machine Learning, consulte supervisar y recopilar 
datos de puntos finales del servicio web ML en la documentación de Azure Machine Learning. 

![2.png](ims%2FC14%2Ftests%2F2.png)

Puede encontrar un enlace a estos recursos desde las lecturas adicionales al final de esta lección.
[Monitor and collect data from ML web service endpoints](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-enable-app-insights)


## 14 Additional Reading
[< Back to Local Index](#14-index)

**Monitor and collect data**
[Monitor and collect data from ML web service endpoints](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-enable-app-insights)

# 15 Monitor data drift with Azure Machine Learning

## 15 INDEX

- [15 Lesson introduction](#15-lesson-introduction)
- [15 Create a data drift monitor](#15-create-a-data-drift-monitor)
- [15 Scheduling alerts](#15-scheduling-alerts)
- [15 Exercise Monitor data drift](#15-exercise-monitor-data-drift)
- [15 Exercise quiz](#15-exercise-quiz)
- [15 Knowledge Check](#15-knowledge-check)
- [15 Test prep](#15-test-prep)
- [15 Lesson summary](#15-lesson-summary)
- [15 Additional Reading](#15-additional-reading)

[< Back to index](#0-index)

## 15 Lesson introduction
[< Back to Local Index](#15-index)

![1.png](ims%2FC15%2Fims%2F1%2F1.png)

Hola, en esta lección, aprenderás a monitorear la deriva de datos. Con el aprendizaje automático de Azure, normalmente se 
entrena un aprendizaje automático modele utilizando un conjunto de datos históricos que sea representativo de los datos 
nuevos que su modelo recibirá para inferir.

Sin embargo, con el tiempo puede haber tendencias que cambian el perfil de los datos y hacen que el modelo sea menos preciso.

![2.png](ims%2FC15%2Fims%2F1%2F2.png)

Por ejemplo, supongamos que un modelo está entrenado para predecir el consumo de combustible esperado de un automóvil en 
función del número de cilindros, tamaño del motor, peso y otras características. Con el tiempo, como fabricación de 
automóviles y motores las tecnologías mejoran la eficiencia de combustible típica de los vehículos podría mejorar 
drásticamente, siguiendo las predicciones del modelo entrenados con datos más antiguos son menos precisos. 

![3.png](ims%2FC15%2Fims%2F1%2F3.png)

Este cambio en los perfiles de datos entre entrenar e influir se conoce como deriva de datos y puede ser un problema 
importante para los modelos predictivos utilizados en la producción. Por lo tanto, es importante poder para monitorear 
la variación de los datos a lo largo del tiempo y volver a entrenar los modelos según sea necesario para mantener la 
precisión predictiva. 

![4.png](ims%2FC15%2Fims%2F1%2F4.png)

En esta lección, aprenderá cómo 
 
- crear un monitor de desviación de datos
- monitoreo programado de la desviación de datos 
- ver los resultados del monitoreo de la desviación de datos.

## 15 Create a data drift monitor
[< Back to Local Index](#15-index)

![5.png](ims%2FC15%2Fims%2F1%2F5.png)

Azure Machine Learning admite la supervisión de la deriva de datos mediante el uso de conjuntos de datos. Puede capturar 
nuevos datos de características en un conjunto de datos y compararlos con el conjunto de datos con el que se entrenó el 
modelo. Es habitual que las organizaciones sigan recopilando nuevos datos después de haber entrenado un modelo. 

![6.png](ims%2FC15%2Fims%2F1%2F6.png) 

Por ejemplo, una clínica de salud podría utilizar mediciones diagnósticas de pacientes anteriores para entrenar un modelo 
que predice la probabilidad de diabetes, pero seguir recogiendo las mismas mediciones diagnósticas de todos los pacientes 
nuevos. 

![7.png](ims%2FC15%2Fims%2F1%2F7.png)

Los científicos de datos de la clínica podrían entonces comparar periódicamente la creciente colección de datos nuevos con 
los datos de entrenamiento originales, e identificar cualquier cambio en las tendencias de los datos que pudiera afectar a 
la precisión del modelo. Para controlar la deriva de los datos utilizando conjuntos de datos registrados, es necesario 
registrar dos conjuntos de datos:

![8.png](ims%2FC15%2Fims%2F1%2F8.png)

Un conjunto de datos de referencia, que suelen ser los datos de entrenamiento originales, y un conjunto de datos objetivo 
que se comparará con el de referencia en función de intervalos de tiempo. 

![9.png](ims%2FC15%2Fims%2F1%2F9.png)

Este conjunto de datos requiere una columna para cada característica que desee comparar y una columna de marca de tiempo, 
para poder medir la velocidad de deriva de los datos. 

Es importante tener en cuenta que puede configurar un servicio desplegado para recopilar nuevos datos enviados al modelo 
para la inferencia, que se guardan en Azure Blob Storage, y pueden utilizarse como conjunto de datos de destino para 
la supervisión de la deriva de datos.

![10.png](ims%2FC15%2Fims%2F1%2F10.png)

Consulte recopilar datos de modelos en producción en la documentación de Azure Machine Learning para obtener más información. 
Puede encontrar un enlace a este recurso en las lecturas adicionales al final de esta lección. 

![11.png](ims%2FC15%2Fims%2F1%2F11.png)

Después de crear estos conjuntos de datos, puede definir un monitor de conjunto de datos para detectar la deriva de datos y 
activar alertas si la tasa de deriva supera un umbral especificado. 

![12.png](ims%2FC15%2Fims%2F1%2F12.png)

Puede crear monitores de conjuntos de datos utilizando la interfaz visual de Azure Machine Learning Studio, o utilizando 
la clase del detector de desviación de datos en el SDK de Azure Machine Learning.


![13.png](ims%2FC15%2Fims%2F1%2F13.png)

Tras crear el monitor de conjuntos de datos, puede rellenar el monitor para comparar inmediatamente el conjunto de datos 
de referencia con los datos existentes en el conjunto de datos de destino, que rellena el monitor basándose en los cambios 
semanales en los datos de las seis semanas anteriores.

## 15 Scheduling alerts
[< Back to Local Index](#15-index)

![14.png](ims%2FC15%2Fims%2F1%2F14.png)

Cuando define un monitor de datos, especifica un horario en el que debe ejecutarse. Además, puede especificar un umbral 
para la tasa de deriva de datos y una dirección de correo electrónico del operador para recibir notificaciones si se 
supera este umbral. 

![15.png](ims%2FC15%2Fims%2F1%2F15.png)

La deriva de datos y la monitorización funcionan ejecutando una comparación con la frecuencia programada y calculando las 
métricas de deriva de datos para las características del conjunto de datos que desea monitorizar. Puede definir un horario 
para que se ejecute cada día, semana o mes. 

![16.png](ims%2FC15%2Fims%2F1%2F16.png)

La deriva de datos se mide utilizando una magnitud calculada de cambio en la distribución estadística de los valores de 
las características a lo largo del tiempo. Puede esperar cierta variación aleatoria natural entre los conjuntos de datos 
de referencia y de destino, pero debe vigilar los grandes cambios que podrían indicar una deriva de datos significativa. 

![17.png](ims%2FC15%2Fims%2F1%2F17.png)

Puede definir un umbral para la magnitud de la deriva de datos por encima del cual desea que se notifique a y configurar 
las notificaciones de alerta por correo electrónico. 

![18.png](ims%2FC15%2Fims%2F1%2F18.png)

Por ejemplo, utilizando código Python, puede programar un monitor de deriva de datos para que se ejecute cada semana y 
envíe una alerta si la magnitud de la deriva es superior a 0,3.

## 15 Exercise Monitor data drift
[< Back to Local Index](#15-index)

> Nota:
> El notebook de esta clase está en: [17 - Monitor Data Drift.ipynb](ims%2FC15%2Fnotebooks%2F17%20-%20Monitor%20Data%20Drift.ipynb)

1. Primero instalamos `azureml-datadrift` y nos conectamos a nuestro `ws`:
   ![s1.gif](ims%2FC15%2Fgifs%2Fs1.gif)

2. Ahora creamos nuestro `baseline` de `dataset`(este en principio es con el que entrenamos nuestro modelo)

   ![s2.gif](ims%2FC15%2Fgifs%2Fs2.gif)

3. Vamos a crear una variación sintética de nuestro dataset para simular unos datos `nuevos`. Este dataset tendrá como nombre la fecha
   en la que se tomaron los datos nuevos.

   ![s3.gif](ims%2FC15%2Fgifs%2Fs3.gif)

4. El siguiente paso es crear el COMPUTE target, pero como ya teníamos una hecha la vamos a utilizar:

   ![s4.gif](ims%2FC15%2Fgifs%2Fs4.gif)

5. Ahora viene la parte más tardada, que es comparar los resultados entre el dataset de baseline - el dataset nuevo, con una diferencia de 6 semanas.

   ![s5.gif](ims%2FC15%2Fgifs%2Fs5.gif)

   Los resultados son:

   ![s6.gif](ims%2FC15%2Fgifs%2Fs6.gif)


## 15 Exercise quiz
[< Back to Local Index](#15-index)

![0.png](ims%2FC15%2Ftests%2F0.png)

## 15 Knowledge Check
[< Back to Local Index](#15-index)

![q1.png](ims%2FC15%2Ftests%2Fq1.png)

![q2.png](ims%2FC15%2Ftests%2Fq2.png)

![q3.png](ims%2FC15%2Ftests%2Fq3.png)

## 15 Test prep
[< Back to Local Index](#15-index)

![t1.png](ims%2FC15%2Ftests%2Ft1.png)

![t2.png](ims%2FC15%2Ftests%2Ft2.png)

![t3.png](ims%2FC15%2Ftests%2Ft3.png)

![t4.png](ims%2FC15%2Ftests%2Ft4.png)

![t5.png](ims%2FC15%2Ftests%2Ft5.png)

![t6.png](ims%2FC15%2Ftests%2Ft6.png)

## 15 Lesson summary
[< Back to Local Index](#15-index)

![1.png](ims%2FC15%2Ftests%2F1.png)

En esta lección, ha aprendido a supervisar el desvío de datos con el aprendizaje automático de Azure. Más concretamente, 
ha aprendido a 

- crear un monitor de desvío de datos
- programar la supervisión del desvío de datos 
- ver los resultados de la supervisión del desvío de datos. 


![2.png](ims%2FC15%2Ftests%2F2.png)

Para obtener más información sobre la supervisión de la deriva de datos en el aprendizaje automático de Azure, consulte detectar la deriva de datos en conjuntos de datos y detectar la deriva de datos en modelos desplegados en el servicio Azure Kubernetes o AKS.

En la documentación del aprendizaje automático de Azure, puede encontrar un enlace a estos recursos desde las lecturas adicionales al final de esta lección.

## 15 Additional Reading
[< Back to Local Index](#15-index)

**Monitoring data drift in Azure machine Learning**

[Collect data from models in production](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-enable-data-collection)

[Detect data drift (preview) on datasets](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-monitor-datasets?tabs=python)
