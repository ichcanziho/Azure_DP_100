# Build and Operate Machine Learning Solutions with Azure

## 0 INDEX:

- [1 Welcome to the Course](#1-welcome-to-the-course)
- [2 Introduction to the Azure Machine Learning SDK](#2-introduction-to-the-azure-machine-learning-sdk)
- [3 Train a machine learning model with Azure Machine Learning](#3-train-a-machine-learning-model-with-azure-machine-learning)
- [4 Work with Data in Azure Machine Learning](#4-work-with-data-in-azure-machine-learning)
- [5 Work with Compute in Azure Machine Learning](#5-work-with-compute-in-azure-machine-learning)
- [6 Orchestrate Machine Learning with Pipelines](#6-orchestrate-machine-learning-with-pipelines)
- [7 Deploy real-time machine learning services with Azure Machine Learning](#7-deploy-real-time-machine-learning-services-with-azure-machine-learning)
- [8 Deploy batch inference pipelines with Azure Machine Learning](#8-deploy-batch-inference-pipelines-with-azure-machine-learning)
- [9 Tune hyperparameters with Azure Machine Learning](#9-tune-hyperparameters-with-azure-machine-learning)
- [10 Automate machine learning model selection with Azure Machine Learning](#10-automate-machine-learning-model-selection-with-azure-machine-learning)
- [11 Explore differential privacy](#11-explore-differential-privacy)
- [12 Explain machine learning models with Azure Machine Learning](#12-explain-machine-learning-models-with-azure-machine-learning)
- [13 Detect and mitigate unfairness in models with Azure Machine Learning](#13-detect-and-mitigate-unfairness-in-models-with-azure-machine-learning)
- [14 Monitor Models with Azure Machine Learning](#14-monitor-models-with-azure-machine-learning)
- [15 Monitor data drift with Azure Machine Learning](#15-monitor-data-drift-with-azure-machine-learning)

# 1 Welcome to the Course

## 1 INDEX:

- [Introduction to Modern Data Warehouse Analytics in Azure](#introduction-to-modern-data-warehouse-analytics-in-azure)
- [Course Syllabus](#course-syllabus)
- [How to be successful in this course](#how-to-be-successful-in-this-course)

[< Back to index](#0-index)

## Introduction to Modern Data Warehouse Analytics in Azure
[< Back to Local Index](#1-index)

![1.png](ims%2FC1%2F1.png)

Hola y bienvenido a este curso, construir y operar soluciones de aprendizaje automático con Azure Machine Learning. En este curso, 
aprenderá a utilizar el Python Azure Machine Learning, SDK, para crear y gestionar soluciones ML listas para la empresa. 

![2.png](ims%2FC1%2F2.png)

Este curso se compone de los siguientes módulos. 

- Utilice el SDK de Azure Machine Learning para entrenar un modelo.
- Trabaje con datos y computación en Azure Machine Learning.
- Orqueste pipelines y despliegue servicios de aprendizaje automático en tiempo real con Azure Machine Learning.
- Despliegue pipelines de inferencia por lotes y ajuste hiperparámetros con Azure Machine Learning. 
- Seleccione modelos y proteja datos sensibles.
- Monitorice despliegues de aprendizaje automático. 

![3.png](ims%2FC1%2F3.png)

Comencemos con el primer módulo. Utilice el SDK de Azure Machine Learning para entrenar un modelo.

![4.png](ims%2FC1%2F4.png)

En este curso, aprovisionará un espacio de trabajo de Azure Machine Learning, utilizará herramientas e interfaces para 
trabajar con Azure Machine Learning, ejecutará experimentos basados en código en espacio de trabajo de Azure Machine Learning. 
Utilice una configuración de ejecución de secuencias de comandos para ejecutar una secuencia de comandos de entrenamiento 
de modelos como Azure Machine Learning, crear secuencias de comandos de entrenamiento parametrizadas reutilizables, y 
registrar modelos entrenados.

![5.png](ims%2FC1%2F5.png)

En el siguiente módulo, explorará cómo entrenar y evaluar modelos de clasificación y agrupación.

![6.png](ims%2FC1%2F6.png)

Los datos son la base del aprendizaje automático. En este módulo, aprenderá a trabajar con almacenes de datos en conjuntos 
de datos en Azure Machine Learning, lo que le permitirá construir soluciones escalables de entrenamiento de modelos basadas 
en la nube. También aprenderá a utilizar Cloud Compute en Azure Machine Learning para ejecutar experimentos de entrenamiento 
a escala. 

![7.png](ims%2FC1%2F7.png)

A continuación, aprenderá a orquestar pipelines y desplegar servicios de aprendizaje automático en tiempo real 
con Azure Machine Learning.

![8.png](ims%2FC1%2F8.png)

En este módulo, aprenderá a crear, publicar, y ejecutar pipelines para entrenar modelos en Azure Machine Learning. 

![9.png](ims%2FC1%2F9.png)

También aprenderá a registrar y desplegar modelos ML con el servicio Azure Machine Learning.


![10.png](ims%2FC1%2F10.png)

A continuación, aprenderá a desplegar pipelines de inferencia por lotes y ajustar hiperparámetros con Azure Machine Learning. 


![11.png](ims%2FC1%2F11.png)

Los modelos de aprendizaje automático se utilizan a menudo para generar predicciones a partir de un gran número de observaciones 
en un proceso por lotes. En este módulo, logrará esto utilizando Azure Machine Learning para publicar un pipeline de inferencia por 
lotes. También aprovechará los experimentos a escala de la nube para elegir los valores óptimos de los hiperparámetros 
para el entrenamiento del modelo

![12.png](ims%2FC1%2F12.png)

A continuación, aprenderá a seleccionar modelos y proteger datos sensibles. 

![13.png](ims%2FC1%2F13.png)

En este módulo, aprenderá a utilizar el aprendizaje automático automatizado en Azure Machine Learning para encontrar el 
mejor modelo para sus datos. Aprenderá cómo la privacidad diferencial es un enfoque de vanguardia que permite un análisis 
útil a la vez que protege los valores de los datos identificables individualmente. También conocerá los factores que influyen 
en las predicciones que hacen los modelos. 

![14.png](ims%2FC1%2F14.png)

Por último, aprenderá a supervisar las implantaciones de aprendizaje automático. Los modelos de aprendizaje automático a 
menudo pueden encapsular sesgos involuntarios que resultan injustos. 

![15.png](ims%2FC1%2F15.png)

En este módulo, aprenderá a utilizar Fairlearn en Azure Machine Learning para detectar y mitigar la injusticia en sus modelos. 
Aprenderá a utilizar la telemetría para comprender cómo se está utilizando un modelo de aprendizaje automático una vez que 
se ha desplegado en producción. Por último, aprenderá a supervisar la deriva de los datos para asegurarse de que su modelo 
sigue prediciendo con precisión.

![16.png](ims%2FC1%2F16.png)

Además, a lo largo de este curso, tendrá la oportunidad de explorar los modelos de aprendizaje automático en Microsoft Azure 
a través de ejercicios interactivos y ejemplos reales de ciencia de datos en acción, comprobaciones de conocimientos y 
exámenes de práctica. Le deseamos mucho éxito al iniciar este viaje de aprendizaje.

## Course Syllabus
[< Back to Local Index](#1-index)

Azure Machine Learning es una plataforma en la nube para entrenar, desplegar, gestionar y monitorizar modelos de aprendizaje 
automático. En este módulo, aprenderá a utilizar el SDK Python de Azure Machine Learning para crear y gestionar soluciones ML 
listas para la empresa.

### Módulo 1 - Utilizar el SDK de Azure Machine Learning para entrenar un modelo
Azure Machine Learning proporciona una plataforma basada en la nube para entrenar, desplegar y gestionar modelos de aprendizaje 
automático. En este módulo, aprenderá a aprovisionar un espacio de trabajo de Azure Machine Learning. Utilizará herramientas 
e interfaces para trabajar con Azure Machine Learning y ejecutar experimentos basados en código en un espacio de trabajo de 
Azure Machine Learning. Por último, aprenderá a utilizar Azure Machine Learning para entrenar un modelo y registrarlo en 
un espacio de trabajo.

### Módulo 2 - Trabajar con datos y computación en Azure Machine Learning
Los datos son la base del aprendizaje automático. En este módulo, aprenderá a trabajar con almacenes de datos y conjuntos 
de datos en Azure Machine Learning, lo que le permitirá construir soluciones de entrenamiento de modelos escalables y 
basadas en la nube. También aprenderá a utilizar la computación en la nube en Azure Machine Learning para ejecutar experimentos 
de entrenamiento a escala.

### Módulo 3 - Orquestrar pipelines y desplegar servicios de aprendizaje automático en tiempo real con Azure Machine Learning
Orquestar el entrenamiento de aprendizaje automático con pipelines es un elemento clave de DevOps para el aprendizaje automático. 
En este módulo, aprenderá a crear, publicar y ejecutar canalizaciones para entrenar modelos en Azure Machine Learning. 
También aprenderá a registrar y desplegar modelos ML con el servicio Azure Machine Learning.

### Módulo 4 - Despliegue pipelines de inferencia por lotes y ajuste hiperparámetros con Azure Machine Learning
Los modelos de aprendizaje automático se utilizan a menudo para generar predicciones a partir de un gran número de observaciones 
en un proceso por lotes. Logrará esto utilizando Azure Machine Learning para publicar una canalización de inferencia por lotes. 
También aprovechará los experimentos a escala de la nube para elegir los valores óptimos de hiperparámetros para el entrenamiento de modelos.

### Módulo 5 - Seleccionar modelos y proteger datos sensibles
En este módulo, aprenderá a utilizar el aprendizaje automático en Azure Machine Learning para encontrar el mejor modelo 
para sus datos. Aprenderá cómo la privacidad diferencial es un enfoque de vanguardia que permite realizar análisis útiles 
a la vez que protege los valores de datos identificables individualmente. También conocerá los factores que influyen en las 
predicciones que realizan los modelos.

### Módulo 6 - Supervisar los despliegues de aprendizaje automático
Los modelos de aprendizaje automático a menudo pueden encapsular sesgos involuntarios que dan lugar a injusticias. En este módulo, 
aprenderá a utilizar Fairlearn y Azure Machine Learning para detectar y mitigar la injusticia en sus modelos. Aprenderá a 
utilizar la telemetría para comprender cómo se está utilizando un modelo de aprendizaje automático una vez desplegado en producción. 
Por último, aprenderá a supervisar la deriva de los datos para asegurarse de que su modelo sigue prediciendo con precisión.

## How to be successful in this course
[< Back to Local Index](#1-index)

Hacer un curso en línea puede resultar abrumador. ¿Cómo puede aprender a su propio ritmo y alcanzar con éxito sus objetivos?

He aquí algunos consejos generales que pueden ayudarle a mantenerse centrado y en el buen camino:

#### 1: Fíjese objetivos diarios de estudio
Pregúntese qué espera conseguir en su curso cada día. Establecer un objetivo claro puede ayudarle a mantenerse motivado y 
a vencer la procrastinación. El objetivo debe ser específico y fácil de medir, como "Veré todos los vídeos del módulo 2 
y completaré la primera tarea de programación" Y no olvide recompensarse cuando avance hacia su objetivo.

### 2: Cree un espacio dedicado al estudio
Es más fácil recordar la información si se está en el mismo lugar donde se aprendió por primera vez, por lo que tener un 
espacio dedicado en casa para tomar cursos en línea puede hacer que su aprendizaje sea más eficaz. Elimine cualquier 
distracción del espacio y, si es posible, sepárelo de su cama o sofá. Una clara distinción entre el lugar donde estudia 
y el lugar donde se toma los descansos puede ayudarle a concentrarse.

### 3: Programe tiempo para estudiar en su calendario
Abra su calendario y elija un horario predecible y fiable que pueda dedicar a ver las clases y completar las tareas. 
Esto le ayudará a asegurarse de que sus cursos no se conviertan en la última cosa de su lista de tareas.

> Consejo: Puede añadir las fechas límite de un curso de Coursera su calendario de Google, al calendario de Apple o a otra aplicación de calendario.

### 4: Hágase responsable
Cuénteles a sus amigos los cursos que está realizando, publique sus logros en sus cuentas de las redes sociales o publique 
en un blog sus tareas. Contar con una comunidad y una red de apoyo de amigos y familiares que le animen marca la diferencia.

### 5: Tome notas activamente
Tomar apuntes puede fomentar el pensamiento activo, impulsar la comprensión y ampliar su capacidad de atención. Es una 
buena estrategia para interiorizar los conocimientos tanto si aprende en línea como en el aula. Así pues, coja un cuaderno 
o encuentre la aplicación digital que mejor se adapte a usted y empiece a sintetizar los puntos clave.

> Consejo: Mientras ve una clase en Coursera, puede hacer clic en el botón "Guardar nota" situado debajo del vídeo para guardar una captura de pantalla en sus notas del curso y añadir sus propios comentarios.

### 6: Únase a la discusión
Los foros de discusión del curso son un lugar estupendo para hacer preguntas sobre las tareas, discutir temas, compartir 
recursos y hacer amigos. Nuestras investigaciones demuestran que los alumnos que participan en los foros de debate tienen 
un 37% más de probabilidades de completar un curso. Así que ¡haga un post hoy mismo!

### 7: Haga una cosa cada vez
La multitarea es menos productiva que centrarse en una sola tarea a la vez. Investigadores de la Universidad de Stanford 
descubrieron que "las personas que son bombardeadas regularmente con varios flujos de información electrónica no pueden 
prestar atención, recordar información o cambiar de un trabajo a otro tan bien como los que completan una tarea a la vez" 
Concéntrese en una cosa cada vez. Absorberá más información y completará las tareas con mayor productividad y facilidad 
que si intentara hacer muchas cosas a la vez.

### 8: Tómese descansos
Descansar el cerebro después de aprender es fundamental para un alto rendimiento. Si se encuentra trabajando en un problema 
difícil sin avanzar mucho durante una hora, tómese un descanso. Caminar al aire libre, darse una ducha o hablar con un amigo 
puede re-energizarle e incluso darle nuevas ideas sobre cómo abordar ese proyecto.

¡Su viaje de aprendizaje de Microsoft Azure comienza ahora!
Mientras se prepara para el examen o trabaja en la consecución de sus objetivos de aprendizaje, le animamos a:

- Revise las directrices del examen y las habilidades medidas como punto de partida.
- Trabaje a través de cada lección del itinerario de aprendizaje. 
- Intente no saltarse ninguna actividad o lección a menos que esté seguro de que ya conoce esta información lo suficientemente bien como para seguir adelante.
- Aproveche la oportunidad para volver atrás y ver un vídeo o leer la información adicional que se le proporcione antes de pasar a la siguiente lección o módulo.
- Complete todos los cuestionarios, las preguntas de práctica del examen y los ejercicios. Durante las sesiones de práctica, tendrá la oportunidad de volver a repasar las preguntas para asegurarse de que está satisfecho con su progreso.
- Lea atentamente los comentarios cuando responda a los cuestionarios o a los exámenes prácticos, ya que le ayudarán a reforzar lo que está aprendiendo.

Aproveche el entorno de aprendizaje práctico que le proporcionan los ejercicios. Podrá obtener un refuerzo sustancial de su aprendizaje mediante la aplicación paso a paso de sus conocimientos.

# 2 Introduction to the Azure Machine Learning SDK

## 2 INDEX:

- [2 Lesson Introduction](#2-lesson-introduction)
- [2 Azure Machine Learning Workspaces](#2-azure-machine-learning-workspaces)
- [2 Exercise - Create a Workspace](#2-exercise---create-a-workspace)
- [2 Exercise Quiz 1](#2-exercise-quiz-1)
- [2 Azure Machine Learning tools and interfaces](#2-azure-machine-learning-tools-and-interfaces)
- [2 Azure Machine Learning experiments](#2-azure-machine-learning-experiments)
- [2 Exercise - Run experiments](#2-exercise---run-experiments)
- [2 Exercise Quiz 2](#2-exercise-quiz-2)
- [2 Knowledge Check](#2-knowledge-check)
- [2 Lesson summary](#2-lesson-summary)
- [2 Additional Reading](#2-additional-reading)

[< Back to index](#0-index)

## 2 Lesson Introduction
[< Back to Local Index](#2-index)

![1.png](ims%2FC2%2F1.png)

Hola, y bienvenido a esta lección, donde aprenderá sobre el Kit de Desarrollo de Software Azure Machine Learning. 
Azure Machine Learning es una plataforma para operar cargas de trabajo de Machine Learning en la Nube. Construida sobre 
la Plataforma en la Nube Microsoft Azure, Azure Machine Learning le permite gestionar computación escalable bajo demanda 
para cargas de trabajo de aprendizaje automático, almacenamiento de datos, y conectividad para ingerir datos desde una 
amplia gama de fuentes. Orquestación de flujos de trabajo de Machine Learning para automatizar el entrenamiento de modelos, 
despliegue, y procesos de gestión, registro de modelos, y gestión. Así podrá realizar un seguimiento de múltiples versiones 
de modelos sobre los datos en los que fueron entrenados. Métricas y monitorización para experimentos de entrenamiento, 
conjuntos de datos y servicios publicados, y despliegue de modelos para inferencias en tiempo real sobre lotes. 

![2.png](ims%2FC2%2F2.png)

En esta lección, aprenderá a aprovisionar un espacio de trabajo de Azure Machine Learning. Utilizar herramientas, e interfaces 
para trabajar con Azure Machine Learning y ejecutar experimentos basados en código en un espacio de trabajo de Azure Machine Learning.

## 2 Azure Machine Learning Workspaces
[< Back to Local Index](#2-index)

![3.png](ims%2FC2%2F3.png)

Bienvenido a esta sección, donde explorará los espacios de trabajo de Azure Machine Learning. Un espacio de trabajo es un 
contexto para los experimentos, datos, objetivos de cálculo y otros activos asociados con la carga de trabajo de aprendizaje automático. 

![4.png](ims%2FC2%2F4.png)

Un espacio de trabajo define el límite para un conjunto de activos de aprendizaje automático relacionados. Puede utilizar 
espacios de trabajo para agrupar activos de aprendizaje automático basados en proyectos, entornos de despliegue, por ejemplo, 
prueba y producción, equipos, o algún otro principio de organización. 

![5.png](ims%2FC2%2F5.png)

Los activos de un espacio de trabajo incluyen: objetivos de cálculo para el desarrollo, la formación y el despliegue, 
datos para la experimentación y la formación de modelos, cuadernos que contienen código compartido y documentación, 
experimentos, incluido el historial de ejecución con métricas y resultados registrados, canalizaciones que definen procesos 
orquestados de varios pasos y modelos que ha entrenado.

![6.png](ims%2FC2%2F6.png)

Los espacios de trabajo son recursos Azure y, como tales, se definen dentro de un grupo de recursos en una suscripción Azure, 
junto con otros recursos Azure relacionados que son necesarios para dar soporte al espacio de trabajo. 

Los recursos Azure creados junto a un espacio de trabajo incluyen; 

- **Una cuenta de almacenamiento**, que se utiliza para almacenar archivos utilizados por el espacio de trabajo así como datos para 
experimentos y entrenamiento de modelos. 
- **Una instancia de Application Insights**, que se utiliza para supervisar servicios predictivos en el espacio de trabajo. 
- **Una instancia de Azure Key Vault**, que se utiliza para gestionar secretos como claves de autenticación y credenciales utilizadas 
por el espacio de trabajo, y 
- **Un registro de contenedores** que se crea según sea necesario para gestionar contenedores para modelos desplegados.

![7.png](ims%2FC2%2F7.png)

Puede asignar políticas de autorización basadas en roles a un espacio de trabajo que le permitan gestionar permisos que 
restrinjan qué acciones específicas de Azure Active Directory o principales de AAD pueden realizar. 

Por ejemplo, podría crear una política que permita sólo a los usuarios del grupo de operaciones de TI crear, objetivos de 
cálculo y almacenes de datos. 

Mientras que permite a los usuarios del grupo de científicos de datos crear y ejecutar experimentos y registrar modelos. 

![8.png](ims%2FC2%2F8.png)

![9.png](ims%2FC2%2F9.png)

Puede crear un espacio de trabajo de varias maneras. En el portal de Microsoft Azure, cree un nuevo recurso de aprendizaje 
automático especificando el grupo de recursos de suscripción y el nombre del espacio de trabajo. 

![10.png](ims%2FC2%2F10.png)

O puede utilizar el SDK de Python de aprendizaje automático de Azure para ejecutar código que cree un espacio de trabajo. 
Por ejemplo, puede crear un espacio de trabajo denominado aml-workspace, suponiendo que el SDK de Azure Machine Learning 
para Python esté instalado y se haya especificado un ID de suscripción válido. 

![11.png](ims%2FC2%2F11.png)

Utilice la interfaz de línea de comandos de Azure o CLI con la extensión Azure Machine Learning CLI. Por ejemplo, podría 
utilizar un comando aml-workspace, que asume que ya se ha creado un grupo de recursos denominado aml-resources. 

![12.png](ims%2FC2%2F12.png)

Para obtener más información sobre el formato de plantilla para un espacio de trabajo de Azure Machine Learning, 
consulte la documentación de Azure Machine Learning en el sitio web de Microsoft. Puede encontrar un enlace a este documento en 
las [lecturas adicionales](#2-additional-reading) al final de esta lección.



## 2 Exercise - Create a Workspace
[< Back to Local Index](#2-index)

Ahora es su oportunidad de empezar con Azure Machine Learning por sí mismo mediante la creación de un espacio de trabajo.

En este ejercicio, usted:

- Aprovisionar un espacio de trabajo de Azure Machine Learning.

- Crear una instancia de computación.

- Ejecutar un cuaderno.

### Instrucciones
Siga estas instrucciones para completar el ejercicio.

1. Si aún no tiene una suscripción a Azure, regístrese para una prueba gratuita en https://azure.microsoft.com.

2. Consulte el repositorio del ejercicio en https://aka.ms/mslearn-dp100.

3. Complete el ejercicio Crear un espacio de trabajo de Azure Machine Learning.

### Create and Explore an Azure Machine Learning Workspace

Enlace: [https://microsoftlearning.github.io/mslearn-dp100/instructions/01-create-a-workspace.html](https://microsoftlearning.github.io/mslearn-dp100/instructions/01-create-a-workspace.html)

Como su nombre indica, un espacio de trabajo es un lugar centralizado para administrar todos los activos de Azure ML que necesita para trabajar en un proyecto de aprendizaje automático.

![m1.gif](ims%2FC2%2Fgifs%2Fm1.gif)

1. En el [portal de Azure](https://portal.azure.com/#home), cree un nuevo recurso de **Aprendizaje automático (Machine Learning)**, especificando la siguiente configuración:

   ![m2.gif](ims%2FC2%2Fgifs%2Fm2.gif)

   - **Subscription:** Su suscripción de Azure
   - **Resource group:** rg-dp100-labs
   - **Workspace name:** mlw-dp100-labs
   - **Region:** Seleccione la región geográfica más cercana a usted
   - **Storage account:** Tenga en cuenta la nueva cuenta de almacenamiento que se creará de forma predeterminada para su espacio de trabajo
   - **Key vault:** Tenga en cuenta el nuevo almacén de claves que se creará de forma predeterminada para su espacio de trabajo
   - **Application insights:** Tenga en cuenta el nuevo recurso de Aplicación Insights que se creará de forma predeterminada para su espacio de trabajo
   - **Container registry:** Ninguno (uno se creará automáticamente la primera vez que implemente un modelo en un contenedor)

    >**Nota:** Cuando crea un espacio de trabajo de Azure Machine Learning, puede utilizar algunas opciones avanzadas para restringir el acceso a través de un punto de conexión privado y especificar claves personalizadas para la encriptación de datos. No utilizaremos estas opciones en este ejercicio, pero debe estar al tanto de ellas.

2. Cuando se hayan creado el espacio de trabajo y sus recursos asociados, vea el espacio de trabajo en el portal.

### Explore Azure Machine Learning studio

Puede administrar algunos activos del espacio de trabajo en el portal de Azure, pero para los científicos de datos, esta herramienta contiene mucha información irrelevante y enlaces que se relacionan con la administración de recursos generales de Azure. Azure Machine Learning Studio proporciona un portal web dedicado para trabajar con su espacio de trabajo.

   ![m3.gif](ims%2FC2%2Fgifs%2Fm3.gif)

1. En la cuchilla del **portal de Azure** para su espacio de trabajo de Azure Machine Learning, haga clic en el enlace para iniciar el estudio; o, alternativamente, en una nueva pestaña del navegador, abra [https://ml.azure.com](https://ml.azure.com). Si se le solicita, inicie sesión con la cuenta de Microsoft que utilizó en la tarea anterior y seleccione su suscripción de Azure y espacio de trabajo.

   > **Consejo** Si tiene varias suscripciones de Azure, debe elegir el directorio de Azure en el que se define la suscripción; luego elija la suscripción y, finalmente, el espacio de trabajo.

2. Vea la interfaz de Azure Machine Learning Studio para su espacio de trabajo; puede administrar todos los activos en su espacio de trabajo desde aquí.

3. En Azure Machine Learning Studio, active el icono ☰ en la parte superior izquierda para mostrar y ocultar las distintas páginas de la interfaz. Puede utilizar estas páginas para administrar los recursos en su espacio de trabajo.

### Create a compute instance

Una de las ventajas de Azure Machine Learning es la capacidad de crear cálculos basados en la nube en los que puede ejecutar experimentos y scripts de formación a escala.

1. En Azure Machine Learning Studio, vea la página de **Compute** page. Aquí es donde administrará los recursos de cálculo 
para sus actividades de ciencia de datos. Hay cuatro tipos de recursos de cálculo que puede crear:

   - **Compute instances:** Estaciones de trabajo de desarrollo que los científicos de datos pueden utilizar para trabajar con datos y modelos.
   - **Compute clusters:** Grupos escalables de máquinas virtuales para el procesamiento bajo demanda del código de experimento.
   - **Inference clusters:** Objetivos de implementación para servicios predictivos que utilizan sus modelos entrenados.
   - **Attached compute:** Vínculos a otros recursos de cálculo de Azure, como máquinas virtuales o grupos de Azure Databricks.

   Para este ejercicio, creará una instancia de cálculo para ejecutar código en sus cuadernos.

2. En la pestaña **Compute instances** agregue una nueva instancia de cálculo con la siguiente configuración. Utilizará esto como una estación de trabajo para ejecutar código en cuadernos.

   ![m4.gif](ims%2FC2%2Fgifs%2Fm4.gif)

   - **Compute name:** ingrese un nombre único
   - **Location:** La misma ubicación que su espacio de trabajo
   - **Virtual machine type:** CPU
   - **Virtual machine size:** Standard_DS11_v2
   - **Total Available Quotas:** Esto muestra núcleos dedicados disponibles.
   - **Show advanced settings:** Tenga en cuenta la siguientes configuraciones, pero no las seleccione:
     - **Enable SSH access:** No seleccionado (puede usar esto para habilitar el acceso directo a la máquina virtual mediante un cliente SSH)
     - **Enable virtual network:** No seleccionado (típicamente se utilizaría esto en un entorno empresarial para mejorar la seguridad de la red)
     - **Assign to another user:** No seleccionado (puede usar esto para asignar una instancia de cálculo a un científico de datos)
     - **Provision with setup script:** No seleccionado (puede usar esto para agregar un script para ejecutar en la instancia remota cuando se crea)

3. Espere a que la instancia de cálculo se inicie y su estado cambie a **En ejecución**.

   ![13.png](ims%2FC2%2F13.png)

> **Nota:** Las instancias de cálculo y los grupos se basan en imágenes estándar de máquinas virtuales de Azure. Para este ejercicio, se recomienda la imagen Standard_DS11_v2 para lograr el equilibrio óptimo entre costos y rendimiento. Si su suscripción no incluye una cuota que no tenga esta imagen, elija una imagen alternativa; pero tenga en cuenta que una imagen más grande puede incurrir en mayores costos y una imagen más pequeña puede no ser suficiente para completar las tareas. Alternativamente, solicite a su administrador de Azure que amplíe su cuota.


### Clone and run a notebook

Gran parte de la experimentación en ciencia de datos y aprendizaje automático se realiza ejecutando código en cuadernos. Su instancia de cálculo incluye entornos de cuaderno Python completamente equipados (_Jupyter y JupyterLab_) que puede utilizar para trabajos extensos; pero para la edición básica de cuadernos, puede utilizar la página integrada de **Cuadernos** en Azure Machine Learning Studio.

> Nota: Puedes encontrar el Notebook en: [01 - Get Started with Notebooks.ipynb](ims%2FC2%2Fnotebooks%2F01%20-%20Get%20Started%20with%20Notebooks.ipynb)

1. En Azure Machine Learning Studio, vea la página de **Cuadernos**.
2. Si se muestra un mensaje que describe las nuevas características, cierre el mensaje.
3. Seleccione **Terminal** o el icono **Abrir terminal** para abrir un terminal y asegúrese de que su Cálculo esté configurado en su instancia de cálculo y que la ruta actual sea la carpeta **/users/your-user-name**.
4. Ingrese el siguiente comando para clonar un repositorio Git que contiene cuadernos, datos y otros archivos en su espacio de trabajo:

   ![m5.gif](ims%2FC2%2Fgifs%2Fm5.gif)

    ```commandline
    git clone https://github.com/MicrosoftLearning/mslearn-dp100 mslearn-dp100
    ```

5. Cuando el comando haya terminado, en el panel de **Archivos**, haga clic en ↻ para actualizar la vista y verifique que se haya creado una nueva carpeta **/users/your-user-name/mslearn-dp100**. Esta carpeta contiene múltiples archivos de cuaderno **.ipynb**.
6. Cierre el panel del terminal para finalizar la sesión.
7. En la carpeta **/users/your-user-name/mslearn-dp100**, abra el cuaderno **Get Started with Notebooks notebook**. Luego, lea las notas y siga las instrucciones que contiene.

   ![m6.gif](ims%2FC2%2Fgifs%2Fm6.gif)

> **Consejo:** Para ejecutar una celda de código, seleccione la celda que desea ejecutar y luego utilice el botón ▷ para ejecutarla.

> **¿Nuevo en Python?** Utilice la [hoja de trucos de Python](https://microsoftlearning.github.io/mslearn-dp100/instructions/cheat-sheets/dp100-cheat-sheet-python.pdf) para entender el código.

> **¿Nuevo en el aprendizaje automático?** Utilice la [descripción general del aprendizaje automático](https://microsoftlearning.github.io/mslearn-dp100/instructions/cheat-sheets/dp100-cheat-sheet-machine-learning.pdf) para obtener una visión general simplificada del proceso de aprendizaje automático en Azure Machine Learning.

### Delete Azure resources

Cuando termine de explorar Azure Machine Learning, debe eliminar los recursos que ha creado para evitar costos innecesarios de Azure.

![m8.gif](ims%2FC2%2Fgifs%2Fm8.gif)

1. Cierre la pestaña de Azure Machine Learning Studio y vuelva al portal de Azure.
2. En el portal de Azure, en la página de **Inicio**, seleccione **Grupos de recursos**.
3. Seleccione el grupo de recursos **rg-dp100-labs**.
4. En la parte superior de la página **Descripción general** de su grupo de recursos, seleccione **Eliminar grupo de recursos**.
5. Ingrese el nombre del grupo de recursos para confirmar que desea eliminarlo y seleccione **Eliminar**.


### Obteniendo el archivo CONFIG.json Manualmente

Puedes crear manualmente este archivo o descargarlo desde el portal de Azure siguiendo estos pasos:

![m7.gif](ims%2FC2%2Fgifs%2Fm7.gif)

1. Ve al portal de Azure (https://portal.azure.com).
2. Navega a tu espacio de trabajo de Azure Machine Learning.

3. En la página de inicio de tu espacio de trabajo, busca la opción "Configuración" o "Información general".

4. En esa sección, deberías encontrar una opción para descargar el archivo de configuración. Este archivo será un archivo JSON que contiene los detalles de conexión necesarios.

Una vez tengas este archivo JSON de configuración, asegúrate de que esté en la misma ubicación que tu notebook local y puedes usar el código que proporcionaste para cargar el espacio de trabajo de Azure Machine Learning en tu entorno local.

Es importante destacar que necesitas tener instalado el SDK de Azure Machine Learning en tu entorno local para que este código funcione. Puedes instalarlo utilizando pip:

```bash
pip install azureml-sdk
```

## 2 Exercise Quiz 1
[< Back to Local Index](#2-index)

![14.png](ims%2FC2%2F14.png)

## 2 Azure Machine Learning tools and interfaces
[< Back to Local Index](#2-index)

![15.png](ims%2FC2%2F15.png)

Azure Machine Learning proporciona un servicio basado en la nube que ofrece flexibilidad en la forma de utilizarlo. 
Existen interfaces de usuario diseñadas específicamente para Azure Machine Learning, o puede utilizar una interfaz 
programática para gestionar recursos del espacio de trabajo y ejecutar operaciones de aprendizaje automático. 

![16.png](ims%2FC2%2F16.png)

Puede gestionar los recursos de su espacio de trabajo de Azure Machine Learning en el portal de Azure. Sin embargo, 
como se trata de una interfaz general para gestionar todos los recursos en Azure, los científicos de datos y otros usuarios 
implicados en operaciones de aprendizaje automático pueden preferir utilizar una interfaz dedicada más centrada. 

![17.png](ims%2FC2%2F17.png)

Azure Machine Learning Studio es una herramienta basada en web para gestionar un espacio de trabajo de Azure Machine Learning. 
Le permite crear, gestionar, y ver todos los activos de su espacio de trabajo y proporciona las siguientes herramientas gráficas: 

![18.png](ims%2FC2%2F18.png)

Diseñador. Se trata de una interfaz de arrastrar y soltar para el desarrollo de modelos de aprendizaje automático sin código.

![19.png](ims%2FC2%2F19.png)

Aprendizaje automático automatizado. Se trata de una interfaz de asistente que le permite entrenar un modelo, utilizando 
una combinación de algoritmos y técnicas de preprocesamiento de datos para encontrar el mejor modelo para sus datos. 

![20.png](ims%2FC2%2F20.png)

Es importante señalar que una herramienta lanzada anteriormente llamada Azure Machine Learning Studio proporcionaba un 
servicio gratuito para el desarrollo de modelos de aprendizaje automático de arrastrar y soltar. La interfaz del estudio 
para el servicio Azure Machine Learning incluye esta capacidad en la herramienta de diseño, así como otras capacidades de 
gestión de activos del espacio de trabajo.

![21.png](ims%2FC2%2F21.png)

Para utilizar Azure Machine Learning Studio, utilice un navegador web para navegar a ml.azure.com e inicie sesión utilizando 
las credenciales asociadas a su suscripción Azure. A continuación, puede seleccionar la suscripción y el espacio de trabajo 
que desea gestionar. 

![22.png](ims%2FC2%2F22.png)

Aunque las interfaces gráficas como Azure Machine Learning Studio facilitan la creación y la gestión de activos de aprendizaje 
automático, a menudo resulta ventajoso utilizar un enfoque basado en código para gestionar los recursos.

Escribiendo scripts para crear y gestionar recursos, puede ejecutar operaciones de aprendizaje automático desde su entorno 
de desarrollo preferido. Automatice la creación y configuración de activos para que sea repetible, asegure la coherencia 
de los recursos que deben replicarse en múltiples entornos. Por ejemplo, desarrollo, pruebas y producción. Incorpore la 
configuración de activos de aprendizaje automático en operaciones de desarrollo o flujos de trabajo DevOps, como integración 
continua, despliegue continuo o conductos CICD.

![23.png](ims%2FC2%2F23.png)

Azure Machine Learning proporciona kits de desarrollo de software o SDK para Python y R, que puede utilizar para crear, 
gestionar, y utilizar activos en un espacio de trabajo de Azure Machine Learning. Tenga en cuenta que este curso se centra 
en el SDK de Python porque tiene capacidades más amplias que el SDK de R. 

![24.png](ims%2FC2%2F24.png)

Aprendamos ahora a instalar el SDK de Azure Machine Learning para Python. Puede instalar el SDK de Azure Machine Learning 
para Python utilizando la utilidad de gestión de paquetes pip y utilizando el comando pip install. El SDK se instala 
utilizando la utilidad pip para Python y consta de el paquete principal azureml-sdk, así como de otros numerosos paquetes 
auxiliares que contienen funcionalidad especializada.

![25.png](ims%2FC2%2F25.png)

Por ejemplo, el paquete Azure-ml widgets proporciona soporte para widgets interactivos en un entorno Jupyter Notebook.

![26.png](ims%2FC2%2F26.png)

Para instalar paquetes adicionales, inclúyalos en el comando pip install. 

![27.png](ims%2FC2%2F27.png)

Para obtener más información sobre la instalación del 
SDK Azure Machine Learning para Python, consulte la documentación del SDK en el sitio web de Microsoft. Puede encontrar un 
enlace a este documento desde las lecturas adicionales al final de esta lección. 

![28.png](ims%2FC2%2F28.png)

Además, debe tener en cuenta que el SDK se actualiza en forma regular y revisar las notas de la versión para conocer la 
última versión. Puede encontrar un enlace a este documento desde las lecturas adicionales al final de esta lección.

![29.png](ims%2FC2%2F29.png)

Después de instalar el paquete SDK en su entorno Python, puede escribir código para conectarse a su espacio de trabajo y 
realizar operaciones de aprendizaje automático. La forma más sencilla de conectarse a un espacio de trabajo es utilizar 
un archivo de configuración del espacio de trabajo, que incluye la suscripción a Azure, el grupo de recursos y los detalles 
del espacio de trabajo.

![30.png](ims%2FC2%2F30.png)

Puede descargar un archivo de configuración para un espacio de trabajo desde la página de resumen de su hoja en el portal 
de Azure o desde Azure Machine Learning Studio. Para conectarse al espacio de trabajo utilizando el archivo de configuración, 
puede utilizar el método from_config de la clase del espacio de trabajo en el SDK. Por defecto, el método from_config 
busca un archivo llamado config.json en la carpeta que contiene el archivo de código Python, pero puede especificar otra 
ruta si es necesario.

![31.png](ims%2FC2%2F31.png)

Como alternativa al uso de un archivo de configuración, puede utilizar el método Get de la clase del espacio de trabajo, 
que especifica explícitamente la suscripción, el grupo de recursos y los detalles del espacio de trabajo. 

![32.png](ims%2FC2%2F32.png)

Sin embargo, la técnica del archivo de configuración suele preferirse debido a su mayor flexibilidad cuando se utilizan varios scripts. 

![33.png](ims%2FC2%2F33.png)

Sea cual sea la técnica que utilice, si no hay una sesión activa con su suscripción Azure, se le pedirá que se autentique. 
La clase del espacio de trabajo es el punto de partida para la mayoría de las operaciones de código. Por ejemplo, puede 
utilizar sus atributos de objetivos de cálculo para recuperar un objeto de diccionario, que contiene los objetivos de cálculo 
definidos en el espacio de trabajo. 

El SDK contiene una rica biblioteca de clases que puede utilizar para crear, gestionar y utilizar muchos activos en el espacio de trabajo de Azure Machine Learning. 

![34.png](ims%2FC2%2F34.png)

Para obtener más información sobre los objetivos de cómputo, Azure Machine Learning SDK, consulte la documentación del SDK 
en el sitio web de Microsoft. Puede encontrar un enlace a este documento en las lecturas adicionales al final de esta lección.

![35.png](ims%2FC2%2F35.png)

La interfaz de línea de comandos de Azure, o CLI, es una herramienta de línea de comandos multiplataforma para gestionar 
los recursos de Azure. La extensión Azure Machine Learning CLI es un paquete adicional que proporciona comandos para trabajar 
con Azure Machine Learning.

![36.png](ims%2FC2%2F36.png)

Para instalar la extensión Azure Machine Learning CLI, primero debe instalar Azure CLI. Consulte las instrucciones de instalación 
completas para todas las plataformas compatibles para obtener más detalles. Puede encontrar un enlace a este documento desde 
las lecturas adicionales al final de esta lección. 

![37.png](ims%2FC2%2F37.png)

Después de instalar la CLI de Azure, puede añadir la extensión CLI de Azure Machine Learning ejecutando un comando de extensión az. 
Para utilizar la extensión Azure Machine Learning CLI, ejecute el comando az ml con los parámetros adecuados para la acción 
que desee realizar. 

![38.png](ims%2FC2%2F38.png)

Es importante tener en cuenta lo siguiente, en el ejemplo de código anterior, el parámetro -g especifica el nombre del 
grupo de recursos en el que se define el espacio de trabajo Azure Machine Learning especificado en el parámetro -w. Estos 
parámetros son alias abreviados para --resource group y --workspace name. 

![39.png](ims%2FC2%2F39.png)

Para más información sobre la extensión CLI de Azure Machine Learning, consulte la documentación. Puede encontrar un enlace a este documento desde las lecturas adicionales al final de esta lección. 

![40.png](ims%2FC2%2F40.png)

Azure Machine Learning incluye la capacidad de crear instancias de cómputo en un espacio de trabajo, para proporcionar un 
entorno de desarrollo que se gestiona con todos los demás activos del espacio de trabajo. Las instancias de computación 
incluyen, Jupyter Notebook y Jupyter instalaciones de laboratorio que puede utilizar para escribir y ejecutar código que 
utiliza el SDK de Azure Machine Learning para trabajar con activos en su espacio de trabajo. 

![41.png](ims%2FC2%2F41.png)

Puede elegir una imagen de instancia de computación que proporcione la especificación de computación que necesite, desde 
pequeñas máquinas virtuales de sólo CPU hasta grandes estaciones de trabajo con GPU.

![42.png](ims%2FC2%2F42.png)

Dado que las instancias de computación se alojan en Azure, sólo paga por los recursos de computación cuando están en 
funcionamiento, por lo que puede crear una instancia de computación que se adapte a sus necesidades. Deténgala cuando su 
carga de trabajo haya finalizado para minimizar los costes. Puede almacenar blocs de notas de forma independiente en el 
almacenamiento del espacio de trabajo y abrirlos en cualquier instancia de computación.

![43.png](ims%2FC2%2F43.png)

Visual Studio Code es un entorno ligero de edición de código para Microsoft Windows, Apple MAC OS y Linux. Proporciona una 
interfaz visual para muchos tipos de código, incluidos Microsoft C#, JavaScript, Python y otros. También proporciona 
Intellisense y formato de sintaxis para formatos de datos comunes como JSON y XML. 

![44.png](ims%2FC2%2F44.png)

La flexibilidad de Visual Studio Code se basa en la capacidad de instalar extensiones modulares que añaden interfaces de 
comprobación de sintaxis, depuración y gestión visual para cargas de trabajo específicas. 

![45.png](ims%2FC2%2F45.png)

Por ejemplo, la extensión Microsoft Python para Visual Studio Code, añade soporte para escribir y ejecutar código Python y 
scripts o cuadernos dentro de la interfaz de Visual Studio Code. 

![46.png](ims%2FC2%2F46.png)

La extensión Azure Machine Learning para Visual Studio Code proporciona una interfaz gráfica para trabajar con activos en 
un espacio de trabajo Azure Machine Learning. Puede combinar las capacidades de las extensiones Azure Machine Learning y 
Python para gestionar una carga de trabajo completa de aprendizaje automático de extremo a extremo en Azure Machine Learning 
desde el entorno de Visual Studio Code.

Para obtener más información sobre el uso de la extensión Azure Machine Learning para Visual Studio Code, consulte la 
documentación. Puede encontrar un enlace a este documento en las lecturas adicionales al final de esta lección.

## 2 Azure Machine Learning experiments
[< Back to Local Index](#2-index)

![47.png](ims%2FC2%2F47.png)

Como cualquier disciplina científica, la ciencia de datos implica la ejecución de experimentos normalmente para explorar 
datos o para construir y evaluar modelos predictivos. En Azure Machine Learning un experimento es un proceso con nombre. 
Normalmente, la ejecución de un script o un pipeline que puede generar métricas y resultados y ser rastreado en el espacio 
de trabajo de Azure Machine Learning. 

![48.png](ims%2FC2%2F48.png)

Este experimento puede ejecutarse varias veces con diferentes datos, código o configuraciones. Azure Machine Learning realiza 
un seguimiento de cada ejecución, lo que le permite ver el historial de ejecución y comparar los resultados de cada ejecución. 

![49.png](ims%2FC2%2F49.png)

Ahora, echemos un vistazo a cómo se controlan los experimentos en Azure Machine Learning. Cuando envía un experimento, 
utiliza su contexto de ejecución para inicializar y finalizar la ejecución del experimento que se rastrea en Azure Machine Learning. 

![50.png](ims%2FC2%2F50.png)

Una vez finalizada la ejecución del experimento, puede ver los detalles de la ejecución la pestaña de experimentos en Azure 
Machine Learning studio. 

![51.png](ims%2FC2%2F51.png)

Los experimentos son más útiles cuando producen métricas y resultados que pueden rastrearse a través de las ejecuciones. 
Cada experimento genera archivos de registro que incluyen los mensajes que se escribirán en el terminal durante la ejecución 
interactiva. Esto le permite utilizar simples sentencias de impresión para escribir mensajes en el registro. Sin embargo, 
si desea registrar métricas con nombre para compararlas entre ejecuciones, puede hacerlo utilizando el objeto run, que 
proporciona una serie de funciones de registro específicas para este fin. 

![52.png](ims%2FC2%2F52.png)

Entre ellas se incluyen: 
- **Log:** registrar un único valor con nombre.
- **Log_list:** registrar una lista de valores con nombre. 
- **Log_row:** registra una fila con múltiples columnas. 
- **Log_table:** registra el diccionario como una tabla. 
- **Log_image:** registra un archivo de imagen o un gráfico. 

![53.png](ims%2FC2%2F53.png)

Para obtener más información sobre el registro de métricas durante las ejecuciones de experimentos, consulte Monitorizar 
ejecuciones y métricas de experimentos Azure ML en el sitio web de Microsoft. Puede encontrar un enlace a este recurso en 
las lecturas adicionales al final de esta lección.

![54.png](ims%2FC2%2F54.png)

Por ejemplo, puede utilizar un código que registre el número de observaciones registradas en un archivo CSV. 

![55.png](ims%2FC2%2F55.png)

Puede ver las métricas registradas por una ejecución de experimento en Azure Machine Learning studio o utilizando el widget 
RunDetails en un cuaderno. 

![56.png](ims%2FC2%2F56.png)

También puede recuperar las métricas utilizando el método run objects get metrics. Este método devuelve una representación 
json de las métricas. A continuación, puede generar observaciones de salida. Además de registrar métricas, un experimento 
puede generar archivos de salida.

![57.png](ims%2FC2%2F57.png)

A menudo, se trata de modelos de aprendizaje automático entrenados, pero puede guardar cualquier tipo de archivo y ponerlo 
a disposición como salida de la ejecución de su experimento. Los archivos de salida de un experimento se guardan en su 
carpeta de salidas. La técnica que utilice para añadir archivos a las salidas de un experimento, depende de cómo esté 
ejecutando el experimento. 

![58.png](ims%2FC2%2F58.png)

Los ejemplos mencionados aquí hasta ahora controlan el ciclo de vida del experimento alineando su código. Si adopta este 
enfoque, puede subir archivos locales a la carpeta de salidas de la ejecución utilizando el método upload file de los 
objetos de ejecución en el código de su experimento. Si ejecuta un experimento en un contexto de cálculo remoto, del que 
hablaremos más adelante en este curso. Cualquier archivo escrito en la carpeta de salidas en el contexto de cálculo se 
sube automáticamente a la carpeta de salidas de la ejecución cuando ésta finaliza. 

![m9.gif](ims%2FC2%2Fgifs%2Fm9.gif)

Sea cual sea el enfoque que utilice para ejecutar sus experimentos, puede recuperar una lista de archivos de salida del 
objeto de ejecución, que produciría una salida, mostrando output/sample.csv. 

![59.png](ims%2FC2%2F59.png)

Puede ejecutar un experimento en línea utilizando el método start_logging del objeto de experimento , pero es más común 
encapsular la lógica del experimento en un script y ejecutar el script como un experimento. El script puede ejecutarse en 
cualquier contexto de computación válido, lo que lo convierte en una solución más flexible para ejecutar experimentos a 
escala. Un script de experimento no es más que un archivo de código python que contiene el código que desea ejecutar en 
el experimento.

![60.png](ims%2FC2%2F60.png)

Para acceder al contexto de ejecución del experimento, necesario para registrar métricas, el script debe importar la clase 
azureml.core.run class y codificar su método get context. 

![61.png](ims%2FC2%2F61.png)

El script puede entonces utilizar el contexto de ejecución para registrar métricas, cargar archivos y completar el experimento.

![62.png](ims%2FC2%2F62.png)

Para ejecutar un script como un experimento, debe definir una configuración de script que defina el script a ejecutar y 
el entorno python en el que ejecutarlo. Esto se implementa utilizando un objeto ScriptRunConfig. Por ejemplo, el código 
podría utilizarse para ejecutar un experimento basado en un script en la carpeta de archivos del experimento, que también 
debe contener cualquier archivo utilizado por el script, como el archivo data.csv del ejemplo de código de script anterior. 

![63.png](ims%2FC2%2F63.png)

Es importante tener en cuenta y objeto de configuración de ejecución creado implícitamente, define el entorno python para 
el experimento, incluyendo los paquetes disponibles para el script. Además, si su script depende de paquetes que no están 
incluidos en el entorno por defecto. Debe asociar el ScriptRunConfig con un objeto de entorno que haga uso de un objeto 
CondaDependencies para especificar los paquetes python necesarios. Los entornos de ejecución se tratan con más detalle 
más adelante en este curso.

## 2 Exercise - Run experiments
[< Back to Local Index](#2-index)

Ahora es su oportunidad de probar Azure Machine Learning por sí mismo.

En este ejercicio, usted:

- Ejecutar un experimento de Azure Machine Learning.
- Ejecutar un script como experimento.
- Utilizar MLflow para realizar un seguimiento de las métricas del experimento.

### Instrucciones
Siga estas instrucciones para completar el ejercicio.

1. Si aún no tiene una suscripción a Azure, regístrese para una prueba gratuita en https://azure.microsoft.com.

2. Consulte el repositorio del ejercicio en https://aka.ms/mslearn-dp100.

3. Si aún no lo ha hecho, complete el ejercicio Crear un espacio de trabajo de Azure Machine Learning para aprovisionar 
un espacio de trabajo de Azure Machine Learning, crear una instancia de cálculo y clonar los archivos necesarios.

4. Complete el ejercicio Ejecutar experimentos

Liga para el tutorial en inglés: https://microsoftlearning.github.io/mslearn-dp100/instructions/04-run-experiments.html

Vamos a omitir los pasos:


- Before you start
- Provision an Azure Machine Learning workspace
- Clone the lab materials

Puesto que estos ya se hicieron en el tutorial anterior.

### Verificar que el SDK de Azure Machine Learning esté instalado

El SDK de Azure Machine Learning se instala de forma predeterminada en su instancia de cálculo. Siga estos pasos para verificar la instalación.

![m10.gif](ims%2FC2%2Fgifs%2Fm10.gif)

1. En la página de **Cuadernos**, cree un nuevo **Terminal** si ya no está abierto. Esto abrirá una nueva pestaña con una shell de comandos.
2. Ingrese el siguiente comando para instalar el SDK de Azure ML:

   ![m11.gif](ims%2FC2%2Fgifs%2Fm11.gif)

   ```bash
   pip install azureml-sdk
   ```
   Tenga en cuenta la versión del paquete SDK instalado.

3. El paquete SDK **azureml-sdk** proporciona las bibliotecas más importantes necesarias para trabajar con Azure Machine Learning. Sin embargo, existen algunos paquetes adicionales que contienen otras bibliotecas útiles que no se incluyen en el paquete principal del SDK. Use el siguiente comando para instalar el paquete **azureml-widgets**, que contiene bibliotecas para mostrar información de Azure Machine Learning en cuadernos:
   ```bash
   pip install azureml-widgets
   ```
4. Cierre la pestaña del **Terminal**.
   > **Más información:** Para obtener más detalles sobre la instalación del SDK de Azure ML y sus componentes opcionales, consulte la [Documentación del SDK de Azure ML](https://learn.microsoft.com/es-mx/python/api/overview/azure/ml/install?view=azure-ml-py).

### Ejecutar experimentos en un cuaderno

Los experimentos en Azure Machine Learning necesitan ser iniciados desde algún tipo de capa de control; a menudo un script o programa. 
En este ejercicio, utilizará un cuaderno para controlar los experimentos.

1. En la **página de Cuadernos**, navegue hasta la carpeta **/users/your-user-name/mslearn-dp100** donde clonó el repositorio de cuadernos y abra el cuaderno **Run Experiments**.
   
   ![m12.gif](ims%2FC2%2Fgifs%2Fm12.gif)   

2. Luego lea las notas en el cuaderno, ejecutando cada celda de código de manera consecutiva.

> ### Nota:
> El notebook completo de esta sección está en: [04 - Run Experiments.ipynb](ims%2FC2%2Fnotebooks%2F04%20-%20Run%20Experiments.ipynb)


### Eliminar los recursos de Azure

Cuando termine de explorar Azure Machine Learning, debe eliminar los recursos que ha creado para evitar costos innecesarios de Azure.

1. Cierre la pestaña de Azure Machine Learning Studio y regrese al portal de Azure.
2. En el portal de Azure, en la **página de Inicio**, seleccione **Grupos de recursos**.
3. Seleccione el grupo de recursos **rg-dp100-labs**.
4. En la parte superior de la **página Descripción general** de su grupo de recursos, seleccione **Eliminar grupo de recursos**.
5. Ingrese el nombre del grupo de recursos para confirmar que desea eliminarlo y seleccione **Eliminar**.


## 2 Exercise Quiz 2
[< Back to Local Index](#2-index)

![64.png](ims%2FC2%2F64.png)

## 2 Knowledge Check
[< Back to Local Index](#2-index)

![t1.png](ims%2FC2%2Ftest%2Ft1.png)

![t2.png](ims%2FC2%2Ftest%2Ft2.png)

![t3.png](ims%2FC2%2Ftest%2Ft3.png)

![t4.png](ims%2FC2%2Ftest%2Ft4.png)

## 2 Lesson summary
[< Back to Local Index](#2-index)

![65.png](ims%2FC2%2F65.png)

En esta lección, aprendiste cómo usar Python para explorar , visualizar y manipular datos o, más específicamente, 
aprovisionar una máquina de Azure Espacio de trabajo de aprendizaje, uso de herramientas e interfaces para trabajar con Azure Aprendizaje automático y ejecución de experimentos basados en código en una máquina de Azure Espacio de trabajo de aprendizaje.


## 2 Additional Reading
[< Back to Local Index](#2-index)

**Azure Machine Learning workspaces**

[Use an Azure Resource Manager template to create a workspace for Azure Machine Learning](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-create-workspace-template?tabs=azcli)

**Azure Machine Learning tools and interfaces**

[Azure Machine Learning release notes](https://docs.microsoft.com/en-us/azure/machine-learning/azure-machine-learning-release-notes)

[What is the Azure Machine Learning SDK for Python?](https://docs.microsoft.com/en-us/python/api/overview/azure/ml/?view=azure-ml-py)

[How to install the Azure CLI](https://docs.microsoft.com/en-us/cli/azure/install-azure-cli?view=azure-cli-latest)

[Install & use the CLI extension for Azure Machine Learning](https://docs.microsoft.com/en-us/azure/machine-learning/reference-azure-machine-learning-cli)

[Manage Azure Machine Learning resources with the VS Code Extension (preview)](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-manage-resources-vscode)

**Azure Machine Learning experiments**

[Log & view metrics and log files](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-log-view-metrics)

# 3 Train a machine learning model with Azure Machine Learning

## 3 INDEX

- [3 Lesson introduction](#3-lesson-introduction)
- [3 Run a training script](#3-run-a-training-script)
- [3 Using script parameters](#3-using-script-parameters)
- [3 Registering models](#3-registering-models)
- [3 Exercise Training and registering a model](#3-exercise-training-and-registering-a-model)
- [3 Exercise quiz](#3-exercise-quiz)
- [3 Knowledge Check](#3-knowledge-check)
- [3 Test prep](#3-test-prep)
- [3 Lesson Summary](#3-lesson-summary)

[< Back to index](#0-index)

## 3 Lesson introduction
[< Back to Local Index](#3-index)

![1.png](ims%2FC3%2Fims%2F1%2F1.png)

El entrenamiento en el modelo de aprendizaje automático puede ser tan fácil como cargar datos y ejecutar una línea de código 
utilizando paquetes como scikit learn. Sin embargo, en un escenario de aprendizaje automático de producción, debe considerar 
la creación de scripts de entrenamiento reutilizables para múltiples entornos informáticos. Registrar las métricas de 
rendimiento del modelo durante los procesos de entrenamiento y evaluación, y realizar un seguimiento de las versiones del 
modelo. 

![2.png](ims%2FC3%2Fims%2F1%2F2.png)

En esta lección, aprenderá a utilizar una configuración de ejecución de script para ejecutar un script de entrenamiento 
de modelo como un experimento de Azure Machine Learning. Crear scripts de entrenamiento reutilizables y parametrizados y 
registrar los modelos entrenados.

## 3 Run a training script
[< Back to Local Index](#3-index)

Puede utilizar un ScriptRunConfig para ejecutar un experimento basado en un script que entrene un modelo de aprendizaje automático.

### Escribir un script para entrenar un modelo

Cuando utilice un experimento para entrenar un modelo, su script debe guardar el modelo entrenado en la carpeta de salidas. 
Por ejemplo, el siguiente script entrena un modelo utilizando Scikit-Learn, y lo guarda en la carpeta de salidas utilizando 
el paquete **joblib**:

Podemos ver el archivo [diabetes.csv](ims%2FC3%2Fdata%2Fdiabetes.csv)
```csv
PatientID,Pregnancies,PlasmaGlucose,DiastolicBloodPressure,TricepsThickness,SerumInsulin,BMI,DiabetesPedigree,Age,Diabetic
1354778,0,171,80,34,23,43.50972593,1.213191354,21,0
1147438,8,92,93,47,36,21.24057571,0.158364981,23,0
1640031,7,115,47,52,35,41.51152348,0.079018568,23,0
```

```python
from azureml.core import Run
import pandas as pd
import numpy as np
import joblib
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression

# Get the experiment run context
run = Run.get_context()

# Prepare the dataset
diabetes = pd.read_csv('data/diabetes.csv')
X, y = diabetes[['Feature1','Feature2','Feature3']].values, diabetes['Label'].values
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30)

# Train a logistic regression model
reg = 0.1
model = LogisticRegression(C=1/reg, solver="liblinear").fit(X_train, y_train)

# calculate accuracy
y_hat = model.predict(X_test)
acc = np.average(y_hat == y_test)
run.log('Accuracy', np.float(acc))

# Save the trained model
os.makedirs('outputs', exist_ok=True)
joblib.dump(value=model, filename='outputs/model.pkl')

run.complete()
```

Para preparar un experimento que entrene un modelo, se crea un script como éste y se guarda en una carpeta. Por ejemplo, 
podría guardar este script como **training_script.py** en una carpeta llamada **training_folder**. Dado que el script 
incluye código para cargar los datos de entrenamiento **diabetes.csv**, este archivo también debe guardarse en la carpeta.

### Ejecutar el script como experimento

Para ejecutar el script, cree una **ScriptRunConfig** que haga referencia a la carpeta y al archivo de script. Por lo general, 
también deberá definir un entorno Python (Conda) que incluya cualquier paquete requerido por el script. En este ejemplo, 
el script utiliza Scikit-Learn por lo que debe crear un entorno que lo incluya. 

El script también utiliza Azure Machine Learning para registrar métricas, por lo que debe acordarse de incluir el paquete
azureml-defaults en el entorno.

```python
from azureml.core import Experiment, ScriptRunConfig, Environment
from azureml.core.conda_dependencies import CondaDependencies

# Create a Python environment for the experiment
sklearn_env = Environment("sklearn-env")

# Ensure the required packages are installed
packages = CondaDependencies.create(conda_packages=['scikit-learn','pip'],
                                    pip_packages=['azureml-defaults'])
sklearn_env.python.conda_dependencies = packages

# Create a script config
script_config = ScriptRunConfig(source_directory='training_folder',
                                script='training.py',
                                environment=sklearn_env) 

# Submit the experiment
experiment = Experiment(workspace=ws, name='training-experiment')
run = experiment.submit(config=script_config)
run.wait_for_completion()
```

> Nota, tambien podemos crear un archivo .yml y crear el ambiente desde el archivo .yml

Con el siguiente código podemos crear el archivo: `environment_test.yml` a partir de la variable `packages` creada anteriormente:

```python
with open('environment_test.yml', 'w') as f:
    f.write(packages.serialize_to_string())
```
La respuesta generada sería:
```yml
# Conda environment specification. The dependencies defined in this file will
# be automatically provisioned for runs with userManagedDependencies=False.

# Details about the Conda environment file format:
# https://conda.io/docs/user-guide/tasks/manage-environments.html#create-env-file-manually

name: project_environment
dependencies:
  # The python interpreter version.
  # Currently Azure ML only supports 3.8 and later.
- python=3.8.13

- pip:
  - azureml-defaults~=1.53.0
- scikit-learn
- pip
channels:
- anaconda
- conda-forge
```
Entonces para crear el `sklearn_env` desde el archivo `.yml`:
```python
# Create a Python environment for the experiment (from a .yml file)
sklearn_env = Environment.from_conda_specification("experiment_env", "environment_test.yml")
```

## 3 Using script parameters
[< Back to Local Index](#3-index)

Puede aumentar la flexibilidad de los experimentos basados en scripts utilizando argumentos para establecer variables en 
el script.

### Trabajar con argumentos de script

Para utilizar parámetros en un script, debe utilizar una biblioteca como **argparse** para leer los argumentos pasados al 
script y asignarlos a variables. Por ejemplo, el siguiente script lee un argumento llamado **--reg-rate**, que se utiliza 
para establecer el hiperparámetro de tasa de regularización para el algoritmo de regresión logística utilizado para entrenar 
un modelo.

```python
from azureml.core import Run
import argparse
import pandas as pd
import numpy as np
import joblib
import os
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression

# Get the experiment run context
run = Run.get_context()

# Set regularization hyperparameter
parser = argparse.ArgumentParser()
parser.add_argument('--reg-rate', type=float, dest='reg_rate', default=0.01)
args = parser.parse_args()
reg = args.reg_rate

# Prepare the dataset
diabetes = pd.read_csv('data/diabetes.csv')
X, y = data[['Feature1','Feature2','Feature3']].values, data['Label'].values
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30)

# Train a logistic regression model
model = LogisticRegression(C=1/reg, solver="liblinear").fit(X_train, y_train)

# calculate accuracy
y_hat = model.predict(X_test)
acc = np.average(y_hat == y_test)
run.log('Accuracy', np.float(acc))

# Save the trained model
os.makedirs('outputs', exist_ok=True)
joblib.dump(value=model, filename='outputs/model.pkl')

run.complete()
```

### Pasar argumentos a un script de experimento

Para pasar valores de parámetros a un script que se está ejecutando en un experimento, necesita proporcionar un valor de 
argumentos que contenga una lista de argumentos separados por comas y sus valores al **ScriptRunConfig**, de la siguiente manera:

```python
# Create a script config
script_config = ScriptRunConfig(source_directory='training_folder',
                                script='training.py',
                                arguments = ['--reg-rate', 0.1],
                                environment=sklearn_env)
```

## 3 Registering models
[< Back to Local Index](#3-index)

Después de ejecutar un experimento que entrena un modelo, puede utilizar una referencia al objeto Ejecutar para recuperar 
sus resultados, incluido el modelo entrenado.

### Recuperación de archivos de modelo

Una vez finalizada la ejecución de un experimento, puede utilizar el método **get_file_names** de los objetos run para 
listar los archivos generados. La práctica estándar es que los scripts que entrenan modelos los guarden en la carpeta de
salidas de la ejecución.

También puede utilizar los métodos **download_file** y **download_files** del objeto run para descargar los archivos de 
salida al sistema de archivos local.

```python
# "run" is a reference to a completed experiment run

# List the files generated by the experiment
for file in run.get_file_names():
    print(file)

# Download a named file
run.download_file(name='outputs/model.pkl', output_file_path='model.pkl')
```

### Registro de un modelo

El registro de modelos le permite realizar un seguimiento de varias versiones de un modelo y recuperar modelos para
inferencias(predicción de valores de etiquetas a partir de nuevos datos). Cuando registra un modelo, puede especificar un 
nombre, una descripción, etiquetas, un marco (como Scikit-Learn o PyTorch), una versión del marco, propiedades personalizadas 
y otros metadatos útiles. Al registrar un modelo con el mismo nombre que un modelo existente, se crea automáticamente una 
nueva versión del modelo, empezando por 1 y aumentando en unidades de 1.

Para registrar un modelo desde un archivo local, puede utilizar el método **register** del objeto **Model** como se muestra aquí:

```python
from azureml.core import Model

model = Model.register(workspace=ws,
                       model_name='classification_model',
                       model_path='model.pkl', # local path
                       description='A classification model',
                       tags={'data-format': 'CSV'},
                       model_framework=Model.Framework.SCIKITLEARN,
                       model_framework_version='0.20.3')
```

Alternativamente, si tiene una referencia a la **Ejecución** utilizada para entrenar el modelo, puede utilizar su método
**register_model** como se muestra aquí:

```python
run.register_model( model_name='classification_model',
                    model_path='outputs/model.pkl', # run outputs path
                    description='A classification model',
                    tags={'data-format': 'CSV'},
                    model_framework=Model.Framework.SCIKITLEARN,
                    model_framework_version='0.20.3')
```

### Visualización de modelos registrados

Puede ver los modelos registrados en Azure Machine Learning studio. También puede utilizar el objeto **Model** para recuperar 
los detalles de los modelos registrados como se muestra aquí:

```python
from azureml.core import Model

for model in Model.list(ws):
    # Get model name and auto-generated version
    print(model.name, 'version:', model.version)
```


## 3 Exercise Training and registering a model
[< Back to Local Index](#3-index)

Ahora es su oportunidad de utilizar Azure Machine Learning para entrenar un modelo de aprendizaje automático

En este ejercicio, usted:


- Utilizar un script para entrenar un modelo
- Utilizar un script parametrizado para entrenar un modelo
- Registrar un modelo.


### Instrucciones

Siga estas instrucciones para completar el ejercicio.

1. Si aún no dispone de una suscripción a Azure, regístrese para obtener una prueba gratuita en 
https://azure.microsoft.com

2. Vea el repositorio del ejercicio en 
https://aka.ms/mslearn-dp100

3. Si aún no lo ha hecho, complete el ejercicio Crear un espacio de trabajo de Azure Machine Learning para aprovisionar un espacio de trabajo de Azure Machine Learning, crear una instancia de cálculo y clonar los archivos necesarios

4. Complete el ejercicio Entrenar modelos.

### Train models using the Azure Machine Learning SDK

![m1.gif](ims%2FC3%2Fgifs%2Fm1.gif)

![m2.gif](ims%2FC3%2Fgifs%2Fm2.gif)

![m3.gif](ims%2FC3%2Fgifs%2Fm3.gif)

![m4.gif](ims%2FC3%2Fgifs%2Fm4.gif)

![m5.gif](ims%2FC3%2Fgifs%2Fm5.gif)

![m6.gif](ims%2FC3%2Fgifs%2Fm6.gif)

![m7.gif](ims%2FC3%2Fgifs%2Fm7.gif)

![m8.gif](ims%2FC3%2Fgifs%2Fm8.gif)

![m9.gif](ims%2FC3%2Fgifs%2Fm9.gif)

![m10.gif](ims%2FC3%2Fgifs%2Fm10.gif)

![m11.gif](ims%2FC3%2Fgifs%2Fm11.gif)

> ### Nota:
> El notebook de esta clase está en: [05 - Train Models.ipynb](ims%2FC3%2Fnotebooks%2F05%20-%20Train%20Models.ipynb)

## 3 Exercise quiz
[< Back to Local Index](#3-index)

![3.png](ims%2FC3%2Fims%2F1%2F3.png)

## 3 Knowledge Check
[< Back to Local Index](#3-index)

![q1.png](ims%2FC3%2Ftest%2Fq1.png)

![q2.png](ims%2FC3%2Ftest%2Fq2.png)

![q3.png](ims%2FC3%2Ftest%2Fq3.png)

## 3 Test prep
[< Back to Local Index](#3-index)

![q4.png](ims%2FC3%2Ftest%2Fq4.png)

![q5.png](ims%2FC3%2Ftest%2Fq5.png)

![q6.png](ims%2FC3%2Ftest%2Fq6.png)

![q7.png](ims%2FC3%2Ftest%2Fq7.png)



## 3 Lesson Summary
[< Back to Local Index](#3-index)

![4.png](ims%2FC3%2Fims%2F1%2F4.png)

En este módulo, ha aprendido a entrenar un modelo de aprendizaje automático con Azure machine learning. O, más concretamente, 
ha aprendido a utilizar un script, run Config para ejecutar un script de entrenamiento de modelos como un experimento de 
aprendizaje automático de Azure. Cree scripts de restricción de parámetros reutilizables y modelos entrenados registrados.

# 4 Work with Data in Azure Machine Learning

## 4 INDEX

- [4 Lesson Introduction](#4-lesson-introduction)
- [4 Introduction to datastores](#4-introduction-to-datastores)
- [4 Use datastores](#4-use-datastores)
- [4 Introduction to datasets](#4-introduction-to-datasets)
- [4 Use datasets](#4-use-datasets)
- [4 Exercise Work with data](#4-exercise-work-with-data)
- [4 Exercise quiz](#4-exercise-quiz)
- [4 Knowledge check](#4-knowledge-check)
- [4 Lesson summary](#4-lesson-summary)
- [4 Additional Reading](#4-additional-reading)

[< Back to index](#0-index)

## 4 Lesson Introduction
[< Back to Local Index](#4-index)

![1.png](ims%2FC4%2Fims%2F1%2F1.png)

Hola, en esta lección, aprenderá a trabajar con datos en el aprendizaje automático de Azure. Los datos son un elemento 
fundamental en cualquier carga de trabajo de aprendizaje automático. 

En esta lección, aprenderá a crear y gestionar almacenes de datos y conjuntos de datos en un espacio de trabajo de 
aprendizaje automático de Azure. Y a utilizarlos en experimentos de entrenamiento de modelos. 

![2.png](ims%2FC4%2Fims%2F1%2F2.png)

En esta lección, aprenderá a crear y utilizar almacenes de datos, y a crear y utilizar conjuntos de datos.

## 4 Introduction to datastores
[< Back to Local Index](#4-index)

![1.png](ims%2FC4%2Fims%2F2%2F1.png)

En Azure machine Learning los almacenes de datos o abstracciones para fuentes de datos en la nube, encapsulan la información 
necesaria para conectarse a las fuentes de datos. Puede acceder a los almacenes de datos directamente codificar utilizando 
el SDK de Azure Machine Learning y utilizarlo para cargar o descargar datos.

![2.png](ims%2FC4%2Fims%2F2%2F2.png)

A medida que su machine learning soporta la creación de almacenes de datos de múltiples tipos de fuente de datos Azure, 
incluyendo Azure storage blob y contenedores de archivos. Almacenes Azure data Lake como su base de datos SQL y Azure data 
bricks, sistema de archivos o D B F S

![3.png](ims%2FC4%2Fims%2F2%2F3.png)

para una lista completa de los almacenes de datos soportados, consulte la documentación de Azure machine Learning de la 
página web de Microsoft, puede encontrar un enlace a esta página web desde las lecturas adicionales al final de esta lección.

![4.png](ims%2FC4%2Fims%2F2%2F4.png)

Cada espacio de trabajo tiene dos almacenes de datos incorporados y como su contenedor de almacenamiento blob y un contenedor 
de archivos de almacenamiento Azure que son utilizados como sistema de almacenamiento por Azure Machine Learning también 
hay un tercer almacén de datos que se añade a su espacio de trabajo. Si hace uso de los conjuntos de datos abiertos 
proporcionados como muestras, por ejemplo, creando un pipeline de diseño basado en un conjunto de datos de muestra. 

![5.png](ims%2FC4%2Fims%2F2%2F5.png)

![6.png](ims%2FC4%2Fims%2F2%2F6.png)

En la mayoría de los proyectos de aprendizaje automático, es probable que necesite trabajar con fuentes de datos propias. 
Esto se debe a que necesitará almacenar volúmenes de datos mayores que los que admite el almacén de datos incorporado o 
porque necesita integrar su solución de aprendizaje automático con datos de aplicaciones existentes

## 4 Use datastores
[< Back to Local Index](#4-index)

![1.png](ims%2FC4%2Fims%2F3%2F1.png)

Para añadir un banco de datos a su espacio de trabajo, puede registrarlo mediante la interfaz gráfica de Azure Machine 
Learning Studio, o puede usar Azure SDK de aprendizaje automático. Por ejemplo, registrar un almacenamiento de Azure 
Contenedores de blobs, nombres de un almacén de datos datos de subrayado de blob.

![2.png](ims%2FC4%2Fims%2F3%2F2.png)

Puede ver y administrar almacenes de datos en Azure Machine Learning Studio o puede usar Azure Machine SDK de aprendizaje. 
Por ejemplo, usar un bucle para enumerar los nombres de cada almacén de datos en el espacio de trabajo

![3.png](ims%2FC4%2Fims%2F3%2F3.png)

puede obtener una referencia a cualquier almacén de datos utilizando el método datastore get.

![4.png](ims%2FC4%2Fims%2F3%2F4.png)

El espacio de trabajo siempre incluye un almacén de datos predeterminado, que puede recuperar mediante el método get default 
datastore de un objeto de espacio de trabajo. El almacén de datos predeterminado está integrado inicialmente en el espacio 
de trabajo almacén de datos de blob store.

![5.png](ims%2FC4%2Fims%2F3%2F5.png)

Cuando planifique un almacén de datos, tenga en cuenta la siguientes pautas : Al usar Azure Blob Storage, nivel premium el 
almacenamiento puede proporcionar un rendimiento de E/S mejorado para conjuntos de datos de gran tamaño. Sin embargo, esta 
opción lo hará incrementará los costos y puede limitar las opciones de replicación para redundancia de datos.

![6.png](ims%2FC4%2Fims%2F3%2F6.png)

Cuando se trabaja con archivos de datos: aunque el formato CSV es muy común, el formato Parquet generalmente da como resultado 
un mejor rendimiento. 

![7.png](ims%2FC4%2Fims%2F3%2F7.png)

![8.png](ims%2FC4%2Fims%2F3%2F8.png)

Puedes acceder a cualquier el almacén de datos por nombre, pero quizá le interese cambiar el almacén 
de datos predeterminado, que inicialmente era el almacén de datos integrado en el espacio de trabajo.

![9.png](ims%2FC4%2Fims%2F3%2F9.png)

Para cambiar el almacén de datos predeterminado, usa el valor predeterminado establecido método de almacén de datos.

## 4 Introduction to datasets
[< Back to Local Index](#4-index)

Los conjuntos de datos son objetos de datos empaquetados y versionados que pueden consumirse fácilmente en experimentos y 
pipelines. Los conjuntos de datos son la forma recomendada de trabajar con los datos, y son el mecanismo principal para 
las capacidades avanzadas de Azure Machine Learning, como el etiquetado de datos y la supervisión de la deriva de los datos.

### Tipos de conjuntos de datos

Los conjuntos de datos suelen basarse en archivos de un almacén de datos, aunque también pueden basarse en URL y otras fuentes. 
Puede crear los siguientes tipos de conjuntos de datos:

- **Tabular:** Los datos se leen del conjunto de datos como una tabla. Debe utilizar este tipo de conjunto de datos cuando 
sus datos estén estructurados de forma consistente y desee trabajar con ellos en estructuras de datos tabulares comunes, 
como los dataframes de Pandas.

- **Archivo:** El conjunto de datos presenta una lista de rutas de archivos que pueden leerse como si procedieran del sistema 
de archivos. Utilice este tipo de conjunto de datos cuando sus datos no estén estructurados, o cuando necesite procesar 
los datos a nivel de archivo (por ejemplo, para entrenar una red neuronal convolucional a partir de un conjunto de archivos 
de imágenes).

### Creación y registro de conjuntos de datos

Puede utilizar la interfaz visual de Azure Machine Learning studio o el SDK de Azure Machine Learning para crear conjuntos 
de datos a partir de archivos individuales o de varias rutas de archivos. Las rutas pueden incluir comodines (por ejemplo
,/archivos/*.csv), lo que permite encapsular datos de un gran número de archivos en un único conjunto de datos.

Una vez creado un conjunto de datos, puede registrarlo en el espacio de trabajo para que esté disponible para su uso posterior 
en experimentos y canalizaciones de procesamiento de datos.

### Creación y registro de conjuntos de datos tabulares

Para crear un conjunto de datos tabular utilizando el SDK, utilice el método **from_delimited_files** de la clase 
**Dataset.Tabular**, como se muestra a continuación:

```python
from azureml.core import Dataset

blob_ds = ws.get_default_datastore()
csv_paths = [(blob_ds, 'data/files/current_data.csv'),
             (blob_ds, 'data/files/archive/*.csv')]
tab_ds = Dataset.Tabular.from_delimited_files(path=csv_paths)
tab_ds = tab_ds.register(workspace=ws, name='csv_table')
```

El conjunto de datos de este ejemplo incluye datos de dos rutas de archivos dentro del almacén de datos predeterminado:

- El archivo **current_data.csv** de la carpeta **data/files**.

- Todos los archivos **.csv** de la carpeta **data/files/archive/.**

Tras crear el conjunto de datos, el código lo registra en el espacio de trabajo con el nombre **csv_table**.

### Creación y registro de conjuntos de datos de archivos

Para crear un conjunto de datos de archivo utilizando el SDK, utilice el método **from_files** de la clase 
**Dataset.File**, como se muestra a continuación:

```python
from azureml.core import Dataset

blob_ds = ws.get_default_datastore()
file_ds = Dataset.File.from_files(path=(blob_ds, 'data/files/images/*.jpg'))
file_ds = file_ds.register(workspace=ws, name='img_files')
```

El conjunto de datos de este ejemplo incluye todos los archivos **.jpg** de la ruta **data/files/images** dentro del almacén 
de datos predeterminado:

Después de crear el conjunto de datos, el código lo registra en el área de trabajo con el nombre **img_files**.

### Recuperación de un conjunto de datos registrado

Después de registrar un conjunto de datos, puede recuperarlo utilizando cualquiera de las siguientes técnicas:

- El atributo de **diccionario datasets** de un objeto **Espacio de trabajo**.

- El método **get_by_name** o **get_by_id** de la claseDataset.

Ambas técnicas se muestran en el siguiente código:

```python
import azureml.core
from azureml.core import Workspace, Dataset

# Load the workspace from the saved config file
ws = Workspace.from_config()

# Get a dataset from the workspace datasets collection
ds1 = ws.datasets['csv_table']

# Get a dataset by name from the datasets class
ds2 = Dataset.get_by_name(ws, 'img_files')
```

### Versionado de conjuntos de datos

Los conjuntos de datos pueden versionarse, lo que le permite realizar un seguimiento de las versiones históricas de los 
conjuntos de datos que se utilizaron en experimentos y reproducir dichos experimentos con datos en el mismo estado.

Puede crear una nueva versión de un conjunto de datos registrándolo con el mismo nombre que un conjunto de datos previamente 
registrado y especificando la propiedad **create_new_version**:

```python
img_paths = [(blob_ds, 'data/files/images/*.jpg'),
             (blob_ds, 'data/files/images/*.png')]
file_ds = Dataset.File.from_files(path=img_paths)
file_ds = file_ds.register(workspace=ws, name='img_files', create_new_version=True)
```

En este ejemplo, los archivos .png de la carpeta **images** se han añadido a la definición del ejemplo de conjunto de datos
**img_paths** utilizado en el tema anterior.

### Recuperación de una versión específica del conjunto de datos

Puede recuperar una versión específica de un conjunto de datos especificando el parámetro **version** en el método 
**get_by_name** de la clase **Dataset**.

```python
img_ds = Dataset.get_by_name(workspace=ws, name='img_files', version=2)
```

## 4 Use datasets
[< Back to Local Index](#4-index)

Los conjuntos de datos son la forma principal de pasar datos a los experimentos que entrenan modelos.

### Trabajar con conjuntos de datos tabulares

Puede leer los datos directamente desde un conjunto de datos tabular convirtiéndolo en un marco de datos Pandas o Spark:

```python
df = tab_ds.to_pandas_dataframe()
# code to work with dataframe goes here, for example:
print(df.head())
```

### Pasar un conjunto de datos tabular a un script de experimento

Cuando necesite acceder a un conjunto de datos en un script de experimento, debe pasar el conjunto de datos al script. 
Hay dos formas de hacerlo.

### Utilizar un argumento de script para un conjunto de datos tabular

Puede pasar un conjunto de datos tabular como argumento de script. Cuando adopta este enfoque, el argumento que recibe el 
script es el ID único para el conjunto de datos en su espacio de trabajo. En el script, puede entonces obtener el espacio 
de trabajo del contexto de ejecución y utilizarlo para recuperar el conjunto de datos por su ID.

_ScriptRunConfig_:

```python
env = Environment('my_env')
packages = CondaDependencies.create(conda_packages=['pip'],
                                    pip_packages=['azureml-defaults',
                                                  'azureml-dataprep[pandas]'])
env.python.conda_dependencies = packages

script_config = ScriptRunConfig(source_directory='my_dir',
                                script='script.py',
                                arguments=['--ds', tab_ds],
                                environment=env)
```
_Script:_

```python
from azureml.core import Run, Dataset

parser.add_argument('--ds', type=str, dest='dataset_id')
args = parser.parse_args()

run = Run.get_context()
ws = run.experiment.workspace
dataset = Dataset.get_by_id(ws, id=args.dataset_id)
data = dataset.to_pandas_dataframe()
```

### Utilizar una entrada con nombre para un conjunto de datos tabular

Como alternativa, puede pasar un conjunto de datos tabular como una entrada con **nombre**. En este enfoque, usted utiliza el 
método **as_named_input** del conjunto de datos para especificar un nombre para el conjunto de datos. 

A continuación, en el script, puede recuperar el conjunto de datos por su nombre de la colección **input_datasets** del contexto 
de ejecución sin necesidad de recuperarlo del espacio de trabajo. Tenga en cuenta que si utiliza este enfoque, seguirá 
necesitando incluir un argumento de script para el conjunto de datos, aunque en realidad no lo utilice para recuperar el 
conjunto de datos.

_ScriptRunConfig:_

```python
env = Environment('my_env')
packages = CondaDependencies.create(conda_packages=['pip'],
                                    pip_packages=['azureml-defaults',
                                                  'azureml-dataprep[pandas]'])
env.python.conda_dependencies = packages

script_config = ScriptRunConfig(source_directory='my_dir',
                                script='script.py',
                                arguments=['--ds', tab_ds.as_named_input('my_dataset')],
                                environment=env)
```

_Script:_

```python
from azureml.core import Run

parser.add_argument('--ds', type=str, dest='ds_id')
args = parser.parse_args()

run = Run.get_context()
dataset = run.input_datasets['my_dataset']
data = dataset.to_pandas_dataframe()
```

### Trabajar con conjuntos de datos de archivos

Cuando trabaje con un conjunto de datos de archivo, puede utilizar el método **to_path()** para devolver una lista de las 
rutas de archivo encapsuladas por el conjunto de datos:

```python
for file_path in file_ds.to_path():
    print(file_path)
```

### Pasar un conjunto de datos de archivo a un script de experimento

Al igual que con un conjunto de datos Tabular, existen dos formas de pasar un conjunto de datos de archivo a un script. 
Sin embargo, existen algunas diferencias clave en la forma de pasar el conjunto de datos.

### Utilizar un argumento de script para un conjunto de datos de archivo

Puede pasar un conjunto de datos de archivo como argumento de script. A diferencia de lo que ocurre con un conjunto de datos 
tabular, debe especificar un modo para el argumento del conjunto de datos de archivo, que puede ser **as_download** o 
**as_mount**. Esto proporciona un punto de acceso que el script puede utilizar para leer los archivos del conjunto de datos. 

En la mayoría de los casos, debería utilizar **as_download**, que copia los archivos a una ubicación temporal en el 
ordenador donde se está ejecutando el script. Sin embargo, si está trabajando con una gran cantidad de datos para los que 
puede no haber suficiente espacio de almacenamiento en el ordenador del experimento, utilice **as_mount** para transmitir 
los archivos directamente desde su fuente.

_ScriptRunConfig:_

```python
env = Environment('my_env')
packages = CondaDependencies.create(conda_packages=['pip'],
                                    pip_packages=['azureml-defaults',
                                                  'azureml-dataprep[pandas]'])
env.python.conda_dependencies = packages

script_config = ScriptRunConfig(source_directory='my_dir',
                                script='script.py',
                                arguments=['--ds', file_ds.as_download()],
                                environment=env)
```

_Script:_

```python
from azureml.core import Run
import glob

parser.add_argument('--ds', type=str, dest='ds_ref')
args = parser.parse_args()
run = Run.get_context()

imgs = glob.glob(args.ds_ref + "/*.jpg")
```

### Utilizar una entrada con nombre para un conjunto de datos de archivo

También puede pasar un conjunto de datos de archivos como una entrada con **nombre**. En este enfoque, utilice el método
**as_named_input** del conjunto de datos para especificar un nombre antes de especificar el modo de acceso. A continuación, 
en el script, puede recuperar el conjunto de datos por su nombre de la colección **input_datasets** del contexto de ejecución 
y leer los archivos desde allí. 

Al igual que con los conjuntos de datos tabulares, si utiliza una entrada con nombre, deberá incluir un argumento de script 
para el conjunto de datos, aunque en realidad no lo utilice para recuperar el conjunto de datos.

_ScriptRunConfig:_

```python
env = Environment('my_env')
packages = CondaDependencies.create(conda_packages=['pip'],
                                    pip_packages=['azureml-defaults',
                                                  'azureml-dataprep[pandas]'])
env.python.conda_dependencies = packages

script_config = ScriptRunConfig(source_directory='my_dir',
                                script='script.py',
                                arguments=['--ds', file_ds.as_named_input('my_ds').as_download()],
                                environment=env)
```

_Script:_

```python
from azureml.core import Run
import glob

parser.add_argument('--ds', type=str, dest='ds_ref')
args = parser.parse_args()
run = Run.get_context()

dataset = run.input_datasets['my_ds']
imgs= glob.glob(dataset + "/*.jpg")
```

## 4 Exercise Work with data
[< Back to Local Index](#4-index)

Ahora es su oportunidad de trabajar con datos en Azure Machine Learning.

En este ejercicio, usted

- Cargar datos en un almacén de datos
- Crear conjuntos de datos
- Utilizar conjuntos de datos para entrenar un modelo

### Instrucciones

1. Si aún no dispone de una suscripción a Azure, suscríbase a una prueba gratuita en
https://azure.microsoft.com.

2. Consulte el repositorio del ejercicio en
https://aka.ms/mslearn-dp100.

3. Si aún no lo ha hecho, complete el ejercicio Crear un espacio de trabajo de Azure Machine Learning para aprovisionar un espacio de trabajo de Azure Machine Learning, crear una instancia de cálculo y clonar los archivos necesarios.

4. Complete el ejercicio Trabajar con datos.

Como ya es costumbre, vamos a iniciar Corriendo nuestro: `Compute-instance` -> `Coursera-cpu`

![1.png](ims%2FC4%2Fims%2F4%2F1.png)

Y ahora vayamos al `Notebook` de: `06 - Work with Data.ipynb`

> ### Nota:
> El Notebook completo de esta clase está en: [06 - Work with Data.ipynb](ims%2FC4%2FNotebooks%2F06%20-%20Work%20with%20Data.ipynb)

![2.png](ims%2FC4%2Fims%2F4%2F2.png)

1. Como ya sabemos el primer paso sería abrir el Notebook de esta clase y verificar la versión de AML que estamos utilizando,
   asi como crear nuestro `ws` a partir de nuestro `config.json`:

   ![m1.gif](ims%2FC4%2Fgifs%2Fm1.gif)

2. Ahora en lugar de crear un nuevo `cluster` vamos a aprovechar que en la sesión anterior, ya habiamos creado uno llamado: `coursera-clsuter`
   el cuál sin problemas podemos volver a usar para esta clase:   
   ![m2.gif](ims%2FC4%2Fgifs%2Fm2.gif)

3. En el momento que creamos un `ws` se nos asigna por defecto un `datastore`al inicio cuando creamos el workspace: `mlw-dp100-labs`
   se nos asignaron un par de datastores.
   ![m3.gif](ims%2FC4%2Fgifs%2Fm3.gif)

4. Esto tambien lo podemos ver en: `Data/datastores` y notar los mismos nombres de datastores

   ![m4.gif](ims%2FC4%2Fgifs%2Fm4.gif)

5. Ahora veamos como nuestro repositorio clonado de `GitHub` ya contiene una carpeta llamada `Data` la cuál contiene dos archivos
   `.csv` sobre diabetes. Nuestro objetivo será sencillo: subir esos documentos a una carpeta llamada `diabetes-data` a nustro 
   `datastore` por defecto, podemos validar que el proceso es éxitoso entrando al mismo:

   ![m5.gif](ims%2FC4%2Fgifs%2Fm5.gif)

6. Ahora, una cosa es que el archivo ya este en la "nube" ya éxiste dentro del datastore default, pero debemos convertirlo en un `tabular dataset`,
   para eso de forma sencilla, apuntamos a nuestro `datastore` a la carpeta `diabetes-data` y podemos emplear todos los archivos que sean `.csv`

   ![m6.gif](ims%2FC4%2Fgifs%2Fm6.gif)

   De forma simple podemos ver las primeras 20 filas de nuestro ahora, tabular dataset 

7. Sin embargo, no siempre nuestros datos tendrán forma tabular, a veces serán archivos, y lo que debemos construir entonces es un `file Dataset` 
   que a diferencia del anterior lo que almacena es una lista que contiene la dirección a cada archivo:

   ![m7.gif](ims%2FC4%2Fgifs%2Fm7.gif)

8. Como ya hemos creado los datasets que vamos a utilizar uno `tabular` y otro del tipo `file` el siguiente paso es `registrarlos` para que esten
   `disponibles` para nuestros futuros experimentos

   ![m8.gif](ims%2FC4%2Fgifs%2Fm8.gif)

9. Podemos observar que ahora que han sido registrados podemos enlistarlos y no solo eso, ahora también éxisten dentro de `Data`, podemos ver
   cada uno de ellos de forma individual y ver como `Tabular` directamente nos regresa una vista del csv mientras que `File` nos regresa una vista previa de cada archivo.

   ![m9.gif](ims%2FC4%2Fgifs%2Fm9.gif)

10. **Entrenar un modelo con un dataset:**
   
   > Atención:
   > 
   > Este proceso puede parecer un poco rebuscado, pero en realidad NO es tan díficil como parece.  

   En las clases anteriores, habíamos visto que para entrenar un modelo, teníamos que tener un archivo de `training.py` que es el que 
   eventualmente crea un archivo .pkl, elige el modelo de scikit lear para entrenar, procesa los datos del dataframe etc.

   Sabíamos que teníamos que crear una carpeta y en dicha carpeta tenía que éxistir tanto el archivo .csv del dataset que iba a entrenar
   al modelo, como el código que generase el modelo. 
   
   Sin embargo, todo lo que hemos echo hasta ahora, ha sido para tener el dataset en la nube ya disponible en AZURE, entonces sería interesante
   que para entrenar el modelo utilicemos información que ya está en la nube.

   Lo que vamos a hacer entonces es que nuestro archivo de entrenamiento, contenga como parámetro un `alias` al dataset que vamos a utilizar que existe en AZURE. 

   ![m10.gif](ims%2FC4%2Fgifs%2Fm10.gif)

   _esto es como decirle que vas a utilizar un dataset a partir de su id_
   ```python
   parser.add_argument("--input-data", type=str, dest='training_dataset_id', help='training dataset')
   ```
   Sin embargo, en el proceso de `ScriptRunConfig`, NO es que pasemos literalmente un `id` al parámetro `--input-data` lo que hacemos es un poco más rebuscado. 

   _primero creamos un apuntador al dataset que nos interesa_

   ```python
   # Get the training dataset
   diabetes_ds = ws.datasets.get("diabetes dataset")
   ```
   
   _después, ahora vamos a enviar el id del dataset, pero con un nombre `alias` que en este caso es `training_data`_

   ```python
   # Create a script config
   script_config = ScriptRunConfig(source_directory=experiment_folder,
                                 script='diabetes_training.py',
                                 arguments = ['--regularization', 0.1, # Regularizaton rate parameter
                                              '--input-data', diabetes_ds.as_named_input('training_data')],
   ```

   Ahora efectivamente podemos crear nuestro experimento: `experiment_name = 'mslearn-train-diabetes'` y entrenar al modelo :D

11. Ahora, ya hemos corrido el experimento, pero le hemos puesto un nombre que ya habíamos utilizado en anteriores clases. Por eso cuando vayamos al apartado de `Jobs` veremos como
   ya teníamos experimentos anteriores asociados al mismo nombre, Pero eso no es mayor problema, solamente tenemos que ir al experimento más reciente, y podemos notar sus métricas
   y adicionalmente en `Code` observamos como es el código más reciente que hemos creado.
   ![m11.gif](ims%2FC4%2Fgifs%2Fm11.gif)

12. Ahora solo nos queda registrar el modelo, sabemos que podemos ponerle cualquier nombre, pero como a fin de cuentas todo lo que hemos hecho corresponde
   a un mismo dataset y a un mismo experimento, le vamos a poner el mismo nombre del modelo, con lo cuál creará una versión 3 del modelo `diabetes_model`
   podemos ir a la pestaña `Models` antes de correr el código para percatarnos de que antes no éxiste y después sí.
   ![m12.gif](ims%2FC4%2Fgifs%2Fm12.gif)

13. Ahora vamos a repetir básicamente el mismo proceso, pero en lugar de utilizar un `Tabular` dataset  estamos empleando un `File` dataset.

   ![m13.gif](ims%2FC4%2Fgifs%2Fm13.gif)

   Lo que más vale la pena destacar aqui. que es diferente al ejemplo pasado, es que ahora NO tuvimos directamente un `dataframe`, si no una lista que contiene los 
   directorios a diferentes archivos .csv, por eso usamos `blob` para ver la ruta a cada archivo, y cada uno de forma independiente lo abrimos y usamos pd.concat para 
   juntar todos en un solo dataframe:

   ```python
   # load the diabetes dataset
   print("Loading Data...")
   data_path = run.input_datasets['training_files'] # Get the training data path from the input
   # (You could also just use args.dataset_folder if you don't want to rely on a hard-coded friendly name)
   
   # Read the files
   all_files = glob.glob(data_path + "/*.csv")
   diabetes = pd.concat((pd.read_csv(f) for f in all_files), sort=False)
   ```
   Básicamente, esa es la principal diferencia, para cada `f` dentro de `all_files` leímos el archivo csv y lo concatenamos para finalmente rear `diabetes

14. Podemos correr el experimento con el mismo nombre, y observar los cambios.

   ![m14.gif](ims%2FC4%2Fgifs%2Fm14.gif)

15. Ahora, veamos los resultados del nuevo experimento, vemos como los resultados de AUC son ligeramente inferiores al experimento anterior.

   ![m15.gif](ims%2FC4%2Fgifs%2Fm15.gif)

16. Lo registramos para tener una versión 4 del modelo:

   ![m16.gif](ims%2FC4%2Fgifs%2Fm16.gif)

17. No olvidemos detener la instancia `compute` para que no nos cobren extra:

   ![m17.gif](ims%2FC4%2Fgifs%2Fm17.gif)

## 4 Exercise quiz
[< Back to Local Index](#4-index)

![1.png](ims%2FC4%2Ftest%2F1.png)

## 4 Knowledge check
[< Back to Local Index](#4-index)

![q1.png](ims%2FC4%2Ftest%2Fq1.png)

![q2.png](ims%2FC4%2Ftest%2Fq2.png)

![q3.png](ims%2FC4%2Ftest%2Fq3.png)

## 4 Lesson summary
[< Back to Local Index](#4-index)

![1.png](ims%2FC4%2Fims%2F5%2F1.png)

En esta lección, ha aprendido cómo trabajar con datos en Azure Machine Learning. Más concretamente, ha aprendido cómo crear y utilizar almacenes de datos, y crear y utilizar conjuntos de datos. 

![2.png](ims%2FC4%2Fims%2F5%2F2.png)

Para más detalles sobre cómo trabajar con datos en Azure Machine Learning, consulte la página web sobre acceso a datos en Azure Machine Learning, que está disponible en el sitio web de Microsoft. Puede encontrar un enlace a esta página web desde las lecturas adicionales al final de esta lección.

## 4 Additional Reading
[< Back to Local Index](#4-index)

**Introduction to datastores**

[Secure data access in Azure Machine Learning](https://docs.microsoft.com/en-us/azure/machine-learning/concept-data#access-data-in-storage)
**Working with data**

[Secure data access in Azure Machine Learning](https://docs.microsoft.com/en-us/azure/machine-learning/concept-data#access-data-in-storage)

# 5 Work with Compute in Azure Machine Learning

## 5 INDEX

- [5 Lesson introduction](#5-lesson-introduction)
- [5 Environments in Azure Machine Learning](#5-environments-in-azure-machine-learning)
- [5 Creating environments](#5-creating-environments)
- [5 Introduction to compute targets](#5-introduction-to-compute-targets)
- [5 Create compute targets](#5-create-compute-targets)
- [5 Use compute targets](#5-use-compute-targets)
- [5 Exercise Work with Compute Contexts](#5-exercise-work-with-compute-contexts)
- [5 Exercise quiz](#5-exercise-quiz)
- [5 Knowledge check](#5-knowledge-check)
- [5 Test prep](#5-test-prep)
- [5 Lesson summary](#5-lesson-summary)
- [5 Additional reading](#5-additional-reading)

[< Back to index](#0-index)

## 5 Lesson introduction
[< Back to Local Index](#5-index)

![1.png](ims%2FC5%2Fims%2F1%2F1.png)

Hola. En esta lección, aprenderá a trabajar con computación en Azure Machine Learning. En Azure Machine Learning, los 
científicos de datos pueden ejecutar experimentos basados en scripts que procesan datos, entrenan modelos de aprendizaje 
automático y realizan otras tareas de ciencia de datos. 

![2.png](ims%2FC5%2Fims%2F1%2F2.png)

El contexto de ejecución de cada experimento consta de dos elementos. El **entorno para el script**, que incluye todos los 
paquetes de los que depende el script y **el objetivo de computación** en el que se desplegará el entorno y ejecutará el script. 

![3.png](ims%2FC5%2Fims%2F1%2F3.png)

En esta lección, aprenderá a crear y utilizar entornos y a crear y utilizar objetivos de computación.

## 5 Environments in Azure Machine Learning
[< Back to Local Index](#5-index)

![1.png](ims%2FC5%2Fims%2F2%2F1.png)

El código Python se ejecuta en el contexto de un entorno virtual que define la versión de el tiempo de ejecución de Python 
que se utilizará, así como los paquetes instalados disponibles para el código. En la mayoría de las instalaciones de Python, 
los paquetes se instalan y gestionan en entornos utilizando Conda o Pip.

![2.png](ims%2FC5%2Fims%2F2%2F2.png)

Para mejorar la portabilidad, solemos crear entornos en contenedores docker que a su vez se alojan en objetivos informáticos 
como su ordenador de desarrollo, máquinas virtuales o clústeres en la Nube. 

![3.png](ims%2FC5%2Fims%2F2%2F3.png)

n general, Azure Machine Learning gestiona la creación de entornos y la instalación de paquetes por usted, normalmente a 
través de la creación de contenedores docker. 

![4.png](ims%2FC5%2Fims%2F2%2F4.png)

Puede especificar los paquetes Conda o Pip que necesite, y hacer que Azure Machine Learning cree un entorno para el experimento. 

![5.png](ims%2FC5%2Fims%2F2%2F5.png)

En una solución de aprendizaje automático empresarial, donde los experimentos pueden ejecutarse en una variedad de contextos 
informáticos, puede ser importante ser consciente de los entornos en los que se ejecuta el código de su experimento. Los 
entornos están encapsulados por la clase environment, que puede utilizar para crear entornos y especificar la configuración 
de tiempo de ejecución para un experimento. Puede hacer que Azure Machine Learning gestione la creación de entornos, y la 
instalación de paquetes para definir un entorno, y luego registrarlo para su reutilización. 

![6.png](ims%2FC5%2Fims%2F2%2F6.png)

![7.png](ims%2FC5%2Fims%2F2%2F7.png)

Alternativamente, puede gestionar sus propios entornos y registrarlos. Esto hace posible definir contextos de tiempo de 
ejecución reutilizables y consistentes para sus experimentos, independientemente de dónde se ejecute el script del experimento.

## 5 Creating environments
[< Back to Local Index](#5-index)

Hay varias formas de crear entornos en Azure Machine Learning.

### Creación de un entorno a partir de un archivo de especificación

Puede utilizar un archivo de especificación Conda o pip para definir los paquetes necesarios en un entorno Python, y 
utilizarlo para crear un objeto **Entorno**.

Por ejemplo, podría guardar los siguientes ajustes de configuración de Conda en un archivo llamado **conda.yml**:

```yaml
name: py_env
dependencies:
  - numpy
  - pandas
  - scikit-learn
  - pip:
    - azureml-defaults
```

A continuación, podría utilizar el siguiente código para crear un entorno Azure Machine Learning a partir del archivo de 
especificaciones guardado:

```python
from azureml.core import Environment

env = Environment.from_conda_specification(name='training_environment',
                                           file_path='./conda.yml')
```

### Creación de un entorno a partir de un entorno Conda existente

Si tiene un entorno **Conda** existente definido en su estación de trabajo, puede utilizarlo para definir un entorno 
Azure Machine Learning:

```python
from azureml.core import Environment

env = Environment.from_existing_conda_environment(name='training_environment',
                                                  conda_environment_name='py_env')
```

### Creación de un entorno especificando paquetes

Puede definir un entorno especificando los paquetes Conda y pip que necesita en un objeto **CondaDependencies**, de esta forma:

```python
from azureml.core import Environment
from azureml.core.conda_dependencies import CondaDependencies

env = Environment('training_environment')
deps = CondaDependencies.create(conda_packages=['scikit-learn','pandas','numpy'],
                                pip_packages=['azureml-defaults'])
env.python.conda_dependencies = deps
```

### Configuración de contenedores de entorno

Normalmente, los entornos para experimentos script se crean en **contenedores**. El siguiente código configura un experimento 
basado en script para alojar el entorno env creado previamente en un contenedor (esto es lo predeterminado a menos que 
utilice un **DockerConfiguration** con un atributo **use_docker** de **False**, en cuyo caso el entorno se crea directamente 
en el objetivo de computación)

```python
from azureml.core import Experiment, ScriptRunConfig
from azureml.core.runconfig import DockerConfiguration

docker_config = DockerConfiguration(use_docker=True)

script_config = ScriptRunConfig(source_directory='my_folder',
                                script='my_script.py',
                                environment=env,
                                docker_runtime_config=docker_config)
```

Azure Machine Learning utiliza una biblioteca de imágenes base para contenedores, eligiendo la base apropiada para el 
objetivo de computación que especifique (por ejemplo, incluyendo soporte Cuda para computación basada en GPU). Si ha creado 
imágenes de contenedor personalizadas y las ha registrado en un registro de contenedores, puede anular las imágenes base 
predeterminadas y utilizar las suyas propias modificando los atributos de la propiedad **docker** del entorno.

```python
env.docker.base_image='my-base-image'
env.docker.base_image_registry='myregistry.azurecr.io/myimage'
```

Alternativamente, puede hacer que se cree una imagen bajo demanda basada en la imagen base y en ajustes adicionales en un archivo dockerfile.

```python
env.docker.base_image = None
env.docker.base_dockerfile = './Dockerfile'
```

Por defecto, Azure machine Learning gestiona las rutas de Python y las dependencias de los paquetes. Si su imagen ya incluye 
una instalación de Python con las dependencias que necesita, puede anular este comportamiento estableciendo **python.user_managed_dependencies** 
en **True** y estableciendo una ruta Python explícita para su instalación.

```python
env.python.user_managed_dependencies=True
env.python.interpreter_path = '/opt/miniconda/bin/python'
```

### Registro y reutilización de entornos

Después de haber creado un entorno, puede registrarlo en su espacio de trabajo y reutilizarlo para futuros experimentos 
que tengan las mismas dependencias de Python.

### Registrar un entorno

Utilice el método **register** de un objeto **Environment** para registrar un entorno:

```python
env.register(workspace=ws)
```

Así puede ver los entornos registrados en su espacio de trabajo:

```python
from azureml.core import Environment

env_names = Environment.list(workspace=ws)
for env_name in env_names:
    print('Name:',env_name)
```

### Recuperar y utilizar un entorno

Puede recuperar un entorno registrado utilizando el método **get** de la clase **Environment** y, a continuación, asignarlo 
a un **ScriptRunConfig**.

Por ejemplo, el siguiente ejemplo de código recupera el entorno registrado **training_environment**, y lo asigna a una 
configuración de ejecución de script:

```python
from azureml.core import Environment, ScriptRunConfig

training_env = Environment.get(workspace=ws, name='training_environment')

script_config = ScriptRunConfig(source_directory='my_folder',
                                script='my_script.py',
                                environment=training_env)
```

Cuando se ejecute un experimento basado en el estimador, Azure Machine Learning buscará un entorno existente que coincida 
con la definición y, si no se encuentra ninguno, se creará un nuevo entorno basado en la especificación del entorno registrado.

## 5 Introduction to compute targets
[< Back to Local Index](#5-index)

![1.png](ims%2FC5%2Fims%2F3%2F1.png)

Bienvenido a esta sección en la que aprenderá sobre los objetivos de computación. En Azure Machine Learning, los objetivos 
de computación son ordenadores físicos o virtuales en los que se ejecutan los experimentos.

![2.png](ims%2FC5%2Fims%2F3%2F2.png)

Azure Machine Learning admite múltiples tipos de computación para la experimentación y el entrenamiento. Esto le permite 
seleccionar el tipo de objetivo de computación más apropiado para sus necesidades particulares. Estos tipos incluyen: 
computación local, clusters de computación y computación adjunta. Veamos ahora cada uno de ellos con un poco más de detalle.

![3.png](ims%2FC5%2Fims%2F3%2F3.png)

Puede especificar un objetivo de computación local para la mayoría de las tareas de procesamiento en Azure Machine Learning. 
Esto ejecuta el experimento en el mismo objetivo de computación que el código utilizado para iniciar el experimento. 
Esta puede ser su estación de trabajo física o una máquina virtual como una instancia de computación de Azure Machine 
Learning en la que esté ejecutando un cuaderno. La computación local es generalmente una gran elección durante el desarrollo 
y las pruebas, con volúmenes de datos de bajos a moderados.

![4.png](ims%2FC5%2Fims%2F3%2F4.png)

Para cargas de trabajo de experimentos con altos requisitos de escalabilidad, puede utilizar los clústeres de computación 
de Azure Machine Learning, que son clústeres de múltiples nodos de máquinas virtuales que se escalan automáticamente hacia 
arriba o hacia abajo para satisfacer la demanda. Esta es una forma rentable de ejecutar experimentos que necesitan manejar 
grandes volúmenes de datos, o utilizar el procesamiento paralelo para distribuir la carga de trabajo y reducir el tiempo 
que tarda en ejecutarse. 

![5.png](ims%2FC5%2Fims%2F3%2F5.png)

Si ya utiliza un entorno de computación basado en Azure para la ciencia de datos, como una máquina virtual o un clúster 
Azure Databricks, puede adjuntarlo a su espacio de trabajo Azure Machine Learning y utilizarlo como objetivo de computación 
para determinados tipos de carga de trabajo.

![6.png](ims%2FC5%2Fims%2F3%2F6.png)

Es importante señalar que en Azure Machine Learning Studio, puede crear otro tipo de computación denominada clústeres de 
inferencia. Este tipo de computación representa un clúster de Azure Kubernetes Service, y sólo puede utilizarse para 
desplegar modelos entrenados como servicios de inferencia. Exploraremos el despliegue más adelante, pero por ahora nos 
centramos en la computación para experimentos y entrenamiento de modelos. 

![7.png](ims%2FC5%2Fims%2F3%2F7.png)

La capacidad de asignar ejecuciones de experimentos a objetivos de computación específicos le ayuda a implementar un ecosistema 
de ciencia de datos flexible de las siguientes maneras. El código puede desarrollarse y probarse en computación local o 
de bajo coste y luego trasladarse a computación más escalable para cargas de trabajo de producción.

![8.png](ims%2FC5%2Fims%2F3%2F8.png)

Puede ejecutar procesos individuales en el objetivo de computación que mejor se adapte a sus necesidades. Por ejemplo, 
utilizando computación basada en CPU para entrenar modelos de aprendizaje profundo, y cambiando a computación basada 
únicamente en CPU de menor coste para probar y registrar el modelo entrenado. 

![9.png](ims%2FC5%2Fims%2F3%2F9.png)

Una de las principales ventajas de la computación en nube es la capacidad de gestionar los costes pagando sólo por lo que se utiliza.

![10.png](ims%2FC5%2Fims%2F3%2F10.png)

En Azure Machine Learning, puede aprovechar este principio definiendo objetivos de computación que se inician bajo demanda 
y se detienen automáticamente cuando ya no son necesarios, y se escalan automáticamente basándose en las necesidades de 
procesamiento de la carga de trabajo.

## 5 Create compute targets
[< Back to Local Index](#5-index)

Las formas más comunes de crear o adjuntar un objetivo de cómputo son utilizar la página de **cómputo** en Azure Machine 
Learning studio, o utilizar el SDK de Azure Machine Learning para aprovisionar objetivos de cómputo en código.

### Creación de un objetivo de cálculo gestionado con el SDK

Un objetivo de computación _gestionado_ es aquel que está gestionado por Azure Machine Learning, como un clúster de 
computación de Azure Machine Learning.

Para crear un clúster de computación de Azure Machine Learning, utilice la clase **azureml.core.compute.ComputeTarget** y 
la clase **AmlCompute**, como en este ejemplo.

```python
from azureml.core import Workspace
from azureml.core.compute import ComputeTarget, AmlCompute

# Load the workspace from the saved config file
ws = Workspace.from_config()

# Specify a name for the compute (unique within the workspace)
compute_name = 'aml-cluster'

# Define compute configuration
compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_DS11_V2',
                                                       min_nodes=0, max_nodes=4,
                                                       vm_priority='dedicated')

# Create the compute
aml_cluster = ComputeTarget.create(ws, compute_name, compute_config)
aml_cluster.wait_for_completion(show_output=True)
```

En este ejemplo, se creará un clúster con hasta cuatro nodos basado en la imagen de máquina virtual **STANDARD_DS12_v2.** 
La prioridad para las máquinas virtuales (VM) se establece en **dedicada**, lo que significa que están reservadas para su 
uso en este clúster (la alternativa es especificar prioridad baja, que tiene un coste **menor** pero significa que las VM 
pueden ser adelantadas si una carga de trabajo de mayor prioridad requiere el cómputo).

> Nota:
> 
> Para obtener una lista completa de las opciones de configuración de [AmlCompute](https://aka.ms/AA70zfq),
> consulte la documentación del SDK de la clase [AmlCompute](https://aka.ms/AA70zfq).

### Adjuntar un objetivo de computación no gestionado con el SDK

Un objetivo de cálculo _no gestionado_ es aquel que se define y gestiona fuera del espacio de trabajo de Azure Machine Learning; 
por ejemplo, una máquina virtual Azure o un clúster Azure Databricks.

El código para adjuntar un objetivo de cómputo no gestionado existente es similar al código utilizado para crear un objetivo 
de cómputo gestionado, excepto que debe utilizar el método **ComputeTarget.attach()** para adjuntar el cómputo existente 
basándose en sus ajustes de configuración específicos del objetivo.

Por ejemplo, el siguiente código puede utilizarse para adjuntar un clúster Azure Databricks existente:

```python
from azureml.core import Workspace
from azureml.core.compute import ComputeTarget, DatabricksCompute

# Load the workspace from the saved config file
ws = Workspace.from_config()

# Specify a name for the compute (unique within the workspace)
compute_name = 'db_cluster'

# Define configuration for existing Azure Databricks cluster
db_workspace_name = 'db_workspace'
db_resource_group = 'db_resource_group'
db_access_token = '1234-abc-5678-defg-90...'
db_config = DatabricksCompute.attach_configuration(resource_group=db_resource_group,
                                                   workspace_name=db_workspace_name,
                                                   access_token=db_access_token)

# Create the compute
databricks_compute = ComputeTarget.attach(ws, compute_name, db_config)
databricks_compute.wait_for_completion(True)
```

### Comprobación de un objetivo de computación existente

En muchos casos, querrá comprobar la existencia de un objetivo de cómputo, y sólo crear uno nuevo si no hay ya uno con 
el nombre especificado. Para lograrlo, puede capturar la excepción **ComputeTargetException**, de la siguiente manera:

```python
from azureml.core.compute import ComputeTarget, AmlCompute
from azureml.core.compute_target import ComputeTargetException

compute_name = "aml-cluster"

# Check if the compute target exists
try:
    aml_cluster = ComputeTarget(workspace=ws, name=compute_name)
    print('Found existing cluster.')
except ComputeTargetException:
    # If not, create it
    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_DS11_V2',
                                                           max_nodes=4)
    aml_cluster = ComputeTarget.create(ws, compute_name, compute_config)

aml_cluster.wait_for_completion(show_output=True)
```

> **Más información:** Para obtener más información sobre la creación de objetivos de cálculo, consulte
[Configurar y utilizar objetivos de cálculo para el entrenamiento de modelos](https://aka.ms/AA70rrg)
 en la documentación de Azure Machine Learning.

## 5 Use compute targets
[< Back to Local Index](#5-index)

Después de haber creado o adjuntado objetivos de cálculo en su espacio de trabajo, puede utilizarlos para ejecutar cargas 
de trabajo específicas; como experimentos.

Para utilizar un objetivo de cálculo concreto, puede especificarlo en el parámetro adecuado para una configuración de 
ejecución de experimentos o un estimador. Por ejemplo, el siguiente código configura un estimador para que utilice el 
objetivo de cálculo denominado _aml-cluster_:

```python
from azureml.core import Environment, ScriptRunConfig

compute_name = 'aml-cluster'

training_env = Environment.get(workspace=ws, name='training_environment')

script_config = ScriptRunConfig(source_directory='my_dir',
                                script='script.py',
                                environment=training_env,
                                compute_target=compute_name)
```

Cuando se envíe un experimento, la ejecución se pondrá en cola mientras se inicia el objetivo de cálculo _aml-cluster_ y 
se crea en él el entorno especificado, y luego la ejecución se procesará en el entorno de cálculo.

En lugar de especificar el nombre del objetivo de cómputo, puede especificar un objeto _ComputeTarget_, así:

```python
from azureml.core import Environment, ScriptRunConfig
from azureml.core.compute import ComputeTarget

compute_name = "aml-cluster"

training_cluster = ComputeTarget(workspace=ws, name=compute_name)

training_env = Environment.get(workspace=ws, name='training_environment')

script_config = ScriptRunConfig(source_directory='my_dir',
                                script='script.py',
                                environment=training_env,
                                compute_target=training_cluster)
```

## 5 Exercise Work with Compute Contexts
[< Back to Local Index](#5-index)

Ahora es su oportunidad de trabajar con entornos y objetivos de computación en Azure Machine Learning.

En este ejercicio, usted podrá:

- Crear y utilizar un entorno.

- Crear y utilizar un objetivo de cómputo.

### Instrucciones

Siga estas instrucciones para completar el ejercicio.

1. Si aún no tiene una suscripción a Azure, regístrese para una prueba gratuita en
https://azure.microsoft.com.

2. Consulte el repositorio del ejercicio en
https://aka.ms/mslearn-dp100.

3. Si aún no lo ha hecho, complete el ejercicioCrear un espacio de trabajo de Azure Machine Learning para aprovisionar un espacio de trabajo de Azure Machine Learning, crear una instancia de computación y clonar los archivos necesarios.

4. Complete el ejercicio **Trabajar con computación**.

### Notebook

Como ya es costumbre, vamos a iniciar Corriendo nuestro: `Compute-instance` -> `Coursera-cpu`

> ### Nota
> El notebook de esta clase está en: [07 - Work with Compute.ipynb](ims%2FC5%2FNotebooks%2F07%20-%20Work%20with%20Compute.ipynb)

![1.png](ims%2FC4%2Fims%2F4%2F1.png)

1. Empezamos con lo básico: creamos nuestro `ws` a partir de nuestra configuración y checamos la versión de AML que usamos

   ![m1.gif](ims%2FC5%2Fgifs%2Fm1.gif)

2. En el notebook anterior ya habiamos registrado un `tabular dataset` de `diabetes dataset`, el cuál podemos verificar en la pestaña de `Data`
   como ya éxiste, entonces sol estamos comprobando que esté registrado, sino entonces lo hubieramos creado con ese código.
   ![m2.gif](ims%2FC5%2Fgifs%2Fm2.gif)

3. Como ya es común, vamos a crear una nueva carpeta `diabetes_training_logistic` para entrenar a nuestro modelo de confianza `logistic_regerssion`
   para este punto ya somos conscientes de como se usa un script con parámetros y que uno de esos parámetros sea el `dataset` y que tenga un:
   `alias` en este caso llamado `training_data
   ![m3.gif](ims%2FC5%2Fgifs%2Fm3.gif)

4. Ahora, vamos a crear un archivo `.yml` (env.yml) que contiene la versión de python a utilizar así como los paquetes `conda` a instalar y los paquetes `pip`
   > Nota: no queda claro porque algunos paquetes son con Conda y otros con Pip
   ![m4.gif](ims%2FC5%2Fgifs%2Fm4.gif)

5. Creamos un `experiment_env` a partir de nuestro `env.yml` que esta en la carpeta `diabetes_training_logistic` y vamos a hacer que la gestion de paquetes NO sea por el contenedor Docker, sino por AZURE.

   ![m5.gif](ims%2FC5%2Fgifs%2Fm5.gif)

6. Con el environment creado ya podemos correr el `RunScriptConfig`, apuntamos al folder, al archivo `.py` obtenemos con un `get` el `diabetes dataset` que esta cargado en Azure, 
   le ponemos como `alias`: `training dataset`, especificamos el `.env` que ya creamos, y finalmente, usamos un `contenedor Docker`

   ![m6.gif](ims%2FC5%2Fgifs%2Fm6.gif)

7. **Veamos los resultados:**
   Podemos ver los resultados de ACU y ACC y en `Jobs` podemos ver nuestro último experimento, con sus métricas e imágenes creadas y también en outputs el modelo `.pkl` generado y en `code` también vemos
   NO solo el archivo .py sino también el archivo `.yml` que usamos para crear el `.env`
   ![m7.gif](ims%2FC5%2Fgifs%2Fm7.gif)

8. Vamos a registrar nuestro nuevo `custom environment` para después usarlo en posteriores proyectos:

   ![m8.gif](ims%2FC5%2Fgifs%2Fm8.gif)  
   
   Podemos observar como realmente nuestro `environment` se ha registrado con éxito :D

9. Nuestro objetivo ahora es crear un nuevo experimento, usar el mismo dataset PERO utilizar un nuevo modelo: `DecisionTreeClassifier`
   Ya conocemos el path: crear un folder y crear el `training.py` y poner como argumento el dataset. Al utilizar un `DTC` NO pasamos el parámetro `--regularization` porque NO tiene ese parámetro.
   ![m9.gif](ims%2FC5%2Fgifs%2Fm9.gif)

10. El objetivo es utilizar `Environment.get(ws, nombre)` para obtener el `environment` que ya creamos anteriormente. De ahí en fuera todo igual

   ![m10.gif](ims%2FC5%2Fgifs%2Fm10.gif)

11. Veamos los resultados del modelo. Ahora nuestro ACC ha aumentado ligeramente a 0.89 y AUC a 0.88 

   ![m11.gif](ims%2FC5%2Fgifs%2Fm11.gif)

12. Vamos a asegurarnos de enlistar los ambientes registrados y ver como sí éxiste `experiment env`

   ![m12.gif](ims%2FC5%2Fgifs%2Fm12.gif)

13. Vamos a crear un nuevo `Cluster`, esto ya lo hemos hecho antes, de echo lo hicimos para crear nuestro `coursera-cluster` ahora hacemos lo mismo para crear un `test-cluster` 

   ![m13.gif](ims%2FC5%2Fgifs%2Fm13.gif)

14. Lo interesante NO es solo checar que hicimos un nuevo `cluster` sino ahora utilizarlo explícitamente para correr un nuevo experimento.

   ![m14.gif](ims%2FC5%2Fgifs%2Fm14.gif)

15. vemos como ahora hemos declarado explícitamente nuestro `compute target`

   ![m15.gif](ims%2FC5%2Fgifs%2Fm15.gif)

16. Efectivamente el `cluster` está corriendo:

   ![m16.gif](ims%2FC5%2Fgifs%2Fm16.gif)

17. Finalmente, veamos los resultados del experimento y registremos nuestro más reciente modelo:

   ![m17.gif](ims%2FC5%2Fgifs%2Fm17.gif)

18. Adicionalmente, podemos ver algo muy interesante:
   Podemos comprobar como hemos utilizado específicamente el `custom environment` que hemos creado anteriormente.
   ![m18.gif](ims%2FC5%2Fgifs%2Fm18.gif)

19. Como paso final, debemos detener nuestro `compute instance`:

   ![1.png](ims%2FC5%2Fgifs%2F1.png)


## 5 Exercise quiz
[< Back to Local Index](#5-index)

![0.png](ims%2FC5%2Ftest%2F0.png)

## 5 Knowledge check
[< Back to Local Index](#5-index)

![q1.png](ims%2FC5%2Ftest%2Fq1.png)

![q2.png](ims%2FC5%2Ftest%2Fq2.png)

![q3.png](ims%2FC5%2Ftest%2Fq3.png)

![q4.png](ims%2FC5%2Ftest%2Fq4.png)

## 5 Test prep
[< Back to Local Index](#5-index)

![w1.png](ims%2FC5%2Ftest%2Fw1.png)

![w2.png](ims%2FC5%2Ftest%2Fw2.png)

![w3.png](ims%2FC5%2Ftest%2Fw3.png)

![w4.png](ims%2FC5%2Ftest%2Fw4.png)

![w5.png](ims%2FC5%2Ftest%2Fw5.png)

![w6.png](ims%2FC5%2Ftest%2Fw6.png)

## 5 Lesson summary
[< Back to Local Index](#5-index)

![1.png](ims%2FC5%2Fims%2F4%2F1.png)

En este módulo, ha aprendido cómo trabajar con computación en Azure Machine Learning. Más concretamente, ha aprendido cómo crear y utilizar entornos, y crear y utilizar objetivos de computación.

![2.png](ims%2FC5%2Fims%2F4%2F2.png)

Para obtener más información sobre entornos en Azure Machine Learning, consulte reutilizar entornos para la formación y el despliegue mediante Azure Machine Learning.

![3.png](ims%2FC5%2Fims%2F4%2F3.png)

Para más información sobre los objetivos de computación en Azure Machine Learning, consulte qué son los objetivos de computación en Azure Machine Learning. Puede encontrar un enlace a estos recursos desde las lecturas adicionales al final de esta lección.

## 5 Additional reading
[< Back to Local Index](#5-index)

**Environments in Azure Machine Learning** 

[Reuse environments for training and deployment by using Azure Machine Learning](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-use-environments)

**Compute targets in Azure Machine Learning**

[What are compute targets in Azure Machine Learning](https://docs.microsoft.com/en-us/azure/machine-learning/concept-compute-target)

# 6 Orchestrate Machine Learning with Pipelines


## 6 INDEX

- [6 Lesson introduction](#6-lesson-introduction)
- [6 Introduction to pipelines](#6-introduction-to-pipelines)
- [6 Pass data between pipeline steps](#6-pass-data-between-pipeline-steps)
- [6 OutputFileDatasetConfig Step Inputs and Outputs](#6-outputfiledatasetconfig-step-inputs-and-outputs)
- [6 Reuse pipeline steps](#6-reuse-pipeline-steps)
- [6 Publish pipelines](#6-publish-pipelines)
- [6 Use pipelines parameters](#6-use-pipelines-parameters)
- [6 Schedule pipelines](#6-schedule-pipelines)
- [6 Exercise Create a pipeline](#6-exercise-create-a-pipeline)
- [6 Exercise quiz](#6-exercise-quiz)
- [6 Knowledge Check](#6-knowledge-check)
- [6 Lesson summary](#6-lesson-summary)
- [6 Additional Reading](#6-additional-reading)

[< Back to index](#0-index)

## 6 Lesson introduction
[< Back to Local Index](#6-index)

![1.png](ims%2FC6%2Fims%2F1%2F1.png)

Hola. En Azure Machine Learning, usted ejecuta cargas de trabajo como experimentos, pero aprovechando los activos de 
datos y los recursos de computación. En un proceso de ciencia de datos empresarial, generalmente querrá separar el proceso 
general en tareas individuales y orquestar estas tareas como Pipelines de pasos conectados.

![2.png](ims%2FC6%2Fims%2F1%2F2.png)

Los pipelines son clave para implementar una solución eficaz de aprendizaje automático operacionalización o MLOps en Azure. 
Explorará cómo definirlos y ejecutarlos en este módulo. 

![3.png](ims%2FC6%2Fims%2F1%2F3.png)

Es importante tener en cuenta que el término pipeline se utiliza ampliamente en el aprendizaje automático, a menudo con 
diferentes significados. Por ejemplo, en Scikit-learn, puede definir pipelines que combinen transformaciones de 
preprocesamiento de datos con un algoritmo de entrenamiento, y en Azure DevOps, puede definir un pipeline de construcción 
o lanzamiento para realizar las tareas de construcción y configuración necesarias para entregar software. Este módulo se 
centra en pipelines de aprendizaje automático de Azure, que encapsula pasos que pueden ejecutarse como un experimento.

![4.png](ims%2FC6%2Fims%2F1%2F4.png)

Sin embargo, es importante tener en mente que es perfectamente factible tener un canal Azure DevOps con una tarea que inicie 
un canal Azure Machine Learning, que a su vez incluya un paso que entrene un modelo que esté basado en un canal Scikit-learn. 

![5.png](ims%2FC6%2Fims%2F1%2F5.png)

En esta lección, aprenderá a crear un canal de Azure Machine Learning, publicar en canal de Azure Machine Learning, y 
programar un canal de Azure Machine Learning.

## 6 Introduction to pipelines
[< Back to Local Index](#6-index)

![1.png](ims%2FC6%2Fims%2F2%2F1.png)

En el aprendizaje automático de Azure, una canalización es un tipo de flujo de trabajo, es un flujo de trabajo de tareas 
de aprendizaje automático en el que cada tarea se implementa como un paso. 

![2.png](ims%2FC6%2Fims%2F2%2F2.png)

Estos pasos pueden organizarse secuencialmente o en paralelo, lo que le permite construir una sofisticada lógica de flujo 
para orquestar las operaciones de aprendizaje automático.

![3.png](ims%2FC6%2Fims%2F2%2F3.png)

Cada paso puede ejecutarse en un objetivo de cómputo específico, lo que hace posible combinar diferentes tipos de 
procesamiento según sea necesario para lograr un objetivo general. 

![4.png](ims%2FC6%2Fims%2F2%2F4.png)

Una canalización puede ejecutarse como un proceso ejecutando la canalización como un experimento. Entonces, cada paso de 
la canalización se ejecuta en su objetivo de computación asignado como parte de la ejecución general del experimento.

![5.png](ims%2FC6%2Fims%2F2%2F5.png)

Una canalización de aprendizaje automático de Azure consta de uno o más pasos que realizan tareas. Existen muchos tipos 
de pasos admitidos por las canalizaciones de aprendizaje automático de Azure, cada uno con su propio propósito especializado 
y opciones de configuración. 

![6.png](ims%2FC6%2Fims%2F2%2F6.png)

Los tipos comunes de pasos en una canalización de aprendizaje automático de Azure incluyen:

- **PythonScriptStep**, ejecuta un script Python especificado. 
- **DataTransferStep**, utiliza la fábrica de datos de Azure para copiar datos entre almacenes de datos. 
- **DataBrickStep**, ejecuta un script de cuaderno o un jar compilado en un clúster de ladrillos de datos. 
- **AdlaStep**, ejecuta un trabajo de secuela de uso en Azure Data lake analytics. 
- **ParallelRunStep**, ejecuta un script Python como una tarea distribuida en múltiples nodos de computación. 

![7.png](ims%2FC6%2Fims%2F2%2F7.png)

Es importante tener en cuenta que para obtener una lista completa de los tipos de pasos soportados, consulte 
[Azure.pipeline.steps](https://docs.microsoft.com/en-us/python/api/azureml-pipeline-steps/azureml.pipeline.steps?view=azure-ml-py) package documentation. Puede encontrar un enlace a este documento en las lecturas adicionales al final de esta lección. 

![8.png](ims%2FC6%2Fims%2F2%2F8.png)


![9.png](ims%2FC6%2Fims%2F2%2F9.png)

Para crear una canalización, primero debe definir cada paso y después crear una canalización que incluya los pasos. 

![10.png](ims%2FC6%2Fims%2F2%2F10.png)

La configuración específica de cada paso depende del tipo de paso, por ejemplo, puede utilizar un código que defina dos 
pasos de script Python para preparar los datos y luego entrenar un modelo. 

![11.png](ims%2FC6%2Fims%2F2%2F11.png)

Una vez definidos estos pasos, puede asignarlos a una canalización y ejecutarla como un experimento.

## 6 Pass data between pipeline steps
[< Back to Local Index](#6-index)

![1.png](ims%2FC6%2Fims%2F3%2F1.png)

A menudo, una canalización incluye al menos un paso que depende de la salida de un paso anterior. 
![2.png](ims%2FC6%2Fims%2F3%2F2.png)

Por ejemplo, puede utilice un paso que desee que un script de Python preprocesar algunos datos, que luego deben usarse en 
un paso posterior para entrenar un modelo.


![3.png](ims%2FC6%2Fims%2F3%2F3.png)

El **OutputFileDatasetConfig** es un conjunto de datos especial. Es el conjunto de datos que hace referencia a una ubicación 
en un almacén de datos para el almacenamiento provisional de datos y crea una dependencia de datos entre los pasos de la canalización.

![4.png](ims%2FC6%2Fims%2F3%2F4.png)

Puede ver un archivo de salida objeto de configuración del conjunto de datos como almacén intermediario para los datos que 
deben pasarse de un paso a un paso posterior.


![5.png](ims%2FC6%2Fims%2F3%2F5.png)

Como se recomienda, puede usar **OutputFileDatasetConfig** para pasar datos entre los pasos. Para ello, debe 

- Definir un archivo de salida con nombre objeto de configuración de conjunto de datos que hace referencia a ubicación en un almacén de datos.
  (Si no es explícito Se especifica el almacén de datos, se utiliza el almacén de datos predeterminado.)
- Pase el archivo de salida el objeto de configuración del conjunto de datos como argumento de script en pasos que ejecutan 
scripts.
- Incluya código en ellos scripts para escribir en el conjunto de datos del archivo de salida argumento de configuración 
como salida o lectura como entrada.

  
![6.png](ims%2FC6%2Fims%2F3%2F6.png)

Por ejemplo, puedes usar código que defina un **OutputFileDatasetConfig**  para los datos preprocesados. 

![7.png](ims%2FC6%2Fims%2F3%2F7.png)

En los propios scripts, puede obtener una referencia **OutputFileDatasetConfig**  el objeto a partir del argumento del 
script y utilice es como una carpeta local. Puede acceder al versión completa de este código desde la lectura al final 
de esta lección.

## 6 OutputFileDatasetConfig Step Inputs and Outputs
[< Back to Local Index](#6-index)

Para utilizar un objeto **OutputFileDatasetConfig** para pasar datos entre pasos, debes:

1. Definir un objeto **OutputFileDatasetConfig** con nombre que haga referencia a una ubicación en un almacén de datos. 
Si no se especifica un almacén de datos explícito, se usará el almacén de datos predeterminado.

2. Pasar el objeto **OutputFileDatasetConfig** como argumento de script en los pasos que ejecuten scripts.

3. Incluir código en esos scripts para escribir en el objeto **OutputFileDatasetConfig** como salida o leerlo como entrada.

Por ejemplo, el siguiente código define un objeto **OutputFileDatasetConfig** para los datos preprocesados que deben 
pasarse entre los pasos.

```python
from azureml.data import OutputFileDatasetConfig
from azureml.pipeline.steps import PythonScriptStep, EstimatorStep

# Get a dataset for the initial data
raw_ds = Dataset.get_by_name(ws, 'raw_dataset')

# Define a PipelineData object to pass data between steps
data_store = ws.get_default_datastore()
prepped_data = OutputFileDatasetConfig('prepped')

# Step to run a Python script
step1 = PythonScriptStep(name = 'prepare data',
                         source_directory = 'scripts',
                         script_name = 'data_prep.py',
                         compute_target = 'aml-cluster',
                         # Script arguments include PipelineData
                         arguments = ['--raw-ds', raw_ds.as_named_input('raw_data'),
                                      '--out_folder', prepped_data])

# Step to run an estimator
step2 = PythonScriptStep(name = 'train model',
                         source_directory = 'scripts',
                         script_name = 'train_model.py',
                         compute_target = 'aml-cluster',
                         # Pass as script argument
                         arguments=['--training-data', prepped_data.as_input()])
```

Dentro de los propios scripts, puedes obtener una referencia al objeto **OutputFileDatasetConfig** a partir del argumento 
de script y usarlo como si fuera una carpeta local.

```python
# code in data_prep.py
from azureml.core import Run
import argparse
import os

# Get the experiment run context
run = Run.get_context()

# Get arguments
parser = argparse.ArgumentParser()
parser.add_argument('--raw-ds', type=str, dest='raw_dataset_id')
parser.add_argument('--out_folder', type=str, dest='folder')
args = parser.parse_args()
output_folder = args.folder

# Get input dataset as dataframe
raw_df = run.input_datasets['raw_data'].to_pandas_dataframe()

# code to prep data (in this case, just select specific columns)
prepped_df = raw_df[['col1', 'col2', 'col3']]

# Save prepped data to the PipelineData location
os.makedirs(output_folder, exist_ok=True)
output_path = os.path.join(output_folder, 'prepped_data.csv')
prepped_df.to_csv(output_path)
```

## 6 Reuse pipeline steps
[< Back to Local Index](#6-index)

Los **pipelines** con múltiples pasos de larga ejecución pueden tardar un tiempo considerable en completarse. 
Azure Machine Learning incluye algunas funciones de almacenamiento en caché y reutilización para reducir este tiempo.

### Gestión de la reutilización de la salida de pasos

Por defecto, la salida del paso de una ejecución anterior del pipeline se reutiliza sin necesidad de volver a ejecutar el 
paso siempre que el script, el directorio de origen y otros parámetros del paso no hayan cambiado. La reutilización de 
pasos puede reducir el tiempo que se tarda en ejecutar una canalización, pero puede dar lugar a resultados obsoletos cuando 
no se han tenido en cuenta los cambios en las fuentes de datos posteriores.

Para controlar la reutilización de un paso individual, puede establecer el parámetro **allow_reuse** en la configuración 
del paso, de la siguiente manera:

```python
step1 = PythonScriptStep(name = 'prepare data',
                         source_directory = 'scripts',
                         script_name = 'data_prep.py',
                         compute_target = 'aml-cluster',
                         runconfig = run_config,
                         inputs=[raw_ds.as_named_input('raw_data')],
                         outputs=[prepped_data],
                         arguments = ['--folder', prepped_data]),
                         # Disable step reuse
                         allow_reuse = False)
```

### Forzar la ejecución de todos los pasos

Cuando tenga varios pasos, puede forzar la ejecución de todos ellos independientemente de la configuración de reutilización 
individual estableciendo el parámetro **regenerate_outputs** al enviar el experimento de canalización:

```python
pipeline_run = experiment.submit(train_pipeline, regenerate_outputs=True)
```

## 6 Publish pipelines
[< Back to Local Index](#6-index)

Después de haber creado una canalización, puede publicarla para crear un punto final REST a través del cual se pueda ejecutar 
la canalización bajo demanda.

### Publicación de una canalización

Para publicar una canalización, puede llamar a su método **publish**, como se muestra aquí:

```python
published_pipeline = pipeline.publish(name='training_pipeline',
                                          description='Model training pipeline',
                                          version='1.0')
```

Alternativamente, puede llamar al método de publicación en una ejecución exitosa de la canalización:

```python
# Get the most recent run of the pipeline
pipeline_experiment = ws.experiments.get('training-pipeline')
run = list(pipeline_experiment.get_runs())[0]

# Publish the pipeline from the run
published_pipeline = run.publish_pipeline(name='training_pipeline',
                                          description='Model training pipeline',
                                          version='1.0')
```

Una vez publicada la canalización, puede verla en Azure Machine Learning studio. También puede determinar el URI 
de su endpoint de esta forma:

```python
rest_endpoint = published_pipeline.endpoint
print(rest_endpoint)
```

### Uso de una canalización publicada

Para iniciar un endpoint publicado, realice una solicitud HTTP a su endpoint REST, pasando una cabecera de autorización 
con un token para un service principal con permiso para ejecutar el pipeline, y una carga útil JSON especificando el 
nombre del experimento. La canalización se ejecuta de forma asíncrona, por lo que la respuesta de una llamada 
REST exitosa incluye el ID de ejecución. Puede utilizarlo para realizar un seguimiento de la ejecución en Azure Machine 
Learning studio.

Por ejemplo, el siguiente código Python realiza una solicitud REST para ejecutar una canalización y muestra el ID de 
ejecución devuelto.

```python
import requests

response = requests.post(rest_endpoint,
                         headers=auth_header,
                         json={"ExperimentName": "run_training_pipeline"})
run_id = response.json()["Id"]
print(run_id)
```

## 6 Use pipelines parameters
[< Back to Local Index](#6-index)

Puede aumentar la flexibilidad de una canalización definiendo parámetros.

### Definición de parámetros para una canalización

Para definir parámetros para una canalización, cree un objeto **PipelineParameter** para cada parámetro y especifique cada 
parámetro en al menos un paso.

Por ejemplo, puede utilizar el siguiente código para incluir un parámetro para una tasa de regularización en el script 
utilizado por un estimador:

```python
from azureml.pipeline.core.graph import PipelineParameter

reg_param = PipelineParameter(name='reg_rate', default_value=0.01)

...

step2 = PythonScriptStep(name = 'train model',
                         source_directory = 'scripts',
                         script_name = 'data_prep.py',
                         compute_target = 'aml-cluster',
                         # Pass parameter as script argument
                         arguments=['--in_folder', prepped_data,
                                    '--reg', reg_param],
                         inputs=[prepped_data])
```

> Nota
>
> Debe definir los parámetros para una canalización antes de publicarla.

### Ejecutar una canalización con un parámetro

Después de publicar una canalización parametrizada, puede pasar valores de parámetros en la carga útil JSON para la 
interfaz REST:

```python
response = requests.post(rest_endpoint,
                         headers=auth_header,
                         json={"ExperimentName": "run_training_pipeline",
                               "ParameterAssignments": {"reg_rate": 0.1}})
```

## 6 Schedule pipelines
[< Back to Local Index](#6-index)

Una vez publicada una canalización, puede iniciarla a petición a través de su punto final REST, o puede hacer que se 
ejecute automáticamente en función de una programación periódica o en respuesta a actualizaciones de datos.

### Programación de una canalización para intervalos periódicos

Para programar una canalización para que se ejecute a intervalos periódicos, debe definir una **ScheduleRecurrence** que 
determine la frecuencia de ejecución, y utilizarla para crear una **Schedule**.

Por ejemplo, el siguiente código programa una ejecución diaria de una canalización publicada.

```python
from azureml.pipeline.core import ScheduleRecurrence, Schedule

daily = ScheduleRecurrence(frequency='Day', interval=1)
pipeline_schedule = Schedule.create(ws, name='Daily Training',
                                        description='trains model every day',
                                        pipeline_id=published_pipeline.id,
                                        experiment_name='Training_Pipeline',
                                        recurrence=daily)
```

### Activar la ejecución de una canalización cuando cambian los datos

Para programar una canalización para que se ejecute cada vez que cambien los datos, debe crear un **Schedule** que supervise 
una ruta especificada en un almacén de datos, de la siguiente manera:

```python
from azureml.core import Datastore
from azureml.pipeline.core import Schedule

training_datastore = Datastore(workspace=ws, name='blob_data')
pipeline_schedule = Schedule.create(ws, name='Reactive Training',
                                    description='trains model on data change',
                                    pipeline_id=published_pipeline_id,
                                    experiment_name='Training_Pipeline',
                                    datastore=training_datastore,
                                    path_on_datastore='data/training')
```

## 6 Exercise Create a pipeline
[< Back to Local Index](#6-index)

En este ejercicio, usted


- Crear un pipeline de Azure Machine Learning

- Publicar un pipeline como un servicio REST

- Programar un pipeline.

### Instrucciones

Siga estas instrucciones para completar el ejercicio.


1. Si aún no tiene una suscripción a Azure, regístrese para una prueba gratuita en 
https://azure.microsoft.com

2. Consulte el repositorio del ejercicio en 
https://aka.ms/mslearn-dp100

3. Si aún no lo ha hecho, complete el ejercicio Crear un espacio de trabajo de Azure Machine Learning para aprovisionar un espacio de trabajo de Azure Machine Learning, crear una instancia de cálculo y clonar los archivos necesarios

4. Complete el ejercicio Crear una canalización.

### Notebook

Como ya es costumbre, vamos a iniciar Corriendo nuestro: `Compute-instance` -> `Coursera-cpu`

> ### Nota
> El notebook de esta clase está en: [08 - Create a Pipeline.ipynb](ims%2FC6%2Fnotebook%2F08%20-%20Create%20a%20Pipeline.ipynb)

![1.png](ims%2FC4%2Fims%2F4%2F1.png)


1. Como ya es costumbre, vamos a empezar definiendo nuestro `ws` y verificando nuestra versión de `AML`:

   ![m1.gif](ims%2FC6%2Fgifs%2Fm1.gif)

2. Ahora vamos a seguir utilizando el `diabetes dataset` que ya hemos registrado anteriormente.

   ![m2.gif](ims%2FC6%2Fgifs%2Fm2.gif)

3. El primer paso para crear nuestro `pipeline` es pensarlo como un `experimento` eso significa que debemos empezar creando
   un folder en donde vamos a tener nuestros scripts de python que vamos a ir ejecutando.

   ![m3.gif](ims%2FC6%2Fgifs%2Fm3.gif)

   El script `prep_diabetes.py` contiene una metodología ya bien conocida en este curso, pero agrega un paso interesante y es
   el de crear un `folder` temporal que necesitan los `pipeline` para poder intercambiar información entre los diferentes pasos del proceso.

   El objetivo del script es simple, preprocesar un `tabular dataset` utilizando un `MinMaxScaler`, una vez que este ha sido pre-procesado correctamente, 
   la salida (el dataset procesado) se guardara en una ruta `save_folder` notar específicamente esta sección:

   ```python
   # se leen los argumentos
   parser = argparse.ArgumentParser()
   # se prepara el argumento de folder temporal:
   parser.add_argument('--prepped-data', type=str, dest='prepped_data', default='prepped_data', help='Folder for results')
   # los argumentos quedan como un diccionario
   args = parser.parse_args()
   # y ahora podemos crear una variable con la dirección del folder temporal
   save_folder = args.prepped_data
   # eventualmente vamos a usar esta variable para crear una carpeta y ahí guardar el dataset procesado
   ```
   Después de procesar el dataset, para utilizar correctamente la metodología del `pipeline` de pasar información entre `steps` tenemos que
   guardar el dato en una ruta específica:

   ```python
   # Save the prepped data
   print("Saving Data...")
   os.makedirs(save_folder, exist_ok=True)
   save_path = os.path.join(save_folder,'data.csv')
   diabetes.to_csv(save_path, index=False, header=True)
   ```

4. El siguiente `step` es crear un script que entrene un modelo de `ML`para la clasificación de diabetes, en este caso usaremos un `DecisionTreeClassifier`

   ![m4.gif](ims%2FC6%2Fgifs%2Fm4.gif)

   > Nota: aqui hay un pequeño `truquito` hardcodeado

   ```python
    # Get parameters
    parser = argparse.ArgumentParser()
    parser.add_argument("--training-data", type=str, dest='training_data', help='training data')
    args = parser.parse_args()
    training_data = args.training_data
    
    # load the prepared data file in the training folder
    print("Loading Data...")
    file_path = os.path.join(training_data,'data.csv')
    diabetes = pd.read_csv(file_path)
   ```
   Técnicamente el argumento recibe la dirección del folder temporal NO el dataset tal cual, es por eso que el `file_path` tiene `hardcodeado` la palabra `data.csv`
   porque eso fue lo que escribimos en el script de python anterior. Esto me parece algo cuestionable pero digno de mencionar.

5. Este paso ya lo conocemos, simplemente es elegir un `ComputeTarget` que en este caso vamos a utilizar el que ya hemos creado anteriormente `coursera-cluster`

   ![m5.gif](ims%2FC6%2Fgifs%2Fm5.gif)

6. Este paso también ya lo conocemos que es crear nuestro archivo `experiment_env.yml` que vamos a utilizar para crear nuestro entorno virtual conda.

   ![m6.gif](ims%2FC6%2Fgifs%2Fm6.gif)

   Aquí asignamos y registramos nuestro `experiment_env`

   ```python
   # Create a Python environment for the experiment (from a .yml file)
   experiment_env = Environment.from_conda_specification("experiment_env", experiment_folder + "/experiment_env.yml")
   
   # Register the environment 
   experiment_env.register(workspace=ws)
   registered_env = Environment.get(ws, 'experiment_env')
   ```

7. Ahora, el punto es que antes de definir propiamente los pasos que van a componer al `pipeline` vamos a configurar sus parámetros, que en este caso
   serán, su `compute cluster` y su `environment`:

   ![m7.gif](ims%2FC6%2Fgifs%2Fm7.gif)

   ```python
    # Create a new runconfig object for the pipeline
    pipeline_run_config = RunConfiguration()
   
    # Use the compute you created above. 
    pipeline_run_config.target = pipeline_cluster
   
    # Assign the environment to the run configuration
    pipeline_run_config.environment = registered_env
   
    print("Run configuration created.")
   ```   

8. Propiamente, no podemos directamente utilizar los scripts de python como `steps` estos deben ser configurados como: `PythonScriptStep` 
   para efectivamente convertirlo a un formato que pueda ser utilizado en un `pipeline`.

   Entre las notas importantes que debemos aclarar es que este es el punto ideal para crear nuestra variable para compartir información:

   ```python
    # Create an OutputFileDatasetConfig (temporary Data Reference) for data passed from step 1 to step 2
    prepped_data = OutputFileDatasetConfig("prepped_data")
   ```

   ![m8.gif](ims%2FC6%2Fgifs%2Fm8.gif)

   > Notas interesantes en este paso:
   > 
   > -  En el Step 1: el argumento  '--prepped-data', es directamente la variable `prepped_data` que es un folder temporal
   > - No me queda super claro si en `compute_target` podría poner un `target` diferente para cada paso
   > - `Allow_reuse` como esta en `True` es para intentar ahorrar recursos si se vuelven a correr estos mismos pasos en futuros experimentos
   > - En el segundo paso del pipeline algo muy interesante es que el argumento que recibe como entra: arguments = ['--training-data', prepped_data.as_input() esta como `as_input()`
   
9. Nuestro pipeline no es más que una lsita de `steps` que ya han sido definidos, vamos a crear el `pipeline` y correr el experimento:

   ```python
    from azureml.core import Experiment
    from azureml.pipeline.core import Pipeline
    from azureml.widgets import RunDetails
   
    # Construct the pipeline
    pipeline_steps = [prep_step, train_step]
    pipeline = Pipeline(workspace=ws, steps=pipeline_steps)
    print("Pipeline is built.")
    
    # Create an experiment and run the pipeline
    experiment = Experiment(workspace=ws, name = 'mslearn-diabetes-pipeline')
    pipeline_run = experiment.submit(pipeline, regenerate_outputs=True)
    print("Pipeline submitted for execution.")
    RunDetails(pipeline_run).show()
    pipeline_run.wait_for_completion(show_output=True)
   ```

   ![m9.gif](ims%2FC6%2Fgifs%2Fm9.gif)

10. Un pipeline contiene varios scripts y cada uno de ellos con logs y metrics diferentes, por eso una vez que el `pipeline` se ha ejecutado por completo
   para revisar los resultados debemos hacerlo script a script:

   ```python
    for run in pipeline_run.get_children():
        print(run.name, ':')
        metrics = run.get_metrics()
        for metric_name in metrics:
            print('\t',metric_name, ":", metrics[metric_name])
   ```

   ![m10.gif](ims%2FC6%2Fgifs%2Fm10.gif)

11. El punto de publicar el `Pipeline` como un `rest endpoint` es poder hacer eventualmente un `request` y correr automáticamente todo el flujo del pipeline
   esto presenta varias ventajas, como por ejemplo poder hacer un `schedule` de cada cuanto ejecutar el pipeline

   ![m11.gif](ims%2FC6%2Fgifs%2Fm11.gif)

12. Básicamente para consumir el `pipeline` debemos obtener un `run_id` y ya con eso es como si fuera nuestro `Api key` que nos identifica a nosotros y al `pipeline` que queremos correr

   ![m12.gif](ims%2FC6%2Fgifs%2Fm12.gif)

13. Perfecto logramos ejecutar el `pipeline` desde un api rest, y ahora podemos proceder haciendo un `schedule` que lo ejecute una vez a la semana

   ![m13.gif](ims%2FC6%2Fgifs%2Fm13.gif)

14. Como paso final, debemos detener nuestro `compute instance`:

   ![1.png](ims%2FC5%2Fgifs%2F1.png)


## 6 Exercise quiz
[< Back to Local Index](#6-index)

![1.png](ims%2FC6%2Ftest%2F1.png)

## 6 Knowledge Check
[< Back to Local Index](#6-index)

![q1.png](ims%2FC6%2Ftest%2Fq1.png)

![q2.png](ims%2FC6%2Ftest%2Fq2.png)

## 6 Lesson summary
[< Back to Local Index](#6-index)

![2.png](ims%2FC6%2Ftest%2F2.png)

En esta lección, aprendió a crear una canalización de Azure Machine Learning, publicar una canalización de Azure Machine Learning, y programar una canalización de Azure Machine Learning.

## 6 Additional Reading
[< Back to Local Index](#6-index)

**Introduction to pipelines:**

[steps Package](https://docs.microsoft.com/en-us/python/api/azureml-pipeline-steps/azureml.pipeline.steps?view=azure-ml-py)

# 7 Deploy real-time machine learning services with Azure Machine Learning

## 7 INDEX

- [7 Lesson introduction](#7-lesson-introduction)
- [7 Deploy a model as a real-time service](#7-deploy-a-model-as-a-real-time-service)
- [7 Consume a real-time inferencing service](#7-consume-a-real-time-inferencing-service)
- [7 Troubleshoot service deployment](#7-troubleshoot-service-deployment)
- [7 Exercise Deploy a model as a real-time service](#7-exercise-deploy-a-model-as-a-real-time-service)
- [7 Exercise quiz](#7-exercise-quiz)
- [7 Knowledge Check](#7-knowledge-check)
- [7 Test prep](#7-test-prep)
- [7 Lesson summary](#7-lesson-summary)

[< Back to index](#0-index)

## 7 Lesson introduction
[< Back to Local Index](#7-index)

![1.png](ims%2FC7%2Fims%2F1.png)

En el aprendizaje automático, la inferencia se refiere al uso de un modelo entrenado para predecir etiquetas para nuevos datos en los que el modelo no ha sido entrenado. 

![2.png](ims%2FC7%2Fims%2F2.png)

A menudo, el modelo se despliega como parte de un servicio que permite a las aplicaciones solicitar predicciones inmediatas o en tiempo real para observaciones de datos individuales o en pequeño número.

![3.png](ims%2FC7%2Fims%2F3.png)

 En Azure Machine Learning, puede crear soluciones de inferencia en tiempo real desplegando un modelo como servicio alojado en una plataforma en contenedores como Azure Kubernetes Services o AKS. 

![4.png](ims%2FC7%2Fims%2F4.png)

En esta lección, aprenderá a desplegar un modelo como servicio de inferencia en tiempo real, servicio de inferencia en tiempo real del consumidor, y a solucionar problemas de despliegue del servicio.

## 7 Deploy a model as a real-time service
[< Back to Local Index](#7-index)

Puede desplegar un modelo como servicio web en tiempo real en varios tipos de destino de cómputo, incluido el cómputo local, 
una instancia de cómputo de Azure Machine Learning, una instancia de contenedor de Azure (ACI), un clúster de Azure Kubernetes 
Service (AKS), una función de Azure o un módulo de Internet de las cosas (IoT). Azure Machine Learning utiliza contenedores 
como mecanismo de despliegue, empaquetando el modelo y el código para utilizarlo como una imagen que puede desplegarse 
en un contenedor en su destino de computación elegido.

> ### Nota
>
> El despliegue en un servicio local, una instancia de computación o un ACI es una buena opción para pruebas y desarrollo. 
> Para producción, debe desplegar en un destino que satisfaga las necesidades específicas de rendimiento, escalabilidad y 
> seguridad de la arquitectura de su aplicación.

Para desplegar un modelo como servicio de inferencia en tiempo real, debe realizar las siguientes tareas:

### Registrar un modelo entrenado

Después de entrenar con éxito un modelo, debe registrarlo en su espacio de trabajo de Azure Machine Learning. Su servicio 
en tiempo real podrá entonces cargar el modelo cuando sea necesario.

Para registrar un modelo desde un archivo local, puede utilizar el método register del objetoModel como se muestra aquí:

```python
from azureml.core import Model

classification_model = Model.register(workspace=ws,
                       model_name='classification_model',
                       model_path='model.pkl', # local path
                       description='A classification model')
```

Alternativamente, si tiene una referencia a laEjecución utilizada para entrenar el modelo, puede utilizar su método
register_model como se muestra aquí:

```python
run.register_model( model_name='classification_model',
                    model_path='outputs/model.pkl', # run outputs path
                    description='A classification model')
```

### Definir una configuración de inferencia

El modelo se desplegará como un servicio que constará de:

- Un script para cargar el modelo y devolver predicciones para los datos enviados.

- Un entorno en el que se ejecutará el script.

Por lo tanto, debe definir el script y el entorno para el servicio.

### Crear un script de entrada

Cree el _script_ de entrada (a veces denominado _script de puntuación_) para el servicio como un archivo Python (.py). 
Debe incluir dos funciones:

- `init():` Llamada cuando se inicializa el servicio.

- `run(raw_data):` Llamada cuando se envían nuevos datos al servicio.

Normalmente, se utiliza la función **init** para cargar el modelo desde el registro de modelos, y se utiliza la función
**run** para generar predicciones a partir de los datos de entrada. El siguiente script de ejemplo muestra este patrón:

```python
import json
import joblib
import numpy as np
from azureml.core.model import Model

# Called when the service is loaded
def init():
    global model
    # Get the path to the registered model file and load it
    model_path = Model.get_model_path('classification_model')
    model = joblib.load(model_path)

# Called when a request is received
def run(raw_data):
    # Get the input data as a numpy array
    data = np.array(json.loads(raw_data)['data'])
    # Get a prediction from the model
    predictions = model.predict(data)
    # Return the predictions as any JSON serializable format
    return predictions.tolist()
```

### Crear un entorno

Su servicio requiere un entorno Python en el que ejecutar el script de entrada, que puede configurar utilizando el archivo de 
configuración **Conda**. Una forma sencilla de crear este archivo es utilizar una clase **CondaDependencies** para crear un entorno 
predeterminado (que incluye el paquete **azureml-defaults** y paquetes de uso común como **numpy** y **pandas**), añadir 
cualquier otro paquete necesario y, a continuación, serializar el entorno a una cadena y guardarlo:

```python
from azureml.core.conda_dependencies import CondaDependencies

# Add the dependencies for your model
myenv = CondaDependencies()
myenv.add_conda_package("scikit-learn")

# Save the environment config as a .yml file
env_file = 'service_files/env.yml'
with open(env_file,"w") as f:
    f.write(myenv.serialize_to_string())
print("Saved dependency info in", env_file)
```

### Combinar el script y el entorno en un InferenceConfig

Después de crear el script de entrada y el archivo de configuración del entorno, puede combinarlos en una **InferenceConfig** 
para el servicio de la siguiente manera:

```python
from azureml.core.model import InferenceConfig

classifier_inference_config = InferenceConfig(runtime= "python",
                                              source_directory = 'service_files',
                                              entry_script="score.py",
                                              conda_file="env.yml")
```

### Definir una configuración de despliegue

Ahora que tiene el script de entrada y el entorno, necesita configurar el ordenador en el que se desplegará el servicio. 
Si va a realizar el despliegue en un clúster AKS, deberá crear el clúster y un objetivo de cómputo para él antes de realizar 
el despliegue:

```python
from azureml.core.compute import ComputeTarget, AksCompute

cluster_name = 'aks-cluster'
compute_config = AksCompute.provisioning_configuration(location='eastus')
production_cluster = ComputeTarget.create(ws, cluster_name, compute_config)
production_cluster.wait_for_completion(show_output=True)
```

Con el objetivo de cómputo creado, ahora puede definir la configuración de despliegue, que establece la especificación de 
cómputo específica del objetivo para el despliegue en contenedor:

```python
from azureml.core.webservice import AksWebservice

classifier_deploy_config = AksWebservice.deploy_configuration(cpu_cores = 1,
                                                              memory_gb = 1)
```

El código para configurar un despliegue ACI es similar, salvo que no necesita crear explícitamente un objetivo de cómputo ACI 
y debe utilizar la clase **deploy_configuration** del espacio de nombres **azureml.core.webservice.AciWebservice**. Del mismo modo, 
puede utilizar el espacio de nombres **azureml.core.webservice.LocalWebservice** para configurar un servicio local basado en Docker.

> Nota
> 
> Para desplegar un modelo en una Azure Function, no necesita crear una configuración de despliegue. En su lugar, necesita 
> empaquetar el modelo en función del tipo de activador de función que desee utilizar. Esta funcionalidad se encuentra en 
> fase de previsualización en el momento de redactar este documento. Para más detalles, consulte
[Desplegar un modelo de aprendizaje automático en Azure Functions](https://aka.ms/AA70rrn)
 en la documentación de Azure Machine Learning.

### Desplegar el modelo

Una vez preparada toda la configuración, puede desplegar el modelo. La forma más sencilla de hacerlo es llamar al método
**deploy** de la clase **Model**, de esta manera:

```python
from azureml.core.model import Model

model = ws.models['classification_model']
service = Model.deploy(workspace=ws,
                       name = 'classifier-service',
                       models = [model],
                       inference_config = classifier_inference_config,
                       deployment_config = classifier_deploy_config,
                       deployment_target = production_cluster)
service.wait_for_deployment(show_output = True)
```

Para ACI o servicios locales, puede omitir el parámetro **deployment_target**(o establecerlo enNone).

Para obtener más información sobre el despliegue de modelos con Azure Machine Learning, consulte
[Despliegue de modelos de aprendizaje automático en Azure](https://aka.ms/AA70zfv)
 en la documentación.

## 7 Consume a real-time inferencing service
[< Back to Local Index](#7-index)

Tras desplegar un servicio en tiempo real, puede consumirlo desde aplicaciones cliente para predecir etiquetas para nuevos casos de datos.

### Utilizar el SDK de aprendizaje automático de Azure

Para realizar pruebas, puede utilizar el SDK de aprendizaje automático de Azure para llamar a un servicio web a través del 
método de ejecución de un objeto WebService que haga referencia al servicio desplegado. Normalmente, usted envía datos al 
método de ejecución en formato JSON con la siguiente estructura:

```json
{
  "data":[
      [0.1,2.3,4.1,2.0], // 1st case
      [0.2,1.8,3.9,2.1],  // 2nd case,
      ...
  ]
}
```

La respuesta del método de ejecución es una colección JSON con una predicción para cada caso que se envió en los datos. 
El siguiente ejemplo de código llama a un servicio y muestra la respuesta:

```python
import json

# An array of new data cases
x_new = [[0.1,2.3,4.1,2.0],
         [0.2,1.8,3.9,2.1]]

# Convert the array to a serializable list in a JSON document
json_data = json.dumps({"data": x_new})

# Call the web service, passing the input data
response = service.run(input_data = json_data)

# Get the predictions
predictions = json.loads(response)

# Print the predicted class for each case.
for i in range(len(x_new)):
    print (x_new[i], predictions[i])
```

### Utilizar un punto final REST 

En producción, la mayoría de las aplicaciones cliente no incluirán el SDK de Azure Machine Learning, y consumirán el servicio 
a través de su interfaz REST. Puede determinar el punto final de un servicio desplegado en Azure Machine Learning studio, 
o recuperando la propiedad **scoring_uri** del objetoWebservice en el SDK, como se muestra a continuación:

```python
endpoint = service.scoring_uri
print(endpoint)
```

Con el endpoint conocido, puede utilizar una solicitud HTTP POST con datos JSON para llamar al servicio. El siguiente 
ejemplo muestra cómo hacerlo utilizando Python:

```python
import requests
import json

# An array of new data cases
x_new = [[0.1,2.3,4.1,2.0],
         [0.2,1.8,3.9,2.1]]

# Convert the array to a serializable list in a JSON document
json_data = json.dumps({"data": x_new})

# Set the content type in the request headers
request_headers = { 'Content-Type':'application/json' }

# Call the service
response = requests.post(url = endpoint,
                         data = json_data,
                         headers = request_headers)

# Get the predictions from the JSON response
predictions = json.loads(response.json())

# Print the predicted class for each case.
for i in range(len(x_new)):
    print (x_new[i]), predictions[i] )
```

### Autenticación

En producción, es probable que desee restringir el acceso a sus servicios aplicando la autenticación. Hay dos tipos de 
autenticación que puede utilizar:

- **Clave**: Las solicitudes se autentican especificando la clave asociada al servicio.

- **Token**: Las solicitudes se autentican proporcionando un Token Web JSON (JWT).

Por defecto, la autenticación está desactivada para los servicios ACI, y configurada como autenticación basada en clave 
para los servicios AKS (para los que se generan automáticamente claves primarias y secundarias). Opcionalmente, puede 
configurar un servicio AKS para que utilice la autenticación basada en token (que no es compatible con los servicios ACI).

Suponiendo que haya establecido una sesión autenticada con el área de trabajo, puede recuperar las claves de un servicio 
utilizando el método **get_keys** del objeto **WebService** asociado al servicio:

```python
primary_key, secondary_key = service.get_keys()
```

Para la autenticación basada en token, su aplicación cliente necesita utilizar la autenticación de principal de servicio 
para verificar su identidad a través de Azure Active Directory (Azure AD) y llamar al método **get_token** del servicio 
para recuperar un token de tiempo limitado.

Para realizar una llamada autenticada al punto final REST del servicio, debe incluir la clave o el token en la cabecera 
de la solicitud de la siguiente manera:

```python
import requests
import json

# An array of new data cases
x_new = [[0.1,2.3,4.1,2.0],
         [0.2,1.8,3.9,2.1]]

# Convert the array to a serializable list in a JSON document
json_data = json.dumps({"data": x_new})

# Set the content type in the request headers
request_headers = { "Content-Type":"application/json",
                    "Authorization":"Bearer " + key_or_token }

# Call the service
response = requests.post(url = endpoint,
                         data = json_data,
                         headers = request_headers)

# Get the predictions from the JSON response
predictions = json.loads(response.json())

# Print the predicted class for each case.
for i in range(len(x_new)):
    print (x_new[i]), predictions[i] )
```

## 7 Troubleshoot service deployment
[< Back to Local Index](#7-index)

![5.png](ims%2FC7%2Fims%2F5.png)

Hay muchos elementos para un despliegue de servicios en tiempo real. Estos pueden incluir el modelo entrenado, la configuración 
del entorno de ejecución, el script de puntuación, la imagen del contenedor, y el host del contenedor. 

![6.png](ims%2FC7%2Fims%2F6.png)

Solucionar problemas de una implementación fallida o de un error al consumir una implementación el servicio puede ser complejo.

![7.png](ims%2FC7%2Fims%2F7.png)

Como paso inicial de solución de problemas, puede comprobar el estado de un servicio examinando su estado a través de la 
herramienta get el método de servicio implementado.

![8.png](ims%2FC7%2Fims%2F8.png)

Es importante tener en cuenta que para para ver el estado de un servicio, debe usar el cómputo específico tipo de servicio, 
por ejemplo, un servicio web de KS y no es un objeto de servicio web genérico. Para un servicio operativo, el estado debe estar sano.

![9.png](ims%2FC7%2Fims%2F9.png)

Si un servicio no es saludable o si tiene errores al usarlo, puede revisar sus registros. Puede revisar estos registros 
mediante un código, los registros incluyen información detallada sobre el aprovisionamiento del servicio y las solicitudes 
que ha procesado.

![10.png](ims%2FC7%2Fims%2F10.png)

A menudo, pueden proporcionar una idea sobre la causa de los errores inesperados. Despliegue y Los errores de ejecución 
pueden ser más fáciles de diagnosticar, puede hacerlo implementando el servicio como contenedor en una instancia de Docker local.

![11.png](ims%2FC7%2Fims%2F11.png)

A continuación, puede probar el localmente servicio implementado mediante el SDK. 

![12.png](ims%2FC7%2Fims%2F12.png)

A continuación, puede solucionar problemas de tiempo de ejecución realizando cambios en el archivo de puntuación al que 
se hace referencia en la configuración de inferencia.

![13.png](ims%2FC7%2Fims%2F13.png)

Luego, recargando el servicio sin volver a implementarlo, algo que solo puedes hacer hazlo con un servicio local.

## 7 Exercise Deploy a model as a real-time service
[< Back to Local Index](#7-index)

Ahora es su oportunidad de utilizar Azure Machine Learning para desplegar un modelo de aprendizaje automático como un servicio en tiempo real.

### Notebook

Como ya es costumbre, vamos a iniciar Corriendo nuestro: `Compute-instance` -> `Coursera-cpu`

> ### Nota
> El notebook de esta clase está en: [09 - Create a Real-time Inferencing Service.ipynb](ims%2FC7%2Fnotebooks%2F09%20-%20Create%20a%20Real-time%20Inferencing%20Service.ipynb)

![1.png](ims%2FC4%2Fims%2F4%2F1.png)


1. Como ya es costumbre, vamos a empezar definiendo nuestro `ws` y verificando nuestra versión de `AML`:

   ![m1.gif](ims%2FC7%2Fgifs%2Fm1.gif)

2. El notebook tiene una celda adicional para crear un modelo y registrarlo, sin embargo, como ya tenemos varios modelos de diabetes, vamos a omitir la celda y vamos a ver cuáles modelos ya tenemos disponibles:

   ![m2.gif](ims%2FC7%2Fgifs%2Fm2.gif)

3. Vamos a seleccionar nuestro modelo más reciente que en este caso es la versión `8`. Para crear el endpoint, primero debemos preparar un folder para crear el `servicio`

   ![m3.gif](ims%2FC7%2Fgifs%2Fm3.gif)

   > Nota: tenemos una variable llamada `script_file` que solo es el nombre del archivo .py, mientras que `script_file` es la concatenación entre el nombre del folder y el nombre del archivo

4. En el `script_file.py` como ya leímos en las notas de este capítulo, dos funciones: `init()` (para cargar al modelo) y `run(raw_data)` que básicamente, lee los archivos en un formato `crudo`
   y los prepara para ser clasificados por el modelo, finalmente utiliza la predicción 0 o 1 para darle una etiqueta de `non diabetic` vs `diabetic`

   ![m4.gif](ims%2FC7%2Fgifs%2Fm4.gif)

5. Ahora debemos seleccionar el ambiente que utilizará para crear el contenedor, en este caso, simplemente estamos utilizando uno de los que ya vienen por defecto en Azure. Ahora, para crear
   el objeto `inference_config` debemos tener 3 ingredientes, el folder donde esta el script, el nombre del script, y el ambiente creado.

   ![m5.gif](ims%2FC7%2Fgifs%2Fm5.gif)

   También debemos crear el `cluster` donde se va a ejecutar la información, pero este será especial puesto que es para hacer `inferencia`, le asignamos solo un core de cpu y un giga de ram.
   Ahora ya podemos hacer Model.deploy() con todos los incredientes:

   ````python
    service = Model.deploy(ws, service_name, [model], inference_config, deployment_config, overwrite=True)
   ````

6. Una vez que se ha publicado nuestro endpoint podemos consultar sus logs, y ver el nombre del servicio que hemos creado `diabetes-service`, adicionalmente, en la pestaña de
   `endpoints` podemos ver que ya esta públicado nuestro `endpoint` y ahí mismo podemos observar la dirección de nuestra `API`
   ![m6.gif](ims%2FC7%2Fgifs%2Fm6.gif)

7. Podemos probar que el modelo funciona correctamente, tanto para una predicción como para múltiples soluciones, el servicio se esta ejecutando y todo funciona bien.

   ![m7.gif](ims%2FC7%2Fgifs%2Fm7.gif)

   sin embargo, no siempre vamos a disponer del SDK para correr al modelo, es por ello que es buena idea contar con la dirección del endpoint:

   ```python
    endpoint = service.scoring_uri
    print(endpoint)
   ```
   Podemos observar que esta en linea en la dirección:

   ```commandline
    http://d2575064-0c24-4cd8-97b1-9932795ec186.eastus2.azurecontainer.io/score
   ```

8. Una alternativa más interesante, es hacer un `post` para hacer inferencia:

   ![m8.gif](ims%2FC7%2Fgifs%2Fm8.gif)

   este método NO necesita tener el SDK de azure instalando, puesto que solo usa `requests` para hacer una solicitud `post` al `API rest` que hemos creado. 

   Finalmente, podemos eliminar el `servicio` para que no consuma más cargos.

9. No olvidemos de detener nuestro `coursera-cpu`:

      ![1.png](ims%2FC5%2Fgifs%2F1.png)


## 7 Exercise quiz
[< Back to Local Index](#7-index)

![1.png](ims%2FC7%2Ftest%2F1.png)

## 7 Knowledge Check
[< Back to Local Index](#7-index)

![q1.png](ims%2FC7%2Ftest%2Fq1.png)

![q2.png](ims%2FC7%2Ftest%2Fq2.png)

![q3.png](ims%2FC7%2Ftest%2Fq3.png)

![q4.png](ims%2FC7%2Ftest%2Fq4.png)

## 7 Test prep
[< Back to Local Index](#7-index)

![t1.png](ims%2FC7%2Ftest%2Ft1.png)

![t2.png](ims%2FC7%2Ftest%2Ft2.png)

![t3.png](ims%2FC7%2Ftest%2Ft3.png)

![t4.png](ims%2FC7%2Ftest%2Ft4.png)

![t5.png](ims%2FC7%2Ftest%2Ft5.png)

![t6.png](ims%2FC7%2Ftest%2Ft6.png)

## 7 Lesson summary
[< Back to Local Index](#7-index)

![14.png](ims%2FC7%2Fims%2F14.png)

En esta lección, ha aprendido a desplegar servicios de aprendizaje automático en tiempo real con Azure Machine Learning. 
O, más concretamente, desplegar un modelo como servicio de influencia en tiempo real, consumir un servicio de influencia 
en tiempo real y solucionar problemas de despliegue del servicio.

# 8 Deploy batch inference pipelines with Azure Machine Learning


## 8 INDEX

- [8 Lesson introduction](#8-lesson-introduction)
- [8 Creating a batch inference pipeline](#8-creating-a-batch-inference-pipeline)
- [8 Publishing a batch inference pipeline](#8-publishing-a-batch-inference-pipeline)
- [8 Exercise Create a batch inference pipeline](#8-exercise-create-a-batch-inference-pipeline)
- [8 Exercise quiz](#8-exercise-quiz)
- [8 Knowledge Check](#8-knowledge-check)
- [8 Lesson Summary](#8-lesson-summary)

[< Back to index](#0-index)

## 8 Lesson introduction
[< Back to Local Index](#8-index)
## 8 Creating a batch inference pipeline
[< Back to Local Index](#8-index)
## 8 Publishing a batch inference pipeline
[< Back to Local Index](#8-index)
## 8 Exercise Create a batch inference pipeline
[< Back to Local Index](#8-index)
## 8 Exercise quiz
[< Back to Local Index](#8-index)
## 8 Knowledge Check
[< Back to Local Index](#8-index)
## 8 Lesson Summary
[< Back to Local Index](#8-index)

# 9 Tune hyperparameters with Azure Machine Learning

## 9 INDEX

- [9 Lesson introduction](#9-lesson-introduction)
- [9 Defining a search space](#9-defining-a-search-space)
- [9 Configuring sampling](#9-configuring-sampling)
- [9 Configuring early termination](#9-configuring-early-termination)
- [9 Running a hyperparameter tuning experiment](#9-running-a-hyperparameter-tuning-experiment)
- [9 Exercise Tune hyperparameters](#9-exercise-tune-hyperparameters)
- [9 Exercise quiz](#9-exercise-quiz)
- [9 Knowledge check](#9-knowledge-check)
- [9 Test prep](#9-test-prep)
- [9 Lesson summary](#9-lesson-summary)

[< Back to index](#0-index)

## 9 Lesson introduction
[< Back to Local Index](#9-index)
## 9 Defining a search space
[< Back to Local Index](#9-index)
## 9 Configuring sampling
[< Back to Local Index](#9-index)
## 9 Configuring early termination
[< Back to Local Index](#9-index)
## 9 Running a hyperparameter tuning experiment
[< Back to Local Index](#9-index)
## 9 Exercise Tune hyperparameters
[< Back to Local Index](#9-index)
## 9 Exercise quiz
[< Back to Local Index](#9-index)
## 9 Knowledge check
[< Back to Local Index](#9-index)
## 9 Test prep
[< Back to Local Index](#9-index)
## 9 Lesson summary
[< Back to Local Index](#9-index)

# 10 Automate machine learning model selection with Azure Machine Learning

## 10 INDEX

- [10 Lesson introduction](#10-lesson-introduction)
- [10 Automated machine learning tasks and algorithms](#10-automated-machine-learning-tasks-and-algorithms)
- [10 Preprocessing and featurization](#10-preprocessing-and-featurization)
- [10 Running an automated machine learning experiment](#10-running-an-automated-machine-learning-experiment)
- [10 Exercise Using automated machine learning](#10-exercise-using-automated-machine-learning)
- [10 Exercise quiz](#10-exercise-quiz)
- [10 Knowledge check](#10-knowledge-check)
- [10 Lesson summary](#10-lesson-summary)
- [10 Additional Reading](#10-additional-reading)

[< Back to index](#0-index)

## 10 Lesson introduction
[< Back to Local Index](#10-index)
## 10 Automated machine learning tasks and algorithms
[< Back to Local Index](#10-index)
## 10 Preprocessing and featurization
[< Back to Local Index](#10-index)
## 10 Running an automated machine learning experiment
[< Back to Local Index](#10-index)
## 10 Exercise Using automated machine learning
[< Back to Local Index](#10-index)
## 10 Exercise quiz
[< Back to Local Index](#10-index)
## 10 Knowledge check
[< Back to Local Index](#10-index)
## 10 Lesson summary
[< Back to Local Index](#10-index)
## 10 Additional Reading
[< Back to Local Index](#10-index)

# 11 Explore differential privacy

## 11 INDEX

- [11 Lesson introduction](#11-lesson-introduction)
- [11 Understand differential privacy](#11-understand-differential-privacy)
- [11 Configure data privacy parameters](#11-configure-data-privacy-parameters)
- [11 Exercise Use differential privacy](#11-exercise-use-differential-privacy)
- [11 Exercise quiz](#11-exercise-quiz)
- [11 Knowledge Check](#11-knowledge-check)
- [11 Lesson Summary](#11-lesson-summary)
- [11 Additional Reading](#11-additional-reading)

[< Back to index](#0-index)

## 11 Lesson introduction
[< Back to Local Index](#11-index)
## 11 Understand differential privacy
[< Back to Local Index](#11-index)
## 11 Configure data privacy parameters
[< Back to Local Index](#11-index)
## 11 Exercise Use differential privacy
[< Back to Local Index](#11-index)
## 11 Exercise quiz
[< Back to Local Index](#11-index)
## 11 Knowledge Check
[< Back to Local Index](#11-index)
## 11 Lesson Summary
[< Back to Local Index](#11-index)
## 11 Additional Reading
[< Back to Local Index](#11-index)

# 12 Explain machine learning models with Azure Machine Learning

## 12 INDEX

- [12 Lesson introduction](#12-lesson-introduction)
- [12 Feature importance](#12-feature-importance)
- [12 Using explainers](#12-using-explainers)
- [12 Creating explanations](#12-creating-explanations)
- [12 Visualizing explanations](#12-visualizing-explanations)
- [12 Exercise Interpret models](#12-exercise-interpret-models)
- [12 Exercise quiz](#12-exercise-quiz)
- [12 Knowledge check](#12-knowledge-check)
- [12 Test prep](#12-test-prep)
- [12 Lesson Summary](#12-lesson-summary)
- [12 Additional Reading](#12-additional-reading)

[< Back to index](#0-index)

## 12 Lesson introduction
[< Back to Local Index](#12-index)
## 12 Feature importance
[< Back to Local Index](#12-index)
## 12 Using explainers
[< Back to Local Index](#12-index)
## 12 Creating explanations
[< Back to Local Index](#12-index)
## 12 Visualizing explanations
[< Back to Local Index](#12-index)
## 12 Exercise Interpret models
[< Back to Local Index](#12-index)
## 12 Exercise quiz
[< Back to Local Index](#12-index)
## 12 Knowledge check
[< Back to Local Index](#12-index)
## 12 Test prep
[< Back to Local Index](#12-index)
## 12 Lesson Summary
[< Back to Local Index](#12-index)
## 12 Additional Reading
[< Back to Local Index](#12-index)

# 13 Detect and mitigate unfairness in models with Azure Machine Learning

## 13 INDEX

- [13 Lesson introduction](#13-lesson-introduction)
- [13 Consider model fairness](#13-consider-model-fairness)
- [13 Analyze model fairness with Fairlearn](#13-analyze-model-fairness-with-fairlearn)
- [13 Mitigate unfairness with Fairlearn](#13-mitigate-unfairness-with-fairlearn)
- [13 Exercise Use Fairlearn with Azure Machine Learning](#13-exercise-use-fairlearn-with-azure-machine-learning)
- [13 Exercise quiz](#13-exercise-quiz)
- [13 Knowledge Check](#13-knowledge-check)
- [13 Lesson summary](#13-lesson-summary)
- [13 Additional Reading](#13-additional-reading)

[< Back to index](#0-index)

## 13 Lesson introduction
[< Back to Local Index](#13-index)
## 13 Consider model fairness
[< Back to Local Index](#13-index)
## 13 Analyze model fairness with Fairlearn
[< Back to Local Index](#13-index)
## 13 Mitigate unfairness with Fairlearn
[< Back to Local Index](#13-index)
## 13 Exercise Use Fairlearn with Azure Machine Learning
[< Back to Local Index](#13-index)
## 13 Exercise quiz
[< Back to Local Index](#13-index)
## 13 Knowledge Check
[< Back to Local Index](#13-index)
## 13 Lesson summary
[< Back to Local Index](#13-index)
## 13 Additional Reading
[< Back to Local Index](#13-index)

# 14 Monitor Models with Azure Machine Learning

## 14 INDEX

- [14 Lesson introduction](#14-lesson-introduction)
- [14 Enable Application Insights](#14-enable-application-insights)
- [14 Capture and view telemetry](#14-capture-and-view-telemetry)
- [14 Exercise Monitor a model](#14-exercise-monitor-a-model)
- [14 Exercise quiz](#14-exercise-quiz)
- [14 Knowledge Check](#14-knowledge-check)
- [14 Lesson summary](#14-lesson-summary)
- [14 Additional Reading](#14-additional-reading)

[< Back to index](#0-index)

## 14 Lesson introduction
[< Back to Local Index](#14-index)
## 14 Enable Application Insights
[< Back to Local Index](#14-index)
## 14 Capture and view telemetry
[< Back to Local Index](#14-index)
## 14 Exercise Monitor a model
[< Back to Local Index](#14-index)
## 14 Exercise quiz
[< Back to Local Index](#14-index)
## 14 Knowledge Check
[< Back to Local Index](#14-index)
## 14 Lesson summary
[< Back to Local Index](#14-index)
## 14 Additional Reading
[< Back to Local Index](#14-index)

# 15 Monitor data drift with Azure Machine Learning

## 15 INDEX

- [15 Lesson introduction](#15-lesson-introduction)
- [15 Create a data drift monitor](#15-create-a-data-drift-monitor)
- [15 Scheduling alerts](#15-scheduling-alerts)
- [15 Exercise Monitor data drift](#15-exercise-monitor-data-drift)
- [15 Exercise quiz](#15-exercise-quiz)
- [15 Knowledge Check](#15-knowledge-check)
- [15 Test prep](#15-test-prep)
- [15 Lesson summary](#15-lesson-summary)
- [15 Additional Reading](#15-additional-reading)

[< Back to index](#0-index)

## 15 Lesson introduction
[< Back to Local Index](#15-index)
## 15 Create a data drift monitor
[< Back to Local Index](#15-index)
## 15 Scheduling alerts
[< Back to Local Index](#15-index)
## 15 Exercise Monitor data drift
[< Back to Local Index](#15-index)
## 15 Exercise quiz
[< Back to Local Index](#15-index)
## 15 Knowledge Check
[< Back to Local Index](#15-index)
## 15 Test prep
[< Back to Local Index](#15-index)
## 15 Lesson summary
[< Back to Local Index](#15-index)
## 15 Additional Reading
[< Back to Local Index](#15-index)


