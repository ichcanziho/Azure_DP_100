{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6053c6f4-250c-455a-88db-b87e21a230a3",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Exploratory Analysis\n",
    "\n",
    "Exploratory data analysis, or EDA, builds intuition from your data.  This lesson introduces the objectives and strategies for EDA including summary statistics, basic plotting, and correlations.\n",
    "\n",
    "## ![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) In this lesson you:<br>\n",
    "* Identify the main objectives of exploratory analysis\n",
    "* Calculate statistical moments to determine the center and spread of data\n",
    "* Create plots of data including histograms and scatterplots\n",
    "* Calculate correlations between variables\n",
    "* Explore more advanced plots to visualize the relation between variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d23cfb7a-4704-4699-a5fa-98dc4fe6ee11",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<iframe  \n",
    "src=\"//fast.wistia.net/embed/iframe/baptj0tmzh?videoFoam=true\"\n",
    "style=\"border:1px solid #1cb1c2;\"\n",
    "allowtransparency=\"true\" scrolling=\"no\" class=\"wistia_embed\"\n",
    "name=\"wistia_embed\" allowfullscreen mozallowfullscreen webkitallowfullscreen\n",
    "oallowfullscreen msallowfullscreen width=\"640\" height=\"360\" ></iframe>\n",
    "<div>\n",
    "<a target=\"_blank\" href=\"https://fast.wistia.net/embed/iframe/baptj0tmzh?seo=false\">\n",
    "  <img alt=\"Opens in new tab\" src=\"https://files.training.databricks.com/static/images/external-link-icon-16x16.png\"/>&nbsp;Watch full-screen.</a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4ae96587-3667-495b-92c0-51e7ec56eabc",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Exploratory Data Analysis\n",
    "\n",
    "The goal of exploratory data analysis (EDA) is to build the intuition into a dataset that will inform how you model the data.  Models are only as strong as data that is fed into them and the more insight a data scientist has into their data, the stronger the features they'll create are and the more informed their design choices will be.\n",
    "\n",
    "<div><img src=\"https://files.training.databricks.com/images/eLearning/ML-Part-1/eda.png\" style=\"height: 500px; margin: 20px\"/></div>\n",
    "\n",
    "Exploratory analysis focuses on the following:<br><br>\n",
    "\n",
    "1. Gain basic intuition into the data\n",
    "  - What does each feature represent?\n",
    "  - Are your features categorical or continuous?\n",
    "  - What data needs to be encoded? (e.g. mapping a variable for gender to a number)\n",
    "  - What data types are you working with? (e.g. integers, strings)\n",
    "2. How is the data distributed?\n",
    "  - What is the mean, median, and/or mode of each variable?\n",
    "  - What is the variance, or spread, of each variable?\n",
    "  - Are there outliers?  Missing values?\n",
    "3. How can we visualize the data?\n",
    "  - Histograms, scatterplots, and boxplots\n",
    "  - Correlation plots\n",
    "4. What hypotheses will I test with my models?\n",
    "  - What features are correlated?\n",
    "  - What are our ideal features and how can we build them if they're not already available?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bcb3c3ca-7579-4dc3-a09a-e91f442ad1fa",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Run the following cell to set up our environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "963a46db-8f2c-46cb-b8ff-d6cc36cb2881",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "",
       "errorTraceType": null,
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run \"./Includes/Classroom-Setup\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e0fe2287-296e-4e48-a1a9-30cc3a6dbf86",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Count, Mean, and Standard Deviation\n",
    "\n",
    "One way to start the EDA process is to calculate **n**, or the number of observations in the dataset, as well as the center and spread of the data.  We can break this down in the following way:<br><br>\n",
    "\n",
    "1. Count gives us the number of observed values, indicating the size of the dataset and whether there are missing values.\n",
    "2. Mean gives us the center of the data.  This could also be accomplished with the median or mode, depending on the data.\n",
    "3. Standard deviation quantifies how spread out the data is from the mean.  A small standard deviation indicates that the data is closely centered on the mean.\n",
    "\n",
    "<div><img src=\"https://files.training.databricks.com/images/eLearning/ML-Part-1/standard-deviation.png\" style=\"height: 250px; margin: 20px\"/></div>\n",
    "\n",
    "This chart indicates how to interpret standard deviation.  68% of the data is within one standard deviation (represented by `Ïƒ`) from the mean.\n",
    "\n",
    "<img alt=\"Side Note\" title=\"Side Note\" style=\"vertical-align: text-bottom; position: relative; height:1.75em; top:0.05em; transform:rotate(15deg)\" src=\"https://files.training.databricks.com/static/images/icon-note.webp\"/> See the <a href=\"https://en.wikipedia.org/wiki/Standard_deviation\" target=\"_blank\">Wikipedia article on Standard Deviation for more details on standard deviation.</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1a0bbecc-459d-4ebc-9101-1d9f077b2fca",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Import the Boston dataset and call the `.describe()` method on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ba541b9c-96f3-4ebf-bab8-9aac945d25f3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "",
       "errorTraceType": null,
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "bostonDF = (spark.read\n",
    "  .option(\"HEADER\", True)\n",
    "  .option(\"inferSchema\", True)\n",
    "  .csv(\"/mnt/training/bostonhousing/bostonhousing/bostonhousing.csv\")\n",
    "  .drop(\"_c0\")\n",
    ")\n",
    "\n",
    "display(bostonDF.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9c9f0b36-1251-4d85-90cc-530a22e883a0",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "This shows that there are 506 observations in our dataset with no missing values since the counts of our records are all equal.  Take a look at just the output variable `medv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4af07f60-aaa4-4b9d-b6d8-9a346f6b8e70",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "",
       "errorTraceType": null,
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(bostonDF.select(\"medv\").describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f3ac0dfc-55f7-4b97-ad67-007fee3a6188",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "As seen with the mean and standard deviation, the average house price is $22,532 with 68% of the observations within $9,197 of that average.\n",
    "\n",
    "<img alt=\"Side Note\" title=\"Side Note\" style=\"vertical-align: text-bottom; position: relative; height:1.75em; top:0.05em; transform:rotate(15deg)\" src=\"https://files.training.databricks.com/static/images/icon-note.webp\"/> `medv` is in 1000's of dollars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dfb80e92-bf7f-4be4-a47f-41eb517e182d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Plotting, Distributions, and Outliers\n",
    "\n",
    "Anscombe's Quartet is a set of four datasets that have identical means, standard deviations, and correlations.  Despite the fact that the descriptive statistics are the same, the underlying data is very different.  This is a cautionary tale for why data should always be plotted in the EDA phase.\n",
    "\n",
    "<div><img src=\"https://files.training.databricks.com/images/eLearning/ML-Part-1/anscombes_quartet.svg\" style=\"height: 400px; margin: 20px\"/></div>\n",
    "\n",
    "Plotting of a single variable is normally first done using a histogram.  This plots the general distribution of the data with the value on the x axis and the frequency the value appears on the y axis.  Plotting of two variables is normally first done with a scatterplot.\n",
    "\n",
    "<img alt=\"Side Note\" title=\"Side Note\" style=\"vertical-align: text-bottom; position: relative; height:1.75em; top:0.05em; transform:rotate(15deg)\" src=\"https://files.training.databricks.com/static/images/icon-note.webp\"/> For plotting a single variable in a more more rigorous way, use <a href=\"https://en.wikipedia.org/wiki/Kernel_density_estimation\" target=\"_blank\">kernel density estimation</a> plots instead of histograms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a45bae45-0c0f-42a3-9c82-f3876013461f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Plot a histogram of the median value in the housing dataset.  Display this column, click on the plotting option, and visualize it as a histogram.\n",
    "\n",
    "<div><img src=\"https://files.training.databricks.com/images/eLearning/ML-Part-1/plotting.png\" style=\"height: 300px; margin: 20px\"/></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f057295b-fc6c-4f27-b152-e6a162a71d8b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "",
       "errorTraceType": null,
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(bostonDF.select(\"medv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dc3a5f33-1744-4c94-bdff-65b83bbb3a92",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "This plot shows the general distribution of median housing prices divided into 20 bins.  Now take a look at how the number of rooms compares to the median value.  Do this by selecting the scatterplot option from the plotting dropped menu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dfcddb7e-aedf-4217-aea1-d0ee8ef6989a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "",
       "errorTraceType": null,
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(bostonDF.select(\"rm\", \"medv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "80df7603-82ec-4322-9359-91df912adf7b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "By clicking the \"LOESS\" box under Plot Options, a local regression line is added showing the trend."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3c42c56f-2b7c-4ef3-b9cb-356b5a7385e7",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Databricks notebooks can display plots generated in pure Python:<br><br>\n",
    "\n",
    "1. Import `matplotlib`, `pandas`, and `seaborn`\n",
    "2. Create a `fig` object\n",
    "3. Use the `.toPandas()` DataFrame method to turn the Spark DataFrame into a Pandas DataFrame.  This way we can use Python's plotting libraries\n",
    "4. Use the `scatter_matrix` pandas function to plot a matrix of scatterplots\n",
    "\n",
    "<img alt=\"Caution\" title=\"Caution\" style=\"vertical-align: text-bottom; position: relative; height:1.3em; top:0.0em\" src=\"https://files.training.databricks.com/static/images/icon-warning.svg\"/> Do not use `.toPandas()` on large datasets since a Pandas DataFrame must fit into the driver node of a cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3d1b4700-2817-4846-b7bb-5c022715a1a3",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Plot a scatter matrix using the `pandas` Python library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8d2ea4ba-8020-4e09-b3d8-51eb0c72932a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "",
       "errorTraceType": null,
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%python\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns # importing for a better color scheme\n",
    "\n",
    "try:\n",
    "  bostonDF\n",
    "except NameError: # Looks for local table if bostonDF not defined\n",
    "  bostonDF = spark.table(\"boston\")\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "pandasDF = bostonDF.select(\"rm\", \"crim\", \"lstat\", \"medv\").toPandas()\n",
    "\n",
    "pd.plotting.scatter_matrix(pandasDF)\n",
    "\n",
    "display(fig.figure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a2d61ae3-737c-4735-a0ed-38dce684d6ca",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "The above plot shows histograms on the diagonal and scatterplots in the other quadrants.  The plot in the upper-left hand quarter is a histogram of the `rm` variable and the plot to its right is a scatterplot with `rm` as the y axis and `crim` as the x axis.  This shows us correlations across our variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c3e955fd-f056-4521-9d2b-9657fc502ee1",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Correlations\n",
    "\n",
    "Correlation is the first way of understanding the relationship between two variables.  The correlation of two variables is the degree to which one variable increases linearly with the other:<br><br>\n",
    "\n",
    "* A positive correlation of 1 means that for each unit increase in one variable, the same increase is seen in the other\n",
    "* A negative correlation of -1 means that for each unit increase in one variable, the same decrease is seen in the other\n",
    "* A correlation of 0 means that there is no association between the variables\n",
    "\n",
    "More formally, correlation is computed as the following:<br><br>\n",
    "\n",
    "<div><img src=\"https://files.training.databricks.com/images/eLearning/ML-Part-1/correlation.svg\" style=\"height: 60px; margin: 20px\"/></div>\n",
    "\n",
    "The correlation of variables X and Y is their covariance over the standard deviation of X multiplied by the standard deviation of Y.  The covariance is calculated by summing up the product of each value minus their respective mean (`Î¼`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8cbb1443-8278-42b1-af6f-140fbe257917",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "To deepen our understanding of correlation, add columns to the `bostonDF` DataFrame that accomplishes the following:<br><br>\n",
    "\n",
    "1. `medvX3`: `medv` multiplied by 3\n",
    "3. `medvNeg`: `medv` multiplied by -3\n",
    "4. `random1`: a random number\n",
    "5. `random2`: a second random number\n",
    "6. `medvWithNoise`: `medv` multiplied by some random noise\n",
    "7. `medvWithNegativeNoise`: negative `medv` multiplied by some random noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "049ab818-e70b-427e-ab76-2e54d046ded8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "",
       "errorTraceType": null,
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, rand\n",
    "\n",
    "bostonWithDummyDataDF = (bostonDF\n",
    "  .select(\"medv\")\n",
    "  .withColumn(\"medvX3\", col(\"medv\")*3)\n",
    "  .withColumn(\"medvNeg\", col(\"medv\")*-3)\n",
    "  .withColumn(\"random1\", rand(seed=41))\n",
    "  .withColumn(\"random2\", rand(seed=44))\n",
    "  .withColumn(\"medvWithNoise\", col(\"medv\")*col(\"random1\"))\n",
    "  .withColumn(\"medvWithNegativeNoise\", col(\"medv\")*col(\"random1\")*-1)\n",
    ")\n",
    "\n",
    "display(bostonWithDummyDataDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8c898348-ea1a-44a5-a1d7-d6564e2042e9",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Calculate correlations between all columns and `id`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "37968cf7-872c-454e-a150-80ccdbcb2bc3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "",
       "errorTraceType": null,
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for col in bostonWithDummyDataDF.columns:\n",
    "  correlation = bostonWithDummyDataDF.stat.corr(\"medv\", col)\n",
    "  \n",
    "  print(\"The correlation between columns 'id' and '{}': \\t{}\".format(col, correlation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bac1894e-e4fd-425b-bf4f-ec8e9bfd48a4",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "The main takeaways:<br><br>\n",
    "\n",
    "* The correlation between `id` and itself is 1, as is the correlation between `id` and `id` multiplied by 3.  \n",
    "* The correlation between `id` and `id` multiplied by -3 is -1.  \n",
    "* The correlations between `id` and random noise varied based on what was in the noise, but the results were closer to 0.  \n",
    "* There were stronger positive and negative correlations in random noise multiplied by `id` than in random noise not correlated to `id`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "88acbaea-92c9-4200-ba45-38b64c9bebb3",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Other Visualization Tools\n",
    "\n",
    "There are a number of other helpful visualizations depending on the needs of your data.  These include:<br><br>\n",
    "\n",
    "* <a href=\"https://en.wikipedia.org/wiki/Heat_map\" target=\"_blank\">Heat maps:</a> similar to a scattermatrix, heatmaps can be especially helpful at visualizing correlations between variables\n",
    "* <a href=\"https://en.wikipedia.org/wiki/Box_plot\" target=\"_blank\">Box plots:</a> visualizes quantiles and outliers\n",
    "* <a href=\"https://en.wikipedia.org/wiki/Q%E2%80%93Q_plot\" target=\"_blank\">Q-Q Plots:</a> visualizes two probability distributions\n",
    "* <a href=\"https://en.wikipedia.org/wiki/Geographic_information_system\" target=\"_blank\">Maps and GIS:</a> visualizes geographically-bound data\n",
    "* <a href=\"https://en.wikipedia.org/wiki/T-distributed_stochastic_neighbor_embedding\" target=\"_blank\">t-SNE:</a> plots high dimensional data (i.e. data that has many variables) by projecting it down into two-diminsional plot\n",
    "* <a href=\"https://en.wikipedia.org/wiki/Time_series\" target=\"_blank\">Time series:</a> plots time-bound variables including run charts, lag plots, and wavelet spectrograms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1cf33b93-7a59-4273-93ff-02650c981fc8",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Assemble all of the `bostonDF` features into a single column `features`.  This allows us to use Spark's built-in correlation functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bf829122-69db-4381-9255-74571835b6cb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "",
       "errorTraceType": null,
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%python\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "assembler = VectorAssembler(inputCols=bostonDF.columns, outputCol=\"features\")\n",
    "\n",
    "bostonFeaturizedDF = assembler.transform(bostonDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4599bc82-fd2e-421c-ba39-e92dd0e7703d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Calculate the correlations across the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2da33860-1688-4bb0-a23d-d6be3ca6152a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "",
       "errorTraceType": null,
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%python\n",
    "from pyspark.ml.stat import Correlation\n",
    "\n",
    "pearsonCorr = Correlation.corr(bostonFeaturizedDF, 'features').collect()[0][0]\n",
    "pandasDF = pd.DataFrame(pearsonCorr.toArray())\n",
    "\n",
    "pandasDF.index, pandasDF.columns = bostonDF.columns, bostonDF.columns # Labels our index and columns so we can interpret the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "526583f9-8e69-4352-ad88-baea352f1f89",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Plot a heatmap of the correlations.  The redder the value, the stronger the positive correlation and the bluer the value the stronger the negative correlation.  Do this in pure Python rather than Spark because Python has better plotting functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "18e5ca13-161e-4786-a502-4ef61d8db8d3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "",
       "errorTraceType": null,
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%python\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "sns.heatmap(pandasDF)\n",
    "display(fig.figure)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "3. Exploratory Analysis",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
