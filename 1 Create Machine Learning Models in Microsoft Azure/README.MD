# Create Machine Learning Models in Microsoft Azure

## INDICE:

- [1 Introduction to the program](#1-introduction-to-the-program)
- [2 Explore & Analyse Data With Python](#2-explore--analyse-data-with-python)
- [3 Train and Evaluate Regression Models](#3-train-and-evaluate-regression-models)
- [4 Train and Evaluate Classification Models](#4-train-and-evaluate-classification-models)
- [5 Train and Evaluate Clustering Models](#5-train-and-evaluate-clustering-models)
- [6 Train a Deep Neural Network](#6-train-a-deep-neural-network)
- [7 Train a Convolutional Neural Network](#7-train-a-convolutional-neural-network)
- [8 Course Wrap-Up](#8-course-wrap-up)

# 1 Introduction to the program
Exploración y análisis de datos en el núcleo de la ciencia de datos. Los científicos de datos requieren habilidades en lenguajes como Python para explorar, visualizar y manipular datos. En este módulo, aprenderás a utilizar Python para explorar, visualizar y manipular datos. También aprenderás cómo la regresión se puede utilizar para crear un modelo de aprendizaje automático que predice valores numéricos. Utilizarás el framework scikit-learn en Python para entrenar y evaluar un modelo de regresión.

## INDICE:

- [Introduction to the course](#introduction-to-the-course)
- [Exam DP-100: Designing and Implementing a Data Science Solution on Azure certification](#exam-dp-100-designing-and-implementing-a-data-science-solution-on-azure-certification)
- [Course Syllabus](#course-syllabus)
- [Exam DP-100: Skills Measured](#exam-dp-100-skills-measured)
- [How to be successful in this course](#how-to-be-successful-in-this-course)

## Introduction to the course

![1.png](ims%2FC1%2F1.png)

En este curso, aprenderás a crear modelos de aprendizaje automático en Microsoft Azure. El aprendizaje automático es fundamental para la modelización predictiva y la inteligencia artificial. El curso se compone de varios módulos:

![2.png](ims%2FC1%2F2.png)


![3.png](ims%2FC1%2F3.png)

**Módulo 1: Exploración de datos y creación de modelos para predecir valores numéricos**

- En este módulo, se enfoca en la exploración y análisis de datos, habilidades esenciales en la ciencia de datos.
- Se utiliza Python para explorar, visualizar y manipular datos.
- Se describe cómo se puede usar la regresión para predecir valores numéricos.
- Se emplea el framework Scikit-learn en Python para entrenar y evaluar un modelo de regresión.

![4.png](ims%2FC1%2F4.png)

**Módulo 2: Entrenamiento y evaluación de modelos de clasificación y agrupación**

- Se aborda la clasificación, una técnica de aprendizaje automático para categorizar elementos en clases.
- Se utiliza el framework Scikit-learn en Python para entrenar y evaluar un modelo de clasificación.
- Se explora cómo la agrupación se emplea para crear modelos de aprendizaje automático no supervisados que agrupan observaciones de datos en clusters.
- Se entrena un modelo de agrupación utilizando Scikit-learn en Python.

![5.png](ims%2FC1%2F5.png)

**Módulo 3: Entrenamiento y evaluación de modelos de aprendizaje profundo**

- Se enseñan los principios fundamentales del aprendizaje profundo y cómo crear modelos de redes neuronales profundas usando PyTorch o TensorFlow.
- Se explora el uso de redes neuronales convolucionales para crear modelos de clasificación de imágenes.
- A lo largo del curso, se ofrece la oportunidad de explorar modelos de aprendizaje automático en Microsoft Azure mediante ejercicios interactivos y ejemplos del mundo real de la ciencia de datos en acción, evaluaciones de conocimientos y exámenes prácticos.

![6.png](ims%2FC1%2F6.png)

Finalmente, al concluir cada sección habrá un apartado de ejercicios interactivos, repasos de información y exámenes prácticos.

## Exam DP-100: Designing and Implementing a Data Science Solution on Azure certification

![7.png](ims%2FC1%2F7.png)

La certificación Microsoft Certified: Azure Data Scientist Associate es una oportunidad para demostrar el conocimiento en la aplicación de la ciencia de datos y el aprendizaje automático para implementar y ejecutar cargas de trabajo de aprendizaje automático en Azure. Esta certificación está diseñada para candidatos con experiencia en ciencia de datos y el uso de Azure Machine Learning y Azure Databricks. El examen de certificación generalmente consta de entre 40 y 60 preguntas, aunque el número puede variar según el examen. Se utilizan diferentes tipos de preguntas, como escenarios, respuestas cortas, opciones múltiples, revisión de marcas y arrastrar y soltar.

![8.png](ims%2FC1%2F8.png)

El examen abarca las siguientes áreas de dominio: gestionar recursos de Azure para el aprendizaje automático, ejecutar experimentos y entrenar modelos, implementar y operativizar soluciones de aprendizaje automático y aplicar principios éticos en el aprendizaje automático. Cuanto mayor sea el porcentaje, más preguntas contendrá esa sección específica del examen.

![9.png](ims%2FC1%2F9.png)

Para prepararte, tendrás acceso a la información necesaria a través de este programa. Una vez que completes con éxito un curso, recibirás un certificado de Coursera, y al finalizar el programa, recibirás un certificado adicional. Además, recibirás una notificación electrónica que te permitirá desbloquear un código de descuento del 50 por ciento para la certificación. 

![10.png](ims%2FC1%2F10.png)

**Ejemplos de candidatos y sus trayectorias:**

- **Carlos**, con experiencia en pruebas de software, decidió cambiar de carrera y completó con éxito la certificación Microsoft Azure Data Scientist Associate, lo que le ayudó a conseguir un empleo en el campo de la ciencia de datos.

- **June**, con una sólida experiencia en datos, aprovechó la certificación para avanzar en su carrera y abrir nuevas oportunidades en su campo.

- **Vikram**, un principiante, está trabajando en obtener la experiencia laboral necesaria para completar la certificación Microsoft Certified: Azure Data Scientist Associate y avanzar en su carrera.

## Course syllabus

El aprendizaje automático es la base de la modelización predictiva e inteligencia artificial. En este curso, aprenderás los principios fundamentales del aprendizaje automático y cómo utilizar herramientas y marcos comunes para entrenar, evaluar y utilizar modelos de aprendizaje automático.

**Módulo 1: Exploración de datos y creación de modelos para predecir valores numéricos**

La exploración y el análisis de datos son fundamentales en la ciencia de datos. Los científicos de datos necesitan habilidades en lenguajes como Python para explorar, visualizar y manipular datos. En este módulo, aprenderás a utilizar Python para explorar, visualizar y manipular datos. También aprenderás cómo la regresión se puede utilizar para crear un modelo de aprendizaje automático que predice valores numéricos. Utilizarás el framework scikit-learn en Python para entrenar y evaluar un modelo de regresión.

**Módulo 2: Entrenar y evaluar modelos de clasificación y agrupación**

La clasificación es un tipo de aprendizaje automático que se utiliza para categorizar elementos en clases. En este módulo, aprenderás cómo la clasificación se puede utilizar para crear un modelo de aprendizaje automático que predice categorías o clases. Utilizarás el framework scikit-learn en Python para entrenar y evaluar un modelo de clasificación. También aprenderás cómo la agrupación se puede utilizar para crear modelos de aprendizaje automático no supervisados que agrupan observaciones de datos en clústeres. Utilizarás el framework scikit-learn en Python para entrenar un modelo de agrupación.

**Módulo 3: Entrenar y evaluar modelos de aprendizaje profundo**

En este módulo, aprenderás los principios fundamentales del aprendizaje profundo y cómo crear modelos de redes neuronales profundas utilizando PyTorch o TensorFlow. También explorarás el uso de redes neuronales convolucionales para crear modelos de clasificación de imágenes.

## Exam DP-100: Skills Measured

**Perfil del público objetivo**

Los candidatos para la certificación Azure Data Scientist Associate deben tener experiencia en la aplicación de la ciencia de datos y el aprendizaje automático para implementar y ejecutar cargas de trabajo de aprendizaje automático en Azure.

Las responsabilidades de este rol incluyen planificar y crear un entorno de trabajo adecuado para las cargas de trabajo de ciencia de datos en Azure. Realizas experimentos de datos y entrenas modelos predictivos. Además, gestionas, optimizas y despliegas modelos de aprendizaje automático en producción.

Un candidato para esta certificación debe tener conocimientos y experiencia en ciencia de datos y en el uso de Azure Machine Learning y Azure Databricks.

###  Habilidades evaluadas

### Administrar recursos de Azure para el aprendizaje automático (25-30%)

**Crear un espacio de trabajo de Azure Machine Learning**

- Configurar ajustes del espacio de trabajo
- Gestionar un espacio de trabajo utilizando Azure Machine Learning Studio

**Gestionar datos en un espacio de trabajo de Azure Machine Learning**

- Seleccionar recursos de almacenamiento de Azure
- Registrar y mantener almacenes de datos
- Crear y gestionar conjuntos de datos

**Gestionar cómputo para experimentos en Azure Machine Learning**

- Determinar las especificaciones de cómputo apropiadas para una carga de trabajo de entrenamiento
- Crear objetivos de cómputo para experimentos y entrenamiento
- Configurar recursos de cómputo adjuntos, incluido Azure Databricks
- Monitorizar la utilización de cómputo

**Implementar seguridad y control de acceso en Azure Machine Learning**

- Determinar los requisitos de acceso y asignar requisitos a roles integrados
- Crear roles personalizados
- Gestionar la membresía de roles
- Gestionar credenciales utilizando Azure Key Vault

**Configurar un entorno de desarrollo de Azure Machine Learning**

- Crear instancias de cómputo
- Compartir instancias de cómputo
- Acceder a espacios de trabajo de Azure Machine Learning desde otros entornos de desarrollo

**Configurar un espacio de trabajo de Azure Databricks**

- Crear un espacio de trabajo de Azure Databricks
- Crear un clúster de Azure Databricks
- Crear y ejecutar cuadernos en Azure Databricks
- Vincular un espacio de trabajo de Azure Databricks a un espacio de trabajo de Azure Machine Learning

### Ejecutar experimentos y entrenar modelos (20-25%)

**Crear modelos utilizando el diseñador de Azure Machine Learning**

- Crear un pipeline de entrenamiento utilizando el diseñador de Azure Machine Learning
- Ingerir datos en un pipeline de diseñador
- Utilizar módulos de diseñador para definir un flujo de datos del pipeline
- Utilizar módulos de código personalizado en el diseñador

**Ejecutar scripts de entrenamiento de modelos**

- Crear y ejecutar un experimento utilizando el SDK de Azure Machine Learning
- Configurar ajustes de ejecución para un script
- Consumir datos de un conjunto de datos en un experimento utilizando el SDK de Azure Machine Learning
- Ejecutar un script de entrenamiento en Azure Databricks Compute
- Ejecutar código para entrenar un modelo en un cuaderno de Azure Databricks

**Generar métricas a partir de la ejecución de un experimento**

- Registrar métricas de la ejecución de un experimento
- Recuperar y ver salidas de experimentos
- Utilizar registros para solucionar problemas de errores de ejecución de experimentos
- Utilizar MLflow para rastrear experimentos
- Rastrear experimentos en ejecución en Azure Databricks

**Utilizar el Aprendizaje Automático Automatizado para crear modelos óptimos**

- Utilizar la interfaz de Aprendizaje Automático Automatizado en Azure Machine Learning Studio
- Utilizar el Aprendizaje Automático Automatizado desde el SDK de Azure Machine Learning
- Seleccionar opciones de preprocesamiento
- Seleccionar los algoritmos a buscar
- Definir una métrica principal
- Obtener datos para una ejecución de Aprendizaje Automático Automatizado
- Recuperar el mejor modelo

**Ajustar hiperparámetros con Azure Machine Learning**

- Seleccionar un método de muestreo
- Definir el espacio de búsqueda
- Definir la métrica principal
- Definir opciones de terminación anticipada
- Encontrar el modelo con valores óptimos de hiperparámetros

### Implementar y operativizar soluciones de aprendizaje automático (35-40%)

**Seleccionar cómputo para el despliegue de modelos**

- Considerar la seguridad para servicios desplegados
- Evaluar opciones de cómputo para el despliegue

**Desplegar un modelo como un servicio**

- Configurar ajustes de despliegue
- Desplegar un modelo registrado
- Desplegar un modelo entrenado en Azure Databricks en un punto de conexión de Azure Machine Learning
- Consumir un servicio desplegado
- Solucionar problemas de contenedor de despliegue

**Gestionar modelos en Azure Machine Learning**

- Registrar un modelo entrenado
- Supervisar el uso del modelo
- Supervisar el cambio de datos

**Crear un pipeline de Azure Machine Learning para inferencia por lotes**

- Configurar un ParallelRunStep
- Configurar cómputo para un pipeline de inferencia por lotes
- Publicar un pipeline de inferencia por lotes
- Ejecutar un pipeline de inferencia por lotes y obtener salidas
- Obtener salidas de un ParallelRunStep

**Publicar un pipeline de diseñador de Azure Machine Learning como un servicio web**

- Crear un recurso de cómputo de destino
- Configurar un pipeline de inferencia
- Consumir un punto de conexión desplegado

**Implementar prácticas de ML Ops**

- Desencadenar un pipeline de Azure Machine Learning desde Azure DevOps
- Automatizar la reentrenamiento del modelo basado en nuevas adiciones de datos o cambios en los datos
- Refactorizar cuadernos en scripts
- Implementar control de fuente para scripts

### Implementar aprendizaje automático responsable (5-10%)

**Utilizar intérpretes de modelos para interpretar modelos**

- Seleccionar un intérprete de modelo
- Generar datos de importancia de características

**Describir consideraciones de equidad para modelos**

- Evaluar la equidad del modelo basada en disparidad de predicción
- Mitigar la inequidad del modelo

**Describir consideraciones de privacidad para datos**

- Describir los principios de la privacidad diferencial
- Especificar niveles aceptables de ruido en los datos y los efectos en la privacidad

## How to be successful in this course

### **Cómo tener éxito en este curso**

Tomar un curso en línea puede resultar abrumador. ¿Cómo aprendes a tu propio ritmo y logras con éxito tus objetivos?

Aquí tienes algunos consejos generales que pueden ayudarte a mantenerte enfocado y en el camino correcto:

### Establece metas diarias para estudiar:
Pregúntate qué esperas lograr en tu curso cada día. Establecer una meta clara puede ayudarte a mantenerte motivado y vencer la procrastinación. La meta debe ser específica y fácil de medir, como "Voy a ver todos los videos del Módulo 2 y completar la primera tarea de programación". ¡Y no olvides recompensarte cuando avances hacia tu objetivo!

### Crea un espacio de estudio dedicado:
Es más fácil recordar la información si te encuentras en el mismo lugar donde la aprendiste por primera vez. Por lo tanto, tener un espacio dedicado en casa para tomar cursos en línea puede hacer que tu aprendizaje sea más efectivo. Elimina cualquier distracción del espacio y, si es posible, mantenlo separado de tu cama o sofá. Una clara distinción entre donde estudias y donde tomas descansos puede ayudarte a concentrarte.

### Programa tiempo para estudiar en tu calendario:
Abre tu calendario y elige un momento predecible y confiable que puedas dedicar a ver clases y completar tareas. Esto ayuda a asegurarte de que tus cursos no se conviertan en la última tarea de tu lista de cosas por hacer.

> Consejo: Puedes agregar fechas límite para un curso de Coursera a tu calendario de Google, calendario de Apple u otra aplicación de calendario.

### Mantente responsable:
Cuéntales a tus amigos sobre los cursos que estás tomando, publica tus logros en tus cuentas de redes sociales o crea un blog sobre tus tareas. Tener una comunidad y una red de apoyo de amigos y familiares que te animen marca la diferencia.

### Toma notas de manera activa:
Tomar notas puede fomentar el pensamiento activo, aumentar la comprensión y ampliar tu capacidad de atención. Es una buena estrategia para interiorizar el conocimiento, ya sea que estés aprendiendo en línea o en el aula. Así que, toma una libreta o encuentra una aplicación digital que funcione mejor para ti y comienza a sintetizar puntos clave.

> Consejo: Mientras ves una conferencia en Coursera, puedes hacer clic en el botón "Guardar nota" debajo del video para guardar una captura de pantalla en tus notas del curso y agregar tus propios comentarios.

### Únete a la discusión:
Los foros de discusión del curso son un gran lugar para hacer preguntas sobre tareas, discutir temas, compartir recursos y hacer amigos. Nuestra investigación muestra que los estudiantes que participan en los foros de discusión son un 37% más propensos a completar un curso. ¡Así que publica hoy mismo!

### Haz una cosa a la vez:
Hacer varias cosas a la vez es menos productivo que centrarse en una tarea a la vez. Investigadores de la Universidad de Stanford encontraron que "las personas que reciben regularmente varias corrientes de información electrónica no pueden prestar atención, recordar información ni cambiar de una tarea a otra tan bien como aquellos que completan una tarea a la vez". Mantente enfocado en una tarea a la vez. Absorberás más información y completarás las tareas con mayor productividad y facilidad que si intentaras hacer muchas cosas al mismo tiempo.

### Tómate descansos:
Descansar tu mente después de aprender es fundamental para un alto rendimiento. Si te encuentras trabajando en un problema desafiante sin mucho progreso durante una hora, tómate un descanso. Salir a caminar, darte una ducha o hablar con un amigo puede revitalizarte e incluso darte nuevas ideas sobre cómo abordar ese proyecto.

-----

¡Tu viaje de aprendizaje de Microsoft Azure AI Fundamentals comienza ahora! Mientras te preparas para el examen AI-900 o trabajas para alcanzar tus metas de aprendizaje, te animamos a:

Revisar las pautas del examen y las habilidades evaluadas como punto de partida.
Trabajar en cada lección en la vía de aprendizaje. Intenta no saltarte ninguna actividad o lección a menos que estés seguro de que ya conoces esta información lo suficientemente bien como para avanzar.
Aprovechar la oportunidad de volver atrás y ver un video o leer la información adicional proporcionada antes de pasar a la siguiente lección o módulo.
Completar todos los cuestionarios, preguntas de práctica del examen y ejercicios. Durante las sesiones de práctica, tienes la oportunidad de repasar las preguntas nuevamente para asegurarte de estar satisfecho con tu progreso.
Leer cuidadosamente los comentarios al responder cuestionarios o exámenes de práctica, ya que esto te ayudará a reforzar lo que estás aprendiendo.
Utilizar el espacio de trabajo de Microsoft Azure Machine Learning. Para utilizar Azure Machine Learning, debes crear un espacio de trabajo en tu suscripción de Azure. Luego, puedes utilizar este espacio de trabajo para completar los ejercicios relacionados. Se te darán instrucciones claras sobre cómo configurarlo. Después de completar cada lección, también recibirás instrucciones sobre cómo "limpiar" para que puedas reutilizar el espacio

# 2 Explore & Analyse Data with Python

## INDICE:

- [2 Lesson introduction](#2-lesson-introduction)
- [Explore data with NumPy and Pandas](#explore-data-with-numpy-and-pandas)
- [Exercise explore data with NumPy and Pandas](#exercise-explore-data-with-numpy-and-pandas)
- [2 Exercise Quiz 1](#2-exercise-quiz-1)
- [Visualize Data](#visualize-data)
- [Exercise Visualize data with Matplotlib](#exercise-visualize-data-with-matplotlib)
- [2 Exercise Quiz 2](#2-exercise-quiz-2)
- [Examine real world data](#examine-real-world-data)
- [Exercise Examine real world data](#exercise-examine-real-world-data)
- [2 Exercise Quiz 3](#2-exercise-quiz-3)
- [2 Knowledge check 1](#2-knowledge-check)
- [2 Lesson summary](#2-lesson-summary)

## 2 Lesson introduction

![11.png](ims%2FC1%2F11.png)

En esta lección, aprenderás a explorar y analizar datos con Python. La función principal de los científicos de datos es, como era de esperar, explorar y analizar datos. Los resultados de un análisis pueden servir de base para un informe o un modelo de aprendizaje automático. Pero todo comienza con los datos, y Python es el lenguaje de programación más popular para los científicos de datos.

![12.png](ims%2FC1%2F12.png)

Después de décadas de desarrollo de código abierto, Python ofrece una amplia funcionalidad con potentes bibliotecas estadísticas y numéricas. NumPy y Pandas simplifican el análisis y la manipulación de datos. Matplotlib proporciona visualizaciones de datos atractivas. Scikit-learn ofrece un análisis de datos predictivo simple y efectivo. TensorFlow y PyTorch proporcionan capacidades de aprendizaje automático y aprendizaje profundo.

![13.png](ims%2FC1%2F13.png)

Por lo general, un proyecto de análisis de datos está diseñado para establecer ideas en torno a un escenario específico o para probar una hipótesis. Por ejemplo, supongamos que un profesor universitario recopila datos de sus estudiantes, incluyendo el número de clases a las que asisten, las horas que pasan estudiando y la calificación final obtenida en el examen de fin de curso.

![14.png](ims%2FC1%2F14.png)

El profesor podría analizar los datos para determinar si existe una relación entre la cantidad de estudio que realiza un estudiante y la calificación final que obtienen. El profesor podría usar los datos para probar una hipótesis de que solo los estudiantes que estudian durante un número mínimo de horas pueden esperar obtener una calificación aprobatoria.

![15.png](ims%2FC1%2F15.png)

![16.png](ims%2FC1%2F16.png)

En esta lección, aprenderás tareas comunes de exploración y análisis de datos, y explorarás cómo utilizar paquetes de Python como NumPy, Pandas y Matplotlib para analizar datos.

## Explore data with NumPy and Pandas

Los científicos de datos pueden utilizar diversas herramientas y técnicas para explorar, visualizar y manipular datos. Una de las formas más comunes en las que los científicos de datos trabajan con datos es utilizando el lenguaje Python y algunos paquetes específicos para el procesamiento de datos.

### ¿Qué es NumPy?
NumPy es una biblioteca de Python que proporciona funcionalidad comparable a herramientas matemáticas como MATLAB y R. Si bien NumPy simplifica significativamente la experiencia del usuario, también ofrece funciones matemáticas completas.

### ¿Qué es Pandas?
Pandas es una biblioteca de Python extremadamente popular para el análisis y la manipulación de datos. Pandas es como Excel para Python, proporcionando funcionalidad fácil de usar para tablas de datos.

![17.png](ims%2FC1%2F17.png)

Tabla de datos con valores de nombre, edad, estado, número de hijos y mascotas.

### Explora datos en un cuaderno Jupyter
Los cuadernos Jupyter son una forma popular de ejecutar scripts básicos utilizando tu navegador web. Normalmente, estos cuadernos son una sola página web, dividida en secciones de texto y secciones de código que se ejecutan en el servidor en lugar de en tu máquina local. Esto significa que puedes empezar rápidamente sin necesidad de instalar Python u otras herramientas.

### Pruebas de hipótesis
La exploración y análisis de datos es típicamente un proceso iterativo, en el que el científico de datos toma una muestra de datos y realiza las siguientes tareas para analizarla y probar hipótesis:

- Limpia los datos para manejar errores, valores faltantes y otros problemas.
- Aplica técnicas estadísticas para comprender mejor los datos y cómo se espera que la muestra represente la población del mundo real de datos, teniendo en cuenta la variación aleatoria.
- Visualiza los datos para determinar las relaciones entre las variables y, en el caso de un proyecto de aprendizaje automático, identifica las características que podrían ser predictivas de la etiqueta.
- Revisa la hipótesis y repite el proceso.

## Exercise explore data with NumPy and Pandas


Explorando Datos con Python
Una parte significativa del rol de un científico de datos consiste en explorar, analizar y visualizar datos. Existe una amplia gama de herramientas y lenguajes de programación que pueden utilizar para hacer esto, y uno de los enfoques más populares es utilizar cuadernos Jupyter (como este) y Python.

Python es un lenguaje de programación flexible que se utiliza en una amplia variedad de escenarios, desde aplicaciones web hasta programación de dispositivos. Es extremadamente popular en la comunidad de ciencia de datos y aprendizaje automático debido a los numerosos paquetes que admite para el análisis y la visualización de datos.

En este ejercicio, explorarás arreglos de datos con NumPy y datos tabulares con Pandas.

Este ejercicio requiere el entorno de aprendizaje de Microsoft Learn para completarse. Puedes acceder al ejercicio desde el siguiente enlace.

https://learn.microsoft.com/en-us/training/modules/explore-analyze-data-with-python/3-exercise-explore-data

> ### Nota:
> Puedes ver todo el notebook en [1 Explore data with Numpy and Pandas.ipynb](notebooks%2FC2%2F1%20Explore%20data%20with%20Numpy%20and%20Pandas.ipynb)
> 
## 2 Exercise Quiz 1

![18.png](ims%2FC1%2F18.png)

## Visualize data

Los científicos de datos visualizan datos para comprenderlos mejor. Esto puede significar mirar los datos en bruto, medidas resumidas como promedios o representar los datos en gráficos. Los gráficos son una poderosa forma de ver los datos, ya que podemos discernir patrones moderadamente complejos rápidamente sin necesidad de definir medidas resumidas matemáticas.

**Representación visual de datos**

La representación visual de datos generalmente implica representarlos gráficamente. Esto se hace para proporcionar una evaluación cualitativa rápida de nuestros datos, lo que puede ser útil para comprender resultados, encontrar valores atípicos, comprender cómo se distribuyen los números, entre otros.

A veces sabemos de antemano qué tipo de gráfico será más útil, otras veces usamos gráficos de manera exploratoria. Para entender el poder de la visualización de datos, considera los datos a continuación: la ubicación (x, y) de un automóvil autónomo. En su forma cruda, es difícil ver patrones reales. La media o el promedio nos dice que su trayectoria se centró alrededor de x=0,2 e y=0,3, y el rango de números parece estar entre aproximadamente -2 y 2.

![19.png](ims%2FC1%2F19.png)

Si ahora representamos la ubicación-X en función del tiempo, podemos ver que aparentemente tenemos algunos valores faltantes entre los tiempos 7 y 12.

![20.png](ims%2FC1%2F20.png)

Coordenadas representadas a lo largo de un eje X que va de cero a veinte, y de dos a menos dos en el eje Y.

Si graficamos X vs Y, obtenemos un mapa de dónde ha conducido el automóvil. Es instantáneamente obvio que el automóvil ha estado conduciendo en círculo, pero en algún momento condujo al centro de ese círculo.

![21.png](ims%2FC1%2F21.png)

Coordenadas X e Y en un gráfico representado.

Los gráficos no se limitan a gráficos de dispersión en 2D como los anteriores, sino que se pueden utilizar para explorar otros tipos de datos, como proporciones, mostradas a través de gráficos circulares; gráficos de barras apiladas para mostrar cómo se distribuyen los datos, con histogramas, diagramas de caja y bigotes para mostrar cómo difieren dos conjuntos de datos.

A menudo, cuando intentamos comprender datos en bruto o resultados, podemos experimentar con diferentes tipos de gráficos hasta encontrar uno que explique los datos de una manera visualmente intuitiva.

## Exercise Visualize data with Matplotlib


Los DataFrames proporcionan una excelente forma de explorar y analizar datos tabulares, pero a veces una imagen vale más que mil filas y columnas. La biblioteca Matplotlib proporciona la base para crear visualizaciones de datos que pueden mejorar en gran medida tu capacidad para analizar los datos.

Este ejercicio requiere el entorno de aprendizaje de Microsoft Learn para completarse. Puedes acceder al ejercicio desde el siguiente enlace.

https://learn.microsoft.com/en-us/training/modules/explore-analyze-data-with-python/5-exercise-visualize-data

> ### Nota:
> Puedes ver todo el notebook en [2 Visualize data with Matplotlib.ipynb](notebooks%2FC2%2F2%20Visualize%20data%20with%20Matplotlib.ipynb)

## 2 Exercise Quiz 2

![22.png](ims%2FC1%2F22.png)

## Examine real world data

Los datos del mundo real pueden contener muchos problemas diferentes que pueden afectar la utilidad de los datos y nuestra interpretación de los resultados.

Es importante darse cuenta de que la mayoría de los datos del mundo real están influenciados por factores que no se registraron en ese momento. Por ejemplo, podríamos tener una tabla de tiempos de pistas de carreras de coches junto con tamaños de motor, pero es probable que también hayan influido otros factores que no se registraron, como el clima. Si estos factores problemáticos, la influencia de estos factores a menudo se puede reducir aumentando el tamaño del conjunto de datos.

En otras situaciones, los puntos de datos que claramente están fuera de lo esperado, también conocidos como 'valores atípicos', a veces se pueden eliminar de manera segura de los análisis, aunque se debe tener cuidado de no eliminar puntos de datos que proporcionen ideas reales.

Otro problema común en los datos del mundo real es el sesgo. El sesgo se refiere a la tendencia a seleccionar ciertos tipos de valores con más frecuencia que otros, de una manera que distorsiona la población subyacente o el 'mundo real'. A veces, el sesgo se puede identificar explorando los datos teniendo en cuenta el conocimiento básico sobre de dónde provienen los datos.

Recuerda, los datos del mundo real siempre tendrán problemas, pero este problema a menudo es superable. Recuerda:

- Verifica la presencia de valores faltantes y datos mal registrados.
- Considera la eliminación de valores atípicos obvios.
- Piensa en qué factores del mundo real podrían afectar tu análisis y considera si el tamaño de tu conjunto de datos es lo suficientemente grande para manejar esto.
- Verifica si los datos en bruto tienen sesgo y considera tus opciones para corregirlo, si se encuentra.

## Exercise Examine real world data

**Explorando datos con Python: datos del mundo real**

La última vez, examinamos las calificaciones de nuestros datos de estudiantes e investigamos esto visualmente con histogramas y gráficos de caja. Ahora vamos a adentrarnos en casos más complejos, describir los datos de manera más completa y discutir cómo hacer comparaciones básicas entre los datos.

Este ejercicio requiere el uso del entorno de aprendizaje de Microsoft Learn para completarse. Puedes acceder al ejercicio a través del siguiente enlace.

https://learn.microsoft.com/en-us/training/modules/explore-analyze-data-with-python/7-exercise-real-world-data

> ## Nota:
> Puedes ver todo el notebook en [3 Examine real world data.ipynb](notebooks%2FC2%2F3%20Examine%20real%20world%20data.ipynb)

## 2 Exercise Quiz 3

![23.png](ims%2FC1%2F23.png)

## 2 Knowledge check

![24.png](ims%2FC1%2F24.png)

![25.png](ims%2FC1%2F25.png)


## 2 Lesson summary

![26.png](ims%2FC1%2F26.png)

En esta lección, aprendiste cómo utilizar Python para explorar, visualizar y manipular datos. La exploración de datos es fundamental en la ciencia de datos y es un elemento clave en el análisis de datos y el aprendizaje automático. El aprendizaje automático es una subcategoría de la ciencia de datos que se ocupa de la modelización predictiva. En otras palabras, el aprendizaje automático utiliza datos para crear modelos predictivos con el fin de predecir valores desconocidos. 

![27.png](ims%2FC1%2F27.png)

Puedes utilizar el aprendizaje automático para predecir cuánta comida necesita pedir un supermercado o para identificar plantas en una fotografía. El aprendizaje automático funciona identificando relaciones entre los valores de datos que describen características de algo, como la altura y el color de una planta, y el valor que queremos predecir, que es la etiqueta, como la especie de la planta. Estas relaciones se incorporan a un modelo a través de un proceso de entrenamient

# 3 Train and Evaluate Regression Models

## INDICE:

- [3 Lesson Introduction](#3-lesson-introduction)
- [What is Regression?](#what-is-regression)
- [Exercise Train and evaluate a regression model](#exercise-train-and-evaluate-a-regression-model)
- [3 Exercise quiz 1](#3-exercise-quiz-1)
- [Discover new regression models](#discover-new-regression-models)
- [Exercise Experiment with more powerful regression models](#exercise-experiment-with-more-powerful-regression-models)
- [3 Exercise quiz 2](#3-exercise-quiz-2)
- [Improve models with hyperparameters](#improve-models-with-hyperparameters)
- [Exercise Optimize and save models](#exercise-optimize-and-save-models)
- [3 Exercise quiz 3](#3-exercise-quiz-3)
- [3 Knowledge Check](#3-knowledge-check)
- [3 Test prep](#3-test-prep)
- [3 Lesson summary](#3-lesson-summary)

## 3 Lesson Introduction

![1.png](ims%2FC3%2F1.png)

En esta lección, aprenderás cómo entrenar y evaluar modelos de regresión. La regresión es un método en el cual los modelos predicen un número. En el aprendizaje automático, el objetivo de la regresión es crear un modelo que pueda predecir un valor numérico cuantificable, como un precio, cantidad, tamaño u otro número escalar. La regresión es una técnica estadística de gran importancia en la ciencia debido a su facilidad de interpretación, robustez y rapidez en los cálculos. Los modelos de regresión proporcionan una base sólida para comprender cómo funcionan técnicas más complejas de aprendizaje automático.

![2.png](ims%2FC3%2F2.png)

En situaciones del mundo real, especialmente cuando hay poca cantidad de datos disponibles, los modelos de regresión son muy útiles para hacer predicciones. Por ejemplo, si una empresa que alquila bicicletas desea predecir la cantidad esperada de alquileres en un día futuro, un modelo de regresión puede realizar esta predicción. Un modelo podría ser creado utilizando datos existentes, como la cantidad de bicicletas alquiladas en días anteriores, o también se podrían tener en cuenta la estación del año, el día de la semana, y otros factores.

![3.png](ims%2FC3%2F3.png)

En esta lección, aprenderás cuándo usar modelos de regresión y cómo entrenar y evaluar estos modelos utilizando el framework Scikit-Learn. Para aprovechar al máximo esta lección, necesitarás conocimientos básicos de matemáticas y algo de experiencia en programación en Python.

## What is Regression?

![4.png](ims%2FC3%2F4.png)

La regresión funciona estableciendo una relación entre variables en los datos que representan características conocidas como las características del objeto observado y la variable que estamos tratando de predecir, conocida como la etiqueta. Imagina una empresa que alquila bicicletas y desea predecir la cantidad esperada de alquileres en un día dado. En este caso, las características incluyen cosas como el día de la semana, el mes, y así sucesivamente, mientras que la etiqueta es el número de alquileres de bicicletas. Para entrenar el modelo, comenzamos con una muestra de datos que contiene las características, así como los valores conocidos para la etiqueta. En este caso, necesitaríamos datos históricos que incluyan fechas, condiciones climáticas y el número de alquileres de bicicletas. 

![5.png](ims%2FC3%2F5.png)

Luego dividimos esta muestra de datos en dos subconjuntos: un conjunto de datos de entrenamiento al que aplicamos un algoritmo que determina una función que encapsula la relación entre los valores de las características y los valores conocidos de la etiqueta, y un conjunto de datos de validación o prueba que podemos usar para evaluar el modelo al generar predicciones para la etiqueta y compararlas con los valores reales conocidos de la etiqueta.

![6.png](ims%2FC3%2F6.png)

El uso de datos históricos con valores conocidos para entrenar un modelo hace que la regresión sea un ejemplo de aprendizaje automático supervisado. 

![7.png](ims%2FC3%2F7.png)

![8.png](ims%2FC3%2F8.png)

Imaginemos un ejemplo simple para entender cómo funciona el proceso de entrenamiento y evaluación en principio. Supongamos que simplificamos el escenario para usar una sola característica, la temperatura promedio diaria, para predecir la etiqueta de alquileres de bicicletas. Comenzamos con datos que incluyen valores conocidos para la característica de temperatura promedio diaria y la etiqueta de alquileres de bicicletas. Luego seleccionamos aleatoriamente cinco de estas observaciones y las usamos para entrenar un modelo de regresión. 

![9.png](ims%2FC3%2F9.png)

Cuando hablamos de entrenar un modelo, lo que queremos decir es encontrar una función, una ecuación matemática, que pueda utilizar la característica de temperatura para calcular el número de alquileres. En otras palabras, necesitamos definir la siguiente función: f(x) = y. Ahora podemos trazar los valores de entrenamiento para x e y en un gráfico. 

![10.png](ims%2FC3%2F10.png)

Luego necesitamos ajustar estos valores a una función que permita cierta variación aleatoria.

![11.png](ims%2FC3%2F11.png)

En nuestro ejemplo, los puntos trazados forman una línea diagonal casi recta, lo que indica una relación lineal aparente entre x e y. Debemos encontrar una función lineal que sea la mejor opción para la muestra de datos. Hay varios algoritmos que podemos usar para determinar esta función, que finalmente encontrará una línea recta con una varianza mínima en general con respecto a los puntos trazados. La línea representa una función lineal que se puede usar con cualquier valor de x para aplicar la pendiente de la línea y su intersección, donde la línea cruza el eje y cuando x es 0, para calcular y. En este caso, si extendemos la línea hacia la izquierda, descubriremos que cuando x es 0, y es alrededor de 20, y la pendiente de la línea es tal que por cada unidad de x que avanzamos hacia la derecha, y aumenta en alrededor de 1.7. Nuestra función f, por lo tanto, se puede calcular como 20 más 1.7x.

![12.png](ims%2FC3%2F12.png)

Ahora que hemos definido nuestra función predictiva, podemos usarla para predecir etiquetas para los datos de validación que manteníamos en reserva y comparar los valores predichos con los valores reales conocidos. Los valores predichos generalmente se indican con el símbolo `y gorro (^)` en inglés `y_hat`.

![13.png](ims%2FC3%2F13.png)

Los puntos trazados que están en la línea de la función son los valores y gorro predichos calculados por la función. Los otros puntos trazados son los valores y reales. 

![14.png](ims%2FC3%2F14.png)

 Hay varias formas de medir la diferencia entre los valores predichos y los valores reales. Podemos usar estas métricas para evaluar cuán bien predice el modelo. Es importante tener en cuenta que el aprendizaje automático se basa en estadísticas y matemáticas. Es importante estar al tanto de los términos específicos que utilizan los estadísticos, matemáticos y, por lo tanto, los científicos de datos. Puedes pensar en la diferencia entre tu valor de etiqueta predicho y el valor de etiqueta real como una medida de error. 

![15.png](ims%2FC3%2F15.png)

Sin embargo, en la práctica, los valores reales se basan en observaciones de muestra, que a su vez pueden estar sujetas a algunas variantes aleatorias. Para dejar claro que estamos comparando un valor predicho y gorro (y ^) con un valor observado y, nos referimos a la diferencia entre ellos como los residuos. Podemos resumir los residuos para todas las predicciones de datos de validación para calcular la pérdida general en el modelo como una medida de su rendimiento predictivo. 

![16.png](ims%2FC3%2F16.png)

Una de las formas más comunes de medir la pérdida es elevar al cuadrado los residuos individuales, sumar los cuadrados y calcular la media. Elevar al cuadrado los residuos tiene el efecto de basar el cálculo en valores absolutos, sin importar si la diferencia es negativa o positiva, y dar más peso a las diferencias más grandes. Esta métrica se llama error cuadrático medio (MSE, por sus siglas en inglés). 

![17.png](ims%2FC3%2F17.png)

 Volviendo a nuestro ejemplo, la pérdida para nuestro modelo basado en la métrica MSE es 9.79. ¿Es eso bueno? 

![18.png](ims%2FC3%2F18.png)


![19.png](ims%2FC3%2F19.png)

 Es difícil decir si el valor de MSE es bueno, ya que no se expresa en una unidad de medida significativa. Sabemos que cuanto menor sea el valor, menos pérdida hay en el modelo y, por lo tanto, mejor es en la predicción.

![20.png](ims%2FC3%2F20.png)

Esto lo convierte en una métrica útil para comparar dos modelos y encontrar el que funciona mejor.

![21.png](ims%2FC3%2F21.png)

A veces es más útil expresar la pérdida en la misma unidad de medida que la etiqueta predicha en sí, en este caso, el número de alquileres. Esto se puede hacer calculando la raíz cuadrada del MSE, lo que produce una métrica conocida, no sorprendentemente, como error cuadrático medio raíz o RMSE (por sus siglas en inglés). 

![22.png](ims%2FC3%2F22.png)

Por ejemplo, la raíz cuadrada de 9.79 es 3.13. El RMSE de nuestro modelo indica que la pérdida es un poco más de tres, lo que puedes interpretar de manera aproximada como que, en promedio, las predicciones incorrectas difieren en alrededor de tres alquileres. 

![23.png](ims%2FC3%2F23.png)

Existen muchas otras métricas que se pueden utilizar para medir la pérdida en una regresión, como R-cuadrado, que a veces se conoce como coeficiente de determinación. Esta es la correlación entre x e y elevada al cuadrado. Esto produce un valor entre cero y uno que mide la cantidad de varianza que puede explicar el modelo. En general, cuanto más cercano esté este valor a uno, mejor será la predicción del modelo.

## Exercise Train and evaluate a regression model

En las técnicas de aprendizaje automático supervisado, se entrena un modelo para operar en un conjunto de características y predecir una etiqueta utilizando un conjunto de datos que incluye algunos valores de etiqueta ya conocidos. El proceso de entrenamiento ajusta las características a las etiquetas conocidas para definir una función general que se puede aplicar a nuevas características para las cuales las etiquetas son desconocidas y predecirlas. Puedes pensar en esta función de la siguiente manera, donde y representa la etiqueta que queremos predecir y x representa las características que el modelo utiliza para predecirla.

En este ejercicio aprenderás cómo entrenar y evaluar un modelo de regresión.

Este ejercicio requiere el entorno de aprendizaje de Microsoft Learn para completarse. Puedes acceder al ejercicio desde el siguiente enlace. 

[Exercise - Train and evaluate a regression model](https://learn.microsoft.com/en-us/training/modules/train-evaluate-regression-models/3-exercise-model)

> ### Nota:
> El notebook de esta sección lo puedes encontrar en: [1 Train and Evaluate a Regression Model.ipynb](notebooks%2FC3%2F1%20Train%20and%20Evaluate%20a%20Regression%20Model.ipynb)

## 3 Exercise quiz 1

![24.png](ims%2FC3%2F24.png)

## Discover new regression models

Hemos visto anteriormente cómo ajustar una línea recta a puntos de datos. Sin embargo, la regresión puede ajustar muchos tipos de relaciones, incluyendo aquellas con múltiples factores y aquellas en las que la importancia de un factor depende de otro.

### Experimentando con modelos

Los modelos de regresión a menudo se eligen porque funcionan con muestras de datos pequeñas, son robustos, fáciles de interpretar y existen variedad de ellos.

**Linear regression** es la forma más simple de regresión, sin límite en la cantidad de características utilizadas. La regresión lineal viene en muchas formas, a menudo nombradas por la cantidad de características utilizadas y la forma de la curva que se ajusta.

**Decision trees** adoptan un enfoque paso a paso para predecir una variable. Si pensamos en nuestro ejemplo de bicicletas, el árbol de decisión podría dividir primero los ejemplos entre aquellos que son durante la primavera/verano y el otoño/invierno, y hacer una predicción basada en el día de la semana. Por ejemplo, la primavera/verano - lunes puede tener una tasa de alquiler de bicicletas de 100 por día, mientras que la primavera/verano - martes puede tener una tasa de alquiler de 20 por día.

**Ensemble algorithms** construyen no solo un árbol de decisión, sino una gran cantidad de árboles, lo que permite mejores predicciones en datos más complejos. Los algoritmos de conjunto, como Random Forest, son ampliamente utilizados en el aprendizaje automático y la ciencia debido a sus sólidas capacidades de predicción.

Los científicos de datos a menudo experimentan con el uso de diferentes modelos. En el siguiente ejercicio, experimentaremos con diferentes tipos de modelos para comparar cómo se desempeñan en los mismos datos.

## Exercise Experiment with more powerful regression models

En el `Notebook`, utilizamos modelos de regresión simples para analizar la relación entre las características de un conjunto de datos de alquiler de bicicletas. En este cuaderno, experimentaremos con modelos más complejos para mejorar nuestro rendimiento en la regresión.

En esta lección, experimentarás con modelos de regresión más potentes.

Este ejercicio requiere el entorno de aprendizaje de Microsoft Learn para completarse. Puedes acceder al ejercicio desde el siguiente enlace. 

[Exercise - Experiment with more powerful regression models](https://learn.microsoft.com/en-us/training/modules/train-evaluate-regression-models/5-exercise-powerful-models)

> ### Nota:
> El notebook de esta clase lo puedes encontrar en: [2 Experiment with more powerfil regression models.ipynb](notebooks%2FC3%2F2%20Experiment%20with%20more%20powerfil%20regression%20models.ipynb)

## 3 Exercise quiz 2

![25.png](ims%2FC3%2F25.png)

## Improve models with hyperparameters

Los modelos simples con conjuntos de datos pequeños a menudo pueden ajustarse en un solo paso, mientras que los conjuntos de datos más grandes y los modelos más complejos deben ajustarse mediante el uso repetido del modelo con datos de entrenamiento y comparando la salida con la etiqueta esperada. Si la predicción es lo suficientemente precisa, consideramos que el modelo está entrenado. Si no lo es, ajustamos ligeramente el modelo y repetimos el proceso.

**Los hiperparámetros** son valores que cambian la forma en que se ajusta el modelo durante estas iteraciones. La tasa de aprendizaje, por ejemplo, es un hiperparámetro que establece cuánto se ajusta el modelo en cada ciclo de entrenamiento. Una tasa de aprendizaje alta significa que un modelo se puede entrenar más rápido, pero si es demasiado alta, los ajustes pueden ser tan grandes que el modelo nunca se "ajusta finamente" y no es óptimo.

**Preprocesamiento de datos**

El preprocesamiento se refiere a los cambios que realizas en tus datos antes de pasarlos al modelo. Hemos mencionado anteriormente que el preprocesamiento puede implicar limpiar tu conjunto de datos, lo cual es importante. Sin embargo, el preprocesamiento también puede incluir cambiar el formato de tus datos para que sea más fácil de usar por el modelo. Por ejemplo, los datos descritos como 'rojo', 'naranja', 'amarillo', 'verde limón' y 'verde' pueden funcionar mejor si se convierten en un formato más nativo para las computadoras, como números que indiquen la cantidad de rojo y la cantidad de verde.

**Escala de características**

El paso de preprocesamiento más común es escalar las características para que caigan entre cero y uno. Por ejemplo, el peso de una bicicleta y la distancia que una persona recorre en una bicicleta pueden ser dos números muy diferentes, pero al escalar ambos números entre cero y uno, los modelos pueden aprender de manera más efectiva a partir de los datos.

**Uso de categorías como características**

En el aprendizaje automático, también puedes usar características categóricas como 'bicicleta', 'patineta' o 'automóvil'. Estas características se representan mediante valores de 0 o 1 en vectores one-hot, que son vectores que tienen un 0 o 1 para cada valor posible. Por ejemplo, bicicleta, patineta y automóvil podrían representarse respectivamente como (1,0,0), (0,1,0) y (0,0,1).

## Exercise Optimize and save models

Este ejercicio requiere del entorno de aprendizaje de Microsoft Learn para completarse. Puedes acceder al ejercicio desde el siguiente enlace.

Regresión - Optimizar y guardar modelos
En el cuaderno anterior, utilizamos modelos de regresión complejos para analizar la relación entre las características de un conjunto de datos de alquiler de bicicletas. En este cuaderno, veremos si podemos mejorar aún más el rendimiento de estos modelos.

En este ejercicio, aprenderás cómo optimizar y guardar modelos.

[Exercise - Optimize and save models](https://learn.microsoft.com/en-us/training/modules/train-evaluate-regression-models/7-exercise-optimize-save-models)

> ### Nota:
> Las notas de esta clase están en: [3 Optimize and save models.ipynb](notebooks%2FC3%2F3%20Optimize%20and%20save%20models.ipynb)

## 3 Exercise quiz 3

![26.png](ims%2FC3%2F26.png)

## 3 Knowledge Check

![27.png](ims%2FC3%2F27.png)

![28.png](ims%2FC3%2F28.png)

![29.png](ims%2FC3%2F29.png)

## 3 Test prep

![30.png](ims%2FC3%2F30.png)

![31.png](ims%2FC3%2F31.png)

![32.png](ims%2FC3%2F32.png)

## 3 Lesson summary

![33.png](ims%2FC3%2F33.png)

En esta lección, aprendiste cómo la regresión puede utilizarse para crear un modelo de aprendizaje automático que predice valores numéricos. Luego, utilizaste el framework Scikit-Learn en Python para entrenar y evaluar un modelo de regresión. Si bien Scikit-Learn es un framework popular para escribir código y entrenar modelos de regresión, también puedes crear soluciones de aprendizaje automático para regresión utilizando las herramientas gráficas en Microsoft Azure Machine Learning. Más adelante, aprenderás más sobre el desarrollo sin código de modelos de regresión utilizando el módulo de diseño de Azure Machine Learning para crear un modelo de regresión con Azure Machine Learning.

# 4 Train and Evaluate Classification Models

## INDICE:
- [Lesson introduction](#4-lesson-introduction)
- [What is Classification?](#what-is-classification)
- [Exercise Train and evaluate a classification model](#exercise-train-and-evaluate-a-classification-model)
- [Exercise Quiz 1](#4-exercise-quiz-1)
- [Evaluate classification models](#evaluate-classification-models)
- [Exercise Perform classification with alternative metrics](#exercise-perform-classification-with-alternative-metrics)
- [Exercise Quiz 2](#4-exercise-quiz-2)
- [Create multiclass classification models](#create-multiclass-classification-models)
- [Exercise Train and evaluate multiclass classification models](#exercise-train-and-evaluate-multiclass-classification-models)
- [Exercise Quiz 3](#4-exercise-quiz-3)
- [Knowledge Check](#4-knowledge-check)
- [Lesson summary](#4-lesson-summary)

## 4 Lesson introduction

![1.png](ims%2FC4%2F1.png)

En esta lección, aprenderás cómo entrenar y evaluar modelos de clasificación. La clasificación es una forma de aprendizaje automático en la que entrenas un modelo para predecir a qué categoría o clase pertenece un elemento. Por ejemplo, una clínica de salud podría utilizar datos diagnósticos como la altura, el peso, la presión arterial y el nivel de glucosa en sangre de un paciente para predecir si el paciente tiene diabetes o no. 

![2.png](ims%2FC4%2F2.png)

Los datos categóricos tienen clases distintas en lugar de valores numéricos. Algunos tipos de datos pueden ser tanto numéricos como categóricos. Por ejemplo, el tiempo de una carrera podría ser un tiempo en segundos o podríamos dividir los tiempos en clases de rápido, medio y lento, que son categorías. 

![3.png](ims%2FC4%2F3.png)

Mientras que otros tipos de datos solo pueden ser categóricos, como el tipo de forma, por ejemplo, círculo, triángulo o cuadrado.

![4.png](ims%2FC4%2F4.png)

n esta lección, aprenderás cuándo usar la clasificación y cómo entrenar y evaluar un modelo de clasificación utilizando el framework Scikit-learn. Para aprovechar al máximo esta lección, es útil tener conocimientos básicos de matemáticas y algo de experiencia en programación en Python.

## What is Classification?

![5.png](ims%2FC4%2F5.png)

La clasificación binaria es una clasificación con dos categorías. Por ejemplo, podríamos etiquetar a los pacientes como no diabéticos o diabéticos. La predicción de clase se realiza determinando la probabilidad para cada posible clase como un valor entre 0 (imposible) y 1 (seguro). La probabilidad total para todas las clases es 1, ya que el paciente definitivamente es diabético o no diabético. 

![6.png](ims%2FC4%2F6.png)

Por lo tanto, si la probabilidad predicha de que un paciente sea diabético es 0.3, entonces existe una probabilidad correspondiente de 0.7 de que el paciente sea no diabético. 

![7.png](ims%2FC4%2F7.png)

El valor de umbral, generalmente 0.5, se utiliza para determinar la clase predicha. Por lo tanto, si la clase positiva en este caso, diabética, tiene una probabilidad predicha mayor que el umbral, se predice una clasificación como diabética.

![8.png](ims%2FC4%2F8.png)

La clasificación es un ejemplo de una técnica de aprendizaje automático supervisado, lo que significa que se basa en datos que incluyen valores de características conocidos. Por ejemplo, mediciones de diagnóstico para pacientes, así como valores de etiquetas conocidos, como una clasificación de no diabético o diabético. 

![9.png](ims%2FC4%2F9.png)

Se utiliza un algoritmo de clasificación para ajustar un subconjunto de los datos a una función que puede calcular la probabilidad de cada etiqueta de clase a partir de los valores de características. Los datos restantes se utilizan para evaluar el modelo mediante la comparación de las predicciones que genera a partir de las características con las etiquetas de clase conocidas.

![10.png](ims%2FC4%2F10.png)

Veamos un ejemplo sencillo para ayudar a explicar los principios clave. Supongamos que tenemos los siguientes datos de pacientes, que consisten en una sola característica, el nivel de glucosa en sangre, y una etiqueta de clase de 0 para no diabéticos y 1 para diabéticos. 

![11.png](ims%2FC4%2F11.png)

Usaremos las primeras ocho observaciones para entrenar un modelo de clasificación y comenzaremos trazando la característica de glucosa en sangre, que llamaremos X, y la etiqueta diabética predicha, que llamaremos Y. 

![12.png](ims%2FC4%2F12.png)

Lo que necesitamos es una función que calcule el valor de probabilidad para Y en función de X. En otras palabras, necesitamos la función F de X igual a Y.

![13.png](ims%2FC4%2F13.png)

Parece que cuanto mayor es el nivel de glucosa en sangre, más probable es que un paciente sea diabético, con el punto de inflexión en algún punto entre 100 y 110. 

![14.png](ims%2FC4%2F14.png)

Necesitamos ajustar una función que calcule un valor entre 0 y 1 para Y en función de estos valores. Una de esas funciones es una función logística que forma una curva en forma de sigma, en forma de "S".

![15.png](ims%2FC4%2F15.png)

Ahora podemos utilizar la función para calcular un valor de probabilidad de que Y sea positivo, lo que significa que el paciente es diabético, a partir de cualquier valor de X. Al encontrar el punto en la línea de la función para X, podemos establecer un valor de umbral de 0.5 como punto de corte para la predicción de la etiqueta de clase.
Probemos esto con los valores de datos que hemos retenido. Los puntos trazados por debajo de la línea de umbral darán como resultado una predicción de clase 0, no diabética, y los puntos por encima de la línea se predicen como 1, diabéticos. 

![16.png](ims%2FC4%2F16.png)

Ahora podemos comparar las predicciones de etiquetas basadas en la función logística encapsulada en el modelo Y hat con las etiquetas de clase reales Y. Por lo general, los valores predichos se indican con el símbolo Y hat.

## Exercise Train and evaluate a classification model

La clasificación es una forma de aprendizaje automático supervisado en la que entrenas un modelo para utilizar las características (los valores x en nuestra función) para predecir una etiqueta (y) que calcula la probabilidad de que el caso observado pertenezca a cada una de varias clases posibles y predice una etiqueta apropiada. La forma más simple de clasificación es la clasificación binaria, en la que la etiqueta es 0 o 1, representando una de dos clases; por ejemplo, "Verdadero" o "Falso"; "Interno" o "Externo"; "Rentable" o "No rentable"; y así sucesivamente.

En este ejercicio, entrenarás y evaluarás un modelo de clasificación.

Este ejercicio requiere el uso del entorno de aprendizaje de Microsoft Learn para completarse. Puedes acceder al ejercicio desde el siguiente enlace.

[Exercise - Train and evaluate a classification model](https://learn.microsoft.com/en-us/training/modules/train-evaluate-classification-models/3-exercise-model)

> ### Nota:
> El notebook de esta clase lo puedes encontrar en: [1 Train and Evaluate a CLassification Model.ipynb](notebooks%2FC4%2F1%20Train%20and%20Evaluate%20a%20CLassification%20Model.ipynb)

## 4 Exercise Quiz 1

![17.png](ims%2FC4%2F17.png)

## Evaluate classification models

![18.png](ims%2FC4%2F18.png)

La precisión del entrenamiento de un modelo de clasificación es mucho menos importante que su capacidad para funcionar bien cuando se le proporcionan nuevos datos no vistos previamente. Después de todo, entrenamos modelos para que puedan ser utilizados en datos nuevos que encontramos en el mundo real. Una vez que hemos entrenado un modelo de clasificación, debemos evaluar cómo se desempeña en un conjunto de datos nuevos y no vistos previamente. 

![19.png](ims%2FC4%2F19.png)

En la lección anterior, creamos un modelo que predeciría si un paciente tenía diabetes o no basado en su nivel de glucosa en sangre. Ahora, cuando se aplica a algunos datos que no formaban parte del conjunto de entrenamiento, obtenemos predicciones. Recuerda que X se refiere a los niveles de glucosa en sangre, Y se refiere a si realmente son diabéticos, y Y hat se refiere a la predicción del modelo sobre si son diabéticos o no.

![20.png](ims%2FC4%2F20.png)

Simplemente calcular cuántas predicciones fueron correctas a veces es engañoso o demasiado simplista para comprender el tipo de errores que cometerá en el mundo real. 

![21.png](ims%2FC4%2F21.png)

Para obtener información más detallada, podemos tabular los resultados en una estructura llamada `matriz de confusión`. La matriz de confusión muestra el número total de: 

- casos en los que el modelo predijo cero y la etiqueta real es cero, `verdaderos negativos`; 
- el modelo predijo uno y la etiqueta real es uno, `verdaderos positivos`; 
- el modelo predijo cero y la etiqueta real es uno, `falsos negativos`; 
- el modelo predijo uno y la etiqueta real es cero, `falsos positivos`. 


![22.png](ims%2FC4%2F22.png)

Las celdas en la matriz de confusión suelen estar sombreadas de manera que los valores más altos tienen un tono más oscuro. Esto facilita ver una fuerte tendencia diagonal de arriba a la izquierda a abajo a la derecha, resaltando las celdas donde el valor predicho y el valor real son iguales. 

![23.png](ims%2FC4%2F23.png)

A partir de estos valores principales, puedes calcular una serie de otras métricas que pueden ayudarte a evaluar el rendimiento del modelo. Por ejemplo, 

- Accuracy (exactitud): de todas las predicciones, ¿cuántas fueron correctas? 
- Recall (sensibilidad): de todos los casos que son positivos, ¿cuántos identificó el modelo? 
- Precision (precisión): de todos los casos que el modelo predijo como positivos, ¿cuántos realmente son positivos?

## Exercise Perform classification with alternative metrics

En el último cuaderno, ajustamos un clasificador binario para predecir si los pacientes eran diabéticos o no. Utilizamos la precisión como medida de qué tan bien se desempeñaba el modelo, pero la precisión no lo es todo. En este cuaderno, exploraremos alternativas a la precisión que pueden ser mucho más útiles en el aprendizaje automático.

En este ejercicio, llevarás a cabo la clasificación utilizando métricas alternativas. Este ejercicio requiere el uso del entorno de aprendizaje de Microsoft Learn para completarse. Puedes acceder al ejercicio desde el siguiente enlace.

[Exercise - Perform classification with alternative metrics](https://learn.microsoft.com/en-us/training/modules/train-evaluate-classification-models/5-exercise-alternative-classification-metrics)

> ### Nota:
> El Notebook de esta sección lo puedes encontrar en: [2 Perform classification with alternative metrics.ipynb](notebooks%2FC4%2F2%20Perform%20classification%20with%20alternative%20metrics.ipynb)

## 4 Exercise Quiz 2

![24.png](ims%2FC4%2F24.png)

## Create multiclass classification models

También es posible crear modelos de clasificación multiclase, en los que hay más de dos clases posibles. Por ejemplo, la clínica de salud podría ampliar el modelo de diabetes para clasificar a los pacientes como:

- No diabético
- Diabético tipo 1
- Diabético tipo 2

Los valores individuales de probabilidad de clase seguirían sumando un total de 1, ya que el paciente definitivamente está en una de las tres clases, y el modelo predecirá la clase más probable.

Uso de modelos de clasificación multiclase
La clasificación multiclase se puede pensar como una combinación de múltiples clasificadores binarios. Hay dos formas de abordar el problema:

![25.png](ims%2FC4%2F25.png)

**Uno contra todos (OVR)**, en el que se crea un clasificador para cada valor de clase posible, con un resultado positivo para los casos en los que la predicción es de esta clase y predicciones negativas para los casos en los que la predicción es de cualquier otra clase. Por ejemplo, un problema de clasificación con cuatro posibles clases de formas (cuadrado, círculo, triángulo, hexágono) requeriría cuatro clasificadores que predicen:

- Cuadrado o no
- Círculo o no
- Triángulo o no
- Hexágono o no

**Uno contra uno (OVO)**, en el que se crea un clasificador para cada par posible de clases. El problema de clasificación con cuatro clases de formas requeriría los siguientes clasificadores binarios:

- Cuadrado o círculo
- Cuadrado o triángulo
- Cuadrado o hexágono
- Círculo o triángulo
- Círculo o hexágono
- Triángulo o hexágono

- En ambos enfoques, el modelo general debe tener en cuenta todas estas predicciones para determinar a qué categoría pertenece el elemento.

Afortunadamente, en la mayoría de los marcos de aprendizaje automático, incluido scikit-learn, la implementación de un modelo de clasificación multiclase no es significativamente más compleja que la clasificación binaria, y en la mayoría de los casos, los estimadores utilizados para la clasificación binaria admiten implícitamente la clasificación multiclase mediante la abstracción de un algoritmo OVR, un algoritmo OVO o permitiendo la elección de cualquiera de los dos.

## Exercise Train and evaluate multiclass classification models

En el último cuaderno, exploramos la clasificación binaria. Esto funciona bien cuando las observaciones de los datos pertenecen a una de las dos clases o categorías, como "Verdadero" o "Falso". Cuando los datos se pueden categorizar en más de dos clases, debes utilizar un algoritmo de clasificación multiclase.

En este ejercicio, entrenarás y evaluarás modelos de clasificación multiclase. Este ejercicio requiere el uso del entorno de aprendizaje de Microsoft Learn para completarse. Puedes acceder al ejercicio desde el siguiente enlace.

[Exercise - Train and evaluate multiclass classification models
Completed
100 XP
](https://learn.microsoft.com/en-us/training/modules/train-evaluate-classification-models/7-exercise-multiclass-classification)

> ### Nota:
> El NoteBook de esta clase lo encuentras en: [3 Train and Evaluate Multiclass Classification models.ipynb](notebooks%2FC4%2F3%20Train%20and%20Evaluate%20Multiclass%20Classification%20models.ipynb)

## 4 Exercise Quiz 3

![26.png](ims%2FC4%2F26.png)

## 4 Knowledge Check

![27.png](ims%2FC4%2F27.png)

![28.png](ims%2FC4%2F28.png)

## 4 Lesson summary

![29.png](ims%2FC4%2F29.png)

En esta lección, aprendiste cómo la clasificación se puede utilizar para crear un modelo de aprendizaje automático que predice categorías o clases. Luego, utilizaste el marco de trabajo de Scikit-Learn en Python para entrenar y evaluar un modelo de clasificación. Si bien Scikit-Learn es un marco de trabajo popular para escribir código para entrenar modelos de clasificación, también puedes crear soluciones de aprendizaje automático para la clasificación utilizando las herramientas gráficas en Microsoft Azure Machine Learning. Puedes aprender más sobre el desarrollo sin código de modelos de clasificación utilizando Azure Machine Learning Designer.

# 5 Train and Evaluate Clustering Models

## INDICE:

- [5 Lesson Introduction](#5-lesson-introduction)
- [What is Clustering](#what-is-clustering)
- [Exercise Train and evaluate a clustering model](#exercise-train-and-evaluate-a-clustering-model)
- [5 Exercise Quiz 1](#5-exercise-quiz-1)
- [Evaluate different types of clustering](#evaluate-different-types-of-clustering)
- [Exercise Train and evaluate advanced clustering models](#exercise-train-and-evaluate-advanced-clustering-models)
- [5 Exercise Quiz 2](#5-exercise-quiz-2)
- [5 Knowledge Check](#5-knowledge-check)
- [5 Test prep](#5-test-prep)
- [5 Lesson summary](#5-lesson-summary)

## 5 Lesson Introduction

![1.png](ims%2FC5%2F1.png)


Hola. En esta lección, aprenderás cómo entrenar y evaluar modelos de agrupación (clustering). La agrupación es el proceso de agrupar objetos similares con otros objetos similares. Por ejemplo, imagina un escenario en el que tienes una colección de coordenadas bidimensionales que se han agrupado en tres categorías: amarillo, rojo y azul.

![2.png](ims%2FC5%2F2.png)

Una diferencia importante entre los modelos de agrupación y los modelos de clasificación es que la agrupación es un método no supervisado, donde el entrenamiento se realiza sin etiquetas. En su lugar, los modelos identifican ejemplos que tienen una colección similar de características. Por ejemplo, las imágenes que tienen un color similar se agrupan juntas. 

![3.png](ims%2FC5%2F3.png)

La agrupación es común y útil para explorar nuevos datos donde los patrones entre los puntos de datos, como las categorías de alto nivel, aún no se conocen. Se utiliza en muchos campos que necesitan etiquetar automáticamente datos complejos, incluido el análisis de redes sociales, la conectividad cerebral, la filtración de spam, y más.


## What is Clustering

![4.png](ims%2FC5%2F4.png)

La agrupación es una forma de aprendizaje automático no supervisado en la que las observaciones se agrupan en clústeres en función de las similitudes en sus valores de datos o características. Este tipo de aprendizaje automático se considera no supervisado porque no utiliza valores de etiquetas conocidos previamente para entrenar un modelo.

![5.png](ims%2FC5%2F5.png)

En un modelo de agrupación, la etiqueta es el clúster al que se asigna la observación basada únicamente en sus características. Por ejemplo, supongamos que un botánico observa una muestra de flores y registra el número de pétalos y hojas en cada flor. Puede ser útil agrupar estas flores en clústeres basados en similitudes entre sus características.

![6.png](ims%2FC5%2F6.png)

Hay muchas formas de hacerlo, por ejemplo, si la mayoría de las flores tienen el mismo número de hojas, se podrían agrupar en aquellas con muchos pétalos versus pocas hojas.

![7.png](ims%2FC5%2F7.png)

Alternativamente, si tanto el recuento de pétalos como de hojas varían considerablemente, puede haber un patrón por descubrir, como que aquellas con muchas hojas también tienen muchos pétalos. El objetivo del algoritmo de agrupación es encontrar la forma óptima de dividir el conjunto de datos en grupos. 

![8.png](ims%2FC5%2F8.png)

Lo que significa "óptimo" depende tanto del algoritmo utilizado como del conjunto de datos proporcionado. Aunque este ejemplo de flores puede ser simple para un ser humano lograrlo con solo algunas muestras, a medida que el conjunto de datos crece a miles de muestras o a más de dos características, los algoritmos de agrupación se vuelven muy útiles para dividir rápidamente un conjunto de datos en grupos.

![9.png](ims%2FC5%2F9.png)


## Exercise Train and evaluate a clustering model

A diferencia del aprendizaje automático supervisado, el aprendizaje no supervisado se utiliza cuando no hay una "verdad absoluta" a partir de la cual entrenar y validar las predicciones de etiquetas. La forma más común de aprendizaje no supervisado es la agrupación (clustering), que es similar conceptualmente a la clasificación, excepto que los datos de entrenamiento no incluyen valores conocidos para la etiqueta de clase que se va a predecir.

La agrupación funciona separando los casos de entrenamiento en función de similitudes que se pueden determinar a partir de sus valores de características. En este ejercicio, entrenarás y evaluarás un modelo de agrupación.

Este ejercicio requiere el entorno de aprendizaje de Microsoft Learn para completarse. Puedes acceder al ejercicio desde el siguiente enlace.

[Exercise - Train and evaluate a clustering model](https://learn.microsoft.com/en-us/training/modules/train-evaluate-cluster-models/3-exercise-model)

> ### Nota:
> El notebook de esta clase está en: [1 Train and evaluate a clustering model.ipynb](notebooks%2FC5%2F1%20Train%20and%20evaluate%20a%20clustering%20model.ipynb)


## 5 Exercise Quiz 1

![10.png](ims%2FC5%2F10.png)

##  Evaluate different types of clustering

Existen múltiples algoritmos que puedes usar para la agrupación (clustering). Uno de los algoritmos más comúnmente utilizados es el agrupamiento K-Means, que en su forma más simple consta de los siguientes pasos:

1. Los valores de las características se vectorizan para definir coordenadas n-dimensionales (donde n es el número de características). En el ejemplo de las flores, tenemos dos características (número de pétalos y número de hojas), por lo que el vector de características tiene dos coordenadas que podemos usar para conceptualmente representar los puntos de datos en un espacio bidimensional.

2. Decides cuántos clústeres deseas usar para agrupar las flores y le asignas a este valor el nombre de "k". Por ejemplo, para crear tres clústeres, usarías un valor de "k" de 3. Luego, se colocan k puntos en coordenadas aleatorias. Estos puntos serán finalmente los puntos centrales de cada clúster, por lo que se les llama centroides.

3. Cada punto de datos (en este caso, una flor) se asigna al centroide más cercano.

4. Cada centroide se mueve al centro de los puntos de datos asignados a él, en función de la distancia media entre los puntos.

5. Después de mover el centroide, los puntos de datos pueden estar más cerca de un centroide diferente, por lo que los puntos de datos se vuelven a asignar a clústeres en función del nuevo centroide más cercano.

6. Los pasos de movimiento de centroides y reasignación de clústeres se repiten hasta que los clústeres se vuelven estables o se alcanza un número máximo predefinido de iteraciones.

La siguiente animación muestra este proceso:

![11.gif](ims%2FC5%2F11.gif)

### Hierarchical Clustering

El agrupamiento jerárquico es otro tipo de algoritmo de agrupamiento en el cual los clústeres mismos pertenecen a un grupo más grande, que a su vez pertenece a grupos aún más grandes, y así sucesivamente. El resultado es que los puntos de datos pueden agruparse en diferentes grados de precisión: con un gran número de grupos muy pequeños y precisos, o un pequeño número de grupos más grandes.

Por ejemplo, si aplicamos el agrupamiento a los significados de las palabras, podríamos obtener un grupo que contiene adjetivos específicos de las emociones ('enojado', 'feliz', y así sucesivamente), que a su vez pertenece a un grupo que contiene todos los adjetivos relacionados con los humanos ('feliz', 'guapo', 'joven'), y esto pertenece a un grupo aún más alto que contiene todos los adjetivos ('feliz', 'verde', 'guapo').

![12.png](ims%2FC5%2F12.png)

El agrupamiento jerárquico es útil no solo para dividir los datos en grupos, sino también para comprender las relaciones entre estos grupos. Una ventaja importante del agrupamiento jerárquico es que no requiere que se defina de antemano el número de clústeres y a veces puede proporcionar resultados más interpretables que enfoques no jerárquicos.

La principal desventaja es que estos enfoques pueden llevar mucho más tiempo en el cálculo que enfoques más simples y a veces no son adecuados para conjuntos de datos grandes.

## Exercise Train and evaluate advanced clustering models

En el último cuaderno, aprendimos que los datos se pueden dividir en clústeres y cómo determinar si los datos pueden ser compatibles con dicho análisis. En este cuaderno, realizaremos esta agrupación de forma automática.

En este ejercicio, entrenarás y evaluarás modelos de agrupación avanzados. Este ejercicio requiere el entorno de aprendizaje de Microsoft Learn para completarse. Puedes acceder al ejercicio desde el siguiente enlace.

[Exercise - Train and evaluate advanced clustering models](https://learn.microsoft.com/en-us/training/modules/train-evaluate-cluster-models/5-exercise-new-models)

> ### Nota:
> El notebook de esta clase está en: [2 Train and evaluate advanced clustering models.ipynb](notebooks%2FC5%2F2%20Train%20and%20evaluate%20advanced%20clustering%20models.ipynb)

## 5 Exercise Quiz 2

![13.png](ims%2FC5%2F13.png)

## 5 Knowledge Check

![14.png](ims%2FC5%2F14.png)

![15.png](ims%2FC5%2F15.png)

![16.png](ims%2FC5%2F16.png)

## 5 Test prep

![17.png](ims%2FC5%2F17.png)

![18.png](ims%2FC5%2F18.png)

![19.png](ims%2FC5%2F19.png)

![20.png](ims%2FC5%2F20.png)

## 5 Lesson summary

![21.png](ims%2FC5%2F21.png)


En esta lección, aprendiste cómo la agrupación puede utilizarse para crear modelos de aprendizaje automático no supervisados que agrupan observaciones de datos en clústeres. Luego, utilizaste el framework Scikit-learn en Python para entrenar un modelo de agrupación. Si bien Scikit-learn es un framework popular para escribir código y entrenar modelos de agrupación, también puedes crear soluciones de aprendizaje automático para la agrupación utilizando las herramientas gráficas en Microsoft Azure Machine Learning. Puedes obtener más información sobre el desarrollo de modelos de agrupación sin código con Azure Machine Learning Designer.

# 6 Train a Deep Neural Network

## INDICE:

- [6 Lesson Introduction](#6-lesson-introduction)
- [Deep Neural Network Concepts](#deep-neural-network-concepts)
- [Exercise Train a Deep Neural Network](#exercise-train-a-deep-neural-network)
- [6 Exercise Quiz 1](#6-exercise-quiz-1)
- [6 Knowledge Check](#6-knowledge-check)
- [6 Lesson Summary](#6-lesson-summary)

## 6 Lesson Introduction

![1.png](ims%2FC6%2F1.png)

En esta lección, aprenderás cómo entrenar y evaluar modelos de aprendizaje profundo. El aprendizaje profundo es una forma avanzada de aprendizaje automático que trata de emular la forma en que el cerebro humano aprende. En nuestro cerebro, tenemos células nerviosas llamadas neuronas que están conectadas entre sí por extensiones nerviosas que transmiten señales eléctricas y químicas a través de la red. 

![2.png](ims%2FC6%2F2.png)

Cuando se estimula la primera neurona en la red, la señal de entrada se procesa. Si supera un umbral específico, la neurona se activa y transmite una señal a las neuronas a las que está conectada. Estas neuronas, a su vez, pueden activarse y transmitir la señal al resto de la red. Con el tiempo, las conexiones entre las neuronas se fortalecen mediante el uso frecuente a medida que aprendemos a responder de manera efectiva.

![3.png](ims%2FC6%2F3.png)

Por ejemplo, si alguien te lanza una pelota, las conexiones neuronales te permiten procesar la información visual y coordinar tus movimientos para atrapar la pelota. Si repites esta acción varias veces, la red de neuronas involucradas en atrapar una pelota se fortalecerá a medida que aprendas a hacerlo mejor.

![4.png](ims%2FC6%2F4.png)

El aprendizaje profundo emula este proceso biológico utilizando redes neuronales artificiales que procesan entradas numéricas en lugar de estímulos electroquímicos. Las conexiones nerviosas entrantes son reemplazadas por entradas numéricas que generalmente se identifican como X. Cuando hay más de un valor de entrada, X se considera un vector con elementos nombrados X1, X2, y así sucesivamente. Asociado a cada valor X hay un peso W que se utiliza para fortalecer o debilitar el efecto del valor X para simular el aprendizaje. Además, se agrega una entrada de sesgo, b, para permitir un control detallado sobre la red. 

![5.png](ims%2FC6%2F5.png)

Durante el proceso de entrenamiento, los valores de W y b se ajustarán para afinar la red de manera que aprenda a producir salidas correctas. La neurona en sí encapsula una función que calcula una suma ponderada de X, W y b. Esta función, a su vez, está encerrada en una función de activación que limita el resultado, a menudo a un valor entre cero y uno, para determinar si la neurona pasa una salida a la siguiente capa de neuronas en la red.

## Deep Neural Network Concepts

![6.png](ims%2FC6%2F6.png)

El aprendizaje automático se preocupa por predecir una etiqueta basada en algunas características de una observación en particular. En términos simples, un modelo de aprendizaje automático es una función que calcula y, la etiqueta, a partir de x, las características, es decir, f de x es igual a y. 

![7.png](ims%2FC6%2F7.png)

Por ejemplo, supongamos que tu observación consiste en algunas mediciones de un pingüino, como la longitud del pico del pingüino, la profundidad del pico, la longitud de la aleta y el peso del pingüino. 

![8.png](ims%2FC6%2F8.png)

En este caso, las características x son un vector de cuatro valores, o matemáticamente, x es igual a x_1, x_2, x_3, x_4.

![9.png](ims%2FC6%2F9.png)

Supongamos que la etiqueta que intentamos predecir, y, es la especie del pingüino y que hay tres posibles especies: 0 para Adelie, 1 para Gentoo o 2 para Chinstrap. 
![10.png](ims%2FC6%2F10.png)

Esto es un ejemplo de un problema de clasificación en el que el modelo de aprendizaje automático debe predecir la clase a la que pertenece la observación. Un modelo de clasificación logra esto al predecir una etiqueta que consiste en la probabilidad para cada clase. En otras palabras, y es un vector de tres valores de probabilidad, uno para cada una de las posibles clases. Y es igual a P(0), P(1), P(2).

![11.png](ims%2FC6%2F11.png)

El proceso de entrenamiento para una red neuronal profunda (DNN) implica múltiples iteraciones llamadas épocas. Comenzamos asignando valores de inicialización aleatoria para los pesos (w) y sesgos (b). Luego, presentamos observaciones de datos para las cuales ya conocemos la etiqueta verdadera. Por ejemplo, podríamos tener mediciones de características para una muestra de Adelie, x es igual a 37.3, 16.8, 19.2 y 30.0, y ya sabemos que esto es un ejemplo de la clase Adelie (0).

![12.png](ims%2FC6%2F12.png)

 Una función de clasificación perfecta debería resultar en una etiqueta que indique una probabilidad del 100 por ciento para la clase 0 y una probabilidad nula para las clases 1 y 2. En este caso, y es igual a 1, 0 y 0.

![13.png](ims%2FC6%2F13.png)

¿Cómo usaríamos el aprendizaje profundo para construir un modelo de clasificación para la clasificación de pingüinos? Echemos un vistazo a un ejemplo. El modelo de red neuronal profunda para el clasificador consta de múltiples capas de neuronas artificiales. 

![14.png](ims%2FC6%2F14.png)

En este caso, hay cuatro capas. Una capa de entrada con una neurona para cada valor de entrada esperado o x. Dos llamadas capas ocultas, cada una con cinco neuronas. Una capa de salida con tres neuronas, una para cada valor de probabilidad de clase o y que se debe predecir mediante el modelo. 

![15.png](ims%2FC6%2F15.png)

Debido a la arquitectura en capas de la red, este tipo de modelo a veces se denomina perceptrón multicapa. Además, todas las neuronas en las capas de entrada y ocultas están conectadas a todas las neuronas en las capas siguientes. Esto es un ejemplo de una red completamente conectada.

![16.png](ims%2FC6%2F16.png)

Cuando creas un modelo como este, debes definir una capa de entrada que admita la cantidad de características que tu modelo procesará y una capa de salida que refleje la cantidad de salidas que esperas que produzca. Puedes decidir cuántas capas ocultas deseas incluir y cuántas neuronas hay en cada una de ellas. Pero no tienes control sobre los valores de entrada y salida para estas capas, ya que son determinados por el proceso de entrenamiento del modelo.

![17.png](ims%2FC6%2F17.png)

El proceso de entrenamiento de una red neuronal profunda consiste en múltiples iteraciones llamadas épocas. Para la primera época, comienzas asignando valores de inicialización aleatoria para los pesos (w) y sesgos (b). Luego, el proceso es el siguiente: las características de las observaciones de datos con etiquetas conocidas se presentan en la capa de entrada. 

![18.png](ims%2FC6%2F18.png)

Generalmente, estas observaciones se agrupan en lotes, a menudo llamados mini-lotes. Las neuronas luego aplican su función y, si se activan, pasan el resultado a la siguiente capa hasta que la capa de salida produzca una predicción. 

![19.png](ims%2FC6%2F19.png)

La predicción se compara con el valor real conocido, y la cantidad de variación entre los valores predichos y reales, a lo que llamamos pérdida, se calcula. 

![20.png](ims%2FC6%2F20.png)

Basándose en los resultados, se calculan valores revisados para los pesos y sesgos para reducir la pérdida, y estos ajustes se retropropagan a las neuronas en las capas de la red. La siguiente época repite el proceso de entrenamiento hacia adelante con lotes revisados de pesos y valores de sesgo, con la esperanza de mejorar la precisión del modelo al reducir la pérdida.

![21.png](ims%2FC6%2F21.png)

Es importante destacar que procesar las características de entrenamiento como un lote mejora la eficiencia del proceso de entrenamiento al procesar múltiples observaciones simultáneamente como una matriz de características con vectores de pesos y sesgos.

![23.png](ims%2FC6%2F23.png)

Las funciones algebraicas lineales que operan con matrices y vectores también se utilizan en el procesamiento gráfico 3D, por lo que las computadoras con unidades de procesamiento gráfico (GPU) ofrecen un rendimiento significativamente mejor para el entrenamiento de modelos de aprendizaje profundo que las computadoras con unidades de procesamiento central (CPU) solamente.

![24.png](ims%2FC6%2F24.png)

Echemos un vistazo más de cerca a las funciones de pérdida y retropropagación. La descripción anterior del proceso de entrenamiento de aprendizaje profundo mencionó que se calcula la pérdida del modelo y se utiliza para ajustar los valores de peso y sesgo. ¿Cómo funciona exactamente esto? 

![25.png](ims%2FC6%2F25.png)

Supongamos que una de las muestras que pasó por el proceso de entrenamiento contiene características de un espécimen de Adelie, clase 0. La salida correcta de la red sería 1, 0 y 0. Ahora supongamos que la salida producida por la red es 0.4, 0.3 y 0.3. Comparando estos valores, podemos calcular una variación absoluta para cada elemento. 

![26.png](ims%2FC6%2F26.png)

En otras palabras, ¿qué tan lejos está cada valor predicho de lo que debería ser, que es 0.6, 0.3 y 0.3? En realidad, dado que estamos tratando con múltiples observaciones, generalmente agregamos la variación. Por ejemplo, al elevar al cuadrado los valores individuales de variación y calcular la media, obtenemos un único valor promedio de pérdida, como 0.18.

![27.png](ims%2FC6%2F27.png)

Ahora, aquí está la parte inteligente. La pérdida se calcula utilizando una función que opera en los resultados de la capa final de la red, que también es una función. En efecto, todo el modelo, desde la capa de entrada hasta el cálculo de la pérdida, es una gran función anidada. Las funciones tienen algunas características realmente útiles. 

![28.png](ims%2FC6%2F28.png)

Puedes conceptualizar una función como una línea trazada que compara su salida con cada uno de sus variables. Puedes usar el cálculo diferencial para calcular la derivada de la función en cualquier punto con respecto a sus variables. Tomemos la primera de estas capacidades. 

![29.png](ims%2FC6%2F29.png)

Podemos trazar la línea de la función para mostrar cómo un valor de peso individual se compara con la pérdida y marcar en esa línea el punto donde el valor de peso actual coincide con el valor de pérdida actual. Ahora, apliquemos la segunda característica de una función. La derivada de una función en un punto dado indica si la pendiente o gradiente de la salida de la función, en este caso, la pérdida, está aumentando o disminuyendo con respecto a una variable de la función, en este caso, el valor del peso. 

![30.png](ims%2FC6%2F30.png)

Una derivada positiva indica que la función está aumentando, y una derivada negativa indica que está disminuyendo. En este caso, en el punto trazado para el valor actual del peso, la función tiene un gradiente descendente. En otras palabras, aumentar el peso tendrá el efecto de disminuir la pérdida. 

![31.png](ims%2FC6%2F31.png)

Usamos un optimizador para aplicar el mismo truco a todos los valores de peso y sesgo en el modelo y determinar en qué dirección debemos ajustarlos, hacia arriba o hacia abajo, para reducir la cantidad total de pérdida en el modelo. Existen múltiples algoritmos de optimización comúnmente utilizados, incluido el descenso de gradiente estocástico, la tasa de aprendizaje adaptativa, la estimación de momento adaptativo y otros. Todos están diseñados para averiguar cómo ajustar los pesos y sesgos para minimizar la pérdida.

![32.png](ims%2FC6%2F32.png)

Ahora, la siguiente pregunta obvia es ¿en qué medida debería el optimizador ajustar los valores de peso y sesgo? Si observas la gráfica para nuestro valor de peso, puedes ver que aumentar el peso en una pequeña cantidad seguirá la línea de la función hacia abajo, reduciendo la pérdida. Pero si lo aumentamos demasiado, la línea de la función comienza a subir de nuevo. 

![33.png](ims%2FC6%2F33.png)

Podríamos aumentar realmente la pérdida, y después de la próxima época, podríamos descubrir que necesitamos reducir el peso. El tamaño del ajuste está controlado por un parámetro que defines para el entrenamiento llamado tasa de aprendizaje. 

![34.png](ims%2FC6%2F34.png)

Una tasa de aprendizaje baja resulta en ajustes pequeños, por lo que puede llevar más épocas minimizar la pérdida. Mientras que una tasa de aprendizaje alta resulta en ajustes grandes, por lo que podrías pasar por alto el mínimo por completo.

## Exercise Train a Deep Neural Network

Hasta ahora, en este módulo, has aprendido mucho sobre la teoría y los principios del aprendizaje profundo con redes neuronales. La mejor manera de aprender cómo aplicar esta teoría es construir realmente un modelo de aprendizaje profundo, y eso es lo que harás en este ejercicio.

Hay muchos marcos disponibles para entrenar redes neuronales profundas, y en este ejercicio, puedes elegir explorar uno o ambos de los dos marcos de aprendizaje profundo más populares para Python: PyTorch y TensorFlow.

### Antes de comenzar

Para completar el ejercicio, necesitarás:

- Una suscripción a Microsoft Azure. Si aún no tienes una, puedes registrarte para una prueba gratuita en https://azure.microsoft.com/free.
- Un espacio de trabajo de Azure Machine Learning con una instancia de cálculo y el repositorio ml-basics clonado.

> Nota: Este módulo utiliza un espacio de trabajo de Azure Machine Learning. Si estás completando este módulo en preparación para la certificación de Azure Data Scientist, considera crear el espacio de trabajo una vez y reutilízalo en otros módulos. Después de completar el ejercicio, asegúrate de seguir las instrucciones para limpiar los recursos de cálculo y conserva el espacio de trabajo si planeas reutilizarlo.

### Crear un espacio de trabajo de Azure Machine Learning

- Si aún no tienes un espacio de trabajo de Azure Machine Learning en tu suscripción de Azure, sigue estos pasos para crear uno:

- Inicia sesión en el [portal de Azure](https://portal.azure.com/#home) utilizando la cuenta de Microsoft asociada con tu suscripción de Azure.

- Selecciona "+ Crear un recurso", busca "Machine Learning" y crea un nuevo recurso de Machine Learning con la siguiente configuración:

  - **Nombre del espacio de trabajo:** introduce un nombre único de tu elección
  - **Suscripción:** tu suscripción de Azure
  - **Grupo de recursos:** crea un nuevo grupo de recursos con un nombre único
  - **Ubicación:** elige cualquier ubicación disponible

- Espera a que se cree tu recurso de espacio de trabajo (puede tomar unos minutos). Luego, ve a él en el portal y en la página de Información general de tu espacio de trabajo, inicia Azure Machine Learning Studio (o ve a https://ml.azure.com) e inicia sesión con tu cuenta de Microsoft.

- En Azure Machine Learning Studio, cambia al icono ☰ en la parte superior izquierda para ver las diferentes páginas de la interfaz. Puedes usar estas páginas para gestionar los recursos en tu espacio de trabajo.

### Crear una instancia de cálculo

Para ejecutar el cuaderno utilizado en este ejercicio, necesitarás una instancia de cálculo en tu espacio de trabajo de Azure Machine Learning.

- En [Azure Machine Learning Studio](https://ml.azure.com/home?tid=54f76ea3-fed9-41fc-a628-e91383900a39), ve a la página de Cálculo para tu espacio de trabajo (en Administrar).

- En la pestaña Instancias de cálculo, si ya tienes una instancia de cálculo, iníciala; de lo contrario, crea una nueva instancia de cálculo con la siguiente configuración:

  - **Tipo de máquina virtual:** CPU
  - **Tamaño de máquina virtual:** Standard_DS11_v2
  - **Nombre de cálculo:** introduce un nombre único

- Espera a que la instancia de cálculo se inicie (esto puede llevar un minuto aproximadamente).

### Clonar el repositorio ml-basics

Los archivos utilizados en este módulo (y otros módulos relacionados) se publican en el repositorio de GitHub de MicrosoftDocs/ml-basics. Si aún no lo has hecho, sigue estos pasos para clonar el repositorio en tu espacio de trabajo de Azure Machine Learning:

- En [Azure Machine Learning Studio](https://ml.azure.com/home?tid=54f76ea3-fed9-41fc-a628-e91383900a39), en la página de Cálculo, ve a tu instancia de cálculo en ejecución.

- Utiliza el enlace de Jupyter para abrir Jupyter Notebooks en una nueva pestaña del navegador.

- En la página de Jupyter, en el menú Nuevo, selecciona Terminal. Esto abrirá una nueva pestaña con una terminal.

- En la terminal, ejecuta los siguientes comandos para cambiar el directorio actual al directorio Users y clonar el repositorio ml-basics, que contiene el cuaderno y los archivos que utilizarás en este ejercicio:

```bash
cd Users
git clone https://github.com/microsoftdocs/ml-basics
```

- Después de que el comando haya finalizado y se haya completado la descarga de los archivos, cierra la pestaña de la terminal y ve a la página de inicio en tu explorador de archivos de Jupyter. Luego, abre la carpeta Users; debería contener una carpeta ml-basics con los archivos que utilizarás en este módulo.

> Nota: Recomendamos encarecidamente utilizar Jupyter en un espacio de trabajo de Azure Machine Learning para este ejercicio. Esta configuración asegura que se instale la versión correcta de Python y los diversos paquetes que necesitarás; y después de crear el espacio de trabajo una vez, puedes reutilizarlo en otros módulos. Si prefieres completar el ejercicio en un entorno de Python en tu propia computadora, puedes hacerlo. Encontrarás detalles para configurar un entorno de desarrollo local que utiliza Visual Studio Code en Ejecutar los laboratorios en tu propia computadora. Ten en cuenta que si eliges hacer esto, las instrucciones en el ejercicio pueden no coincidir con la interfaz de tu cuaderno.

### Entrenar un modelo de red neuronal profunda

Después de haber creado un entorno Jupyter y clonado el repositorio ml-basics, estás listo para explorar el aprendizaje profundo.

- En Jupyter, en la carpeta ml-basics, abre el cuaderno Deep Neural Networks (PyTorch).ipynb o Deep Neural Networks (Tensorflow).ipynb, según tu preferencia de framework, y sigue las instrucciones que contiene.

- Cuando hayas terminado, cierra y detén todos los cuadernos.

Cuando hayas terminado de trabajar en el cuaderno, vuelve a este módulo y continúa con la siguiente unidad para aprender más.

> ### Nota:
> El Notebook resulto está en: [1 Train a Deep Neural Network.ipynb](notebooks%2FC6%2F1%20Train%20a%20Deep%20Neural%20Network.ipynb)


## 6 Exercise Quiz 1

![35.png](ims%2FC6%2F35.png)

## 6 Knowledge Check

![36.png](ims%2FC6%2F36.png)

![37.png](ims%2FC6%2F37.png)

## 6 Lesson Summary

![38.png](ims%2FC6%2F38.png)

En esta lección, ha aprendido sobre los principios fundamentales del aprendizaje profundo y cómo crear modelos de redes neuronales profundas utilizando PyTorch o TensorFlow. También ha explorado el uso de redes neuronales convolucionales para crear modelos de clasificación de imágenes. Las técnicas de aprendizaje profundo están en la vanguardia del aprendizaje automático y la inteligencia artificial y se utilizan para implementar soluciones empresariales.

# 7 Train a Convolutional Neural Network

## INDICE:

- [7 Lesson Introduction](#7-lesson-introduction)
- [Layers in a Convolutional Neural Network](#layers-in-a-convolutional-neural-network)
- [Exercise Train a Convolutional Neural Network](#exercise-train-a-convolutional-neural-network)
- [7 Exercise Quiz 1](#7-exercise-quiz-1)
- [Transfer Learning](#transfer-learning)
- [Exercise Use Transfer Learning](#exercise-use-transfer-learning)
- [7 Exercise Quiz 2](#7-exercise-quiz-2)
- [7 Knowledge Check](#7-knowledge-check)
- [7 Test Prep](#7-test-prep)
- [7 Lesson summary](#7-lesson-summary)

## 7 Lesson Introduction

## Layers in a Convolutional Neural Network

## Exercise Train a Convolutional Neural Network

## 7 Exercise Quiz 1

## Transfer Learning

## Exercise Use Transfer Learning

## 7 Exercise Quiz 2

## 7 Knowledge Check

## 7 Test Prep

## Lesson summary

# 8 Course Wrap-Up

## INDICE:

- [Course Wrap Up](#course-wrap-up)
- [New Discussion Prompt](#new-discussion-prompt)
- [What to expect next](#what-to-expect-next)

## Course Wrap Up

## New Discussion Prompt

## What to expect next